{"title": "Enhancing Drug-Drug Interaction Extraction from Texts by Molecular Structure Information", "abstract": "We propose a novel neural method to extract drug-drug interactions (DDIs) from texts using external drug molecular structure information. We encode textual drug pairs with convolutional neural networks and their molecular pairs with graph convolutional networks (GCNs), and then we concatenate the outputs of these two networks. In the experiments, we show that GCNs can predict DDIs from the molecular structures of drugs in high accuracy and the molecular information can enhance text-based DDI extraction by 2.39 percent points in the F-score on the DDIExtraction 2013 shared task data set.", "text": [{"id": 0, "string": "Introduction When drugs are concomitantly administered to a patient, the effects of the drugs may be enhanced or weakened, which may also cause side effects."}, {"id": 1, "string": "These kinds of interactions are called Drug-Drug Interactions (DDIs)."}, {"id": 2, "string": "Several drug databases have been maintained to summarize drug and DDI information such as DrugBank (Law et al., 2014) , Therapeutic Target database , and PharmGKB (Thorn et al., 2013) ."}, {"id": 3, "string": "Automatic DDI extraction from texts is expected to support the maintenance of databases with high coverage and quick update to help medical experts."}, {"id": 4, "string": "Deep neural network-based methods have recently drawn a considerable attention (Liu et al., 2016; Sahu and Anand, 2017; Zheng et al., 2017; Lim et al., 2018) since they show state-of-the-art performance without manual feature engineering."}, {"id": 5, "string": "In parallel to the progress in DDI extraction from texts, Graph Convolutional Networks (GCNs) have been proposed and applied to estimate physical and chemical properties of molec-ular graphs such as solubility and toxicity (Duvenaud et al., 2015; Gilmer et al., 2017) ."}, {"id": 6, "string": "In this study, we propose a novel method to utilize both textual and molecular information for DDI extraction from texts."}, {"id": 7, "string": "We illustrate the overview of the proposed model in Figure 1 ."}, {"id": 8, "string": "We obtain the representations of drug pairs in molecular graph structures using GCNs and concatenate the representations with the representations of the textual mention pairs obtained by convolutional neural networks (CNNs)."}, {"id": 9, "string": "We trained the molecule-based model using interacting pairs mentioned in the DrugBank database and then trained the entire model using the labeled pairs in the text data set of the DDIExtraction 2013 shared task (SemEval-2013 Task 9) (Segura ."}, {"id": 10, "string": "In the experiment, we show GCNs can predict DDIs from molecular graphs in a high accuracy."}, {"id": 11, "string": "We also show molecular information can enhance the performance of DDI extraction from texts in 2.39 percent points in F-score."}, {"id": 12, "string": "The contribution of this paper is three-fold: \u2022 We propose a novel neural method to extract DDIs from texts with the related molecular structure information."}, {"id": 13, "string": "\u2022 We apply GCNs to pairwise drug molecules for the first time and show GCNs can predict DDIs between drug molecular structures in a high accuracy."}, {"id": 14, "string": "\u2022 We show the molecular information is useful in extracting DDIs from texts."}, {"id": 15, "string": "Methods Text-based DDI Extraction Our model for extracting DDIs from texts is based on the CNN model by Zeng et al."}, {"id": 16, "string": "(2014) ."}, {"id": 17, "string": "When an input sentence S = (w 1 , w 2 , \u00b7 \u00b7 \u00b7 , w N ) is given, We prepare word embedding w w i of w i and word Figure 1 : Overview of the proposed model position embeddings w p i,1 and w p i,2 that correspond to the relative positions from the first and second target entities, respectively."}, {"id": 18, "string": "We concatenate these embeddings as in Equation (1) , and we use the resulting vector as the input to the subsequent convolution layer: w i = [w w i ; w p i,1 ; w p i,2 ], (1) where [; ] denotes the concatenation."}, {"id": 19, "string": "We calculate the expression for each filter j with the window size k l ."}, {"id": 20, "string": "z i,l = [w i\u2212(k l \u22121)/2 , \u00b7 \u00b7 \u00b7 , w i\u2212(k l +1)/2 ], (2) m i,j,l = relu(W conv j z i,l + b conv ), (3) m j,l = max i m i,j,l , (4) where L is the number of windows, W conv j and b conv are the weight and bias of CNN, and max indicates max pooling (Boureau et al., 2010) ."}, {"id": 21, "string": "We convert the output of the convolution layer into a fixed-size vector that represents a textual pair as follows: m l = [m 1,l , \u00b7 \u00b7 \u00b7 , m J,l ], (5) h t = [m 1 ; ."}, {"id": 22, "string": "."}, {"id": 23, "string": "."}, {"id": 24, "string": "; m L ], (6) where J is the number of filters."}, {"id": 25, "string": "We get a prediction\u0177 t by the following fully connected neural networks: h (1) t = relu(W (1) t h t + b (1) t ), (7) y t = softmax(W (2) t h (1) t + b (2) t ), (8) where W (1) t and W (2) t are weights and b (1) t and b (2) t are bias terms."}, {"id": 26, "string": "Molecular Structure-based DDI Classification We represent drug pairs in molecular graph structures using two GCN methods: CNNs for fingerprints (NFP) (Duvenaud et al., 2015) and Gated Graph Neural Networks (GGNN) ."}, {"id": 27, "string": "They both convert a drug molecule graph G into a fixed size vector h g by aggregating the representation h T v of an atom node v in G. We represent atoms as nodes and bonds as edges in the graph."}, {"id": 28, "string": "NFP first obtains the representation h t v by the following equations (Duvenaud et al., 2015) ."}, {"id": 29, "string": "m t+1 v = h t v + w\u2208N (v) h t w , (9) h t+1 v = \u03c3(H deg(v) t m t+1 v ), (10) where h t v is the representation of v in the t-th step, N (v) is the neighbors of v, and H deg(v) t is a weight parameter."}, {"id": 30, "string": "h 0 v is initialized by the atom features of v. deg(v) is the degree of a node v and \u03c3 is a sigmoid function."}, {"id": 31, "string": "NFP then acquires the representation of the graph structure h g = v,t softmax(W t h t v ), (11) where W t is a weight matrix."}, {"id": 32, "string": "GGNN first obtains the representation h t v by using Gated Recurrent Unit (GRU)-based recurrent neural networks  as follows: m t+1 v = w\u2208N (v) A evw h t w (12) h t+1 v = GRU([h t v ; m t+1 v ]), (13) where A evw is a weight for the bond type of each edge e vw ."}, {"id": 33, "string": "GGNN then acquires the representation of the graph structure."}, {"id": 34, "string": "h g = v \u03c3(i([h T v ; h 0 v ])) (j(h T v )), (14) where i and j are linear layers and is the element-wise product."}, {"id": 35, "string": "We obtain the representation of a molecular pair by concatenating the molecular graph representations of drugs g 1 and g 2 , i.e., h m = [h g 1 ; h g 2 ]."}, {"id": 36, "string": "We get a prediction\u0177 m as follows: h (1) m = relu(W (1) m h m + b (1) m ), (15) y m = softmax(W (2) m h (1) m + b (2) m ), (16) where W (1) m and W (2) m are weights and b (1) m and b (2) m are bias terms."}, {"id": 37, "string": "DDI Extraction from Texts Using Molecular Structures We realize the simultaneous use of textual and molecular information by concatenating a textbased and molecule-based vectors: h all = [h t ; h m ]."}, {"id": 38, "string": "We normalize molecule-based vectors."}, {"id": 39, "string": "We then use h all instead of h t in Equation 7 ."}, {"id": 40, "string": "In training, we first train the molecular-based DDI classification model."}, {"id": 41, "string": "The molecular-based classification is performed by minimizing the loss function L m = \u2212 y m log\u0177 m ."}, {"id": 42, "string": "We then fix the parameters for GCNs and train text-based DDI extraction model by minimizing the loss function L t = \u2212 y t log\u0177 t ."}, {"id": 43, "string": "Experimental Settings In this section, we explain the textual and molecular data and task settings and training settings."}, {"id": 44, "string": "Text Corpus and Task Setting We followed the task setting of Task 9.2 in the DDIExtraction 2013 shared task  for the evaluation."}, {"id": 45, "string": "This data set is composed of documents annotated with drug mentions and their four types of interactions: Mechanism, Effect, Advice and Int."}, {"id": 46, "string": "For the data statistics, please refer to the supplementary materials."}, {"id": 47, "string": "The task is a multi-class classification task, i.e., to classify a given pair of drugs into the four interaction types or no interaction."}, {"id": 48, "string": "We evaluated the performance with micro-averaged precision (P), Figure 2 : Associating DrugBank entries with texts and molecular graph structures recall (R), and F-score (F) on all the interaction types."}, {"id": 49, "string": "We used the official evaluation script provided by the task organizers."}, {"id": 50, "string": "As preprocessing, we split sentences into words using the GENIA tagger (Tsuruoka et al., 2005) ."}, {"id": 51, "string": "We replaced the drug mentions of the target pair with DRUG1 and DRUG2 according to their order of appearance."}, {"id": 52, "string": "We also replaced other drug mentions with DRUGOTHER."}, {"id": 53, "string": "We did not employ negative instance filtering unlike other existing methods, e.g., Liu et al."}, {"id": 54, "string": "(2016) , since our focus is to evaluate the effect of the molecular information on texts."}, {"id": 55, "string": "We linked mentions in texts to DrugBank entries by string matching."}, {"id": 56, "string": "We lowercased the mentions and the names in the entries and chose the entries with the most overlaps."}, {"id": 57, "string": "As a result, 92.15% and 93.09% of drug mentions in train and test data set matched the DrugBank entries."}, {"id": 58, "string": "Data and Task for Molecular Structures We extracted 255,229 interacting (positive) pairs from DrugBank."}, {"id": 59, "string": "We note that, unlike text-based interactions, DrugBank only contains the information of interacting pairs; there are no detailed labels and no information for non-interacting (negative) pairs."}, {"id": 60, "string": "We thus generated the same number of pseudo negative pairs by randomly pairing drugs and removing those in positive pairs."}, {"id": 61, "string": "To avoid overestimation of the performance, we also deleted drug pairs mentioned in the test set of the text corpus."}, {"id": 62, "string": "We split positive and negative pairs into 4:1 for training and test data, and we evaluated the classification accuracy using only the molecular information."}, {"id": 63, "string": "To obtain the graph of a drug molecule, we took (Weininger, 1988) string encoding of the molecule from DrugBank and then converted it into the graph using RDKit (Landrum, 2016) as illustrated in Figure 2 ."}, {"id": 64, "string": "For the atom features, we used randomly embedded vectors for each atoms (i.e., C, O, N, ...)."}, {"id": 65, "string": "We also used 4 bond types: single, double, triple, or aromatic."}, {"id": 66, "string": "Training Settings We employed mini-batch training using the Adam optimizer (Kingma and Ba, 2015) ."}, {"id": 67, "string": "We used L2 regularization to avoid over-fitting."}, {"id": 68, "string": "We tuned the bias term b (2) t for negative examples in the final softmax layer."}, {"id": 69, "string": "For the hyper-parameters, please refer to the supplementary materials."}, {"id": 70, "string": "We employed pre-trained word embeddings trained by using the word2vec tool (Mikolov et al., 2013) on the 2014 MEDLINE/PubMed baseline distribution."}, {"id": 71, "string": "The vocabulary size was 215,840."}, {"id": 72, "string": "The embedding of the drugs, i.e., DRUG1 and DRUG2 were initialized with the pre-trained embedding of the word drug."}, {"id": 73, "string": "The embeddings of training words that did not appear in the pretrained embeddings were initialized with the average of all pre-trained word embeddings."}, {"id": 74, "string": "Words that appeared only once in the training data were replaced with an UNK word during training, and the embedding of words in the test data set that did not appear in both training and pre-trained embeddings were set to the embedding of the UNK word."}, {"id": 75, "string": "Word position embeddings are initialized with random values drawn from a uniform distribution."}, {"id": 76, "string": "We set the molecule-based vectors of unmatched entities to zero vectors."}, {"id": 77, "string": "Table 1 shows the performance of DDI extraction models."}, {"id": 78, "string": "We show the performance without negative instance filtering or ensemble for the fair comparison."}, {"id": 79, "string": "We observe the increase of recall and F-score by using molecular information,    Both GCNs improvements were statistically significant (p < 0.05 for NFP and p < 0.005 for GGNN) with randomized shuffled test."}, {"id": 80, "string": "Table 2 shows F-scores on individual DDI types."}, {"id": 81, "string": "The molecular information improves Fscores especially on type Mechanism and Effect."}, {"id": 82, "string": "Results We also evaluated the accuracy of binary classification on DrugBank pairs by using only the molecular information in Table 3 ."}, {"id": 83, "string": "The performance is high, although the accuracy is evaluated on automatically generated negative instances."}, {"id": 84, "string": "Finally, we applied the molecular-based DDI classification model trained on DrugBank to the DDIExtraction 2013 task data set."}, {"id": 85, "string": "Since the Drug-Bank has no detailed labels, we mapped all four types of interactions to positive interactions and evaluated the classification performance."}, {"id": 86, "string": "The results in Table 4 show that GCNs produce higher recall than precision and the overall performance is low considering the high performance on Drug-Bank pairs."}, {"id": 87, "string": "This might be because the interactions of drugs are not always mentioned in texts even if the drugs can interact with each other and because hedged DDI mentions are annotated as DDIs in the text data set."}, {"id": 88, "string": "We also trained the DDI extraction model only with molecular information by replacing h all with h m , but the F-scores were quite low (< 5%)."}, {"id": 89, "string": "These results show that we cannot predict textual relations only with molecular information."}, {"id": 90, "string": "Related Work Various feature-based methods have been proposed during and after the DDIExtraction-2013 shared task ."}, {"id": 91, "string": "Kim et al."}, {"id": 92, "string": "(2015) proposed a two-phase SVM-based approach that employed a linear SVM with rich features that consist of word, word pair, dependency graph, parse tree, and noun phrase-based constrained coordination features."}, {"id": 93, "string": "Zheng et al."}, {"id": 94, "string": "(2016) proposed a context vector graph kernel to exploit various types of contexts."}, {"id": 95, "string": "Raihani and Laachfoubi (2017) also employed a two-phase SVM-based approach using non-linear kernels and they proposed five groups of features: word, drug, pair of drug, main verb and negative sentence features."}, {"id": 96, "string": "Our model does not use any features or kernels."}, {"id": 97, "string": "Various neural DDI extraction models have been recently proposed using CNNs and Recurrent Neural Networks (RNNs)."}, {"id": 98, "string": "Liu et al."}, {"id": 99, "string": "(2016) built a CNN-based model based on word and position embeddings."}, {"id": 100, "string": "Zheng et al."}, {"id": 101, "string": "(2017) proposed a Bidirectional Long Short-Term Memory RNN (Bi-LSTM)-based model with an input attention mechanism, which obtained target drug-specific word representations before the Bi-LSTM."}, {"id": 102, "string": "Lim et al."}, {"id": 103, "string": "(2018) proposed Recursive neural networkbased model with a subtree containment feature and an ensemble method."}, {"id": 104, "string": "This model showed the state-of-the-art performance on the DDIExtraction 2013 shared task data set if systems do not use negative instance filtering."}, {"id": 105, "string": "These approaches did not consider molecular information, and they can also be enhanced by the molecular information."}, {"id": 106, "string": "Vilar et al."}, {"id": 107, "string": "(2017) focused on detecting DDIs from different sources such as pharmacovigilance sources, scientific biomedical literature and social media."}, {"id": 108, "string": "They did not use deep neural networks and they did not consider molecular information."}, {"id": 109, "string": "Learning representations of graphs are widely studied in several tasks such as knowledge base completion, drug discovery, and material science Gilmer et al., 2017) ."}, {"id": 110, "string": "Several graph convolutional neural networks have been proposed such as NFP (Duvenaud et al., 2015) , GGNN , and Molecular Graph Convolutions (Kearnes et al., 2016) , but they have not been applied to DDI extraction."}, {"id": 111, "string": "Conclusions We proposed a novel neural method for DDI extraction using both textual and molecular informa-tion."}, {"id": 112, "string": "The results show that DDIs can be predicted with high accuracy from molecular structure information and that the molecular information can improve DDI extraction from texts by 2.39 percept points in F-score on the data set of the DDIExtraction 2013 shared task."}, {"id": 113, "string": "As future work, we would like to seek the way to model the textual and molecular representations jointly with alleviating the differences in labels."}, {"id": 114, "string": "We will also investigate the use of other information in DrugBank."}], "headers": [{"section": "Introduction", "n": "1", "start": 0, "end": 14}, {"section": "Text-based DDI Extraction", "n": "2.1", "start": 15, "end": 25}, {"section": "Molecular Structure-based DDI Classification", "n": "2.2", "start": 26, "end": 36}, {"section": "DDI Extraction from Texts Using Molecular Structures", "n": "2.3", "start": 37, "end": 40}, {"section": "Experimental Settings", "n": "3", "start": 41, "end": 43}, {"section": "Text Corpus and Task Setting", "n": "3.1", "start": 44, "end": 57}, {"section": "Data and Task for Molecular Structures", "n": "3.2", "start": 58, "end": 65}, {"section": "Training Settings", "n": "3.3", "start": 66, "end": 81}, {"section": "Results", "n": "4", "start": 82, "end": 89}, {"section": "Related Work", "n": "5", "start": 90, "end": 110}, {"section": "Conclusions", "n": "6", "start": 111, "end": 114}], "figures": [{"filename": "../figure/image/1120-Figure2-1.png", "caption": "Figure 2: Associating DrugBank entries with texts and molecular graph structures", "page": 2, "bbox": {"x1": 306.71999999999997, "x2": 526.0799999999999, "y1": 61.44, "y2": 208.32}}, {"filename": "../figure/image/1120-Figure1-1.png", "caption": "Figure 1: Overview of the proposed model", "page": 1, "bbox": {"x1": 116.64, "x2": 481.44, "y1": 61.44, "y2": 261.12}}, {"filename": "../figure/image/1120-Table1-1.png", "caption": "Table 1: Evaluation on DDI extraction from texts", "page": 3, "bbox": {"x1": 72.0, "x2": 294.24, "y1": 62.879999999999995, "y2": 160.32}}, {"filename": "../figure/image/1120-Table4-1.png", "caption": "Table 4: Classification of DDIs in texts by molecular structure-based DDI classification model", "page": 3, "bbox": {"x1": 309.59999999999997, "x2": 523.1999999999999, "y1": 250.56, "y2": 293.28}}, {"filename": "../figure/image/1120-Table2-1.png", "caption": "Table 2: Performance on individual DDI types in F-scores", "page": 3, "bbox": {"x1": 307.68, "x2": 525.12, "y1": 62.879999999999995, "y2": 119.03999999999999}}, {"filename": "../figure/image/1120-Table3-1.png", "caption": "Table 3: Accuracy of binary classification on DrugBank pairs", "page": 3, "bbox": {"x1": 354.71999999999997, "x2": 478.08, "y1": 161.76, "y2": 204.95999999999998}}]}