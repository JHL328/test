{"title": "Weblio Pre-reordering Statistical Machine Translation System", "abstract": "This paper describes details of the Weblio Pre-reordering Statistical Machine Translation (SMT) System, participated in the English-Japanese translation task of 1st Workshop on Asian Translation (WAT2014). In this system, we applied the pre-reordering method described in (Zhu et al., 2014) , and extended the model to obtain N -best pre-reordering results. We also utilized N -best parse trees simultaneously to explore the potential improvement for pre-reordering system with forest input.", "text": [{"id": 0, "string": "Introduction In this paper, we describe the details of Weblio Pre-reordering Statistical Machine Translation (SMT) System, experiments and some issues we faced."}, {"id": 1, "string": "For this SMT system, we applied the pre-reordering method proposed in (Zhu et al., 2014) ."}, {"id": 2, "string": "In particular, this method automatically learns pre-reordering model from word alignments and parse trees."}, {"id": 3, "string": "Statistical language model is integrated in the pre-reordering model in order to reorder each node layer in parse trees."}, {"id": 4, "string": "In the 1st Workshop on Asian Translation (WAT2014) (Nakazawa et al., 2014) , we mainly applied this method in English-Japanese translation subtask."}, {"id": 5, "string": "The parse tree we used is head-restructured CFG parse tree for English, which is also proposed in (Zhu et al., 2014) ."}, {"id": 6, "string": "After the pre-reordering phase, we trained a conventional Phrase-based model to do the final translation."}, {"id": 7, "string": "To make some improvements, we enabled the pre-reordering system to output N -best reordering results."}, {"id": 8, "string": "Also, we feed the whole translation pipe line with N -best parse trees generated by Egret parser."}, {"id": 9, "string": "As a result, multiple translation hypotheses can be collected for one input sentence."}, {"id": 10, "string": "Fi-nally, we select the best hypothesis according to a balanced score."}, {"id": 11, "string": "In our experiments, the system utilizes N -best pre-reordering results shows the ability to obtain more accurate translation result."}, {"id": 12, "string": "After incorporating N -best parse trees, improvements on the automatic evaluation scores are also observed."}, {"id": 13, "string": "In section 2 and 3, we briefly describe the method used for tree parsing and pre-reordering."}, {"id": 14, "string": "In the remaining sections, we give some details of the experiments of our system."}, {"id": 15, "string": "Head-restructured CFG parse tree In order to reorder SVO (subject-verb-object) order into SOV (subject-object-verb) order, correctly reordering long-distance words those play important roles in a sentence is crucial."}, {"id": 16, "string": "Thus, the reordering model is required to capture the reordering patterns for those words."}, {"id": 17, "string": "Obviously, using dependency tree should be a quick solution for this problem."}, {"id": 18, "string": "As in a dependency tree, all closely related words of a specific head word come underneath that head word."}, {"id": 19, "string": "All we need to do is to find the best order for the branches under those related words."}, {"id": 20, "string": "In particular, if the head word is the root of the whole sentence (usually a verb), then it's reasonable to think each dependent word leads to a branch that contains a important part of the whole sentence."}, {"id": 21, "string": "However, using dependency tree naively does not work well in practice."}, {"id": 22, "string": "First of all, not all components in a sentence need to be reorder."}, {"id": 23, "string": "In the case of English-Japanese translation, noun phrases are usually in the identical order of English."}, {"id": 24, "string": "Secondly, some local grammar structures tend to keep their unique order."}, {"id": 25, "string": "For example, the combination of an adjective word with a noun usually has the same order in Japanese."}, {"id": 26, "string": "But a noun follows the preposition \"of\" in English will appear before it in the order of Japanese."}, {"id": 27, "string": "A model merely based on dependency parse trees will be sparse and hard to deal with unknown words correctly."}, {"id": 28, "string": "POS (partof-speech) tags and also structural information are still necessary."}, {"id": 29, "string": "The approach in (Zhu et al., 2014) addresses this problem by injecting sentence-level dependencies into CFG parse trees."}, {"id": 30, "string": "Local grammatical structures are still kept unchanged in the parse tree."}, {"id": 31, "string": "This new parse tree is called \"Headrestructured CFG parse tree\" in the original paper."}, {"id": 32, "string": "In this paper, we use \"HRCFG tree\" in short to represent it."}, {"id": 33, "string": "An example of HRCFG tree is shown in Figure 1 ."}, {"id": 34, "string": "In Figure 1 , A normal CFG parse tree is shown in the left, and the corresponding HRCFG tree in the right."}, {"id": 35, "string": "In this example, tree components explicitly shows subject, object and verb parts in the sentence."}, {"id": 36, "string": "This structure with explicit annotations makes the reordering model easier to capture longdistance reordering patterns."}, {"id": 37, "string": "Reordering model integrated with language model The reordering model we used in our MT systems follows the same fashion of the model in (Zhu et al., 2014) ."}, {"id": 38, "string": "A language model is integrated to identify the best order of a node layer according to the order of target language."}, {"id": 39, "string": "Although the using of language model still involves spare problem and fails to give the correct probability in some cases, it makes the implementation fairly simple."}, {"id": 40, "string": "With a bilingual training data and automatically learned word alignments given by GIZA++ (Och and Ney, 2004) , we find the best order for each node layer in all parse trees, make them fit the order of aligned parts in the target sentence."}, {"id": 41, "string": "Specifically, for tree nodes n = (n 1 , n 2 , ..., n k ), terminal nodes beneath n i is defined as t i ."}, {"id": 42, "string": "Let w i represent a set of words in target side which are aligned with any terminal node in t i ."}, {"id": 43, "string": "I this step, for each node layer n, we redetermine the order of n according to the average position of aligned words w i for each node n i ."}, {"id": 44, "string": "Then we exports a sequence of reordered nonterminal tags."}, {"id": 45, "string": "For some kinds of node, nonterminal tags in the sequences are replaced by head word."}, {"id": 46, "string": "After we trained a language model on them, the language model can be used to estimate the likelihood that a tag sequence follows the order of target language."}, {"id": 47, "string": "We show an example of this reordering process in Figure 2 ."}, {"id": 48, "string": "To reorder the node layer underneath the \"S\" node in Figure 2 , we list all possible orders for the tag sequence \"nsubj hits dobj\" (6 possibilities in all)."}, {"id": 49, "string": "Then we use the language model we trained on reordered tag sequences to estimate the probability for each possible order."}, {"id": 50, "string": "Finally, it is expected that the sequence \"nsubj dobj hits\" gets the highest language model score, as it is most closer to the order in Japanese."}, {"id": 51, "string": "The reordering operation in this fashion is applied to all node layers in the HRCFG tree."}, {"id": 52, "string": "We export all terminal words in the reordered parse trees as new training data in the source side."}, {"id": 53, "string": "Like Head-finalization (Isozaki et al., 2010) , we also incorporate seed words in the results."}, {"id": 54, "string": "So the final reordering result of the sentence shown in Figure  1 will be \"John va nsubjpass a ball va dobj hits\"."}, {"id": 55, "string": "N -best reordering In the reordering model we described above, the best order for the whole sentence is actually comprised by all 1 -best orders of every node layers in the parse tree."}, {"id": 56, "string": "Although the language model usually works perfectly to give the best reordering result."}, {"id": 57, "string": "In some cases, the best reordering result is unclear until the translation phase."}, {"id": 58, "string": "We give an example here, for the sentence \"The rocket is launched by NASA\", two plausible reordering results are shown in Table 1 ."}, {"id": 59, "string": "The first reordering result in Table 1 is preferred by the reordering model as \"nsubjpass auxpass launched prep by\" is usually reordered into \"nsubjpass prep by launched auxpass\"."}, {"id": 60, "string": "Unfortunately, Table 1 , it's hard to find out a best order before translation."}, {"id": 61, "string": "Considering N -best reordering results is necessary in order to obtain the best translation result."}, {"id": 62, "string": "In our MT system, we implement this feature simply by collecting N -best reordering results for all node layers, and finally rank the reordering results by accumulated language model score."}, {"id": 63, "string": "Experiments Experimental settings For our baseline system, we use 1 -best parse trees for training and test."}, {"id": 64, "string": "Stanford tokenizer and Berkeley parser (Petrov et al., 2006) are selected in the pre-processing phase in order to produce CFG parse trees."}, {"id": 65, "string": "Then we obtain dependency parse trees by applying Stanford rules (Klein and Manning, 2002) to CFG parse trees."}, {"id": 66, "string": "HRCFG trees are built upon these two kinds of parse trees."}, {"id": 67, "string": "For the Japanese text, we use Kytea (Neubig, Nakata, and Mori, 2011) to tokenize it."}, {"id": 68, "string": "Due to the limitation of computational resource, we are only able to train our reordering model on 1.5M bilingual text (with relatively high scores in ASPEC parallel corpus) for English-to-Japanese translation task."}, {"id": 69, "string": "We used this trained reordering model to reorder all training data in the source side."}, {"id": 70, "string": "We use conventional Phrase-based model implemented in Moses toolkit to finish remaining SMT pipe line."}, {"id": 71, "string": "Distortion limit is set to 6 in all our experiments."}, {"id": 72, "string": "For system translates forest inputs, we use Egret parser to generate N -best packed forests."}, {"id": 73, "string": "We unpack each forest and parse each individual tree to HRCFG tree."}, {"id": 74, "string": "For all candidate of parse trees, we reorder them and merge same reordering results."}, {"id": 75, "string": "Then for all reordering results we obtained, we translate them and record translation scores given by Moses."}, {"id": 76, "string": "Finally, a best translation result is selected out by the sum of translation score and reordering score."}, {"id": 77, "string": "Experiment results We carried out several experiments combining the use of N -best parse trees and N -best reordering results."}, {"id": 78, "string": "A list of automatic evaluation scores for different system settings are listed in Table 2 ."}, {"id": 79, "string": "In particular, for systems marked with \"N -best parse\", 30 parse trees with highest parsing scores are used."}, {"id": 80, "string": "For systems marked with \"N -best reorder\", 10 reordering results with highest reordering scores are accepted for each parse tree."}, {"id": 81, "string": "That is, for System 4, a maximum of 300 reordering results are generated for one sentence."}, {"id": 82, "string": "In WAT2014, we submitted System 3 and System 4 to human evaluation."}, {"id": 83, "string": "Note that in Table  2 , our in-house automatic evaluation scores are slightly different from that on the score board of WAT2014 due to different automatic evaluation pipe line we used."}, {"id": 84, "string": "Official evaluation scores are listed in Table 3 ."}, {"id": 85, "string": "Where \"BASELINE\" refers to Phrase-based SMT system (Koehn, Och, and Marcu, 2003) as the official baseline for human evaluation."}, {"id": 86, "string": "Our experiment results shown in Table 2 show that incorporating N -best parse tree and reordering results gained improvements for both BLEU and RIBES metrics."}, {"id": 87, "string": "In the official human evaluation, although System 4 achieved better results in automatic evaluations."}, {"id": 88, "string": "Human evaluation score of it degraded compared to System 3, which only considers 1 -best parse tree."}, {"id": 89, "string": "In Figure 3 and 4, we show the growth of BLEU and RIBES when increasing candidate number considered for N -best parse trees and reordering results."}, {"id": 90, "string": "Both BLEU and RIBES scores are tending to converge after we increased the N -best parse tree candidates to 30 for System 2."}, {"id": 91, "string": "For System 3, the automatic evaluation scores are still increasing after 10 reordering results are considered."}, {"id": 92, "string": "Evaluation for pre-reordering In this section, we evaluate the performance of pre-reordering."}, {"id": 93, "string": "Follows the method described in (Isozaki et al., 2010) , we estimate Kendall's \u03c4 from word alignments."}, {"id": 94, "string": "A comparison of Kendall's \u03c4 distribution upon first 1.5M sentences of ASPEC corpus is shown in Figure 5 ."}, {"id": 95, "string": "Average Kendall's \u03c4 of natural order and adjusted order is 0.30 and 0.71 respectively."}, {"id": 96, "string": "Note that in (Isozaki et al., 2010) , the algorithm for estimating Kendall's \u03c4 does not take the words with multiple alignments into account."}, {"id": 97, "string": "Hence, the graph of Kendall's \u03c4 only gives a rough idea of the performance of pre-reordering."}, {"id": 98, "string": "In particular, the algorithm skipped 20.30% aligned words for corpus in natural order and 14.06% aligned words for pre-reordered corpus."}, {"id": 99, "string": "However, the distribution of Kendall's \u03c4 in Figure 5 gives a intuitive picture of the improvements of word order."}, {"id": 100, "string": "Sentences which are fully identical in word order increased from 1.8% to 15% after pre-reordering (labeled with \"=1.0\" in Figure 5 )."}, {"id": 101, "string": "Error analysis Issues of pre-reordering Although our pre-reordering SMT system is able to produce relatively better translation results compared to baseline SMT systems."}, {"id": 102, "string": "In many cases, the translation results still suffer from the defect of the reordering model."}, {"id": 103, "string": "As the reordering model described in Section 3 is actually a language model built on sequences mixed with nonterminal tags and words."}, {"id": 104, "string": "Involving words in the model makes the reordering more flexible, but also makes the model sparse."}, {"id": 105, "string": "For some rare or unknown words, the reordering model usually fails to reorder sentences correctly."}, {"id": 106, "string": "In Table 4 , we show 2 reordering samples."}, {"id": 107, "string": "In Sample 1, the sentence is correctly reordered."}, {"id": 108, "string": "The word \"were\" in English side should be placed in the end of the reordered sentence, which is expected to be translated to \" \" in Japanese."}, {"id": 109, "string": "In Sample 2, we replace the verb \"confirmed\" in Sample 1 to \"observed\", then the reordering model the changes were observed \u2192 the changes va nsubjpass were observed fails to place the word \"were\" into the rightmost position."}, {"id": 110, "string": "The errors like what we show in Table 4 are actually widespread in the reordering results for the ASPEC test corpus."}, {"id": 111, "string": "Although in the decoding phase, the lexical distortion model of Phrasebased SMT model can partially mitigate some local errors, some critical errors still can be observed from the final translations."}, {"id": 112, "string": "Issues for Context-aware Machine Translation In this section, we describe some efforts for utilizing context information during the translation."}, {"id": 113, "string": "We made an attempt to tackle the phrase selection problem for English-Japanese translation."}, {"id": 114, "string": "In Japanese, many English words have multiple translations."}, {"id": 115, "string": "Especially Japanese words in the form of Katakana usually also have corresponding expressions comprised of Chinese characters."}, {"id": 116, "string": "For instance, the phrase \"remote control\" can be translated to both \"ENKAKUSEIGYO\"( ) and \"RIMOKON\"( )."}, {"id": 117, "string": "We show the distribution of these two translations across different domains in Figure 6 ."}, {"id": 118, "string": "Figure 6 , it's reasonable to think the phrase \"RIMOKON\" is more preferred in domain J, P, Q and R. While in domain N, the two phrases appear almost same times."}, {"id": 119, "string": "A simple solution is to make language model more domain-specific."}, {"id": 120, "string": "We carried out experiments that simply interpolate general language model and in-domain language model."}, {"id": 121, "string": "The experiment results for first three domains are shown in Figure  7 ."}, {"id": 122, "string": "Figure 7 , we show the language model perplexity achieved on domain-specific test data using different settings."}, {"id": 123, "string": "Different interpolation weights for the in-domain language model are tried."}, {"id": 124, "string": "We can see the interpolated language model generally achieves best perplexities when the weight for in-domain language model is set to 0.5."}, {"id": 125, "string": "Applying these interpolated language models for translation tasks in corresponding domains should help improving the quality of translation."}, {"id": 126, "string": "Conclusion In this paper, we described the reordering model we applied in Weblio Pre-reordering SMT system, and also some efforts to utilize N -best parse trees and N -best reordering results."}, {"id": 127, "string": "According to our in-house experiment results, the automatic evaluation scores are generally improved when multiple candidates of parse tree and reordering result are considered."}, {"id": 128, "string": "However, in the human evaluation, incorporating N -best parse trees did not gain improvements."}, {"id": 129, "string": "As we demonstrated in Section 5.1, the reordering model is still unstable, and fails to work correctly even for some simple cases."}, {"id": 130, "string": "Further improvement is required to enable the reordering model to deal with general cases correctly."}, {"id": 131, "string": "Then, in Section 5.2, we show interpolating general and in-domain language models can be a quick solution to improve translation quality when domain information is given as context."}, {"id": 132, "string": "For future research, we still plan to explore the performance limit of pre-reordering models."}, {"id": 133, "string": "With a complex reordering model considers multiple factors of the language, it's still plausible for this approach to grow in performance."}, {"id": 134, "string": "Also, as the prereordering model used in this paper is independent of specific language pair, more experiments can be conducted on different language pairs."}], "headers": [{"section": "Introduction", "n": "1", "start": 0, "end": 14}, {"section": "Head-restructured CFG parse tree", "n": "2", "start": 15, "end": 36}, {"section": "Reordering model integrated with language model", "n": "3", "start": 37, "end": 54}, {"section": "N -best reordering", "n": "3.1", "start": 55, "end": 62}, {"section": "Experimental settings", "n": "4.1", "start": 63, "end": 76}, {"section": "Experiment results", "n": "4.2", "start": 77, "end": 91}, {"section": "Evaluation for pre-reordering", "n": "4.3", "start": 92, "end": 100}, {"section": "Issues of pre-reordering", "n": "5.1", "start": 101, "end": 111}, {"section": "Issues for Context-aware Machine Translation", "n": "5.2", "start": 112, "end": 125}, {"section": "Conclusion", "n": "6", "start": 126, "end": 134}], "figures": [{"filename": "../figure/image/1231-Table1-1.png", "caption": "Table 1: Two reordering results of the sentence \u201cThe rocket is launched by NASA\u201d", "page": 2, "bbox": {"x1": 80.64, "x2": 293.28, "y1": 120.96, "y2": 227.04}}, {"filename": "../figure/image/1231-Table2-1.png", "caption": "Table 2: Experiment results for different system settings", "page": 2, "bbox": {"x1": 305.76, "x2": 529.4399999999999, "y1": 284.64, "y2": 352.32}}, {"filename": "../figure/image/1231-Table3-1.png", "caption": "Table 3: Official evaluation scores in WAT2014 (kytea used for post-processing)", "page": 2, "bbox": {"x1": 315.84, "x2": 503.03999999999996, "y1": 627.84, "y2": 681.12}}, {"filename": "../figure/image/1231-Table4-1.png", "caption": "Table 4: Samples of reordering result", "page": 4, "bbox": {"x1": 80.64, "x2": 293.28, "y1": 108.96, "y2": 201.12}}, {"filename": "../figure/image/1231-Figure6-1.png", "caption": "Figure 6: Translation distribution for \u201cremote control\u201d across several categories", "page": 4, "bbox": {"x1": 93.6, "x2": 287.03999999999996, "y1": 570.72, "y2": 705.12}}, {"filename": "../figure/image/1231-Figure7-1.png", "caption": "Figure 7: LM perplexity on domain-specific test data using interpolated language models", "page": 4, "bbox": {"x1": 318.71999999999997, "x2": 516.0, "y1": 222.72, "y2": 356.15999999999997}}, {"filename": "../figure/image/1231-Figure1-1.png", "caption": "Figure 1: An example of HRCFG tree converted from CFG parse tree (A direct parent nodes of terminal nodes are now include)", "page": 1, "bbox": {"x1": 85.92, "x2": 294.24, "y1": 249.6, "y2": 303.36}}, {"filename": "../figure/image/1231-Figure2-1.png", "caption": "Figure 2: An example of HRCFG tree reordering", "page": 1, "bbox": {"x1": 310.56, "x2": 519.36, "y1": 225.6, "y2": 277.44}}, {"filename": "../figure/image/1231-Figure4-1.png", "caption": "Figure 4: Growth of RIBES with increasing N - best candidates", "page": 3, "bbox": {"x1": 85.92, "x2": 287.03999999999996, "y1": 461.76, "y2": 596.16}}, {"filename": "../figure/image/1231-Figure5-1.png", "caption": "Figure 5: A comparison of Kendall\u2019s \u03c4 distribution", "page": 3, "bbox": {"x1": 313.92, "x2": 513.12, "y1": 81.6, "y2": 217.44}}, {"filename": "../figure/image/1231-Figure3-1.png", "caption": "Figure 3: Growth of BLEU with increasing N - best candidates", "page": 3, "bbox": {"x1": 88.8, "x2": 287.03999999999996, "y1": 264.0, "y2": 396.47999999999996}}]}