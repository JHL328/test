{"title": "Integrating Query Performance Prediction in Term Scoring for Diachronic Thesaurus", "abstract": "A diachronic thesaurus is a lexical resource that aims to map between modern terms and their semantically related terms in earlier periods. In this paper, we investigate the task of collecting a list of relevant modern target terms for a domain-specific diachronic thesaurus. We propose a supervised learning scheme, which integrates features from two closely related fields: Terminology Extraction and Query Performance Prediction (QPP). Our method further expands modern candidate terms with ancient related terms, before assessing their corpus relevancy with QPP measures. We evaluate the empirical benefit of our method for a thesaurus for a diachronic Jewish corpus.", "text": [{"id": 0, "string": "Introduction In recent years, there has been growing interest in diachronic lexical resources, which comprise terms from different language periods."}, {"id": 1, "string": "(Borin and Forsberg, 2011; Riedl et al., 2014) ."}, {"id": 2, "string": "These resources are mainly used for studying language change and supporting searches in historical domains, bridging the lexical gap between modern and ancient language."}, {"id": 3, "string": "In particular, we are interested in this paper in a certain type of diachronic thesaurus."}, {"id": 4, "string": "It contains entries for modern terms, denoted as target terms."}, {"id": 5, "string": "Each entry includes a list of ancient related terms."}, {"id": 6, "string": "Beyond being a historical linguistic resource, such thesaurus is useful for supporting searches in a diachronic corpus, composed of both modern and ancient documents."}, {"id": 7, "string": "For example, in our historical Jewish corpus, the modern Hebrew term for terminal patient 1 has only few verbatim occurrences, in modern documents, but this topic has been widely discussed in ancient periods."}, {"id": 8, "string": "A domain searcher needs the diachronic thesaurus to enrich the search with ancient synonyms or related terms, such as dying and living for the moment."}, {"id": 9, "string": "Prior work on diachronic thesauri addressed the problem of collecting relevant related terms for given thesaurus entries."}, {"id": 10, "string": "In this paper we focus on the complementary preceding task of collecting a relevant list of modern target terms for a diachronic thesaurus in a certain domain."}, {"id": 11, "string": "As a starting point, we assume that a list of meaningful terms in the modern language is given, such as titles of Wikipedia articles."}, {"id": 12, "string": "Then, our task is to automatically decide which of these candidate terms are likely to be relevant for the corpus domain and should be included in the thesaurus."}, {"id": 13, "string": "In other words, we need to decide which of the candidate modern terms corresponds to a concept that has been discussed significantly in the diachronic domain corpus."}, {"id": 14, "string": "Our task is closely related to term scoring in the known Terminology Extraction (TE) task in NLP."}, {"id": 15, "string": "The goal of corpus-based TE is to automatically extract prominent terms from a given corpus and score them for domain relevancy."}, {"id": 16, "string": "In our setting, since all the target terms are modern, we avoid extracting them from the diachronic corpus of modern and ancient language."}, {"id": 17, "string": "Instead, we use a given candidate list and apply only the term scoring phase."}, {"id": 18, "string": "As a starting point, we adopt a rich set of state-of-the-art TE scoring measures and integrate them as features in a common supervised classification approach (Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012) ."}, {"id": 19, "string": "Given our Information Retrieval (IR) motivation, we notice a closely related task to TE, namely Query Performance Prediction (QPP)."}, {"id": 20, "string": "QPP methods are designed to estimate the retrieval quality of search queries, by assessing their relevance to the text collection."}, {"id": 21, "string": "Therefore, QPP scoring measures seem to be potentially suitable also for our terminology scoring task, by considering the candidate term as a search query."}, {"id": 22, "string": "Some of the QPP measures are indeed similar in nature to the TE methods, analyzing the distribution of the query terms within the collection."}, {"id": 23, "string": "However, some of the QPP methods have different IR-biased characteristics and may provide a marginal contribution."}, {"id": 24, "string": "Therefore, we adopted them as additional features for our classifier and indeed observed a performance increase."}, {"id": 25, "string": "Most of the QPP methods prioritize query terms with high frequency in the corpus."}, {"id": 26, "string": "However, in a diachronic corpus, such criterion may sometimes be problematic."}, {"id": 27, "string": "A modern target term might appear only in few modern documents, while being referred to, via ancient terminology, also in ancient documents."}, {"id": 28, "string": "Therefore, we would like our prediction measure to be aware of these ancient documents as well."}, {"id": 29, "string": "Following a particular QPP measure (Zhou and Croft, 2007) , we address this problem through Query Expansion (QE)."}, {"id": 30, "string": "Accordingly, our method first expands the query containing the modern candidate term, then calculates the QPP scores of the expanded query and then utilizes them as scoring features."}, {"id": 31, "string": "Combining the baseline features with our expansion-based QPP features yields additional improvement in the classification results."}, {"id": 32, "string": "Term Scoring Measures This section reviews common measures developed for Terminology Extraction (Section 2.1) and for Query Performance Prediction (Section 2.2)."}, {"id": 33, "string": "Table 1 lists those measures that were considered as features in our system, as described in Section 3."}, {"id": 34, "string": "Terminology Extraction Terminology Extraction (TE) methods aim to identify terms that are frequently used in a specific domain."}, {"id": 35, "string": "Typically, linguistic processors (e.g."}, {"id": 36, "string": "POS tagger, phrase chunker) are used to filter out stop words and restrict candidate terms to nouns or noun phrases."}, {"id": 37, "string": "Then, statistical measures are used to rank the candidate terms."}, {"id": 38, "string": "There are two main terminological properties that the statistical measures identify: unithood and termhood."}, {"id": 39, "string": "Measures that express unithood indicate the collocation strength of units that comprise a single term."}, {"id": 40, "string": "Measures that express termhood indicate the statistical prominence of the term in the target do-main corpus."}, {"id": 41, "string": "For our task, we focus on the second property, since the candidates are taken from a key-list of terms whose coherence in the language is already known."}, {"id": 42, "string": "Measures expressing termhood are based either on frequency in the target corpus (1, 2, 3, 4, 9, 11, 12, 13 ) 2 , or on comparison with frequency in a reference background corpus (8, 14, 16) ."}, {"id": 43, "string": "Recently, approaches which combine both unithood and termhood were investigated as well (7, 8, 15, 16) ."}, {"id": 44, "string": "Query Performance Prediction Query Performance Prediction (QPP) aims to estimate the quality of answers that a search system would return in response to a particular query."}, {"id": 45, "string": "Statistical QPP methods are categorized into two types: pre-retrieval methods, analyzing the distribution of the query term within the document collection; and post-retrieval methods, additionally analyzing the search results."}, {"id": 46, "string": "Some of the preretrieval methods are similar to TE methods based on the same term frequency statistics."}, {"id": 47, "string": "Pre-retrieval methods measure various properties of the query: specificity (17, 18, 24, 25) , similarity to the corpus (19) , coherence of the documents containing the query terms (26), variance of the query terms' weights over the documents containing it (20); and relatedness, as good performance is expected when the query terms co-occur frequently in the collection (21)."}, {"id": 48, "string": "Post-retrieval methods are usually more complex, where the top search results are retrieved and analyzed."}, {"id": 49, "string": "They are categorized into three main paradigms: clarity-based methods (28), robustness-based methods (22) and score distribution based methods (23, 29)."}, {"id": 50, "string": "We pay special attention to two post-retrieval QPP methods; Query Feedback (22) and Clarity (23)."}, {"id": 51, "string": "The Clarity method measures the coherence of the query's search results with respect to the corpus."}, {"id": 52, "string": "It is defined as the KL divergence between a language model induced from the result list and that induced from the corpus."}, {"id": 53, "string": "The Query Feedback method measures the robustness of the query's results to query perturbations."}, {"id": 54, "string": "It models retrieval as a communication channel."}, {"id": 55, "string": "The input is the query, the channel is the search system, and the set of results is the noisy output of the channel."}, {"id": 56, "string": "A new query is generated from the list of search (Liu et al., 2005) 13 Term Variance Quality (Liu et al., 2005 ) 6 TF-Disjoint Corpora Frequency (Lopes et al., 2012) 14 Weirdness (Ahmad et al., 1999) 7 C-value (Frantzi and Ananiadou, 1999) 15 NC-value (Frantzi and Ananiadou, 1999) 8 Glossex (Kozakov et al., 2004) 16 TermExtractor (Sclano and Velardi, 2007 ) Query Performance Prediction measures 17 Average IDF  24 Average ICTF (Inverse collection term frequency) (Plachouras et al., 2004) 18 Query Scope  25 Simplified Clarity Score (He and Ounis, 2004) 19 Similarity Collection Query (Zhao et al., 2008) 26 Query Coherence (He et al., 2008 ) 20 Average Variance (Zhao et al., 2008) 27 Average Entropy (Cristina, 2013) 21 Term Relatedness (Hauff et al., 2008) 28 Clarity (Cronen-Townsend et al., 2002) 22 Query Feedback (Zhou and Croft, 2007) 29 Normalized Query Commitment (Shtok et al., 2009 ) 23 Weighted Information Gain (Zhou and Croft, 2007) Table 1: Prior art measures considered in our work results, taking the terms with maximal contribution to the Clarity score, and then a second list of results is retrieved for that second query."}, {"id": 57, "string": "The overlap between the two lists is the robustness score."}, {"id": 58, "string": "Our suggested method was inspired by the Query Feedback measure, as detailed in the next section."}, {"id": 59, "string": "Integrated Term Scoring We adopt the supervised framework for TE (Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012) , considering each candidate target term as a learning instance."}, {"id": 60, "string": "For each candidate, we calculate a set of features over which learning and classification are performed."}, {"id": 61, "string": "The classification predicts which candidates are suitable as target terms for the diachronic thesaurus."}, {"id": 62, "string": "Our baseline system (TE) includes state-of-the-art TE measures as features, listed in the upper part of Table 1 ."}, {"id": 63, "string": "Next, we introduce two system variants that integrate QPP measures as additional features."}, {"id": 64, "string": "The first system, TE-QPP T erm , applies the QPP measures to the candidate term as the query."}, {"id": 65, "string": "All QPP measures, listed in the lower part of Table 1 , are utilized except for the Query Feedback measure (22) (see below)."}, {"id": 66, "string": "To verify which QPP features are actually beneficial for terminology scoring, we measure the marginal contribution of each feature via ablation tests in 10-fold cross validation over the training data (see Section 4.1)."}, {"id": 67, "string": "Features which did not yield marginal contribution were not included 3 ."}, {"id": 68, "string": "3 Removed features from TE-QPPT erm: 17, 19, 22, 23, The two systems, described so far, rely on corpus occurrences of the original candidate term, prioritizing relatively frequent terms."}, {"id": 69, "string": "In a diachronic corpus, however, a candidate term might be rare in its original modern form, yet frequently referred to by archaic forms."}, {"id": 70, "string": "Therefore, we adopt a query expansion strategy based on Pseudo Relevance Feedback, which expands a query based on analyzing the top retrieved documents."}, {"id": 71, "string": "In our setting, this approach takes advantage of a typical property of modern documents in a diachronic corpus, namely their temporally-mixed language."}, {"id": 72, "string": "Often, modern documents in a diachronic domain include ancient terms that were either preserved in modern language or appear as citations."}, {"id": 73, "string": "Therefore, an expanded query of a modern term, which retrieves only modern documents, is likely to pick some of these ancient terms as well."}, {"id": 74, "string": "Thus, the expanded query would likely retrieve both modern and ancient documents and would allow QPP measures to evaluate the query relevance across periods."}, {"id": 75, "string": "Therefore, our second integrated system, TE-QPP QE , utilizes the Pseudo Relevance Feedback Query Expansion approach to expand our modern candidate with topically-related terms."}, {"id": 76, "string": "First, similarly to the Query Feedback measure (measure (22) in the lower part of Table 1), we expand the candidate by adding terms with maximal contribution (top 5, in our experiments) to the Clarity score (Section 2.2)."}, {"id": 77, "string": "Then, we calculate all QPP measures for the expanded query."}, {"id": 78, "string": "Since the expan- 24, 25. sions that we extract from the top retrieved documents typically include ancient terms as well, the new scores may better express the relevancy of the candidate's topic across the diachronic corpus."}, {"id": 79, "string": "We also performed feature selection, as done for the first system 4 ."}, {"id": 80, "string": "Evaluation Evaluation Setting We applied our method to the diachronic corpus is the Responsa project Hebrew corpus 5 ."}, {"id": 81, "string": "The Responsa corpus includes rabbinic case-law rulings which represent the historical-sociological milieu of real-life situations, collected over more than a thousand years, from the 11 th century until today."}, {"id": 82, "string": "The corpus consists of 81,993 documents, and was used for previous NLP and IR research (Choueka et al., 1971; Choueka et al., 1987; HaCohen-Kerner et al., 2008; Liebeskind et al., 2012; Zohar et al., 2013; ."}, {"id": 83, "string": "The candidate target terms for our classification task were taken from the publicly available keylist of Hebrew Wikipedia entries 6 ."}, {"id": 84, "string": "Since many of these tens of thousands entries, such as person names and place names, were not suitable as target terms, we first filtered them by Hebrew Named Entity Recognition 7 and manually."}, {"id": 85, "string": "Then, a list of approximately 5000 candidate target terms was manually annotated by two domain experts."}, {"id": 86, "string": "The experts decided which of the candidates corresponds to a concept that has been discussed significantly in our diachronic domain corpus."}, {"id": 87, "string": "Only candidates that the annotators agreed on their annotation were retained, and then balanced for equal number of positive and negative examples."}, {"id": 88, "string": "Consequently, the balanced training and test sets contain 500 and 200 candidates, respectively."}, {"id": 89, "string": "For classification, Weka's 8 Support Vector Machine supervised classifier with polynomial kernel was used."}, {"id": 90, "string": "We train the classifier with our training set and measure the accuracy on the test set."}, {"id": 91, "string": "Results Table 2 compares the classification performance of our baseline (TE) and integrated systems, (TE-QPP T erm ) and (TE-QPP QE ), proposed in Section 3."}, {"id": 92, "string": "Feature Set Accuracy (%) TE 61.5 TE-QPP T erm 65 TE-QPP QE 66.5 (McNemar, 1947) , on our diachronic corpus it seems to help."}, {"id": 93, "string": "Yet, when the QPP score is measured over the expanded candidate, and ancient documents are utilized, the performance increase is more notable (5 points) and the improvement over the baseline is statistically significant according to the McNemar's test with p<0.05."}, {"id": 94, "string": "We analyzed the false negative classifications of the baseline that were classified correctly by the QE-based configuration."}, {"id": 95, "string": "We found that their expanded forms contain ancient terms that help the system making the right decision."}, {"id": 96, "string": "For example, the Hebrew target term for slippers was expanded by the ancient expression corresponding to made of leather."}, {"id": 97, "string": "This is a useful expansion since in the ancient documents slippers are discussed in the context of fasts, as in two of the Jewish fasts wearing leather shoes is forbidden and people wear cloth-made slippers."}, {"id": 98, "string": "Conclusions and Future Work We introduced a method that combines features from two closely related tasks, terminology extraction and query performance prediction, to solve the task of target terms selection for a diachronic thesaurus."}, {"id": 99, "string": "In our diachronic setting, we showed that enriching TE measures with QPP measures, particularly when calculated on expanded candidates, significantly improves performance."}, {"id": 100, "string": "Our results suggest that it may be worth investigating this integrated approach also for other terminology extraction and QPP settings."}, {"id": 101, "string": "We plan to further explore the suggested method by utilizing additional query expansion algorithms."}, {"id": 102, "string": "In particular, to avoid expanding queries for which expansion degrade retrieval performance, we plan to investigate the selective query expansion approach (Cronen-Townsend et al., 2004) ."}], "headers": [{"section": "Introduction", "n": "1", "start": 0, "end": 30}, {"section": "Term Scoring Measures", "n": "2", "start": 31, "end": 33}, {"section": "Terminology Extraction", "n": "2.1", "start": 34, "end": 43}, {"section": "Query Performance Prediction", "n": "2.2", "start": 44, "end": 58}, {"section": "Integrated Term Scoring", "n": "3", "start": 59, "end": 79}, {"section": "Evaluation Setting", "n": "4.1", "start": 80, "end": 88}, {"section": "Results", "n": "4.2", "start": 89, "end": 97}, {"section": "Conclusions and Future Work", "n": "5", "start": 98, "end": 102}], "figures": [{"filename": "../figure/image/1013-Table1-1.png", "caption": "Table 1: Prior art measures considered in our work", "page": 2, "bbox": {"x1": 77.75999999999999, "x2": 520.3199999999999, "y1": 62.879999999999995, "y2": 260.15999999999997}}, {"filename": "../figure/image/1013-Table2-1.png", "caption": "Table 2: Comparison of system performance", "page": 3, "bbox": {"x1": 341.76, "x2": 491.03999999999996, "y1": 62.879999999999995, "y2": 119.03999999999999}}]}