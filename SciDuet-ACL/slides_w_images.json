{
  "952": {
    "slides": {
      "0": {
        "title": "Background What is Aspect Opinion Extraction",
        "text": [
          "Figure 1: An example of review outputs.",
          "I Our focus: Aspect and Opinion Terms Co-extraction",
          "I Challenge: Limited resources for fine-grained annotations"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Problem Definition",
        "text": [
          "Task formulation: Sequence labeling",
          "Labels N N N N BO B\u000f I\u000f",
          "B \u000f { Beginning of aspect",
          "Features I\u000f { Inside of aspect",
          "B O { Beginning of opinion",
          "Input x The phone has a good screen size",
          "IO { Inside of opinion",
          "Figure 2: A deep learning model for sequence labeling.",
          "I Given: Labeled data in source domain DS ={(xSi ySi i=1, nS unlabeled",
          "data in target domain DT ={xTj} nT j=1 I Idea: Build bridges across domains, learn shared space"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "2": {
        "title": "Motivation Domain Adaptation",
        "text": [
          "Domain shift & bridges",
          "Figure 3: Domain shift for different domains. Figure 4: Syntactic patterns.",
          "I Adaptive bootstrapping [Li et al., 2012]",
          "I Auxiliary task with Recurrent neural network [Ding et al., 2017]"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "3": {
        "title": "Overview and Contribution",
        "text": [
          "Recursive Neural Structural Correspondence Network (RNSCN)",
          "I Structural correspondences are built based on common syntactic",
          "I Use relation vectors with auxiliary labels to learn a shared space across",
          "I Deal with auxiliary label noise",
          "I Group relation vectors into their intrinsic clusters in an unsupervised",
          "A joint deep model"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Model Architecture Recursive Neural Network",
        "text": [
          "Relation vectors: Relations as embeddings in the feature space",
          "they o er good appetizers",
          "Figure 5: A recursive neural network.",
          "Auxiliary task: Dependency relation prediction",
          "nsubj amod R43 y = softmax(WRr43 bR) root dobj"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "5": {
        "title": "Model Architecture Learn Shared Representations",
        "text": [
          "Recursive Neural Structural Correspondence Network (RNSCN)",
          "they o er good appetizers The laptop has a nice screen",
          "nsubj amod det nsubj amod root dobj det \u0001ource Target dobj",
          "Figure 6: An example of how RNSCN learns the correspondences.",
          "h\u0001\u000e h h h h h h h h h"
        ],
        "page_nums": [
          14,
          15,
          16,
          17
        ],
        "images": [
          "figure/image/952-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Model Architecture Auxiliary Label Denoising",
        "text": [
          "correct l\u0001bel noisy l\u0001bel h6",
          "good \u0001ppetizers nice screen Auxiliary task:",
          "Figure 7: An autoencoder for label denoising.",
          "Auto encoder Auto encoder",
          "intrinsic group intrinsic group",
          "Reduce label noise: auto-encoders",
          "amod dobj y Rnm = softmax(WRgnm)",
          "rnm Wenc Wdec r\u0002nm",
          "Figure 8: An autoencoder for relation grouping.",
          "exp(r>nmWencgj `R1 rnm Wdecgnm",
          "yRnm[k] log yR nm[k]"
        ],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": [
          "figure/image/952-Figure3-1.png"
        ]
      },
      "7": {
        "title": "Experiments",
        "text": [
          "Dataset Description # Sentences Training Testing",
          "Table 1: Data statistics with number of sentences.",
          "Table 2: Comparisons with different baselines.",
          "Injecting noise into syntactic relations",
          "RL RD LR LD DR DL",
          "AS OP AS OP AS OP AS OP AS OP AS OP",
          "Table 3: Effect of auto-encoders for auxiliary label denoising.",
          "Words grouping learned from auto-encoders",
          "Group 1 this, the, their, my, here, it, I, our, not",
          "Group 2 quality, jukebox, maitre-d, sauces, portions, volume, friend, noodles, calamari",
          "Group 3 in, slightly, often, overall, regularly, since, back, much, ago",
          "Group 4 handy, tastier, white, salty, right, vibrant, first, ok",
          "Group 5 get, went, impressed, had, try, said, recommended, call, love",
          "Group 6 is, are, feels, believes, seems, like, will, would",
          "Table 4: Case studies on word clustering",
          "trade-off parameter () number of groups (|G|)",
          "(a) trade-off (b) Groups",
          "Figure 9: Sensitivity studies for LD."
        ],
        "page_nums": [
          22,
          23,
          24
        ],
        "images": [
          "figure/image/952-Table1-1.png",
          "figure/image/952-Figure4-1.png"
        ]
      },
      "8": {
        "title": "Domain Adaptation Experiments",
        "text": [
          "proportion of unlabeled target data proportion of unlabeled target data",
          "Figure 10: F1 vs proportion of unlabeled target data."
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/952-Figure5-1.png"
        ]
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "A novel deep learning framework for Cross-domain aspect and opinion terms extraction.",
          "Embed syntactic structure into a deep model to bridge the gap between different domains.",
          "Apply auxiliary task to assist knowledge transfer.",
          "Address the problem of negative effect brought by label noise."
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "10": {
        "title": "Appendix Domain Adaptation",
        "text": [
          "RL RD LR LD DR DL",
          "Models AS OP AS OP AS OP AS OP AS OP AS OP",
          "Table 5: Comparisons with different baselines."
        ],
        "page_nums": [
          29
        ],
        "images": []
      }
    },
    "paper_title": "Recursive Neural Structural Correspondence Network for Cross-domain Aspect and Opinion Co-Extraction"
  },
  "953": {
    "slides": {
      "0": {
        "title": "Numeracy",
        "text": [
          "brown sleeping three sat",
          "four jumped numbers two"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Literate Language Models",
        "text": [
          "A apple eats I I eats an apple An apple eats meI eat an apple"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Numerate Language Models",
        "text": [
          "John is m tall John is m tall John is m tall John is m tall"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Numeracy Matters",
        "text": [
          "Unemployment of the US is",
          "Patients temperature is degrees",
          "Our model is times better than the baseline"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "A Neural Language Model",
        "text": [],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation Adjusted Perplexity",
        "text": [
          "John is m tall",
          "Perplexity Adjusted Perplexity [Ueberla, 1994]",
          "BUT from test data"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "6": {
        "title": "Datasets",
        "text": [
          "Clinical Dataset Scientific Dataset",
          "16,015 clinical patient reports",
          "Source: London Chest Hospital from scientific papers"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Results Adjusted Perplexity",
        "text": [
          "all tokens words numerals"
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Strategy Softmax and Hierarchical Softmax",
        "text": [
          "cat ht s numeral cat mat mat",
          "UNK ht V UNK",
          "h-softmax digit-by-digit from PDF etc. UNKNUM"
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": []
      },
      "9": {
        "title": "Strategy Digit by Digit Composition",
        "text": [],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "10": {
        "title": "Strategy from continuous PDF",
        "text": [],
        "page_nums": [
          21,
          22
        ],
        "images": []
      },
      "11": {
        "title": "Overview of Strategies",
        "text": [],
        "page_nums": [
          23,
          24
        ],
        "images": []
      },
      "12": {
        "title": "Results Language Modelling 1",
        "text": [
          "(lower is better) softmax h-softmax d-RNN MoG combination"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "13": {
        "title": "Results Language Modelling 2",
        "text": [
          "softmax h-softmax d-RNN MoG combination (lower is better)"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "14": {
        "title": "Results Number Prediction",
        "text": [
          "(lower is better) mean median softmax h-softmax d-RNN MoG combination",
          "Clinical mean softmax d-RNN combination"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": []
      },
      "15": {
        "title": "Softmax versus Hierarchical Softmax",
        "text": [
          "cosine similarities softmax h-softmax"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "16": {
        "title": "Analysis d RNN and Benfords Law",
        "text": [
          "1st digit 4th digit",
          "cosine similarities d-RNN d-RNN Benford"
        ],
        "page_nums": [
          30,
          31
        ],
        "images": [
          "figure/image/953-Figure4-1.png"
        ]
      },
      "17": {
        "title": "Analysis Model Predictions",
        "text": [],
        "page_nums": [
          32
        ],
        "images": []
      },
      "18": {
        "title": "Analysis Strategy Selection",
        "text": [
          "Small integers, percentiles, years",
          "2-digit integers, some ids",
          "HIP and GL reals, some ids"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "19": {
        "title": "Conclusion 1",
        "text": [
          "Are existing LMs numerate? Johns height is ___"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "20": {
        "title": "Conclusion 2",
        "text": [
          "the numeracy of LMs?",
          "Johns height is ___"
        ],
        "page_nums": [
          36,
          37
        ],
        "images": []
      }
    },
    "paper_title": "Numeracy for Language Models: Evaluating and Improving their Ability to Predict Numbers"
  },
  "954": {
    "slides": {
      "0": {
        "title": "Syntax in Statistical Machine Translation",
        "text": [
          "Translation Model vs Language Model",
          "Syntactic LM Decoder Integration Results Questions?"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Syntax in the Language Model",
        "text": [
          "Translation Model vs Language Model",
          "Syntactic LM Decoder Integration Results Questions?",
          "An incremental syntactic language model uses an incremental statistical parser to define a probability model over the dependency or phrase structure of target language strings.",
          "Phrase-based decoder produces translation in the target language incrementally from left-to-right",
          "Phrase-based syntactic LM parser should parse target language hypotheses incrementally from left-to-right",
          "Galley & Manning (2009) obtained 1-best dependency parse using a greedy dependency parser",
          "We use a standard HHMM parser (Schuler et al., 2010)",
          "Engineering simple model, equivalent to PPDA",
          "Algorithmic elegant fit into phrase-based decoder",
          "Cognitive nice psycholinguistic properties"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "2": {
        "title": "Incremental Parsing",
        "text": [
          "DT NN VP PP",
          "The president VB NP IN NP",
          "meets DT NN on Friday NP/NN NN VP/NP DT board",
          "Motivation Decoder Integration Results Questions?",
          "the president VB NP VP/NN",
          "Transform right-expanding sequences of constituents into left-expanding sequences of incomplete constituents",
          "NP VP S/NP NP",
          "the board DT president VB the",
          "Incomplete constituents can be processed incrementally using a",
          "Hierarchical Hidden Markov Model parser. (Murphy & Paskin, 2001; Schuler et al."
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14
        ],
        "images": [
          "figure/image/954-Figure2-1.png"
        ]
      },
      "3": {
        "title": "Incremental Parsing using HHMM Schuler et al 2010",
        "text": [
          "Hierarchical Hidden Markov Model",
          "Circles denote hidden random variables",
          "Edges denote conditional dependencies",
          "NP/NN NN VP/NP DT board",
          "Isomorphic Tree Path DT president VB the",
          "Shaded circles denote observed values",
          "Motivation Decoder Integration Results Questions?",
          "Analogous to Maximally Incremental",
          "e1 =The e2 =president e3 =meets e4 =the e5 =board e =on e7 =Friday",
          "Push-Down Automata NP VP/NN NN"
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "4": {
        "title": "Phrase Based Translation",
        "text": [
          "Der Prasident trifft am Freitag den Vorstand",
          "The president meets the board on Friday",
          "s president president Friday",
          "s that that president Obama met",
          "AAAAAA EAAAAA EEAAAA EEIAAA",
          "s s the the president president meets",
          "Stack Stack Stack Stack",
          "Motivation Syntactic LM Results Questions?"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "5": {
        "title": "Phrase Based Translation with Syntactic LM",
        "text": [
          "represents parses of the partial translation at node h in stack t",
          "s president president Friday",
          "s that that president Obama met",
          "AAAAAA EAAAAA EEAAAA EEIAAA",
          "s s the the president president meets",
          "Stack Stack Stack Stack",
          "Motivation Syntactic LM Results Questions?"
        ],
        "page_nums": [
          36,
          37
        ],
        "images": [
          "figure/image/954-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Integrate Parser into Phrase based Decoder",
        "text": [
          "EAAAAA EEAAAA EEIAAA EEIIAA",
          "s the the president president meets meets the",
          "Motivation Syntactic LM Results Questions?",
          "president meets the board"
        ],
        "page_nums": [
          38,
          39
        ],
        "images": [
          "figure/image/954-Figure6-1.png"
        ]
      },
      "7": {
        "title": "Direct Maximum Entropy Model of Translation",
        "text": [
          "e argmax exp jhj(e,f)",
          "h Distortion model n-gram LM",
          "Set of j feature weights",
          "Syntactic LM P( th)",
          "AAAAAA EAAAAA EEAAAA EEIAAA",
          "s s the the president president meets",
          "Stack Stack Stack Stack",
          "Motivation Syntactic LM Results Questions?"
        ],
        "page_nums": [
          40
        ],
        "images": [
          "figure/image/954-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Does an Incremental Syntactic LM Help Translation",
        "text": [
          "but will it make my BLEU score go up?",
          "Motivation Syntactic LM Decoder Integration Questions?",
          "Moses with LM(s) BLEU",
          "Using n-gram LM only",
          "Using n-gram LM + Syntactic LM",
          "NIST OpenMT 2008 Urdu-English data set",
          "Moses with standard phrase-based translation model",
          "Tuning and testing restricted to sentences 20 words long",
          "Results reported on devtest set",
          "n-gram LM is WSJ 5-gram LM"
        ],
        "page_nums": [
          41,
          45,
          46,
          47
        ],
        "images": []
      },
      "9": {
        "title": "Perplexity Results",
        "text": [
          "Language models trained on WSJ Treebank corpus",
          "Motivation Syntactic LM Decoder Integration Questions?",
          "WSJ 5-gram + WSJ SynLM",
          "...and n-gram model for larger English Gigaword corpus.",
          "Gigaword 5-gram + WSJ SynLM"
        ],
        "page_nums": [
          42,
          43,
          44
        ],
        "images": []
      },
      "10": {
        "title": "Summary",
        "text": [
          "Straightforward general framework for incorporating any",
          "Incremental Syntactic LM into Phrase-based Translation",
          "We used an Incremental HHMM Parser as Syntactic LM",
          "Syntactic LM shows substantial decrease in perplexity on out-of-domain data over n-gram LM when trained on same data",
          "Syntactic LM interpolated with n-gram LM shows even greater decrease in perplexity on both in-domain and out-of-domain data, even when n-gram LM is trained on substantially larger corpus",
          "+1 BLEU on Urdu-English task with Syntactic LM",
          "All code is open source and integrated into Moses",
          "Motivation Syntactic LM Decoder Integration Results"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "11": {
        "title": "This looks a lot like CCG",
        "text": [
          "Our parser performs some CCG-style operations:",
          "Type raising in conjunction with forward function composition",
          "Motivation Syntactic LM Decoder Integration Results"
        ],
        "page_nums": [
          50
        ],
        "images": []
      },
      "12": {
        "title": "Why not just use CCG",
        "text": [
          "No probablistic version of incremental CCG",
          "Our parser is constrained",
          "(we dont have backward composition)",
          "We do use those components of CCG (forward function application and forward function composition) which are useful for probabilistic incremental parsing",
          "Motivation Syntactic LM Decoder Integration Results"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "13": {
        "title": "Speed Results",
        "text": [
          "Mean per-sentence decoding time",
          "Parser beam sizes are indicated for the syntactic LM",
          "Parser runs in linear time, but were parsing all paths through the Moses lattice as they are generated by the decoder",
          "More informed pruning, but slower decoding",
          "Motivation Syntactic LM Decoder Integration Results"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "14": {
        "title": "Phrase Based Translation w ntactic",
        "text": [
          "e string of n target language words e1. . .en",
          "et the first t words in e, where tn",
          "t set of all incremental parses of et",
          "def t subset of parses t that remain after parser pruning",
          "e argmax P( e) t1 t",
          "Motivation Syntactic LM Decoder Integration Results"
        ],
        "page_nums": [
          53
        ],
        "images": []
      }
    },
    "paper_title": "Incremental Syntactic Language Models for Phrase-based Translation"
  },
  "955": {
    "slides": {
      "0": {
        "title": "Background Semantic Hashing",
        "text": [
          "Fast and accurate similarity search (i.e., finding documents from a large corpus that are most similar to a query of interest) is at the core of many information retrieval applications;",
          "One strategy is to represent each document as a continuous vector: such as Paragraph",
          "Cosine similarity is typically employed to measure relatedness;",
          "Semantic hashing is an effective approach: the similarity between two documents can be evaluated by simply calculating pairwise Hamming distances between hashing (binary) codes;"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation and contributions",
        "text": [
          "Existing semantic hashing approaches typically require two-stage training procedures (e.g. continuous representations are crudely binarized after training);",
          "Vast amount of unlabeled data is not fully leveraged for learning binary document representations.",
          "we propose a simple and generic neural architecture for text hashing that learns binary latent codes for documents, which be trained an end-to-end manner;",
          "We leverage a Neural Variational Inference (NVI) framework, which introduces data-dependent noises during training and makes effective use of unlabeled information."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Framework components Hashing under the NVI Framework",
        "text": [
          "Notations: let x and z denote the input document and its corresponding binary hash code, respectively;",
          "We define a generative model that simultaneously accounts for both the encoding distribution, p(z |x), and decoding distribution, p(x |z),",
          "x <latexit sha1_base64=\"wrYRrS9nqr2/jTKdHNfdRLtLB0k=\">AAAB53icbVBNS8NAEJ3Ur1q/qh69LBbBU0lFUG9FLx5bMLbQhrLZTtq1m03Y3Ygl9Bd48aDi1b/kzX/jts1BWx8MPN6bYWZekAiujet+O4WV1bX1jeJmaWt7Z3evvH9wr+NUMfRYLGLVDqhGwSV6hhuB7UQhjQKBrWB0M/Vbj6g0j+WdGSfoR3QgecgZNVZqPvXKFbfqzkCWSS0nFcjR6JW/uv2YpRFKwwTVulNzE+NnVBnOBE5K3VRjQtmIDrBjqaQRaj+bHTohJ1bpkzBWtqQhM/X3REYjrcdRYDsjaoZ60ZuK/3md1ISXfsZlkhqUbL4oTAUxMZl+TfpcITNibAllittbCRtSRZmx2ZRsCLXFl5eJd1a9qrrN80r9Ok+jCEdwDKdQgwuowy00wAMGCM/wCm/Og/PivDsf89aCk88cwh84nz9UTYzP</latexit> log x",
          "We define approximations q(z |x) and q(x |z) via inference and generative networks, parameterized by and , respectively."
        ],
        "page_nums": [
          3
        ],
        "images": [
          "figure/image/955-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Framework components Training with Binary Latent Variables",
        "text": [
          "The generative term provides a natural training objective for semantic hashing: with the decoder network modeling p(x |z), the key semantic information from x is naturally encapsulated.",
          "To tailor the NVI framework for semantic hashing, we cast z as a binary latent variable and assume a multivariate Bernoulli prior on z",
          "The encoding (approximate posterior) distribution q(z |x) is restricted to take the form q(z |x) = Bernoulli(h), where h is inferred from x with the encoder network.",
          "We can obtain samples from the Bernoulli posterior either deterministically or stochastically:",
          "Suppose z is a l-bit hash code, the deterministic binarization is defined as (for i l):",
          "stochastic binarization (where i Uniform(0,",
          "To estimate the parameters of the encoder and decoder networks, we maximize a variational lower bound:",
          "The KL-divergence DKL(q(z |x)||p(z)) encourages the approximate posterior q(z |x) to be close to the multivariate Bernoulli prior p(z);",
          "It is challenging to backpropagate gradients through the discrete",
          "(binary) latent variable, since the derivative of the sign function is zero for almost all input values;",
          "Instead, we utilize the straight-through (ST) estimator, which was irst f introduced by [Hinton (2012)]. It simply backpropagates through the hard threshold by approximating the gradient z/(g i(x)) as 1:"
        ],
        "page_nums": [
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Framework components Injecting Data dependent Noise to z",
        "text": [
          "We found that injecting random",
          "Gaussian noise into z makes the decoder a more favorable regularizer for the binary codes;",
          "x <latexit sha1_base64=\"wrYRrS9nqr2/jTKdHNfdRLtLB0k=\">AAAB53icbVBNS8NAEJ3Ur1q/qh69LBbBU0lFUG9FLx5bMLbQhrLZTtq1m03Y3Ygl9Bd48aDi1b/kzX/jts1BWx8MPN6bYWZekAiujet+O4WV1bX1jeJmaWt7Z3evvH9wr+NUMfRYLGLVDqhGwSV6hhuB7UQhjQKBrWB0M/Vbj6g0j+WdGSfoR3QgecgZNVZqPvXKFbfqzkCWSS0nFcjR6JW/uv2YpRFKwwTVulNzE+NnVBnOBE5K3VRjQtmIDrBjqaQRaj+bHTohJ1bpkzBWtqQhM/X3REYjrcdRYDsjaoZ60ZuK/3md1ISXfsZlkhqUbL4oTAUxMZl+TfpcITNibAllittbCRtSRZmx2ZRsCLXFl5eJd1a9qrrN80r9Ok+jCEdwDKdQgwuowy00wAMGCM/wCm/Og/PivDsf89aCk88cwh84nz9UTYzP</latexit> log x",
          "The objective function in (4) can be written in a form similar to the rate-distortion tradeoff:"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/955-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Framework components Extension to Supervised Hashing",
        "text": [
          "While labeled data are available, we can explicitly learn a mapping from latent variable z to labels y , here parametrized by a two-layer",
          "MLP followed by a fully-connected softmax layer.",
          "As a result, the loss function is a combination of variational lower bound and discriminative (cross-entropy) loss:"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Experiments Datasets and Experimental Setup",
        "text": [
          "Datasets: we evaluate the proposed method on three benchmarks:",
          "Reuters21578, 20Newsgroups, TMC (SIAM text mining competition);",
          "TFIDF features are utilized as the input x for documents;",
          "we set the dimension of z i.e., the number of bits within the hashing",
          "We employed precision as the evaluation metric: the percentage of documents among the top 100 retrieved ones that belong to the same label (topic) with the query document."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Experiments Semantic Hashing Evaluation",
        "text": [
          "Table: Precision of the top 100 retrieved documents on Reuters dataset (Unsupervised hashing).",
          "Consistently outperform several strong baseline methods;",
          "Enjoy the attractive property of end-to-end training;",
          "Same observations on other benchmarks."
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/955-Table1-1.png"
        ]
      },
      "8": {
        "title": "Experiments Ablation study",
        "text": [
          "Figure: The precisions of the top 100 retrieved Table: Ablation study with different documents for NASH-DN with stochastic or encoder/decoder networks. deterministic binary latent variables.",
          "Leveraging stochastically sampling during training generalizes better;",
          "Linear decoder networks gives rise to better empirical results."
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/955-Table6-1.png",
          "figure/image/955-Figure3-1.png"
        ]
      },
      "9": {
        "title": "Experiments Qualitative Analysis",
        "text": [
          "Figure: Examples of learned compact hashing codes on 20Newsgroups dataset.",
          "NASH typically compresses documents with shared topics into very similar binary codes."
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/955-Table5-1.png"
        ]
      },
      "10": {
        "title": "Conclusions Take away",
        "text": [
          "This paper presents a first step towards end-to-end semantic hashing;",
          "A neural variational framework is introduced to optimize the hash function during training;",
          "The connections between the proposed method and rate-distortion theory are established."
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing"
  },
  "956": {
    "slides": {
      "0": {
        "title": "Abstract",
        "text": [
          "Emotions, a complex state of feeling results in physical and psychological changes that influence human behavior. Thus, in order to extract the emotional key phrases from psychological texts, here, we have presented a phrase level emotion identification and classification system. The system takes pre- defined emotional statements of seven basic emotion classes",
          "(anger, disgust, fear, guilt, joy, sadness and shame) as input and extracts seven types of emotional trigrams. The trigrams were represented as Context Vectors. Between a pair of",
          "Context Vectors, an Affinity Score was calculated based on the law of gravitation with respect to different distance metrics",
          "(e.g., Chebyshev, Euclidean and Hamming)."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "1": {
        "title": "Introduction",
        "text": [
          "Emotions, a complex state of feeling results in physical and psychological changes that influence human behavior.",
          "Human emotions are the most complex and unique features to be described. If we ask someone regarding emotion, he or she will reply simply that it is a 'feeling'.",
          "Psychological texts contain huge number of emotional words because psychology and emotions are inter-wined, though they are different."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Corpus Preparation",
        "text": [
          "The emotional statements were collected from the ISEAR",
          "(International Survey on Emotion Antecedents and Reactions) database",
          "It is found that only 1096 statements belong to anger, disgust sadness and shame classes whereas the fear, guilt and joy"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Corpus Preparation contd",
        "text": [
          "Each statement may contain multiple sentences, so after sentence tokenization, it is observed that the anger and fear classes contain the maximum number of sentences.",
          "It is observed that the anger class contains the maximum number of tokenized words."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Corpus Statistics",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Context Windows",
        "text": [
          "The tokenized words were grouped to form trigrams in order to grasp the roles of the previous and next tokens with respect to the target token.",
          "(CW) to acquire the emotional phrases."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Context Windows contd",
        "text": [
          "It is considered that, in each of the Context Windows, the first word appears as a non-affect word, second word as an affect word, and third word as a non-affect word (<NAW1>, <AW>,",
          "A few example patterns of the CWs which follows the pattern",
          "and, sorry, just (Shame)"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Statistics",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Similar and Dissimilar NAWs",
        "text": [
          "It was observed that the stop words are mostly present in",
          "<NAW1, AW, NAW2> pattern where similar and dissimilar",
          "NAWs are appeared before and after their corresponding CWs."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Similar and Dissimilar NAWs contd",
        "text": [
          "NAW1= Non Affect Word1; AW=Affect Word; NAW2=Non Affect Word2"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Context Vector Formation",
        "text": [
          "In order to identify whether the Context Windows (CWs) play any significant role in classifying emotions or not, we have mapped the Context Windows in a Vector space by representing them as vectors."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Vector Formation Formula",
        "text": [],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Context Vector Formation contd",
        "text": [
          "T= Total count of CW in an emotion class",
          "#NAW1 = Total occurrence of a non affect word in NAW1 position"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Affinity Score Calculation",
        "text": [
          "An Affinity Score was calculated for each pair of",
          "respect to each of the emotion classes."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "14": {
        "title": "Affinity Score Calculation contd",
        "text": [
          "The final Score is calculated using the following gravitational formula as described in (Poria et al.,",
          "Score p q dist p , q",
          "The Score of any two context vectors p and q of an emotion class is the dot product of the vectors divided by the square of distance (dist) between p and q. This score was inspired by",
          "Newtons law of gravitation. This score values reflect the affinity between two context vectors p and q. Higher score implies higher affinity between p and q."
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "15": {
        "title": "Affinity Scores using Distance Metrics",
        "text": [
          "In the vector space, it is needed to calculate how close the context vectors are in the space in order to conduct better classification into their respective emotion classes. The Score values were calculated for all the emotion classes with respect to different metrics of distance (dist) viz. Chebyshev,"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Distance Metrics",
        "text": [
          "Chebyshev distance (Cd) = max |xi yi | where xi and yi represents two vectors.",
          "Euclidean distance (Ed) = ||x y||2 for vectors x and y.",
          "Hamming distance (Hd) = (c01 c10) / n where cij is the number of occurrence in the boolean vectors x and y and x[k] = i and y[k] = j for k < n. Hamming distance denotes the proportion of disagreeing components in x and y."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "17": {
        "title": "POS Tagged Context Windows and POS Tagged Windows",
        "text": [
          "The sentences were POS tagged using the Stanford POS",
          "Tagger and the POS tagged Context Windows were extracted and termed as PTCW. Similarly, the POS tag sequence from each of the PTCWs were extracted and named each as POS"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "18": {
        "title": "Count of CW PTCW PTW",
        "text": [
          "Figurel:Count of CW,PTCW and PTW",
          "= No of POS tagged Context Window(CW)",
          "= No of Unique POS tagged Context Window(CW)",
          "= No of Unique PTW",
          "Anger Disgust Fear Guilt Joy Sadness Shame Emotions"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "19": {
        "title": "Total Count of CW PTCW PTW",
        "text": [
          "Figure 2:Total Count of CW,PTCW and PTW",
          "Total CW Totla PTCW Total PTW Different windows"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "20": {
        "title": "TF and TF IDF Measure",
        "text": [
          "The Term Frequencies (TFs) and the Inverse Document",
          "Frequencies (IDFs) of the CWs for each of the emotion classes were calculated. In order to identify different ranges of the TF and TF-IDF scores, the minimum and maximum values of the",
          "TF and the variance of TF were calculated for each of the"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "21": {
        "title": "TF Range of CW PTCW PTW",
        "text": [],
        "page_nums": [
          28
        ],
        "images": []
      },
      "22": {
        "title": "Tf IDF Range of CW PTCW PTW",
        "text": [],
        "page_nums": [
          29
        ],
        "images": []
      },
      "23": {
        "title": "Ranking Score of CW",
        "text": [
          "A ranking score was calculated for each of the context windows. Each of the words in a context window was searched in the SentiWordNet lexicon and if found, we considered either positive or negative or both scores. The summation of the absolute scores of all the words in a Context",
          "Window is returned. The returned scores were sorted so that, in windows obtains a emotion class. turn, rank each of the context in its corresponding",
          "All the ranks were calculated for each emotion class, successively. Examples from the list of top 12 important context windows according to their rank are much anger when (anger), whom love after (happy), felt sad about (sadness) etc."
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "24": {
        "title": "Result Analysis",
        "text": [
          "When Euclidean distance is considered",
          "Classifiers Test Data 10 fold cross validation"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "25": {
        "title": "Result Analysis contd",
        "text": [
          "When Hamming distance is considered",
          "Classifiers Test Data 10 fold cross validation",
          "When Chebyshev distance is considered"
        ],
        "page_nums": [
          32,
          33
        ],
        "images": []
      },
      "26": {
        "title": "Conclusion",
        "text": [
          "In this paper, vector formation was done for each of the",
          "Context Windows; TF and TF-IDF measures were calculated.",
          "The calculated affinity score, depending on the distance values was inspired from Newton's law of gravitation. To classify these CWs, BayesNet, J48, NaivebayesSimple and",
          "DecisionTable classifiers is used."
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "27": {
        "title": "Future Work",
        "text": [
          "In future, we would like to incorporate more number of lexicons to identify and classify emotional expressions.",
          "Moreover, we are planning to include associative learning process to identify some important rules for classification."
        ],
        "page_nums": [
          35
        ],
        "images": []
      }
    },
    "paper_title": "Identification and Classification of Emotional Key Phrases from Psycho- logical Texts"
  },
  "957": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I How far can we go with a language agnostic model?",
          "I We experiment with [Enright and Kondrak, 2007]s parallel document identification",
          "I We adapt the method to the BUCC-2015 Shared task based on two assumptions:",
          "Source documents should be paired 1-to-1 with target documents",
          "We have access to comparable documents in several languages"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Method",
        "text": [
          "I Fast parallel document identification [Enright and Kondrak, 2007]",
          "I Documents = bags of hapax words",
          "I Words = blank separated strings that are 4+ characters long",
          "I Given a document in language A, the document in language B that shares the largest",
          "number of words is considered as parallel",
          "I Works very well for parallel documents",
          "I 80% precision on Wikipedia [Patry and Langlais, 2011]",
          "I We use this approach as baseline for detecting comparable documents"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Improvements using 1 to 1 alignments",
        "text": [
          "I In baseline, document pairs are scored independently",
          "I Multiple source documents are paired to a same target document",
          "I 60% of English pages are paired with multiple pages in French or German",
          "I We remove multiply assigned source documents using pigeonhole reasoning",
          "I From 60% to 11% of multiply assigned source documents"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Improvements using cross lingual information",
        "text": [
          "I Simple document weighting function score ties",
          "I We break the remaining score ties using a third language",
          "I From 11% to less than 4% of multiply assigned source documents"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Experimental settings",
        "text": [
          "I We focus on the French-English and German-English pairs",
          "I The following measures are considered relevant",
          "I Mean Average Precision (MAP)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Results FR EN",
        "text": [
          "Strategy MAP Succ. P@5 MAP Succ. P@5"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Results DE EN",
        "text": [
          "Strategy MAP Succ. P@5 MAP Succ. P@5"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Summary",
        "text": [
          "I Unsupervised, hapax words-based method",
          "I Promising results, about 60% of success using pigeonhole reasoning",
          "I Using a third language slightly improves the performance",
          "I Finding the optimal alignment across the all languages",
          "I Relaxing the hapax-words constraint"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "LINA: Identifying Comparable Documents from Wikipedia"
  },
  "959": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "Information Retrieval (IR) and Recommender Systems (RS) techniques",
          "have been used to address:-",
          "Literature Review (LR) search tasks",
          "Explicit and implicit ad-hoc information needs",
          "Examples of such tasks include",
          "Building a reading list of research papers",
          "Recommending papers based on query logs",
          "Recommending papers based on publication history",
          "Serendipitous discovery of interesting papers and more.",
          "What about recommending papers during manuscript preparation"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Addressed scenarios in mp",
        "text": [
          "Recommending papers based on Citation Contexts in manuscripts",
          "Recommending new papers based on To-Be-Cited papers from the",
          "Recommending papers based on the full text of the draft",
          "What more could be done?",
          "Explore the total list of papers compiled during literature review",
          "Explore the article-type preference to vary recommendations correspondingly?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Enter rec4lrw",
        "text": [
          "Rec4LRW is a task-based assistive system that offers",
          "recommendations for the below tasks:-",
          "Task 1 Building an initial reading list of research papers",
          "Task 2 Finding similar papers based on a seed set of papers",
          "Task 3 Shortlisting papers from the final reading list based on",
          "The system is based on a threefold intervention framework",
          "For better meeting the task requirements",
          "Novel informational display features",
          "For speeding up the relevance judgement decisions",
          "For establishing the natural relationships between tasks"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Rec4lrw usage sequence",
        "text": [
          "Select papers from Task 2 to the final reading list",
          "N Execute Task 3 with the final reading list papers"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Corpus",
        "text": [
          "ACM DL extract of papers published between 1951 and 2011 used as",
          "AnyStyle (https://anystyle.io) parser used to extract article title, venue",
          "and year from references",
          "Data stored in a MySQL database with the tables related using a"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Task objective and steps",
        "text": [
          "OBJECTIVE: To identify the important papers from the final reading list",
          "and vary recommendations count based on article-type preference",
          "Input: P set of papers in the final reading list",
          "AT article-type choice of the user",
          "1: RC the average references count retrieved for AT",
          "2: R list of retrieved citations & references of papers from P",
          "3: G directed sparse graph created with papers from R",
          "4: run edge betweenness algorithm on G to form cluster set C 5: S final list of shortlisted papers 6: if |C| > RC then while |S = RC for each cluster in C do sort papers in the cluster on citation count s top ranked paper from the cluster add s to S end for end while 14: else N while |S = RC N N +1 for each cluster in C do sort papers in the cluster on citation count s N ranked paper from the cluster add s to S end for end while 24: end if 25: display papers from S to user"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "User evaluation study",
        "text": [
          "OBJECTIVE: To ascertain the usefulness and effectiveness",
          "of the task to researchers",
          "Ascertain the agreement percentages of the evaluation",
          "Relevance The shortlisted papers are relevant to my article-type preference",
          "Usefulness The shortlisted papers are useful for inclusion in my manuscript",
          "Importance The shortlisted papers comprises of important papers from my reading list",
          "Certainty The shortlisted list comprises of papers which I would definitely cite in my manuscript Good_List This is a good recommendation list, at an overall level Improvement_Needed There is a need to further improve this shortlisted papers list",
          "Shortlisting_Feature I would like to see the feature of shortlisting papers from reading list based on article-type preference, in academic search systems and databases",
          "Identify the top preferred and critical aspects of the task",
          "through the subjective feedback of the participants",
          "Feedback responses were coded by a single coder using an inductive approach"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Study information",
        "text": [
          "The study was conducted between November 2015 and January 2016",
          "Pre-screening survey conducted to identify participants who have authored at",
          "least one journal or conference paper",
          "116 participants completed the whole study inclusive of the three tasks in the",
          "57 participants were Ph.D./Masters students while 59 were research staff,",
          "academic staff and librarians",
          "The average research experience for students was 2 years while for staff, it",
          "51% of participants were from the computer science, electrical and electronics disciplines, 35% from information and communication studies discipline while 14% from other disciplines"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Study procedure",
        "text": [
          "Step Participant selects one of the available 43 topics for executing task 1",
          "Step Re-run task 1 and select at least five papers for the seed basket",
          "Step Execute task 2 with the seed basket papers",
          "Step Re-run task 2 (and task 1) to select at least 30 papers for the final",
          "Step 5: Execute task 3 with the final reading list papers and article-type",
          "Four article-type choices: conference full paper, poster, case study and a generic research paper"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Screenshots",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Results",
        "text": [
          "Biggest differences found for the below measures:-",
          "The measures with the highest agreement:-"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/959-Figure2-1.png"
        ]
      },
      "11": {
        "title": "Qualitative feedback",
        "text": [
          "Rank Preferred Aspects Categories Critical Aspects Categories",
          "Shortlisting Feature & Rec. Quality (24%) Rote Selection of Papers (16%)",
          "Information Cue Labels (15%) Limited Dataset Issue (5%)",
          "View Papers in Clusters (11%) Quality can be Improved (5%)",
          "Rich Metadata (7%) Not Sure of the Usefulness of the Task (4%)",
          "Ranking of Papers (3%) UI can be Improved (3%)",
          "The newly introduced informational display features were a big hit",
          "The purely experimental nature of the study affected the experience of",
          "Tasks effectiveness needs to be validated with a longitudinal study with a large collection of papers in the final reading list"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Limitations",
        "text": [
          "Lack of an offline evaluation experiment",
          "Study procedure involved selection of comparatively fewer number of papers",
          "in the final reading list",
          "Not much variations in the final shortlisted papers for the different article-type",
          "Information displayed in a purely textual manner"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Future work",
        "text": [
          "The scope for this task will be expanded to bring in more variations for the",
          "Inclusion of new papers in the output which could have been missed during",
          "Provide more user control in the system so that the user can select papers as",
          "mandatory to be shortlisted",
          "Integrate this task with the citation context recommendation task",
          "Represent the information in the form of citation graphs"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "What papers should I cite from my reading list? User evaluation of a manuscript preparatory assistive task"
  },
  "960": {
    "slides": {
      "0": {
        "title": "Semantic Similarity Task",
        "text": [
          "Given two texts, rate the degree of equivalence in meaning",
          "Dataset: pairs of text & human annotated similarity, e.g. 0 5 scale",
          "I will give her a ride to work.",
          "I will drive her to the company.",
          "Output: A machine predicts similarity scores for all pairs"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Multi Relational Semantic Similarity Task",
        "text": [
          "Similarity can be defined in different ways, i.e. relations",
          "Some datasets are annotated in multiple relations of similarity",
          "Human Activity: similarity, relatedness, motivation, actor (Wilson",
          "SICK: relatedness, entailment (Marelli et al. 2014)",
          "Typed Similarity: general, author, people, time, location, event, action, subject, description (Agirre et al. 2013)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Human Activity",
        "text": [
          "Similarity: do the two activities describe the same thing?",
          "Relatedness: are the two activities related to one another?",
          "Motivation: are the two activities done with the same motivation?",
          "Actor: are the two activities likely to done by the same person?",
          "Check email vs. write email (scale of 0-4):",
          "Similarity Relatedness Motivation Actor"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Sick",
        "text": [
          "Sentences Involving Compositional Knowledge",
          "Relatedness: are the two texts related to one another? (scale 1-5)",
          "Entailment: does one text entail the other? (three-way)",
          "Two dogs are wrestling and hugging vs. There is no dog wrestling and hugging"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Typed Similarity",
        "text": [
          "A collection of meta-data describing books, paintings, films, museum objects and archival records (scale of 0-5)",
          "Title: London Bridge, City of London",
          "Description: A view of London Bridge which is packed with horse-drawn traffic and pedestrians.",
          "This bridge replaced the earlier medieval bridge upstream. It was built by John Rennie in 1823-31.",
          "A new bridge, built in the late 1960s now stands on this site today.",
          "Title: Serpentine Bridge, Hyde Park, Westminster,",
          "Creator: de Mare, Eric",
          "Subject: Waterscape Animals Bridge Gardens And",
          "Description: The Serpentine Bridge in Hyde Park seen from the bank. It was built by George and John",
          "Rennie, the sons of the geat architect John Rennie, in",
          "general author people time location event subject description"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Existing Model Single Task",
        "text": [
          "Fine-tuning with pre-trained sentence encoder / sentence embeddings",
          "InferSent: Bi-LSTM with max pooling",
          "A logistic regression layer is used as the output layer",
          "All parameters are being tuned during transfer learning",
          "Treats each relation as a single separate task Relation A: LSTM Out",
          "No parameter or information is shared among relations of similarity",
          "Question: can we learn across different relations, by sharing parameters?"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": [
          "figure/image/960-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Proposed Multi Label Model",
        "text": [
          "Same sentence encoder model",
          "All relations share the lower-level parameters in the LSTM",
          "Each relation has its own output layers",
          "Each output layer makes a prediction at the same time",
          "Assuming 2 relations (A and B)",
          "One output layer per relation Relation A: Out",
          "The rest of the parameters are shared between the 2 relations",
          "The 2 losses are summed as the final loss",
          "All parameters in the model are updated"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": [
          "figure/image/960-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Alternative Multi Task Model",
        "text": [
          "Same sentence encoder model",
          "Alternate between batches of different relations",
          "Update the related parameters each time",
          "Assuming 2 relations (A and B) Relation A: Out",
          "Still 2 output layers LSTM",
          "Take a batch of pairs, predict relation A Relation B: Out",
          "Relation A: Out Update parameters",
          "LSTM The Multi-Task model"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": [
          "figure/image/960-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Comparison Between the Models",
        "text": [
          "Relation A: LSTM Out",
          "A: Out A: Out",
          "Multi-Task Learning LSTM LSTM",
          "B: Out B: Out"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Results",
        "text": [
          "means MLL underperforms by a statistically significant margin",
          "Human Activity dataset (Spearmans correlation)",
          "Multi-Label Learning (MLL) setting has the best performance mostly SICK dataset (Pearsons correlation)",
          "Typed-Similarity dataset (Pearsons correlation)"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/960-Table1-1.png",
          "figure/image/960-Table3-1.png"
        ]
      },
      "10": {
        "title": "Discussion and Conclusion",
        "text": [
          "Multi-Label Learning is a simple but effective way to approach multi- relational semantic similarity tasks",
          "Learning from one similarity relation helps with learning another",
          "The idea can be applied to any kind of fine-tuning setting (e.g. graph encoder, language model) used in any multi-label datasets",
          "Further questions and discussions can be directed to Li Zhang"
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Multi-Label Transfer Learning for Multi-Relational Semantic Similarity"
  },
  "961": {
    "slides": {
      "0": {
        "title": "Key point Syntactic Information",
        "text": [
          "To use or not to use?",
          "string-to-string model tree/graph-to-string model"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "Sequence to sequence Model with Attention Mechanism",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "2": {
        "title": "Tree based NMT Change network structure",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "3": {
        "title": "Tree based NMT Change model input",
        "text": [],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "4": {
        "title": "Tree Linearization",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Packed Forest",
        "text": [],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/961-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Forest Linearization",
        "text": [
          "Packed forest is directed acyclic graph, not tree",
          "Fixed traversal order does not exist.",
          "Outputs are not always optimal for MT.",
          "Important information may be lost"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "7": {
        "title": "Data",
        "text": [],
        "page_nums": [
          50
        ],
        "images": [
          "figure/image/961-Table1-1.png"
        ]
      },
      "8": {
        "title": "English Chinese",
        "text": [
          "s2s is the worst",
          "More syntactic information is useful Chinese",
          "No score is the worst English-",
          "Score is useful Chinese",
          "SoA is better than SoE",
          "Adjusting attention is better than adjusting word embedding",
          "Forest is better than 1-best English-",
          "Forest (No score) is worse than 1-best (SoE/SoA)",
          "FS/TN is worse than 1-best (SoE/SoA) English-",
          "Better to use score in linearization Chinese"
        ],
        "page_nums": [
          51,
          52,
          53,
          54,
          55,
          56
        ],
        "images": [
          "figure/image/961-Table3-1.png",
          "figure/image/961-Table2-1.png"
        ]
      },
      "9": {
        "title": "English Japanese",
        "text": [
          "s2s is the worst",
          "No score is the worst",
          "SoA is better than SoE",
          "Forest is better than 1-best",
          "Forest (No score) is worse",
          "FS/TN is worse than 1-best"
        ],
        "page_nums": [
          57
        ],
        "images": [
          "figure/image/961-Table3-1.png"
        ]
      },
      "10": {
        "title": "Merits and Demerits",
        "text": [
          "Use syntactic information explicitly",
          "Simpler model, more information",
          "Robust to parsing errors",
          "Lots of sentences are filtered out due to lengths"
        ],
        "page_nums": [
          58
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [],
        "page_nums": [
          59
        ],
        "images": []
      }
    },
    "paper_title": "Forest-Based Neural Machine Translation"
  },
  "963": {
    "slides": {
      "0": {
        "title": "Why document level machine translation",
        "text": [
          "Most state-of-the-art NMT models translate sentences independently",
          "Discourse phenomena are ignored, e.g., pronominal anaphora and coherence, which may have long-range dependency",
          "Most of the works in document NMT focus on using a few previous sentences as context ignoring the rest of the document",
          "The global document context for MT [Maruf and Haffari, 2018]"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "Why selective attention for document MT",
        "text": [
          "Soft attention over words in the document context",
          "Forms a long-tail absorbing significant probability mass",
          "Incapable of ignoring irrelevant words",
          "Not scalable to long documents"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "2": {
        "title": "This Work",
        "text": [
          "We propose a sparse and hierarchical attention approach for document",
          "identifies the key sentences in the global document context, and",
          "attends to the key words within those sentences"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "3": {
        "title": "Hierarchical Selective Context Attention",
        "text": [
          "For each query word:",
          "s : attention weights given to sentences in context",
          "w : attention weights given to words in context",
          "hier : re-scaled attention weights of words in context",
          "Vw : from words in context"
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "Hierarchical Selective Attention over Source Document",
        "text": [
          "Sparse sentence-level key matching: identify relevant sentences",
          "Qs : representation of words in current sentence Ks : representation of sentences in context",
          "Sparse word-level key matching: identify relevant words in relevant sentences",
          "Qw : representation of words in current sentence Kw : representation of words in context",
          "Read the word-level values with the attention weights"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32
        ],
        "images": [
          "figure/image/963-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Flat Attention over Source Document",
        "text": [
          "Soft sentence-level attention over all sentences in the document context",
          "K V : representation of sentences in context",
          "Comparison to [Maruf and Haffari, 2018]:",
          "Soft word-level attention over all words in the document context",
          "K V : representation of words in context"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
        ],
        "images": [
          "figure/image/963-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Document level Context Layer",
        "text": [
          "Hierarchical selective or Flat",
          "Monolingual context (source) integrated in encoder",
          "Bilingual context (source & target) integrated in decoder"
        ],
        "page_nums": [
          41,
          42,
          43,
          44
        ],
        "images": [
          "figure/image/963-Figure2-1.png",
          "figure/image/963-Figure3-1.png"
        ]
      },
      "7": {
        "title": "Our Models and Settings",
        "text": [
          "Hierarchical Attention over context",
          "sparse at sentence-level, soft at word-level sparse at both sentence and word-level",
          "Flat Attention over context"
        ],
        "page_nums": [
          45,
          46,
          47,
          48,
          49
        ],
        "images": []
      },
      "8": {
        "title": "Experimental Setup",
        "text": [
          "Training/dev/test corpora statistics for En-De:",
          "Domain #Sentences Document length",
          "Context-agnostic baselines (RNNSearch, Transformer)",
          "Local source context baselines for online document MT:",
          "Evaluation Metrics: BLEU, METEOR"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "9": {
        "title": "Bilingual Context integration in Decoder Online Setting",
        "text": [
          "Transformer [Miculicich et al., 2018] Attention(sent) Attention(word) H-Attention(sp-soft) H-Attention(sp-sp)"
        ],
        "page_nums": [
          52,
          53,
          54,
          55,
          56,
          57,
          58
        ],
        "images": []
      },
      "10": {
        "title": "Analyses",
        "text": [
          "Automatic evaluation metrics for translation do not assess how well models translate inter-sentential phenomena",
          "Measure accuracy of translating English pronoun it to its German counterparts es, er and sie using a contrastive test set",
          "Perform subjective evaluation in terms of adequacy and fluency"
        ],
        "page_nums": [
          59,
          60,
          61
        ],
        "images": []
      },
      "11": {
        "title": "Accuracy of pronoun translation vs antecedent distance",
        "text": [
          "Transformer [Miculicich et al., 2018] Attention(sent) Attention(word) H-Attention(sp-soft) H-Attention(sp-sp)"
        ],
        "page_nums": [
          62,
          63,
          64,
          65,
          66
        ],
        "images": []
      },
      "12": {
        "title": "Model Complexity",
        "text": [
          "Model #Params Speed (words/sec.)"
        ],
        "page_nums": [
          67,
          68,
          69,
          70,
          71
        ],
        "images": []
      },
      "13": {
        "title": "Qualitative Analysis",
        "text": [
          "Src: Croatia is their homeland , too .",
          "Tgt: Kroatien ist auch ihre Heimat .",
          "Transformer: Kroatien ist auch seine Heimat .",
          "Our Model: Kroatien ist auch ihr Heimatland .",
          "Head 8: Top sentences with attention to words related to the antecedent",
          "s j1: to name but a few , these include cooperation with the Hague Tribunal efforts",
          "made so far in prosecuting corruption restructuring the economy and finances",
          "and greater commitment and sincerity in eliminating the obstacles to the return",
          "of Croatia s Serbian population",
          "s j4: by signing a border arbitration agreement with its neighbour Slovenia",
          "the new Croatian Government has not only eliminated an obstacle to the",
          "negotiating process but has also paved the way for the resolution of other",
          "Src: my thoughts are also with the victims .",
          "Our Model: meine Gedanken sind auch bei den Opfern .",
          "Transformer: ich denke auch an die Opfer .",
          "Head 2: Top sentences with attention to related words",
          "s j2: ( FR ) Madam President , many things have already been said , but I would",
          "like to echo all the words of sympathy and support that have already been",
          "addressed to the peoples of Tunisia and Egypt",
          "s j+4: it must implement a strong strategy towards these countries",
          "s j1: they are a symbol of hope for all those who defend freedom"
        ],
        "page_nums": [
          72,
          73,
          74,
          75,
          76,
          86,
          87
        ],
        "images": []
      },
      "14": {
        "title": "Summary",
        "text": [
          "Proposed a novel and scalable top-down approach to hierarchical attention for document NMT",
          "Our experiments in two document MT settings show that our approach surpasses context-agnostic and context-aware baselines in majority cases",
          "Investigate benefits of sparse attention in terms of better interpretability of context-aware NMT models"
        ],
        "page_nums": [
          78,
          79,
          80
        ],
        "images": []
      },
      "15": {
        "title": "Implementation and Hyperparameters",
        "text": [
          "DyNet C++ interface [Neubig et al., 2017], using Transformer-DyNet"
        ],
        "page_nums": [
          83
        ],
        "images": []
      },
      "16": {
        "title": "Monolingual Context Integration in Encoder",
        "text": [],
        "page_nums": [
          84
        ],
        "images": [
          "figure/image/963-Figure2-1.png",
          "figure/image/963-Figure3-1.png"
        ]
      },
      "17": {
        "title": "Bilingual Context Integration in Decoder",
        "text": [],
        "page_nums": [
          85
        ],
        "images": [
          "figure/image/963-Figure2-1.png",
          "figure/image/963-Figure3-1.png"
        ]
      }
    },
    "paper_title": "Selective Attention for Context-aware Neural Machine Translation"
  },
  "964": {
    "slides": {
      "0": {
        "title": "Sentence Representation in Conversations",
        "text": [
          "Traditional System: hand-crafted semantic frame",
          "Not scalable to complex domains",
          "Neural dialog models: continuous hidden vectors",
          "Directly output system responses in words",
          "Hard to interpret & control",
          "[Ritter et al 2011, Vinyals et al"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Why discrete sentence representation",
        "text": [
          "1. Inrepteablity & controbility & multimodal distribution",
          "2. Semi-supervised Learning [Kingma et al 2014 NIPS, Zhou et al 2017 ACL]",
          "3. Reinforcement Learning [Wen et al 2017]",
          "X = What time do you want to travel?",
          "Model Z1Z2Z3 Encoder Decoder"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Baseline Discrete Variational Autoencoder VAE",
        "text": [
          "M discrete K-way latent variables z with RNN recognition & generation network.",
          "Reparametrization using Gumbel-Softmax [Jang et al., 2016; Maddison et al., 2016]",
          "M discrete K-way latent variables z with GRU encoder & decoder.",
          "FAIL to learn meaningful z because of posterior collapse (z is constant regardless of x)",
          "MANY prior solution on continuous VAE, e.g. (not exhaustive), yet still open-ended question",
          "KL-annealing, decoder word dropout [Bowman et a2015] Bag-of-word loss [Zhao et al 2017] Dilated CNN decoder"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": [
          "figure/image/964-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Anti Info Nature in Evidence Lower Bound ELBO",
        "text": [
          "Write ELBO as an expectation over the whole dataset",
          "Expand the KL term, and plug back in:",
          "Minimize I(Z, X) to 0",
          "Posterior collapse with powerful decoder."
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Discrete Information VAE DI VAE",
        "text": [
          "A natural solution is to maximize both data log likelihood & mutual information.",
          "Match prior result for continuous VAE. [Mazhazni et al 2015, Kim et al 2017]",
          "Propose Batch Prior Regularization (BPR) to minimize KL [q(z)||p(z)] for discrete latent",
          "Fundamentally different from KL-annealing, since"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Learning from Context Predicting DI VST",
        "text": [
          "Skip-Thought (ST) is well-known distributional sentence representation [Hill et al 2016]",
          "The meaning of sentences in dialogs is highly contextual, e.g. dialog acts.",
          "We extend DI-VAE to Discrete Information Variational Skip Thought (DI-VST)."
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/964-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Integration with Encoder Decoders",
        "text": [
          "Policy Network z P(z|c)",
          "Recognition Network z Generator",
          "Optional: penalize decoder if generated x not exhibiting z [Hu et al 2017]"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Evaluation Datasets",
        "text": [
          "a. Past evaluation dataset for text VAE [Bowman et al 2015]",
          "Stanford Multi-domain Dialog Dataset (SMD) [Eric and Manning 2017]",
          "a. 3,031 Human-Woz dialog dataset from 3 domains: weather, navigation & scheduling.",
          "Switchboard (SW) [Jurafsky et al 1997]",
          "a. 2,400 human-human telephone non-task-oriented dialogues about a given topic.",
          "a. 13,188 human-human non-task-oriented dialogs from chat room."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "The Effectiveness of Batch Prior Regularization BPR",
        "text": [
          "DAE: Autoencoder + Gumbel Softmax",
          "DVAE: Discrete VAE with ELBO loss",
          "DI-VAE: Discrete VAE + BPR",
          "DST: Skip thought + Gumbel Softmax",
          "DI-VST: Variational Skip Thought + BPR Table 1: Results for various discrete sentence representations."
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": [
          "figure/image/964-Table1-1.png"
        ]
      },
      "9": {
        "title": "How large should the batch size be",
        "text": [
          "When batch size N = 0",
          "A large batch size leads to",
          "more meaningful latent action z",
          "I(x,z) is not the final goal"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/964-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Intropolation in the Latent Space",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "11": {
        "title": "Differences between DI VAE DI VST",
        "text": [
          "DI-VAE cluster utterances based on the",
          "More error-prone since harder to predict",
          "Utterance used in the similar context",
          "Easier to get agreement."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "Interpreting Latent Actions",
        "text": [
          "M=3, K=5. The trained R will map any utterance into a1 -a2 -a3 . E.g. How are you?",
          "Automatic Evaluation on SW & DD",
          "Compare latent actions with",
          "The higher the more correlated",
          "Human Evaluation on SMD",
          "Expert look at 5 examples and give a",
          "name to the latent actions",
          "5 workers look at the expert name and",
          "Select the ones that match the expert"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": [
          "figure/image/964-Table3-1.png",
          "figure/image/964-Table4-1.png"
        ]
      },
      "13": {
        "title": "Predict Latent Action by the Policy Network",
        "text": [
          "Provide useful measure about the",
          "complexity of the domain.",
          "Usr > Sys & Chat > Task",
          "Predict latent actions from DI-VAE is harder",
          "than the ones from DI-VST",
          "Two types of latent actions has their own",
          "pros & cons. Which one is better is"
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/964-Table7-1.png"
        ]
      },
      "14": {
        "title": "Interpretable Response Generation",
        "text": [
          "Examples of interpretable dialog",
          "First time, a neural dialog system"
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/964-Table8-1.png"
        ]
      },
      "15": {
        "title": "Conclusions and Future Work",
        "text": [
          "An analysis of ELBO that explains the posterior collapse issue for sentence VAE.",
          "DI-VAE and DI-VST for learning rich sentence latent representation and integration",
          "Learn better context-based latent actions",
          "Encode human knowledge into the learning process.",
          "Learn structured latent action space for complex domains.",
          "Evaluate dialog generation performance in human-study."
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "16": {
        "title": "Semantic Consistency of the Generation",
        "text": [
          "Use the recognition network as a classifier to",
          "predict the latent action z based on the",
          "Report accuracy by comparing z and z.",
          "DI-VAE has higher consistency than DI-VST",
          "L helps more in complex domain attr",
          "L helps DI-VST more than DI-VAE attr",
          "DI-VST is not directly helping generating x",
          "ST-ED doesnt work well on SW due to complex",
          "Spoken language and turn taking"
        ],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/964-Table6-1.png"
        ]
      },
      "17": {
        "title": "What defines Interpretable Latent Actions",
        "text": [
          "Definition: Latent action is a set of discrete variable that define the high-level attributes of",
          "an utterance (sentence) X. Latent action is denoted as Z.",
          "Z should capture salient sentence-level features about the response X.",
          "The meaning of latent symbols Z should be independent of the context C.",
          "If meaning of Z depends on C, then often impossible to interpret Z",
          "Since the possible space of C is huge!",
          "Conclusion: context-independent semantic ensures each assignment of z has the same",
          "meaning in all context."
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation"
  },
  "965": {
    "slides": {
      "0": {
        "title": "Lemmatization",
        "text": [
          "INST ar celu ar celiem",
          "Latvian: cels (English: road)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Previous work",
        "text": [
          "sentence context helps to lemmatize",
          "ambiguous and unseen words",
          "Bergmanis and Goldwater, 2018"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Ambiguous words",
        "text": [
          "A cels (road): NOUN, sing., ACC",
          "B celis (knee): NOUN, plur., DAT"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Learning from sentences",
        "text": [
          "Lemma annotated sentences are scarce for low resource languages annotating sentences is slow",
          "N types > N (contiguous) tokens"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "N types N tokens",
        "text": [
          "Training on 1k UDT tokens/types"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Types in context",
        "text": [
          "algorithms get smarter computers faster",
          "Bergmanis and Goldwater, 2018"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Proposal Data Augmentation",
        "text": [
          "...to get types in context"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Method Data Augmentation",
        "text": [
          "Inflection cels cela N;LOC;SG",
          "Dzives pedeja cela pavadot musu cels",
          "Context cels cela N;LOC;SG",
          "Lemma cels cela N;LOC;SG"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "Inflection Tables",
        "text": [
          "INST ar celu ar celiem",
          "Latvian: cels (English: road)",
          "ACC celu celiem celus",
          "celt (build) celot (travel) celis (knee)"
        ],
        "page_nums": [
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "9": {
        "title": "Key question",
        "text": [
          "If ambiguous words enforce the use of context:",
          "Is context still useful in the absence of ambiguous forms?"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "10": {
        "title": "Experiments",
        "text": [
          "Train: 1k types from universal dependency corpus",
          "UniMorph in Wikipedia contexts",
          "Estonian, Finnish, Latvian, Polish,",
          "Romanian, Russian, Swedish, Turkish",
          "Metric: type level macro average accuracy",
          "Test: on standard splits of universal dependency corpus"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      },
      "11": {
        "title": "Results Data augmentation",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "12": {
        "title": "Does model learn from context",
        "text": [
          "context vs no context"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "13": {
        "title": "Afix ambiguity wuger",
        "text": [
          "Lemma depends on context:",
          "A if wuger is adjective then lemma could be wug",
          "B if wuger is noun then lemma could be wuger"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "14": {
        "title": "Takeaways conclusions",
        "text": [
          "Despite biased data and divergent lemmatization standards",
          "Type based data augmentation helps",
          "Even without the ambiguous types that enforce the use of context",
          "Model use context to disambiguate affixes of unseen words"
        ],
        "page_nums": [
          23,
          24
        ],
        "images": []
      }
    },
    "paper_title": "Data Augmentation for Context-Sensitive Neural Lemmatization Using Inflection Tables and Raw Text"
  },
  "966": {
    "slides": {
      "0": {
        "title": "What is Automated Essay Scoring AES",
        "text": [
          "Computer produces summative assessment for evaluation",
          "Aim: reduce human workload",
          "AES has been put into practical use by ETS from 1999"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Prompt specific and Independent AES",
        "text": [
          "Most existing AES approaches are prompt-specific",
          "Require human labels for each prompt to train",
          "Can achieve satisfying human-machine agreement",
          "Prompt-independent AES remains a challenge",
          "Only non-target human labels are available"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Challenges in Prompt independent AES",
        "text": [
          "Source Prompts Target Prompt",
          "Learn essays Predict target",
          "Previous approaches learn on source prompts",
          "Domain adaption [Phandi et al. EMNLP 2015] Cross-domain learning [Dong & Zhang, EMNLP",
          "Achieved Avg. QWK = 0.6395 at best with up to 100 labeled target essays",
          "Off-topic: essays written for source prompts are mostly irrelevant"
        ],
        "page_nums": [
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "TDNN A Two stage Deep Neural Network for Prompt",
        "text": [
          "Based on the idea of transductive transfer learning",
          "Learn on target essays",
          "Utilize the content of target essays to rate"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "The Two stage Architecture",
        "text": [
          "Prompt-independent stage: train a shallow model to create pseudo labels on the target prompt",
          "Prompt-dependent stage: learn an end-to-end model to predict essay ratings for the target prompts"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": [
          "figure/image/966-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Prompt independent stage",
        "text": [
          "Train a robust prompt-independent AES model",
          "Learning algorithm: RankSVM for AES",
          "Select confident essays written for the target prompt",
          "Predicted ratings in as negative examples",
          "Predicted ratings in as positive examples",
          "Converted to 0/1 labels",
          "Common sense: 8 is good, <5 is bad"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "Prompt dependent stage",
        "text": [
          "Train a hybrid deep model for a prompt-",
          "An end-to-end neural network with three parts"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "7": {
        "title": "Architecture of the hybrid deep model",
        "text": [
          "Multi-layer structure: Words (phrases) - Sentences Essay"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24
        ],
        "images": [
          "figure/image/966-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Model Training",
        "text": [
          "Training loss: MSE on 0/1 pseudo labels",
          "Validation metric: Kappa on 30% non-target essays",
          "Select the model that can best rate"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "9": {
        "title": "Dataset and Metrics",
        "text": [
          "We use the standard ASAP corpus",
          "8 prompts with >10K essays in total",
          "Prompt-independent AES: 7 prompts are used for training, 1 for testing",
          "Report on common human-machine agreement metrics",
          "Pearsons correlation coefficient (PCC)",
          "Spearmans correlation coefficient (SCC)",
          "Quadratic weighted Kappa (QWK)"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "10": {
        "title": "Baselines",
        "text": [
          "RankSVM based on prompt-independent handcrafted",
          "Also used in the prompt-independent stage in TDNN",
          "Two LSTM layer + linear layer",
          "CNN + LSTM + linear layer"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "11": {
        "title": "RankSVM is the most robust baseline",
        "text": [
          "High variance of DNN models performance on all 8 prompts",
          "Possibly caused by learning on non-target prompts RankSVM appears to be the most stable baseline Justifies the use of RankSVM in the first stage of TDNN"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "12": {
        "title": "Comparison to the best baseline",
        "text": [
          "TDNN outperforms the best baseline on 7 out of 8 prompts Performance improvements gained by learning on the target prompt"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "13": {
        "title": "Average performance on 8 prompts",
        "text": [
          "Method QWK PCC SCC"
        ],
        "page_nums": [
          31,
          32,
          33
        ],
        "images": []
      },
      "14": {
        "title": "Sanity Check Relative Precision",
        "text": [
          "How the quality of pseudo examples affects the performance of",
          "The sanctity of the selected essays, namely, the number of positive",
          "(negative) essays that are better (worse) than all negative (positive)",
          "Such relative precision is at least 80% and mostly beyond 90% on different prompts",
          "TDNN can at least learn",
          "from correct 0/1 labels"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "15": {
        "title": "Conclusions",
        "text": [
          "It is beneficial to learn an AES model on the target prompt",
          "Syntactic features are useful addition to the widely used Word2Vec embeddings",
          "Sanity check: small overlap between pos/neg examples",
          "Prompt-independent AES remains an open problem",
          "TDNN can achieve 0.68 at best"
        ],
        "page_nums": [
          35
        ],
        "images": []
      }
    },
    "paper_title": "TDNN: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring"
  },
  "967": {
    "slides": {
      "0": {
        "title": "Adversarial Attacks Perturbations",
        "text": [
          "Apply a small (indistinguishable) perturbation to the input that elicit large changes in the output",
          "Figure from Goodfellow et al. (2014)"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "Indistinguishable Perturbations",
        "text": [
          "Small perturbations are well defined in vision",
          "Small l2 ~= indistinguishable to the human eye"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Not all Text Perturbations are Equal",
        "text": [
          "Hes very annoying Hes pretty friendly Hes She friendly Hes very freindly",
          "[Different meaning] [Similar meaning] [Nonsensical] [Typo]",
          "Cant expect the model to output the same output!",
          "Why and How you should evaluate adversarial perturbations"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "3": {
        "title": "A Framework for Evaluating Adversarial Attacks",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "4": {
        "title": "Problem Definition",
        "text": [
          "Reference They plow it right back into filing",
          "Original Ils le reinvestissent directement en engageant",
          "Base output They direct it directly by engaging",
          "A dv. src Ilss le reinvestissent dierctement en engagaent plus de proces. Adv. output .. de plus."
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20,
          21,
          22
        ],
        "images": []
      },
      "5": {
        "title": "Source Side Evaluation",
        "text": [
          "Evaluate meaning preservation on the source side",
          "Where is a similarity metric such that",
          "Hes very friendly H es pretty friendly Hes very friendly H es very annoying",
          "Hes very friendly H es pretty friendly Hes very friendly Hes She friendly"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "6": {
        "title": "Target Side Evaluation",
        "text": [
          "Evaluate relative meaning destruction on the target side"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "7": {
        "title": "Successful Adversarial Attacks",
        "text": [
          "Source meaning destruction Target meaning destruction",
          "Destroy the meaning on the target side more than on the source side"
        ],
        "page_nums": [
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "8": {
        "title": "Which similarity metric to use",
        "text": [
          "How would you rate the similarity between the meaning of these two sentences?",
          "6 point scale, details in paper",
          "The meaning is completely different or one of the sentence s is meaningless",
          "The topic is the same but the meaning is different",
          "Some key information is different",
          "The key information is the same but the details differ",
          "Meaning is essentially the same but some expressions are unnatural Meaning is essentially equal and the two sentences are well-formed [Language]",
          "Geometric mean of n-gram precision + length penalty",
          "METEOR [Banerjee and Lavie, 2005]",
          "Word matching taking into account stemming, synonyms, paraphrases...",
          "chrF [Popovic, 2015] Character n-gram F-score"
        ],
        "page_nums": [
          35,
          36,
          37,
          38
        ],
        "images": []
      },
      "9": {
        "title": "Experimental Setting",
        "text": [],
        "page_nums": [
          39
        ],
        "images": []
      },
      "10": {
        "title": "Data and Models",
        "text": [
          "{Czech, German, French} English",
          "Both word and sub-word based models"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "11": {
        "title": "Gradient Based Adversarial Attacks on Text",
        "text": [
          "Idea: Back propagate through the model to score possible substitutions",
          "Le g ros c hien The big dog .",
          "The big dog . <eos>",
          "Idea: Word substitution Adding word vector difference",
          "Use the 1st order approximation to maximize the loss"
        ],
        "page_nums": [
          41,
          42,
          43,
          44,
          45,
          46,
          71
        ],
        "images": []
      },
      "12": {
        "title": "Constrained Adversarial Attacks",
        "text": [],
        "page_nums": [
          47,
          50
        ],
        "images": [
          "figure/image/967-Table1-1.png"
        ]
      },
      "13": {
        "title": "Constrained Adversarial Attacks kNN",
        "text": [
          "Only replace words with 10 nearest neighbors in embedding space",
          "Example from our fren Transformer source embeddings",
          "grand (tall SING+MASC) grands (tall PL+MASC) grande (tall SING+FEM) grandes (tall PL+FEM) gros (fat SING+MASC) grosse (fat SING+FEM) math (math) maths (maths) mathematique (mathematic) mathematiques (mathematics) objective (objective [ADJ] SING+FEM)"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "14": {
        "title": "Constrained Adversarial Attacks CharSwap",
        "text": [
          "Only swap word internal characters to get OOVs",
          "adversarial ad vresa rial",
          "If thats impossible, repeat the last character"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "15": {
        "title": "Choosing an Similarity Metric",
        "text": [
          "Human vs automatic (pearson r):",
          "Humans score original/adversarial outpu t",
          "Compare scores to automatic metric with",
          "(Relative Decrease in chrF)"
        ],
        "page_nums": [
          51,
          52,
          53
        ],
        "images": []
      },
      "16": {
        "title": "Effect of Constraints on Evaluation",
        "text": [
          "a feet eae Unconstrained"
        ],
        "page_nums": [
          54
        ],
        "images": [
          "figure/image/967-Figure1-1.png"
        ]
      },
      "17": {
        "title": "Effect of Constraints on Adversarial Training",
        "text": [
          "Adversarial training training with adversarial examples",
          "= 0: Standard training",
          "= 1 : Training only on adversarial examples",
          "Training with Unconstrained attacks vs CharSwap attacks",
          "Robustness to CharSwap attacks on the validation set",
          "Accuracy on non-adversarial data",
          "Adversarial training better robustness",
          "Accuracy on Non-Adversarial Input",
          "Target chrF on the original test set",
          "Unconstrained attacks hurts accuracy"
        ],
        "page_nums": [
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65
        ],
        "images": []
      },
      "18": {
        "title": "Takeway",
        "text": [
          "How would you rate the similarity between the meaning of these two sentences?",
          "The meaning is complete ly different or one of the sentence s is meaningless",
          "The topic is the same but the meaning is different Some key information is different",
          "When doing adversarial attacks",
          "The key information is th e same but the details differ Meaning is essentially the same but some expressions are unnatural Meaning is essentially eq ual and the two sentences are we ll-formed [Language]",
          "Evaluate meaning preservation on the source side",
          "When doing adversarial training",
          "Consider adding constraints to your attacks",
          "Not only true for seq2seq!",
          "Easily transposed to classification, etc..",
          "Just adapt and accordingly"
        ],
        "page_nums": [
          66,
          67,
          68
        ],
        "images": []
      },
      "19": {
        "title": "Human Evaluation the Gold Standard",
        "text": [
          "Check for semantic similarity and fluency",
          "How would you rate the similarity between the meaning of these two sentences?",
          "The meaning is completely different o r one of the sentences is meaningless",
          "The topic is the same but the meaning is different",
          "Some key information is different",
          "The key information is the same but the details differ",
          "Meaning is essentially the same but some expressions are unnatural",
          "Meaning is essentially equal and the two sentences are well-formed [Language]"
        ],
        "page_nums": [
          72
        ],
        "images": []
      },
      "20": {
        "title": "Example of a Successful Attack",
        "text": [
          "Original Ils le reinvestissent directement en engageant plus de proces.",
          "Adv. src. Ilss le reinvestissent dierctement en engagaent plus de proces.",
          "Ref. They plow it right back into filing more troll lawsuits.",
          "Base output They direct it directly by engaging more cases.",
          "Adv. output .. de plus."
        ],
        "page_nums": [
          73
        ],
        "images": []
      },
      "21": {
        "title": "Example of an Unsuccessful Attack",
        "text": [
          "Original Cetait en Juillet 1969.",
          "Adv. src. Cetiat en Jiullet",
          "Base output This was in July 1969."
        ],
        "page_nums": [
          74
        ],
        "images": []
      }
    },
    "paper_title": "On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models"
  },
  "969": {
    "slides": {
      "0": {
        "title": "Do we really need context",
        "text": [
          "It has 48 columns.",
          "What does it refer to?",
          "Possible translations into Russian:",
          "48 . (masculine or neuter)",
          "What do columns mean?",
          "Under the cathedral lies the antique chapel."
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "1": {
        "title": "Recap antecedent and anaphora resolution",
        "text": [
          "Under the cathedral lies the antique chapel. It has 48 columns.",
          "An antecedent is an expression that gives its meaning to",
          "a proform (pronoun, pro-verb, pro-adverb, etc.)",
          "Anaphora resolution is the problem of resolving references to earlier",
          "or later items in the discourse."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "2": {
        "title": "Context in Machine Translation",
        "text": [
          "focused on handling specific phenomena",
          "directly provide context to an NMT system at training time",
          "what kinds of discourse phenomena are successfully handled",
          "how they are modeled"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "3": {
        "title": "Plan",
        "text": [
          "we introduce a context-aware neural model, which is effective",
          "an d has a sufficiently simple and interpretable interface between Model Archit cture",
          "the context and the rest of the translation model",
          "we analyze the flow of information from the context and identify",
          "Overall performance pr onoun translation as the key phenomenon captured by the",
          "by comparing to automatically predicted or human-annotated Analys s",
          "coreference relations, we observe that the model implicitly"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "4": {
        "title": "Transformer model architecture",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "5": {
        "title": "Context aware model architecture",
        "text": [
          "start with the Transformer [Vaswani et al, 2018]",
          "incorporate context information on the encoder side",
          "use a separate encoder for context",
          "share first N-1 layers of source and context encoders",
          "the last layer incorporates contextual information"
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": [
          "figure/image/969-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Overall performance",
        "text": [
          "Dataset: OpenSubtitles2018 (Lison et al., 2018) for English and Russian"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "7": {
        "title": "Overall performance models comparison",
        "text": [
          "(context is the previous sentence)",
          "concatenation: modification of the",
          "context encoder (our approach by [Tiedemann and work) Scherrer,"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "8": {
        "title": "Our model different types of context",
        "text": [
          "Next sentence does not appear",
          "previous sentence Performance drops for a random",
          "Model is robust towards being",
          "shown a random context",
          "(the only significant at p<0.01 difference is with the best model;",
          "differences between other results are not significant)"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "9": {
        "title": "Analysis",
        "text": [
          "we introduce a context-aware neural model, which is effective",
          "and ha s a sufficiently simple and interpretable interface between Top words influenced by context",
          "the context and the rest of the translation model",
          "we an alyze the flow of information from the context and identify Non-lexical patterns affecting attention",
          "prono un translation as the key phenomenon captured by the to context",
          "by com paring to automatically predicted or human-annotated Latent anaphor resolution",
          "coreference relations, we observe that the model implicitly"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": []
      },
      "10": {
        "title": "What do we mean by attention to context",
        "text": [
          "attention from source to context",
          "mean over heads of per-head attention",
          "take sum over context words",
          "(excluding <bos>, <eos> and punctuation)"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "11": {
        "title": "Top words influenced by context",
        "text": [
          "it Need to know gender, because",
          "yours verbs must agree in gender with I",
          "(in past tense) yes",
          "yes Many of these words appear at",
          "i sentence initial position.",
          "you Maybe this is all that matters?",
          "word pos word pos",
          "Only positions i after the first m"
        ],
        "page_nums": [
          26,
          27,
          28,
          29,
          30,
          31
        ],
        "images": [
          "figure/image/969-Table3-1.png"
        ]
      },
      "12": {
        "title": "Dependence on sentence length",
        "text": [
          "high attention to context"
        ],
        "page_nums": [
          33,
          34,
          35
        ],
        "images": []
      },
      "13": {
        "title": "Is context especially helpful for short sentences",
        "text": [],
        "page_nums": [
          36
        ],
        "images": []
      },
      "14": {
        "title": "Dependence on token position",
        "text": [],
        "page_nums": [
          37
        ],
        "images": []
      },
      "15": {
        "title": "Analysis of pronoun translation",
        "text": [],
        "page_nums": [
          38
        ],
        "images": []
      },
      "16": {
        "title": "Ambiguous pronouns and translation quality how to evaluate",
        "text": [
          "Metric: BLEU (standard metric for MT)",
          "feed CoreNLP (Manning et al., 2014) with pairs of sentences",
          "pick examples with a link between the pronoun and a noun group in a context",
          "gather a test set for each pronoun",
          "use the test sets to evaluate the context-aware NMT system"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "17": {
        "title": "Ambiguous pronouns and translation quality noun antecedent",
        "text": [],
        "page_nums": [
          40
        ],
        "images": []
      },
      "18": {
        "title": "Ambiguous it noun antecedent",
        "text": [
          "masculine feminine neuter plural"
        ],
        "page_nums": [
          41
        ],
        "images": []
      },
      "19": {
        "title": "It with noun antecedent example",
        "text": [
          "It was locked up in the hold with 20 other boxes of supplies.",
          "Possible translations into Russian:",
          "You left money unattended?"
        ],
        "page_nums": [
          42,
          43
        ],
        "images": []
      },
      "20": {
        "title": "Latent anaphora resolution",
        "text": [],
        "page_nums": [
          44
        ],
        "images": []
      },
      "21": {
        "title": "Hypothesis",
        "text": [
          "Large improvements in BLEU on test sets with pronouns",
          "co-referent with an expression in context",
          "Attention mechanism Latent anaphora resolution"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "22": {
        "title": "How to test the hypothesis agreement with CoreNLP",
        "text": [
          "Find an antecedent noun phrase (using CoreNLP)",
          "Pick examples where the noun phrase contains a single noun",
          "Pick examples with several nouns in context",
          "Identify the token with the largest attention weight (excluding punctuation,",
          "If the token falls within the antecedent span, then its an agreement"
        ],
        "page_nums": [
          46,
          47
        ],
        "images": []
      },
      "23": {
        "title": "Does the model learn anaphora",
        "text": [
          "or just some simple heuristic?"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "24": {
        "title": "Agreement with CoreNLP predictions",
        "text": [
          "random first last attention agreement of attention is the",
          "first noun is the best heuristic"
        ],
        "page_nums": [
          49,
          50
        ],
        "images": []
      },
      "25": {
        "title": "Compared to human annotations for it",
        "text": [
          "pick 500 examples from the",
          "ask human annotators to mark",
          "pick examples where an",
          "antecedent is a noun phrase",
          "calculate the agreement with"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "26": {
        "title": "Attention map examples",
        "text": [
          "There was a time I would",
          "have lost my heart to a",
          "And you, no doubt, would"
        ],
        "page_nums": [
          52,
          53,
          54
        ],
        "images": [
          "figure/image/969-Figure5-1.png"
        ]
      },
      "27": {
        "title": "Conclusions",
        "text": [
          "introduce a context-aware NMT system based on the Transformer",
          "the model outperforms both the context-agnostic baseline and a simple",
          "context-aware baseline (on an En-Ru corpus)",
          "pronoun translation is the key phenomenon captured by the model",
          "the model induces anaphora relations"
        ],
        "page_nums": [
          55
        ],
        "images": []
      }
    },
    "paper_title": "Context-Aware Neural Machine Translation Learns Anaphora Resolution"
  },
  "970": {
    "slides": {
      "0": {
        "title": "The task",
        "text": [
          "Why AstraZeneca plc Dixons Carphone PLC Are Red-Hot Growth",
          "Training data: 1142 samples, 960 headlines/sentences.",
          "Testing data: 491 samples, 461 headlines/sentences."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Models",
        "text": [
          "1. Support Vector Regression (SVR) [1]",
          "2. Bi-directional Long Short-Term Memory BLSTM [2][3]"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Pre Processing and Additional data used",
        "text": [
          "Used 189, 206 financial articles (e.g. Financial Times) that were",
          "manually downloaded from Factiva1 to create a Word2Vec model [5]2.",
          "These were created using Gensim3."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Support Vector Regression SVR 1",
        "text": [
          "Features and settings that we changed",
          "1. Tokenisation - Whitespace or Unitok4",
          "2. N-grams - uni-grams, bi-grams and both.",
          "3. SVR settings - penalty parameter C and epsilon parameter."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Word Replacements",
        "text": [
          "AstraZeneca PLC had an improved performance where as Dixons",
          "companyname had an posword performance where as companyname"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Two BLSTM models",
        "text": [
          "Drop out between layers",
          "25 times trained over",
          "Early stopping used to"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "BLSTM Loss function",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "SVR best features",
        "text": [
          "Using uni-grams and bi-grams to be the best. 2.4% improvement",
          "Using a tokeniser always better. Affects bi-gram results the most.",
          "1% improvement using Unitok5 over whitespace.",
          "SVR parameter settings important 8% difference between using",
          "Incorporating the target aspect increased performance. 0.3%",
          "Using all word replacements. N=10 for POS and NEG words and",
          "N=0 for company. 0.8% improvement using company and 0.2% for"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Results across the different metrics",
        "text": [
          "Metric 1 was the final metric used."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Future Work",
        "text": [
          "1. Incorporate aspects into the BLSTMs shown to be useful by Wang",
          "2. Improve BLSTMs by using an attention model Wang et al. [7].",
          "3. Add known financial sentiment lexicon into the LSTM model [6]."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Summary",
        "text": [
          "1. BLSTM outperform SVRs with minimal feature engineering.",
          "2. The future is to incorporate more financial information into the"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Lancaster A at SemEval-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines"
  },
  "971": {
    "slides": {
      "0": {
        "title": "Exploring intellectual structures",
        "text": [
          "Collaboration, Author co-citation analysis,",
          "Journal Impact Factor, SJR",
          "Document citation analysis, Co-word analysis,",
          "Citation sentence: Containing brief content of cited work and opinion",
          "that the author of citing work on the cited work",
          "Topic Model: Adopting Author Conference Topic (ACT) model (Tang, Jin",
          "Oncology: The recent surge in number of publications in this field. Stem",
          "cells, one of the subfields of oncology, has been at the forefront of medicine",
          "Tang, J., Jin, R., & Zhang, J. (2008, December). A topic modeling approach and its integration into the random walk framework for academic search. In Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on (pp. 1055-1060). IEEE."
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Citation Sentence",
        "text": [
          "Embedding useful contents signifying the influence of cited authors on",
          "Being considered as an invisible intellectual place for idea exchanging",
          "Playing a role of supporting and expressing their own arguments by",
          "Exploring the implicit topics resided in citation sentences"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Original ACT Model Tang Jin and Zhang 2008",
        "text": [
          "Purpose of Academic search"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Modified AJT Model",
        "text": [
          "1) Citation Data Extraction",
          "2n d journal Topic 2",
          "Which topic is most salient? Who is the active authors sharing other authors ideas? Which journal leads such endeavor?"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Method",
        "text": [
          "The 77-SNP PRS was associated with a larg er effect",
          "than previously reported for a 10-SNP-PRS (<xref 3) Citing Authors rid=CIT0020 ref-type=bibr> 20 </xref>)."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Data collection",
        "text": [
          "PubMed Central: 6,360 full-text articles",
          "15 journals of Oncology: by Thomson Reuters JCR & journals impact factor",
          "Cancer Cell, Journal of the National Cancer Institute, Leukemia, Oncogene,",
          "Annals of Oncology, Neuro-Oncology, Stem Cells, Oncotarget, OncoInnunology,",
          "Molecular Oncology, Breast Cancer Research Journal of Thoracic Oncology,",
          "Pigment Cell & Melanoma Resaerch, Clinical Epigenetics, Molecular Cancer"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Research Flow",
        "text": [
          "1) Citation Data Extraction"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Results 8 Topics",
        "text": [
          "Labeled by 3 Experts",
          "Author Group 1 Author Group 2 Author Group 3 Author Group 4",
          "Journal Group 1 Journal Group 2 Journal Group 3 Journal Group 4",
          "Research Annals of Oncology",
          "Pigment Cell & Melanoma Research",
          "Journal of Thoracic Oncology"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Results contd",
        "text": [
          "Author Group 5 Author Group 6 Author Group Author Group 8",
          "Journal Group 5 Journal Group 6 Journal Group 7 Journal Group 8",
          "Annals of Oncology Cancer Cell",
          "Annals of Oncology Breast Cancer Research"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "AJT model: to detect leading authors and journals in sub-disciplines",
          "represented by discovered topics in a certain field",
          "Citation sentences: Discovering latent meaning associated citation sentences",
          "and the major players leading the field"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Future works",
        "text": [
          "Comparing the proposed approach with the general topic modeling",
          "Investigating whether there is a different impact of using citation",
          "sentences and general meta-data (abstract and title)",
          "Considering the window size of citation sentences enriching citation"
        ],
        "page_nums": [
          13
        ],
        "images": []
      }
    },
    "paper_title": "Exploring the leading authors and journals in major topics by citation sentences and topic modeling"
  },
  "972": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Extracting cognates for related languages in Romance and",
          "Reducing the number of unknown words on SMT training data",
          "Learning regular differences in words roots/endings shared across related languages"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Method",
        "text": [
          "Produce n-best lists of cognates using a family of distance measures from comparable corpora",
          "Prune the n-best lists by ranking Machine Learning (ML) algorithm trained over parallel corpora",
          "Motivation n-best list allows surface variation on possible cognate translations"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Similarity metrics",
        "text": [
          "Compare words between frequency lists over comparable corpora",
          "L matching between the languages using Levenshtein distance:",
          "L-R Levenshtein distance computed separately for the roots and for the endings: aceito (pt) vs acepto (es) rejeito (pt) vs rechazo (es)",
          "L-C Levenshtein distance over words with similar number of starting characters (i.e. prefix): introducao (pt) vs introduccion (es) introduziu (pt) vs introdujo (es)"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Search space constraints",
        "text": [
          "Motivation Exhaustive method compares all the combinations of source and target words",
          "Order the target side frequency list into bins of similar frequency",
          "Compare each source word with target bins of similar frequency around a window",
          "L-C metric only compares words that share a given n prefix"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Ranking",
        "text": [
          "Motivation Prune n-best lists by ranking ML algorithm",
          "Training data come from aligned parallel corpora where the rank is given by the alignment probability from GIZA++",
          "Simulate cognate training data by pruning pairs of words below a Levenshtein threshold"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Features",
        "text": [
          "Number of times of each edit operation, the model assigns a different weight to each operation",
          "Cosine between the distributional vectors of the source and target words vectors from word2vec mapped to same space via a learned transformation matrix",
          "SVM ranking default configuration (RBF kernel)",
          "Easy-adapt features given different domains (Wikipedia, subtitles)"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Data description",
        "text": [
          "n-best lists from Wikipedia dumps (frequency lists)",
          "ML training Wiki-titles, parallel data from inter language links from the tittles of the Wikipedia articles 500K aligned links (i.e. sentences)",
          "Opensubs, 90K training instances",
          "Zoo proprietary corpus of subtitles produced by professional translators, 20K training instances",
          "Ranking test Heldout data from training",
          "Manual cognate test Wikipedia most frequent words",
          "SMT test Zoo data"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Language pairs",
        "text": [
          "Romance Source: Portuguese, French, Italian Target: Spanish",
          "Slavonic Source: Ukrainian, Bulgarian Target: Russian"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Results on heldout data",
        "text": [
          "Error score on heldout data",
          "E Edit distance features",
          "EC Edit distance plus distributed vectors features",
          "Zoo error% Opensubs error% Wiki-titles error%",
          "Romance pt-es it-es fr-es",
          "Model E Model EC Model E Model EC Model E Model EC"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Manual evaluation",
        "text": [
          "Conclusions Results Machine Translation",
          "Results on sample of 100 words",
          "n-best lists L, L-R, L-C ranking model E",
          "List L List L-R List L-C"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Addition of lists SMT",
        "text": [
          "1-best lists with L-C and E ranking pt-es: 80K training sentences, 100K cognate pairs",
          "significant uk-ru: 140K training sentences, 100K cognate pairs"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Out of vocabulary reduction",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "MT dictionaries extracted from comparable resources for related languages",
          "Positive results on the n-bes lists with L-C",
          "Frequency window heuristic shows poor results",
          "ML models are able to rank similar words on the top of the list",
          "Preliminary results on an SMT system show modest improvements compare to the baseline",
          "The OOV rate shows improvements around reduction on word types"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Future work",
        "text": [
          "Morphology features for the n-best list (Unsupervised)",
          "Instead of prefix heuristic (L-C) and stemmer (L-R)",
          "Contribution for all the produced cognate lists on SMT",
          "Using char-based transliteration model trained on Zoo plus n-best lists",
          "Motivation alignment learns useful transformations: e.g. introducao (pt) vs introduccion (es)"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Obtaining SMT dictionaries for related languages"
  },
  "973": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "User attribute prediction from text is successful:",
          "I Gender (Burger et al. 2011 EMNLP)",
          "I Location (Eisenstein et al. 2010 EMNLP)",
          "I Personality (Schwartz et al. 2013 PLoS One)",
          "I Impact (Lampos et al. 2014 EACL)",
          "I Political Orientation (Volkova et al. 2014 ACL)",
          "I Mental Illness (Coppersmith et al. 2014 ACL)",
          "I Occupation (Preotiuc-Pietro et al. 2015 ACL)",
          "I Income (Preotiuc-Pietro et al. 2015 PLoS One)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "However",
        "text": [
          "Most text prediction methods uncover topical differences",
          "correlation strength relative frequency"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Stylistic differences",
        "text": [
          "We need to be aware of style differences, rather than topical",
          "Not useful for many practical applications that adapt to traits:",
          "I machine translation (Mirkin et al. 2015 EMNLP, Rabinovich et al 2017 EACL)",
          "I agents (e.g. customer service, tutoring)",
          "I controlling for gender or racial bias",
          "One type of stylistic difference is phrase choice in context."
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Data",
        "text": [
          "We study the Big Five personality traits:",
          "I Personality scores obtained through the MyPersonality",
          "I For each trait, take top and bottom 20% of users"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Paraphrasing",
        "text": [
          "Paraphrases alternative ways to convey the same information",
          "I annotated with type and confidence (filter equivalent",
          "paraphrases with >.2 confidence)",
          "I >6M automatically derived paraphrase pairs",
          "I we use only 13 grams",
          "I difference in a pair more than just change of stopwords or",
          "root form of word"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Prediction",
        "text": [
          "Openness Conscientiousness Extraversion Agreeableness Neuroticism",
          "Paraphrases only Phrases w/o paraphrases All Phrases",
          "Accuracy, Naive Bayes, 90-10 training-testing, balanced data"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Quantifying Preference",
        "text": [
          "Within a paraphrase pair (w1,w2), the difference",
          "Extraversion(w1) Extraversion(w2) is the stylistic distance.",
          "Used previously to study paraphrase preference across age, gender and occupational class (Preotiuc-Pietro, Xu & Ungar, AAAI 2016)."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Linguistic Theories",
        "text": [
          "Study which attributes of words in a pair are preferred by one group:",
          "I Word Length in Characters",
          "I Word Length in Syllables",
          "Simple proxies for word complexity",
          "I Affective Norms: Valence, Arousal, Dominance",
          "I Age of Acquisition",
          "I More in the paper ...",
          "Openess Conscientiousness Extraversion Agreeableness Neuroticism",
          "Correlation coefficients between paraphrase pair preference and user group usage."
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "Take Aways",
        "text": [
          "I Stylistic difference between user groups have important",
          "I Paraphrase choice contains valuable information",
          "I Shed light on psycholinguistic theories",
          "I Potential way to generate text perceived to be from a",
          "See our EMNLP 2017 paper (Preotiuc-Pietro, Guntuku, Ungar - Controlling",
          "Human Perception of Basic User Traits)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      }
    },
    "paper_title": "Personality Driven Differences in Paraphrase Preference"
  },
  "974": {
    "slides": {
      "0": {
        "title": "Errors made by keyphrase extraction systems",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "I Most errors are due to over-generation",
          "I System correctly outputs a keyphrase because it contains an important word, but",
          "erroneously predicts other candidates as keyphrases because they contain the same word",
          "I e.g. olympics, olympic movement, international olympic comittee",
          "I Why over-generation errors are frequent?",
          "I Candidates are ranked independently, often according to their component words",
          "I We propose a global inference model to tackle the problem of over-generation errors"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Proposed method",
        "text": [
          "I Weighting candidates vs. weighting component words",
          "I Words are easier to extract, match and weight",
          "I Useful for reducing over-generation errors",
          "I Ensure that the importance of each word is counted only once in the set of keyphrases",
          "I Keyphrases should be extracted as a set rather than independently",
          "I Finding the optimal set of keyphrases combinatorial optimisation problem",
          "I Formulated as an integer linear problem (ILP)",
          "I Solved exactly using off-the-shelf solvers"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "ILP model definition",
        "text": [
          "I Based on the concept-based model for summarization [Gillick and Favre, 2009]",
          "I The value of a set of keyphrases is the sum of the weights of its unique words",
          "Word weights Candidates Olympic games"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "ILP model definition cont",
        "text": [
          "I Let xi and cj be binary variables indicating the presence of word i and candidate j in",
          "the set of extracted keyphrases",
          "wixi Summing over unique word weights",
          "s.t. cj N Number of extracted keyphrases",
          "cjOccij xi, i, j Constraints for consistency",
          "cjOccij xi, i Occij if word i is in candidate j",
          "I By summing over word weights, the model overly favors long candidates",
          "I e.g. olympics < olympic games < modern olympic games",
          "I To correct this bias in the model",
          "Adding constraints to prefer shorter candidates",
          "Adding a regularization term to the objective function"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "5": {
        "title": "Regularization",
        "text": [
          "I Let lj be the size, in words, of candidate j , and substrj the number of times cj occurs",
          "as a subtring in other candidates",
          "candidates that occur frequently as substrings"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Experimental parameters",
        "text": [
          "I Experiments are carried out on the SemEval dataset [Kim et al., 2010]",
          "I Scientific articles from the ACM Digital Library",
          "I Keyphrase candidates are sequences of nouns and adjectives",
          "I Evaluation in terms of precision, recall and f -measure at the top N keyphrases",
          "I Sets of combined author- and reader-assigned keyphrases as reference keyphrases",
          "I Extracted/reference keyphrases are stemmed",
          "I Regularization parameter tuned on the training set"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Word weighting functions",
        "text": [
          "I IDF weights are computed on the training set",
          "I TextRank [Mihalcea and Tarau, 2004]",
          "I Window is sentence, edge weights are co-occurrences",
          "I Logistic regression [Hong and Nenkova, 2014]",
          "I Reference keyphrases in training data are used to generate positive/negative examples",
          "I Features: position first occurrence, TFIDF, presence in first sentence"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Baselines",
        "text": [
          "I norm : ranking candidates using the sum of the weights of their component words",
          "normalized by their lengths",
          "I Redundant keyphrases are pruned from the ranked lists"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Results",
        "text": [
          "Top-5 candidates Top-10 candidates",
          "Weighting + Ranking P R F P R F",
          "TFIDF + sum norm ilp",
          "TextRank + sum norm ilp",
          "Logistic regression + sum norm ilp"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Results cont",
        "text": [
          "Top-5 candidates Top-10 candidates",
          "Method P R F rank P R F rank",
          "Logistic regression + ilp"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Example J 3txt",
        "text": [
          "TFIDF + sum (P advertis bid; certain advertis budget; keyword bid; convex hull landscap; budget optim bid; uniform bid strategi; advertis slot; advertis campaign; ward advertis; searchbas advertis",
          "TFIDF + norm (P advertis; advertis bid; keyword; keyword bid; landscap; advertis slot; advertis cam- paign; ward advertis; searchbas advertis; advertis random",
          "TFIDF + ilp (P click; advertis; uniform bid; landscap; auction; convex hull; keyword; budget optim; single-bid strategi; queri"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "I Proposed ILP model",
          "I Can be applied on top of any word weighting function",
          "I Reduces over-generation errors by weighting candidates as a set",
          "I Substancial improvement over commonly used word-based ranking approaches",
          "I Phrase-based model regularized by word redundancy"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Reducing Over-generation Errors for Automatic Keyphrase Extraction using Integer Linear Programming"
  },
  "975": {
    "slides": {
      "0": {
        "title": "Latent Dirichlet Allocation",
        "text": [
          "David Blei. Probabilistic topic models. Comm. ACM. 2012"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Types of metadata",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Variations and extensions",
        "text": [
          "Author topic model (Rosen-Zvi et al 2004)",
          "Supervised LDA (SLDA; McAuliffe and Blei, 2008)",
          "Dirichlet multinomial regression (Mimno and McCallum, 2008)",
          "Sparse additive generative models (SAGE; Eisenstein et al,",
          "Structural topic model (Roberts et al, 2014)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Desired features of model",
        "text": [
          "Easy modification by end-users.",
          "Covariates: features which influences text (as in SAGE).",
          "Labels: features to be predicted along with text (as in SLDA).",
          "Possibility of sparse topics.",
          "Incorporate additional prior knowledge.",
          "Use variational autoencoder (VAE) style of inference (Kingma"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Desired outcome",
        "text": [
          "Coherent groupings of words (something like topics), with offsets for observed metadata",
          "Encoder to map from documents to latent representations",
          "Classifier to predict labels from from latent representation"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "5": {
        "title": "Model",
        "text": [
          "p( w) i generator network: p(w i) = fg( )",
          "ELBO Eq[log p(words ri DKL[q(ri words)p(ri",
          "encoder network: q( i w) = fe( )"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "6": {
        "title": "Scholar",
        "text": [
          "p(word i ci softmax(d Ti B(topic) cTi B(cov))",
          "Optionally include interactions between topics and covariates",
          "p(yi i ci fy (i ci",
          "log i f(words, ci yi",
          "Optional incorporation of word vectors to embed input"
        ],
        "page_nums": [
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "7": {
        "title": "Optimization",
        "text": [
          "Tricks from Srivastava and Sutton, 2017:",
          "Adam optimizer with high-learning rate to bypass mode collapse",
          "Batch-norm layers to avoid divergence",
          "Annealing away from batch-norm output to keep results interpretable"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "8": {
        "title": "Output of Scholar",
        "text": [
          "B(topic),B(cov): Coherent groupings of positive and negative",
          "deviations from background ( topics)",
          "f, f: Encoder network: mapping from words to topics:",
          "i softmax(fe(words, ci yi",
          "fy : Classifier mapping from i to labels: y fy (i ci"
        ],
        "page_nums": [
          31,
          32,
          33
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation",
        "text": [
          "1. Performance as a topic model, without metadata (perplexity, coherence)",
          "2. Performance as a classifier, compared to SLDA",
          "3. Exploratory data analysis"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "10": {
        "title": "Quantitative results basic model",
        "text": [
          "LDA SAGE NVDM Scholar Scholar Scholar +wv +sparsity"
        ],
        "page_nums": [
          35,
          36,
          37,
          38,
          39,
          40
        ],
        "images": []
      },
      "11": {
        "title": "Classification results",
        "text": [
          "LR SLDA Scholar Scholar (labels) (covariates)"
        ],
        "page_nums": [
          41
        ],
        "images": []
      },
      "12": {
        "title": "Exploratory Data Analysis",
        "text": [
          "Data: Media Frames Corpus (Card et al, 2015)",
          "Collection of thousands of news articles annotated in terms of tone and framing",
          "Relevant metadata: year of publication, newspaper, etc."
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "13": {
        "title": "Tone as a label",
        "text": [
          "english language city spanish community boat desert died men miles coast haitian visas visa applications students citizenship asylum judge appeals deportation court labor jobs workers percent study wages bush border president bill republicans state gov benefits arizona law bill bills arrested charged charges agents operation"
        ],
        "page_nums": [
          43
        ],
        "images": [
          "figure/image/975-Figure2-1.png"
        ]
      },
      "14": {
        "title": "Tone as a covariate with interactions",
        "text": [
          "Base topics Anti-immigration Pro-immigration ice customs agency population born percent judge case court guilty patrol border miles licenses drivers card island story chinese guest worker workers benefits bill welfare criminal customs jobs million illegals guilty charges man patrol border foreign sept visas smuggling federal bill border house republican california detainees detention english newcomers asylum court judge died authorities desert green citizenship card island school ellis workers tech skilled law welfare students"
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "15": {
        "title": "Conclusions",
        "text": [
          "Variational autoencoders (VAEs) provide a powerful framework for latent variable modeling",
          "We use the VAE framework to create a customizable model for documents with metadata",
          "We obtain comparable performance with enhanced flexibility and scalability",
          "Code is available: www.github.com/dallascard/scholar"
        ],
        "page_nums": [
          45
        ],
        "images": []
      }
    },
    "paper_title": "Neural Models for Documents with Metadata"
  },
  "976": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Name pronunciations can be fickle",
          "- Speech synthesis systems must handle them",
          "- Best G2P system can't account for how | decide my name is pronounced",
          "Existing transliterations encode this info",
          "- Ample data that can be easily mined from the"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Objective apply transliterations",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Applying transliterations",
        "text": [
          "Assume existing G2P base systems",
          "- Produce n-best output lists",
          "e Assume available transliteration",
          "Pick candidate output that is most similar to"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Data",
        "text": [
          "~ Provides name annotations",
          "e Transliterations: NEWS Shared Task 2010"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Base systems",
        "text": [
          "- Popular end-to-end speech synthesis",
          "- Generative joint n-grams",
          "- Discriminative phrasal decoding"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Similarity",
        "text": [
          "bey i 00) | t= Tai N an aalsys el Rosse",
          "- ALINE phoneme-to-phoneme aligner score",
          "Rule-based G2P converter for Hindi",
          "- M2M-Aligner alignment system score",
          "e Extension of learned edit distance algorithm",
          "- Use highest similarity score",
          "- Combine similarity score with system score"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Similarity results",
        "text": [
          "Sie ls\\s) ~ ALINE LWA ALINE+Base _ M2M+Base"
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "7": {
        "title": "Similarity post mortem",
        "text": [
          "Can't follow transliterations exactly",
          "- Differences in languages (phonologies)",
          "Need to smooth out this volatility",
          "Limited to one language"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "SVM re ranking",
        "text": [
          "- Similarity scores (M2M-Aligner)",
          "- N-grams based on alignments between transcriptions and",
          "Similar to features used in",
          "- English-to-{Bengali, Chinese, Hindi, Thai,",
          "Japanese, Kannada, Korean, Russian, Tamil}",
          "- Features repeated for each transliteration",
          "Te Yael sol CM Le LH ha VA e eH DU V eee Vi io) ee datdbtcse-leCeyit TICs eye 2",
          "1S- tio) _ SVM-score = SVM-ngram SVIV-all"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "images": [
          "figure/image/976-Table3-1.png"
        ]
      },
      "9": {
        "title": "Analysis",
        "text": [
          "SVM re-ranking gives significant improvements",
          "Festival and Sequitur get higher improvement",
          "- The better the base system, the harder it is to",
          "n-gram features styled after DirecTL+",
          "This benefits Festival and Sequitur",
          "Similar features in a novel direction can lead",
          "N-gram features most useful",
          "mm J er-la10lt-lmmist lib lasso"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "10": {
        "title": "Multiple languages",
        "text": [
          "Absolute improvement in word accuracy"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "11": {
        "title": "Future work",
        "text": [
          "Apply same re-ranking approach to different tasks (e.g. transliteration) and different data",
          "- Very successful results so far",
          "Leverage noisy web transcriptions",
          "Incorporate supplemental information directly in system"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "First use of transliterations for G2P",
          "Basic similarity-based methods don't work",
          "SVM re-ranking improves all tested base systems",
          "Multiple languages are vital",
          "Relevant scripts, etc. are online"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "How do you pronounce your name? Improving G2P with transliterations"
  },
  "977": {
    "slides": {
      "0": {
        "title": "Language generation Equivalence in the target space",
        "text": [
          "Ground truth sequences lie in a union of low-dimensional subspaces where sequences convey the same message.",
          "I France won the world cup for the second time.",
          "I France captured its second world cup title.",
          "Some words in the vocabulary share the same meaning.",
          "I Capture, conquer, win, gain, achieve, accomplish, . . .",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Contributions",
        "text": [
          "Take into consideration the nature of the target language space with:",
          "A token-level smoothing for a robust multi-class classification.",
          "A sequence-level smoothing to explore relevant alternative sequences.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Maximum likelihood estimation MLE",
        "text": [
          "For a pair (x y), we model the conditional distribution:",
          "Given the ground truth target sequence y?:",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "Zero-one loss, all the outputs y y? are treated equally.",
          "Discrepancy at the sentence level between the training (1-gram) and evaluation metric (4-gram)."
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Loss smoothing",
        "text": [
          "Prerequisite: A word embedding w (e.g. Glove) in the target space and a distance d",
          "with a temperature st. r"
        ],
        "page_nums": [
          5,
          6,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Token level smoothing",
        "text": [
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Loss smoothing Token level",
        "text": [
          "Uniform label smoothing over all words in the vocabulary:",
          "We can leverage word co-occurrence statistics to build a non-uniform and meaningful distribution.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "We can estimate the exact KL divergence for every target token."
        ],
        "page_nums": [
          8,
          10,
          11
        ],
        "images": []
      },
      "6": {
        "title": "Sequence level smoothing",
        "text": [
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Loss smoothing Sequence level",
        "text": [
          "Prerequisite: A distance d in the sequences space Vn, n N.",
          "Hamming Edit 1BLEU 1CIDEr",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "Can we evaluate the partition function Z for a given reward?",
          "We can approximate Z for Hamming distance."
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Loss smoothing Sequence level Hamming distance",
        "text": [
          "consider only sequences of the same length as y? (d(y y if |y |y",
          "We partition the set of sequences y?:",
          "their distance to the ground truth",
          "d d Sd Sd",
          "The reward in each subset is a constant.",
          "The cardinality of each subset is known.",
          "d Z |Sd exp",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "We can easily draw from r with Hamming distance:",
          "Pick d positions in the sequence to be changed among {1, . . . ,T}.",
          "Sample substitutions from V of the vocabulary."
        ],
        "page_nums": [
          15,
          16,
          17
        ],
        "images": []
      },
      "9": {
        "title": "Loss smoothing Sequence level Other distances",
        "text": [
          "We cannot easily sample from more complicated rewards such as BLEU or CIDEr.",
          "Choose q the reward distribution relative to Hamming distance.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "10": {
        "title": "Loss smoothing Sequence level Support reduction",
        "text": [
          "Can we reduce the support of r?",
          "Reduce the support from V |y?| to V |y",
          "sub where Vsub V.",
          "Vsub Vbatch tokens occuring in the SGD mini-batch.",
          "Vsub Vrefs tokens occuring in the available references.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "11": {
        "title": "Loss smoothing Sequence level Lazy training",
        "text": [
          "Default training Lazy training",
          "l y l is: l y l is:",
          "not forwarded in the RNN.",
          "log p(yl |yl x)",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "|y ||cell |, where cell are the cell parameters."
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "12": {
        "title": "Image captioning on MS COCO Setup",
        "text": [
          "5 captions for every image.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "13": {
        "title": "Image captioning on MS COCO Results",
        "text": [
          "Loss Reward Vsub BLEU-1 BLEU-4 CIDEr",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "14": {
        "title": "Machine translation Setup",
        "text": [
          "Bi-LSTM encoder-decoder with attention (Bahdanau et al. 2015)",
          "IWSLT14 DEEN WMT14 ENFR",
          "Dev 7k Dev 6k",
          "Test 7k Test 3k",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "15": {
        "title": "Machine translation Results",
        "text": [
          "Loss Reward Vsub WMT14 EnFr IWSLT14 DeEn",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          29,
          30,
          31
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "17": {
        "title": "Takeaways",
        "text": [
          "Improving over MLE with:",
          "Sequence-level smoothing: an extension of RAML (Norouzi et al. 2016)",
          "I Reduced support of the reward distribution.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing",
          "Token-level smoothing: smoothing across semantically similar tokens instead of",
          "the usual uniform noise.",
          "Both schemes can be combined for better results."
        ],
        "page_nums": [
          33,
          34
        ],
        "images": []
      },
      "18": {
        "title": "Future work",
        "text": [
          "Validate on other seq2seq models besides LSTM encoder-decoders.",
          "Validate on models with BPE instead of words.",
          "I Experiment with other distributions for sampling other than the Hamming distance.",
          "I Sparsify the reward distribution for scalability.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "19": {
        "title": "Appendices",
        "text": [
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "20": {
        "title": "Training time",
        "text": [
          "Average wall time to process a single batch (10 images 50 captions) when training the RNN language model with fixed CNN (without attention) on a Titan X GPU.",
          "Loss MLE Tok Seq Seq lazy Seq Seq lazy Seq Seq lazy Tok-Seq Tok-Seq Tok-Seq",
          "Reward Glove sim Hamming",
          "Vsub V V Vbatch Vbatch Vrefs Vrefs V Vbatch Vrefs",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "21": {
        "title": "Generated captions",
        "text": [
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          40,
          41
        ],
        "images": []
      },
      "22": {
        "title": "Generated translations EnFr",
        "text": [
          "I think its conceivable that these data are used for mutual benefit.",
          "Jestime quil est concevable que ces donnees soient utilisees dans leur interet mutuel.",
          "Je pense quil est possible que ces donnees soient utilisees a des fins reciproques.",
          "Je pense quil est possible que ces donnees soient utilisees pour le benefice mutuel.",
          "The public will be able to enjoy the technical prowess of young skaters , some of whom , like Hyeres young star , Lorenzo Palumbo , have already taken part in top-notch competitions.",
          "Le public pourra admirer les prouesses techniques de jeunes qui , pour certains , frequentent deja les competitions au plus haut niveau , a linstar du jeune prodige hyerois Lorenzo Palumbo.",
          "Le public sera en mesure de profiter des connaissances techniques des jeunes garcons , dont certains , a linstar de la jeune star americaine , Lorenzo , ont deja participe a des competitions de competition.",
          "Le public sera en mesure de profiter de la finesse technique des jeunes musiciens , dont certains , comme la jeune star de lentreprise , Lorenzo , ont deja pris part a des competitions de gymnastique.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "23": {
        "title": "MS COCO server results",
        "text": [
          "BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE-L CIDEr SPICE",
          "Ours: Tok-Seq CIDEr Ours: Tok-Seq CIDEr +",
          "Table: MS-COCO s server evaluation . (+) for ensemble submissions, for submissions with CIDEr optimization and () for models using additional data.",
          "ACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ],
        "page_nums": [
          43
        ],
        "images": []
      }
    },
    "paper_title": "Token-level and sequence-level loss smoothing for RNN language models"
  },
  "978": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "based on predefined event schema and rich features encoded from annotated event",
          "Pros: extract high quality events for predefined types",
          "Cons: require large amount of human annotations and cannot extract event mentions for new event types",
          "Traditional Event Extraction Pipeline",
          "Consumer 1: I want an event extractor for Transport",
          "Annotators: We will annotate 500 documents The resources for existing",
          "event types cannot be re- System Developer: Ill train a classifier",
          "Consumer 2: I want an event extractor for Attack Annotators: We will annotate 500 documents",
          "used for new types; not to mention we have event types",
          "Zero Shot Transfer Learning",
          "Learning a regression function between object (e.g., image, entity) semantic space and label semantic space based on annotated data for seen labels",
          "The regression model can be used to predict the unseen labels for any given image",
          "Andrea Frome, Greg S. Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc Aurelio Ranzato, Tomas Mikolov, DeViSE: A Deep Visual-Semantic Embedding Model"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Zero Shot Learning for Event Extraction",
          "both event mentions and types have rich semantics and structures, which can specify their consistency and connections",
          "E1. The Government of China has ruled Tibet since 1951 after dispatching troops to the",
          "E2. Iranian state television stated that the conflict between the Iranian police and the drug smugglers took place near the town of mirjaveh."
        ],
        "page_nums": [
          3
        ],
        "images": [
          "figure/image/978-Figure2-1.png"
        ]
      },
      "2": {
        "title": "Approach Overview",
        "text": [],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/978-Figure3-1.png"
        ]
      },
      "3": {
        "title": "Approach Details",
        "text": [
          "Trigger and Argument Identification",
          "AMR parsing and FrameNet verbs/nominal lexical units",
          "Subset of AMR relations",
          "None-Core Roles mod, location, instrument, poss, manner, topic, medium, prep-X",
          "Temporal year, duration, decade, weekday, time",
          "Spatial destination, path, location",
          "Event and Type Structure Construction",
          "Structure Composition and Representation",
          "We use a matrix M to represent each AMR relation , and compose its semantics with two concepts for each tuple:",
          "Similarly, we assume an implicit relation exists between any pair of type and argument, and use a tensor U [1:2d to represent it, and compose its semantics with each pair of type and argument role",
          "u y,r e.g., <Transport_Person, Person>",
          "Joint Event Mention and Type Label",
          "Representation learning for each event mention structure and type structure",
          "Take each structure (a sequence of tuples) as input, and encode each event mention and type structure into a vector representation using a weight-sharing Convolutional Neural",
          "Align the vector representations of each event mention structure with its corresponding event type structure",
          "Minimize their distance within a share vector space",
          "Over-fitting to seen types seen types are usually very limited",
          "To avoid over-fitting for seen types",
          "Add negative event mentions into training",
          "Negative event mentions: the mentions that are not annotated with any seen types, namely other. Extracted from the event mention clusters generated by Huang et. al. (2016)",
          "where y is the positive event type for the candidate trigger t is the type set of the event ontology, is the seen type set. y is the type which ranks the highest among all event types for event mention t",
          "Joint Event Argument and Role Embedding",
          "Mapping between argument and role path",
          "Argument path: e.g., dispatch01 :Arg0 China",
          "Role path: Transport_person Agent",
          "Learn path representations using two weight-sharing CNNs",
          "where r is the positive argument role for the candidate argument a are the set of argument roles which are predefined for trigger type and y and all seen types r is argument role which ranks the highest for a when a or y is annotated as Other"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Evaluation",
        "text": [
          "Zero-Shot Classification for ACE Events",
          "Given trigger and argument boundaries, use a subset of ACE types for training, and remained types for testing",
          "Seen types for each experiment setting",
          "Setting Top-N Seen Types for Training/Dev",
          "D Attack, Transport, Die, Meet, Arrest-Jail, Transfer-Money, Sentence, Elect, Transfer-Ownership, End-Position",
          "Statistics for Positive/Negative instances on Training,",
          "Development, and Test sets for each experiment setting",
          "Negative instances are sampled from the trigger and argument clustering output of (Huang et. al., 2016)",
          "Hit@K performance on trigger and argument classification",
          "Hit@K Accuracy: the correct label occurs within the top K ranked output labels",
          "WSD-Embedding: directly map event triggers and arguments to event types and argument roles according to their cosine similarity of word sense embeddings",
          "Training subtypes of Justice: Arrest-Jail, Convict, Charge-Indict,",
          "Performance on Various Unseen Types",
          "Event Extraction for ACE Types",
          "Target Event Ontology: ACE(33 types)+FrameNet (1161 frames)",
          "Seen types for training: 10 ACE types",
          "Performance on ACE types",
          "Errors: misclassification within the same scenario",
          "e.g., Being-Born v.s. Giving-Birth",
          "Abby was a true water birth ( 3kg - normal) and with Fiona I was dragged out of the pool after the head crowned."
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14
        ],
        "images": [
          "figure/image/978-Table7-1.png",
          "figure/image/978-Table6-1.png",
          "figure/image/978-Table4-1.png"
        ]
      },
      "5": {
        "title": "Discussion",
        "text": [
          "Impact of AMR Parsing",
          "AMR is used to identify candidate triggers and arguments, as well as construct event structures",
          "Compare AMR with Semantic Role Labeling (SRL) on a subset of",
          "ERE corpus with perfect AMR annotations",
          "Train on top-6 most popular seen (training) types: Arrest-Jail,",
          "Execute, Die, Meet, Sentence, Charge-Indict, and test on 200 sentences, with 128 attack event mentions and 40 convict event mentions",
          "Transfer Learning v.s. Supervised Model",
          "Target Event Ontology: ACE(33 types)+FrameNet (1161 frames)",
          "Seen types for training: 10 most popular ACE types",
          "Unseen type: 23 remaining ACE types"
        ],
        "page_nums": [
          15,
          16
        ],
        "images": [
          "figure/image/978-Figure4-1.png",
          "figure/image/978-Table8-1.png"
        ]
      },
      "6": {
        "title": "Conclusion and Future Work",
        "text": [
          "We model event extraction as a generic grounding problem, instead of classification",
          "By leveraging existing human constructed event schemas and manual annotations for a small set of seen types, the zero shot framework can improve the scalability of event extraction and save human effort",
          "In the future, we will extend this framework to other"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "7": {
        "title": "Q and A",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Zero-Shot Transfer Learning for Event Extraction"
  },
  "979": {
    "slides": {
      "0": {
        "title": "Authors",
        "text": [
          "Amulya Gupta Zhu (Drew) Zhang",
          "Email: guptaam@iastate.edu Email: zhuzhang@iastate.edu"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Agenda",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Problem Statement",
        "text": [
          "Given two sentences, determine the semantic similarity between them."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Tasks",
        "text": [
          "Semantic relatedness for sentence pairs.",
          "Paraphrase detection for question pairs.",
          "Predict relatedness score (real value) for a pair of sentences",
          "Given a pair of questions, classify them as paraphrase or not",
          "Higher score implies higher semantic similarity among sentences",
          "Essence: Given two sentences, determine the semantic similarity between them."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Datasets used",
        "text": [
          "Semantic relatedness for sentence pairs.",
          "Paraphrase detection for question pairs."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Examples",
        "text": [
          "The badger is burrowing a hole A hole is being burrowed by the badger",
          "The reading for both August and July is the best seen since the survey began in August",
          "It is the highest reading since the index was created in August 1997.",
          "Quora What is bigdata? Is bigdata really doing well?"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Linear",
        "text": [
          "Generally, a sentence is read in a linear form.",
          "English (Left to Right): Traditional Chinese",
          "The badger is burrowing a hole. (Top to Bottom):",
          "Urdu (Right to Left):"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Long Short Term Memory LSTM",
        "text": [
          "LSTM cell LSTM cell LSTM cell LSTM cell LSTM cell LSTM cell",
          "e_The e_badger e_is e_burrowing e_a e_hole"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "8": {
        "title": "Attention mechanism",
        "text": [
          "Neural Machine Translation (NMT) Global Attention Model (GAM)"
        ],
        "page_nums": [
          10,
          13
        ],
        "images": [
          "figure/image/979-Figure4-1.png"
        ]
      },
      "9": {
        "title": "Tree",
        "text": [],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/979-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Tree LSTM Tai et al 2015",
        "text": [
          "Introduction Classical world Alternate world"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Decomposable Attention Parikh et al",
        "text": [
          "e1 e2 e3 e4 e5 e6 e7 e8 Sentence L Attend: Attention matrix e1 e2 e3 e4 Sentence R",
          "Introduction Classical world Alternate world"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Modified Decomposable Attention MDA",
        "text": [
          "(Absolute Distance similarity: (Sign similarity:",
          "Element wise absolute difference) Element wise multiplication)",
          "MDA is employed after encoding sentences.",
          "T-LSTM cell T-LSTM cell o1 o2 Modification 1 T-LSTM cell T-LSTM cell T-LSTM cell T-LSTM cell",
          "Sentence L Sentence R",
          "Introduction Classical world Alternate Our contribution world"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Testset Results",
        "text": [
          "w/o Attention MDA w/o Attention MDA w/o Attention MDA",
          "Introduction Classical world Alternate world Our contribution",
          "Attention MDA PA w/o"
        ],
        "page_nums": [
          16,
          21
        ],
        "images": []
      },
      "14": {
        "title": "Progressive Attention PA",
        "text": [
          "T-LSTM cell T-LSTM cell T-LSTM cell T-LSTM cell",
          "Start Sentence L Phase 1 Sentence R",
          "Introduction Classical world Alternate world Our contribution",
          "T-LSTM cell T-LSTM cell T- T- T-LSTM cell T-LSTM cell T- T-",
          "PA is employed during encoding sentences.",
          "(Absolute Distance similarity: (Sign similarity:",
          "Element wise absolute difference) Element wise multiplication)"
        ],
        "page_nums": [
          17,
          18,
          19
        ],
        "images": []
      },
      "15": {
        "title": "Effectiveness of PA",
        "text": [
          "ID Sentence 1 Sentence 2 Gold Linear Constituency Dependency",
          "PA No attn PA",
          "The badger is burrowing a hole",
          "A hole is being burrowed by the badger",
          "Introduction Classical world Alternate world Our contribution"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Discussion",
        "text": [
          "Is it because attention can be considered as an implicit form of structure which complements the explicit form of syntactic structure?",
          "If yes, does there exist some tradeoff between modeling efforts invested in syntactic and attention sDtoruecst uthreis? mean there is a closer affinity between dependency structure and compositional semantics?",
          "If yes, is it because dependency structure embody more semantic information?",
          "Introduction Classical world Alternate world Our contribution"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": []
      },
      "17": {
        "title": "Summary",
        "text": [
          "Proposed a modified decomposable attention (MDA) and a novel progressive attention (PA) model on tree based structures.",
          "Investigated the impact of proposed attention models on syntactic structures in linguistics."
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "To Attend or not to Attend: A Case Study on Syntactic Structures for Semantic Relatedness"
  },
  "980": {
    "slides": {
      "0": {
        "title": "An Example Dialogue with Movie Bot",
        "text": [
          "Actual dialogues can be more complex:",
          "Speech/Natural language understanding errors",
          "o Input may be spoken language form o Need to reason under uncertainty",
          "o Revise information collected earlier",
          "Source code available at https://github/com/MiuLab/TC-Bot"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Task oriented slot filling Dialogues",
        "text": [
          "Domain: movie, restaurant, flight,",
          "Slot: information to be filled in before completing a task",
          "o For Movie-Bot: movie-name, theater, number-of-tickets, price,",
          "o Inspired by speech act theory (communication as action)",
          "request, confirm, inform, thank-you,",
          "o Some may take parameters:",
          "\"Is Kungfu Panda the movie you are looking for?\""
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "A Multi turn Task oriented Dialogue Architecture",
        "text": [
          "Request(movie; actor=bill murray) Knowledge Base",
          "When was it released"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "A unified view dialogue as optimal decision making",
        "text": [
          "Dialogue as a Markov Decision Process (MDP)",
          "Given state , select action according to (hierarchical) policy",
          "Receive reward , observe new state",
          "Continue the cycle until the episode terminates.",
          "Goal of dialogue learning: find optimal to maximize expected rewards",
          "Dialogue State (s) Action (a) Reward (r)",
          "(Q&A bot over KB, Web etc.)",
          "Task Completion Bots (Movies, Restaurants, ) Understanding of user goal (belief state) Dialog act + slot_value Task success rate # of turns",
          "Social Bot (XiaoIce) Conversation history Response Engagement"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Task completion dialogue as RL",
        "text": [
          "(utterances in natural language form)",
          "o +10 upon successful termination o -10 upon unsuccessful termination o -1 per turn o",
          "Pioneered by [Levin+ 00] Other early examples: [Singh+ 02; Pietquin+ 04; Williams&Young 07; etc.]"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "RL vs SL supervised learning",
        "text": [
          "Differences from supervised learning",
          "Learn by trial-and-error (experimenting)",
          "Optimize long-term reward (1",
          "Need temporal credit assignment",
          "Similarities to supervised learning",
          "input/feature Generalization and representation",
          "SL Hierarchical problem solving"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Learning w real users",
        "text": [
          "- Expensive: need large amounts of real experience except for very simple tasks",
          "- Risky: bad experiences (during exploration) drive users away"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Learning w user simulators",
        "text": [
          "- Inexpensive: generate large amounts of simulated experience for free",
          "- Overfitting: discrepancy btw real users and simulators",
          "Dialog agent simulated experience"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Dyna Q integrating planning and learning",
        "text": [
          "combining model-free and model-based RL",
          "tabular methods and linear function approximation"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Deep Dyna Q DDQ Integrating Planning for Dialogue Policy Learning",
        "text": [
          "Policy as DNN, trained using DQN",
          "Apply to dialogue: simulated user as world model",
          "Dialogued agent trained using",
          "Limited real user experience",
          "Large amounts of simulated experience Acting Direct World model",
          "Limited real experience is used to improve RL",
          "World model (simulated user) Model learning"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Task completion DDQ dialogue agent",
        "text": [],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/980-Figure2-1.png"
        ]
      },
      "11": {
        "title": "The world model architecture",
        "text": [],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/980-Figure3-1.png"
        ]
      },
      "12": {
        "title": "Dialogue System Evaluation",
        "text": [
          "Metrics: what numbers matter?",
          "o Success rate: #Successful_Dialogues / #All_Dialogues o Average turns: average number of turns in a dialogue o User satisfaction o Consistency, diversity, engaging, ... o Latency, backend retrieval cost,",
          "Methodology: how to measure those numbers?"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Evaluation methodology",
        "text": [
          "(lab, Mechanical Turk, )",
          "(optionally with continuing incremental refinement)"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "A Simulator for E2E Neural Dialogue System",
        "text": [],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Agenda based Simulated User",
        "text": [
          "[Schatzmann & Young 09]",
          "User state consists of (agenda, goal); goal is fixed throughout dialogue",
          "Agenda is maintained (stochastically) by a first-in-last-out stack",
          "Implementation of a simplified user simulator: https://github.com/MiuLab/TC-Bot"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "16": {
        "title": "Simulated user evaluation",
        "text": [
          "DQN vs DDQ ()",
          ": number of planning steps",
          "(generating K simulated dialogues per real dialogue)"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": [
          "figure/image/980-Figure5-1.png",
          "figure/image/980-Figure4-1.png"
        ]
      },
      "17": {
        "title": "Impact of world model quality",
        "text": [
          "pretrained on labeled data, and updated using real dialogue on the fly"
        ],
        "page_nums": [
          20,
          21,
          22
        ],
        "images": [
          "figure/image/980-Figure5-1.png",
          "figure/image/980-Figure4-1.png"
        ]
      },
      "18": {
        "title": "Human in the loop experiments learning dialogue via interacting with real users",
        "text": [
          "DDQ agents significantly outperforms the DQN agent",
          "A larger leads to more aggressive planning and better results",
          "Pre-training world model with human conversational data improves the learning efficiency and the agents performance"
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/980-Figure6-1.png"
        ]
      },
      "19": {
        "title": "Conclusion and Future Work",
        "text": [
          "Deep Dyna-Q: integrating planning for dialogue policy learning",
          "Make the best use of limited real user experiences",
          "Learning when to switch between real and simulated users",
          "Exploration: trying actions to improve the world model",
          "Exploitation: trying to behave in the optimal way given the current world model"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning"
  },
  "981": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Degree of self-disclosure in a relationship depends on the strength of the relationship",
          "Strategic self-disclosure can strengthen the relationship",
          "Youre my best friend!",
          "I like you too!",
          "I want to Korea. Where are be your"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Hypothesis",
        "text": [
          "Twitter conversations also show a similar pattern",
          "Dyads with high relationship strength show more self- disclosure behavior",
          "Dyads with low relationship strength show less self-disclosure behavior",
          "Youre my best friend!",
          "I like you too! Hello~"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Methodology",
        "text": [
          "Analysis with Topic Models",
          "Latent Dirichlet allocation (LDA, [Blei, JMLR 2003])",
          "Aspect and sentiment unification model (ASUM, [Jo, WSDM 2011])"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Twitter Conversation",
        "text": [
          "Example of a conversation chain",
          "3 or more tweets at least one reply by each user"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Relationship Strength",
        "text": [
          "Social psychology literature states relationship strength can be measured by communication frequency and length",
          "The number of conversational chains between the dyad averaged per month",
          "A high CF or CL for a dyad means the relationship is strong",
          "A low CF or CL for a dyad means the relationship is weak"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Self Disclosure",
        "text": [
          "Open communication - Openness",
          "Receptive openness difficult to find in tweets",
          "General-style openness not clearly defined in the literature",
          "Personally Identifiable Information (PII)",
          "Personally Embarrassing Information (PEI)",
          "nigga, ass, wtf, lmao"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Self Disclosure Openness",
        "text": [
          "We use ASUM with emoticons as seed words",
          "Aspect and sentiment unification model for online review analysis, Jo, WSDM11]",
          "ASUM is LDA-based joint model of topic and sentiment",
          "ASUM takes unannotated data and classifies each sentence (tweet) as positive/negative/neutral",
          "We look for emoticons, lol, xxx",
          "Emoticons are like facial expressions -- :P lol (laughing out loud) and xxx (kisses) are very frequently used in a similar manner to nonverbal openness",
          "Look for tweets that contain common expressions of feeling words"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "7": {
        "title": "Self Disclosure Personal Information",
        "text": [
          "Personally Identifiable Information (PII)",
          "Ex) name, location, email address, job, social security number",
          "Personally Embarrassing Information (PEI)",
          "Ex) clinical history, sexual life, job loss, family problem",
          "Discover topics in each conversation",
          "LDA outputs a topic proportion for each conversation",
          "LDA outputs a multinomial word distribution for each topic",
          "Annotate conversations that best represent each topic",
          "Use Amazon Mechanical Turk",
          "Turkers annotated conversations for",
          "existence of PII existence of PEI keywords",
          "Example of PII, PEI and Profanity topics",
          "Shown by high probability words in each topic",
          "PII 1 PII 2 PEI 1 PEI 2 PEI 3 Profanity",
          "san tonight pants teeth family nigga",
          "live time wear doctor brother lmao",
          "state tomorrow boobs dr sister shit",
          "texas good naked dentist uncle ass",
          "south ill wearing tooth cousin bitch"
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [
          "Analyzing outliers: a dyad linked weakly but shows high self- disclosure"
        ],
        "page_nums": [
          15,
          20
        ],
        "images": [
          "figure/image/981-Figure2-1.png"
        ]
      },
      "9": {
        "title": "sentiment nonverbal emotional profanity PII and PEI",
        "text": [],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/981-Figure1-1.png"
        ]
      },
      "10": {
        "title": "emotional PII and PEI",
        "text": [],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/981-Figure1-1.png"
        ]
      },
      "11": {
        "title": "Results Interpretation",
        "text": [
          "When they are not very close, they express frequent encouragements, or polite reactions to baby or pets",
          "When they meet new acquaintances, they use PII to introduce themselves",
          "When they are not very close, they express frequent greetings, encouragements, or polite reactions to baby or pets",
          "Top 3 topics in weak relationships",
          "greeting encourage ment baby/pets"
        ],
        "page_nums": [
          18,
          19,
          24
        ],
        "images": [
          "figure/image/981-Figure2-1.png"
        ]
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "Collected a large corpus of Twitter conversations",
          "Measured relationship strength by conversation frequency and conversation length",
          "Negative, nonverbal, emotional openness",
          "Annotated PII and PEI using Mturk",
          "Confirmed hypothesis that stronger relationships show more self-disclosure behaviors",
          "Found some exceptions in emotional openness and PII"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "13": {
        "title": "Backup slides",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "14": {
        "title": "Future work",
        "text": [
          "Network distance, community, relationship duration",
          "Suggest new semi-supervised model",
          "Structure of questions and answers"
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/981-Figure2-1.png"
        ]
      },
      "15": {
        "title": "Method",
        "text": [
          "Information that can be used to uniquely identify a person",
          "Information that the damage that can be done by people that they know, the people for whom they might be embarrassed in front of"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Self-Disclosure and Relationship Strength in Twitter Conversations"
  },
  "982": {
    "slides": {
      "0": {
        "title": "Outlook",
        "text": [],
        "page_nums": [
          1,
          3,
          7,
          11,
          17
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Hierarchical phrase-based model limit",
          "Linguistic features (Japanese) subject object verb structure auxiliary words"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Verb Case Frame",
        "text": [
          "Deep verb case frame between paralleled sentences in two languages",
          "Subject Object Time Location Tool",
          "Specific to Japanese explicit case frame",
          "Agent Time Object Goal Tool Verb",
          "Time Agent Tool Verb Object Goal",
          "Deep case frame to shallow case frame for Japanese"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "Method",
        "text": [
          "Case Frame Rule extraction",
          "Obtain case frame rules from paralleled sentences with word alignments",
          "Transform case frame rules into hiero rules.",
          "examples of case frame rules",
          "(a) the example of phrase rule transformation",
          "(b) the example of reordering rule transformation"
        ],
        "page_nums": [
          8,
          9,
          10
        ],
        "images": [
          "figure/image/982-Figure5-1.png"
        ]
      },
      "4": {
        "title": "Experiment",
        "text": [
          "CWMT 2011 Japanese-Chinese Corpus (sentence pairs)",
          "ASPEC-JC Corpus (sentence pairs)",
          "Training data: 680 thousand",
          "exp1: Strong hierarchical phrase-based system (baseline)",
          "exp2: exp1 with case frame rules",
          "exp3: exp1 with manually case frame rules",
          "Variables in rule are without distinction during decoding",
          "system system CWMT ASPEC",
          "transformed case rule X-> (X X) is applied in span [18, 23]"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16
        ],
        "images": [
          "figure/image/982-Figure7-1.png"
        ]
      },
      "5": {
        "title": "Conclusion",
        "text": [
          "This paper presented an approach to improve HPB model systems by augmenting the SCFG with Japanese CFRs.",
          "The CF are used to introduce new linguistically sensible hypotheses into the translation search space while maintaining the Hiero robustness qualities and avoiding computational explosions.",
          "We obtain significant improvements over a strong HPB",
          "baseline in the Japanese-to-Chinese task."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "6": {
        "title": "Future work",
        "text": [
          "Soft/hard constraints on case frame rule matching",
          "Challenge to resolve the problem of tense and aspect etc."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "7": {
        "title": "and A",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      }
    },
    "paper_title": "Integrating Case Frame into Japanese to Chinese Hierarchical Phrase-based Translation Model"
  },
  "983": {
    "slides": {
      "0": {
        "title": "Constructicon",
        "text": [
          "A collection of conventionalized (learned) pairings of form and meaning",
          "Semantics is associated directly with the surface form vs. Lexical units in a dictionary: pairings of word and meaning (frame)",
          "Including fixed multi-word units",
          "Each construction (cx) contains at least one variable element",
          "Often at least one fixed element as well",
          "Thus, somewhere in-between the syntax and the lexicon",
          "Structure: {Motion verb [Verb] [PossNP]}",
          "[ThemeThey] {hacked their way} [Sourceout] [Goalinto the open].",
          "[ThemeWe] {sang our way} [Pathacross Europe]."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Constructicons",
        "text": [
          "A pilot project (around 70 cx), linked to Berkeley FrameNet",
          "An ongoing project (nearly 400 cx so far), partially linked to FrameNet",
          "ToDo: links to BCxn",
          "A multilingual (interlingual) constructicon would allow for non-",
          "compositional translation in a compositional way"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "SweCcn",
        "text": [
          "Partially schematic multi-word units/expressions",
          "Particularly addresses constructions of relevance for second-language learning, but also covers argument structure constructions",
          "Descriptions are manually derived from corpus examples",
          "Internal CEs are a part of the cx",
          "External CEs are a part of the valency of the cx",
          "Described in more detail by attribute-value matrices specifying their syntactic and semantic features",
          "A central part of cx descriptions is the free text definitions",
          "eat himself full vs. feel himself tired (ata sig matt vs. kanna sig trott)"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/983-Table1-1.png"
        ]
      },
      "3": {
        "title": "SweCcn GF",
        "text": [
          "Task: convert the semi-formal SweCcn into a computational CxG",
          "Test Grammatical Framework (GF) as a framework for implementing CxG",
          "There is no formal distinction between lexical and syntactic functions in GF fits the nature of constructicons",
          "The potential support for multilinguality",
          "Based on GF Resource Grammar Library (RGL) / an extension to RGL",
          "An extension to a FrameNet-based grammar and lexicon in GF",
          "From the linguistic point of view",
          "Improve insights into the interaction between the lexicon and the grammar Allow for testing the linguistic descriptions of constructions",
          "From the language technology point of view: Facilitate the language processing in both mono- and multilingual settings e.g. Information Extraction, Machine Translation"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Conversion steps",
        "text": [
          "Automatic normalization and consistency checking",
          "Automatic rewriting of the original structures in case of optional CEs and",
          "alternative types of CEs, so that each combination has a separate GF function",
          "Does not apply to alternative LUs (either free variants or should be split into alternative constructions, or the CE should be made more general)",
          "Automatic conversion of SweCcn categories to RGL categories",
          "May result in more rewriting",
          "Automatic generation of the abstract syntax",
          "Automatic generation of the concrete syntax",
          "By systematically applying the high-level RGL constructors",
          "And limited low-level means",
          "Manual verification and completion (ToDo)",
          "Requires a good knowledge and linguistic intuition of the language"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Preprocessing examples",
        "text": [
          "behova NP1 till NP2|VP behovaV NP1 tillPrep NP2 behovaV NP tillPrep VP",
          "snacka|prata|tala NPindef snackaV|prataV|talaV aSg_Det CN snackaV|prataV|talaV aPl_Det CN snackaV|prataV|talaV CN",
          "(~synonyms of to talk)",
          "V av Pnrefl (NP)",
          "V avPrep reflPron NP V avPrep reflPron",
          "N stadaV A stadaV"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Abstract syntax",
        "text": [
          "Each construction is represented by one or more functions depending on how many alternative structures are produced in the preprocessing steps",
          "Each function takes one or more arguments that correspond to the variable CEs of the respective alternative construction",
          "behova_nagot_till_nagot_VP1 NP -> NP -> VP behova_nagot_till_nagot_VP2 NP -> VP -> VP",
          "verba_av_sig_transitiv2: V -> VP"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Concrete syntax",
        "text": [
          "Many constructions can be implemented by systematically applying the high-level RGL constructors",
          "A parsing problem: which constructors in which order?",
          "behova_nagot_till_nagot_VP_1 behova_V NP_1 till_Prep NP_2 {V} NP {Prep} NP",
          "mkVP (mkVP (mkV2 mkV) NP) (mkAdv mkPrep NP) A simple GF grammar",
          "The parser failed at token VP",
          "Final code (by automatic post-processing)"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Gf rgl api",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Code generating grammar",
        "text": [
          "A simplified fragment of the abstract syntax",
          "mkVP__VP_Adv (mkVP__V _mkV___V) (mkAdv _mkPrep_ _NP_) A simplified fragment of the concrete syntax"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/983-Figure2-1.png",
          "figure/image/983-Figure3-1.png"
        ]
      },
      "10": {
        "title": "Running examples",
        "text": [
          "parse \"jag behover nagot till nagot\"",
          "(behova_nagot_till_nagot_1 (DetNP someSg_Det) (DetNP someSg_Det))",
          "(behova_nagot_till_nagot_1 (DetNP someSg_Det) something_NP)",
          "(behova_nagot_till_nagot_1 something_NP (DetNP someSg_Det))",
          "parse \"han ater sig matt\""
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Results",
        "text": [
          "In the current experiment, we have considered only the VP constructions which resulted in functions",
          "Dominating in SweCcn; have the most complex internal structure",
          "Given the 127 functions, we have automatically generated the implementation for functions (77%) achieving a accuracy",
          "There is clear space for improvement",
          "Manual completion postponed because of the active development of",
          "A methodology on how to systematically formalise the semi-formal representation of SweCcn in GF, showing that a GF construction grammar can be, to a large extent, acquired automatically",
          "Consequence: feedback to SweCcn developers on how to improve the annotation consistency and adequacy of the original construction resource"
        ],
        "page_nums": [
          13
        ],
        "images": []
      }
    },
    "paper_title": "Formalising the Swedish Constructicon in Grammatical Framework"
  },
  "984": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "State-of-the-art MT models still use a simplistic view of the data",
          "I words typically treated as independent, unrelated units",
          "I relations between words only captured through linear context",
          "Unified semantic representations, such as Abstract Meaning",
          "Representation (AMR, Banarescu et al. 2013), (re)gaining popularity",
          "Abstraction from surface words, semantic relations made explicit, related words brought together (possibly distant in the surface realization)",
          "I Richer models of source context our work",
          "I Target-side (or joint) models to capture semantic coherence",
          "I Semantic transfer followed by target-side generation"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Semantic Representation",
        "text": [
          "Logical Form transformed into an AMR-style representation",
          "Labeled directed graph, not necessarily acyclic (e.g. coreference)",
          "Nodes content words, edges semantic relations",
          "Function words (mostly) not represented as nodes",
          "Bits capture various linguistic properties",
          "Figure 1 : Logical Form (computed tree) for the sentence: I would like to give you a sandwich taken from the fridge."
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/984-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Graph to String Translation",
        "text": [
          "Translation = generation of target-side surface words in order, conditioned on source semantic nodes and previously generated words.",
          "Start in the (virtual) root",
          "At each step, transition to a semantic node and emit a target word",
          "A single node can be visited multiple times",
          "One transition can move anywhere in the LF"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Translation Example",
        "text": [
          "Figure 2 : An example of the translation process illustrating several first steps of translating the sentence into German (Ich mochte dir einen Sandwich...).",
          "Labels in italics correspond to the shortest undirected paths between the nodes."
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/984-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Alignment of Graph Nodes",
        "text": [
          "How do we align source-side semantic nodes to target-side words?"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Alignment of Graph Nodes Gibbs Sampling",
        "text": [
          "Alignment ( transition) distribution P(ai ) modeled as a categorical distribution:",
          "Translation ( emission) distribution modeled as a set of categorical distributions, one for each source semantic node:",
          "P(ei |nai c(lemma(nai ei",
          "Sample from the following distribution:"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Alignment of Graph Nodes Evaluation",
        "text": [
          "I Linearize the LF, run GIZA++ (standard word alignment)",
          "I Heuristic linearization, try to preserve source surface word order",
          "I Source-side nodes to source-side tokens",
          "I Source-target word alignment GIZA++",
          "Manual inspection of alignments",
          "Alignment composition clearly superior",
          "Not much difference between GIZA++ and parser alignments"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Discriminative Translation Model",
        "text": [
          "Possible classes: top 50 translations observed with given lemma",
          "Online learning with stochastic gradient descent",
          "Learning rate 0.05, cumulative L1 regularization with weight 1, batch size 1, 22 hash bits",
          "Early stopping when held-out perplexity increases",
          "Parallelized (multi-threading) and distributed learning for tractability"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Feature Set",
        "text": [
          "Ich mochte dir einen Sandwich",
          "Current node, previous node, parent node lemma, POS, bits",
          "Path from previous node path length, path description",
          "Bag of lemmas capture overall topic of the sentence",
          "Graph context features from nodes close in the graph (limited by the length of shortest undirected path)",
          "Generated tokens fertility; some nodes should generate a function word first (e.g. an article) and then the content word",
          "Previous tokens target-side context July 30, 2015"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/984-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Experiments",
        "text": [
          "Evaluated in a n-best re-ranking experiment",
          "I Generate 1000-best translations of devset sentences",
          "I Add scores from our model",
          "I Re-run MERT on the enriched n-best lists",
          "Basic phrase-based system, FrenchEnglish",
          "1 million parallel training sentences",
          "Obtained small but consistent improvements",
          "Differences would most likely be larger after integration in decoding",
          "Table 1 : BLEU scores of n-best reranking in FrenchEnglish translation."
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/984-Table1-1.png"
        ]
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "Initial attempt at including semantic features in statistical MT",
          "Feature set comprising morphological, syntactic and semantic properties",
          "Small but consistent improvement of BLEU",
          "Integrate directly in the decoder",
          "Parser accuracy limited use multiple analyses",
          "Explore other ways of integration",
          "I Target-side models of semantic plausibility",
          "I Semantic transfer and generation"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "A Discriminative Model for Semantics-to-String Translation"
  },
  "986": {
    "slides": {
      "0": {
        "title": "Corpus highlights",
        "text": [
          "Slides available at http://bit.ly/cl-scisumm|6-slides and will be filed in GitHub.",
          "Continuing effort to advance scientific document summarization by encouraging the incorporation of semantic and citation information.",
          "Corpus enlarged from 10 (pilot) to 30 CL articles",
          "Annotation by 6 paid and trained annotators from U-Hyderabad",
          "Sponsorship from Microsoft Research Asia"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Oral Sessions",
        "text": [
          "Slides available at http://bit.ly/cl-scisummi|6-slides and will be filed in GitHub.",
          "Rais) nai System 8 Top in Task |B, among top performers for",
          "Task |A and Task 2",
          "* Remote presentation from China pose | onl) System 6 Among top performers for Task IA"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Evaluation",
        "text": [
          "Still a work in progress:",
          "Will present results based on the CEUR paper (old), stacked average ofall runs...",
          "... and contrast with newer (still preliminary) results (new), individual runs separated",
          "Task |A Exact sentence ID match",
          "EC asi conditional on Task |A",
          "Bag of Words (BOVV) overlap between discourse facets",
          "BIRNDL 2016: CL-SciSumm 16 Overview VER t-wAel"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "System Results Task 1A and 1B",
        "text": [
          "es) \\ HS VY S S 6 Gy a PS) aS as a ne aS ns as A ro a i of of? of? ro a a of? a of oY PY oy of? of a",
          "BIRNDL 2016: CL-SciSumm 16 Overview 23 June 2016 7 CEUR version (all system runs averaged)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Best Performing System Task 1A",
        "text": [
          "System ID Avg Best performing StDev performance Systems"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Best Performing System Task 1B",
        "text": [
          "System ID Avg StDev performance Best performing"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Best Performing System Task 2",
        "text": [
          "System ID Approaches Comments Systems"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "New Results Task 1A",
        "text": [
          "New Results (Task | A)",
          "BIRNDL 2016: CL-SciSumm 16 Overview VER TAO) a",
          "System ID Approach Task 1a Comments"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "New Results Task 1B",
        "text": [
          "ID Approach Task 1B"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "9": {
        "title": "New Results Task 2",
        "text": [
          "New Results Task 2",
          "Peele n ulate kod)",
          "TINWAaa$oT MSc eRRCAAicne een a Nts tch Aone Le ests ech Atom CERAM Stch Aine Mee a Si-6co ALL m Pac tco Aine - TNL SST",
          "ZNOUSOT Bay ieh- e-L0h a",
          "ONTLOASS ZTINISE ONTLOASS BBS Ete",
          "Ba feXol Bits qduwoowrss CawoowLss",
          "Tek oh cuks take)",
          "ONILOASS Bere oR Ao)",
          "ante sew tt 7TDWISE (aCe) Rte ~ TNYAML $ST Aree ithe TNMML SST Seas yctce AT aawoowrs TNYSML $S TNYGML $S TNYGML $S Mets foe) au} ONILOASE Be TANS) Avie elo 8 pa sier--fohg",
          "OMMNONNAW m N vn oO ro) fo} le o fo} o o Ce corel aE",
          "ReneS! tch Arica y Meas tce Alone Mee ast ich Aion 8 ! ONILOASS cuWOOWLS: RANE) aawoowrs!",
          "ae asd LSS NS sits} Kd Ay Iw",
          "nae RS og eo 7s eS ie RNS AOS",
          "a Leen may Eas",
          "Rraee\\ ect (Chom Lena ts 6co aon Pena tsece Alone Bayer: e-L0hm ZNNUSOT 8-TNYSML Mout arc nd Beary X12) Rts spc kre Ba eXec uk) FAB DSN Ete"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Supplemental Analyses",
        "text": [
          "We investigated whether high deviations could be because of the topic",
          "Topics with both high and low number of citances have mixed results",
          "No significant patterns of performance against:",
          "Number of citances of the topic set",
          "Age of the paper",
          "BIRNDL 2016: CL-SciSumm 16 Overview PEM wA0 Ty a)"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Limitations",
        "text": [
          "Task |B: limited number of samples for most (e.g.,hypothesis) discourse facets, inconsistent labeling",
          "Preprocessing: OCR + Parsing",
          "Software: Protege w/ manual alignment and post-processing",
          "Scaling the corpus was difficult: key bottleneck in the corpus development",
          "The Corpus size, #citing papers"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Next Steps IJDL Special Issue",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Conclusions",
        "text": [
          "Slides available at http://bit.ly/cl-scisummi|6-slides and will be filed in GitHub.",
          "Successful enlargement of the 2014 pilot task, albeit with some clarification issues",
          "We invite teams to examine the detailed results available with the GitHub repo: https://erthub.com/WING-NUS/scisumm-corpus/",
          "Results and finalized analyses still in development; CEUR version should be deemed preliminary notebook version of paper",
          "Look forward to your discussion for the planning and coordination of the next",
          "Thanks to all teams participation for the success of CL-Scisumm 201 6!",
          "BIRNDL 2016: CL-SciSumm 16 Overview PEM wA0 Ty yal"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Additional Slides",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "15": {
        "title": "Scientific Document Summarization",
        "text": [
          "wos 1ie-lell Yom I nal eae",
          "Surface, lexical, semantic or rhetorical features of the paper",
          "Community creates a summary when citing",
          "Capture all aspects of a paper"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Scientific Document Summarization Citation based extractive summaries",
        "text": [
          "Qazvinian,V.,and Radey, D.R.Identifying non-explicit citing sentences for citation-based summarization (ACL, 2010)",
          "Abu-|bara, Amjad, and Dragomir Radev. Reference scope identification in citing sentences. (ACL, 2012)",
          "Abu-Jbara, Amjad, and Dragomir Radev. Coherent citation- based summarization of scientific papers. (ACL 201 1)",
          "BIRNDL 2016: CL-SciSumm 16 Overview PEM wA0 Ty yz)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "17": {
        "title": "In summary",
        "text": [
          "Community concurs that a citation-based summary of a scientific document Is important.",
          "Citing papers cite different aspects of the same reference paper.",
          "Assigning facets to these citances may help create"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "18": {
        "title": "Annotation Pipeline",
        "text": [],
        "page_nums": [
          25
        ],
        "images": []
      },
      "19": {
        "title": "Annotating the SciSumm corpus",
        "text": [
          "6 annotators selected from a pool of 25",
          "6 hours of training",
          "Gold standard annotations for Task |A and IB,",
          "per topic or reference paper",
          "Community and hand-written summaries for Task 2,"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Overview of the CL-SciSumm 2016 Shared Task"
  },
  "987": {
    "slides": {
      "0": {
        "title": "Co citation Network",
        "text": [
          "=a linkage between a pair of documents",
          "concurrently cited by a third document",
          "Node = cited document",
          "a e c Edge = co-citation linkage",
          "f number of co-citing documents"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Outline of Co citation Network Searching",
        "text": [
          "2. System creates a network and ranks the",
          "documents in the network",
          "1. User inputs a 3. System outputs",
          "seed document ranked documents"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Enlarging the Co citation Networks so as to Include New Relevant Documents",
        "text": [
          "Co-citation linkage Word-based linkage",
          "Satellite documents of B",
          "Title words of B",
          "Do satellite documents have relevant linkages to the",
          "seed that are not identified by co-citation linkages?"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Specifying Satellite Documents",
        "text": [
          "Host documents are sources",
          "a e for specifying satellite documents",
          "f Each host document is",
          "d one hop from the seed",
          "b Title words Top-ranked",
          "Tf-idf (Indri Search Engine by Lemure project)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Problem of Satellite Documents",
        "text": [
          "Not all co-citation linkages are relevant",
          "a lot of relevant satellite documents b f",
          "Checking the appropriateness of host documents"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Checking the Appropriateness of Host Documents optional process",
        "text": [
          "Co-citation contexts are analyzed",
          "Doc. X Co-citation in the same paragraph",
          "A and B are cited in the same paragraph",
          "Doc. B is selected as host",
          "A and C are cited in different paragraphs",
          "Doc. C is not selected as host Citing document"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Incorporating Satellite Documents",
        "text": [
          "New or already Existing",
          "documents of b in the initial co-citation network",
          "New node and new edge Added weight or New edge",
          "T1 T2 T weight"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Ranking Documents in the Network by the RWR Random walk With Restart Algorithm Tong 2008",
        "text": [
          "The walker proceeds to the connected documents based",
          "on transition probabilities calculated by weights of edges"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "RWR What is Restart",
        "text": [
          "The walker returns to the seed document with",
          "the probability r at every step",
          "r parameter of the penalty for distance from the seed",
          "(If r is high, documents near the seed have high document scores1)5"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "RWR How are document scores calculated",
        "text": [
          "The position of the walker at Step (t) can be estimated by the",
          "When t is low, the position probability is unstable. As the",
          "number of t increases, the position probability may converge"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "RWR How are documents ranked",
        "text": [
          "Converged position probability ="
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Information Retrieval Experiment",
        "text": [
          "Baseline (initial co-citation network)",
          "Network created by taking up to two hops from the seed",
          "All one hop documents from the seed are host documents",
          "Host documents are selected by co-citation context",
          "Each document has MeSH descriptors"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Search Run",
        "text": [
          "Input a seed document documents",
          "Create an initial co-citation network b b a e a e Incorporating Seed c",
          "Seed c satellite documents f",
          "Ranked results by - All",
          "- Context RWR are compared"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Relevance Assessment",
        "text": [
          "Seed document Top K ranked retrieved documents",
          "Relevance scores were estimated based on",
          "similarity between the seed and each retrieved document",
          "based on MeSH descriptors"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Result averaging results of 100 seed",
        "text": [
          "K Baseline all context all context",
          "The maximum scores at each K are the",
          "results of Proposed with N = 100",
          "Proposed methods tended to outperform the baseline",
          "The scores of Proposed (context) are higher than",
          "those of the baseline method in all cases",
          "The checking process had a stable and positive",
          "impact on improving the search performance"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "This study proposed a technique to enlarge co-",
          "citation networks by incorporating satellite",
          "documents in scientific paper searches",
          "Retrieval methods using the proposed technique",
          "tended to outperform the baseline method, which",
          "was based on the initial co-citation network"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Q and A",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Incorporating Satellite Documents into Co-citation Networks for Scientific Paper Searches"
  },
  "988": {
    "slides": {
      "0": {
        "title": "Typical expert annotation task",
        "text": [
          "Does the sentence express TREATS?",
          "Rheumatoid arthritis and have been treated with",
          "For prevention of malaria, use only in individuals traveling to malarious",
          "areas where resistant P. falciparum has",
          "Among 56 subjects reporting to a clinic with symptoms of",
          "53 (95%) had ordinarily effective levels of in blood.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "But when you encourage disagreement",
        "text": [
          "Does the sentence express TREATS?",
          "Rheumatoid arthritis and have been treated with",
          "For prevention of malaria, use only in individuals traveling to malarious",
          "areas where resistant P. falciparum has",
          "Among 56 subjects reporting to a clinic with symptoms of",
          "53 (95%) had ordinarily effective levels of in blood.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "And ask the crowd",
        "text": [
          "Does the sentence express TREATS?",
          "Rheumatoid arthritis and have been treated with",
          "Theres a difference between these two BETTER",
          "For prevention of malaria, use only in individuals traveling to malarious",
          "areas where resistant P. falciparum has",
          "Among 56 subjects reporting to a clinic with symptoms of",
          "53 (95%) had ordinarily effective levels of in blood.",
          "This one isnt utterly wrong",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "What causes disagreement",
        "text": [
          "Workers spam, lazy, unskilled",
          "Sentences missing context tokenization, span detection, etc. doesnt quite fit the task poorly written, vague, ambiguous",
          "Target Semantics unclear, confusing relations or types granularity issues limits of inference",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "CrowdTruth Methodology",
        "text": [
          "Annotator disagreement is signal, not noise",
          "It is indicative of the variation in human semantic interpretation CrowdTruth.org",
          "It can indicate ambiguity, vagueness, similarity, over-generality, as well as quality",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "What is FrameNet",
        "text": [
          "FrameNet: computational linguistics resource based",
          "on the frame semantics theory (Baker, Fillmore, Lowe,",
          "collection of semantic frames",
          "documents annotated with these frames",
          "semantic frame: abstract representation of a word",
          "sense, describing a type of entity, relation, or event",
          "grounded in roles implied by the frame",
          "e.g. from to are roles in a movement frame",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Frame Disambiguation",
        "text": [
          "= task of selecting the best frame for a word phrase",
          "Illegal skimming of profits is rampant.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth",
          "The frame picked by the expert is marked with (*). What do es the crowd think?"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "7": {
        "title": "Dataset",
        "text": [
          "9000 sentence-word pairs from Wikipedia",
          "<= 25 candidate frames per word",
          "in 1000 pairs from this set, the word (i.e. Lexical Unit) is not in FrameNet",
          "Pre-processing to find candidate frames for each word:",
          "match word to synonym sets in WordNet corpus (Miller, 1995)",
          "match synonym set to FrameNet frame using Framester corpus (Gangemi et al., 2016)",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Crowdsourcing task",
        "text": [
          "15 workers / sentence",
          "ran on Amazon Mechanical Turk",
          "Example sentences for each frame, toggled by button",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Worker Vectors",
        "text": [
          "unica pt su tion as ion e ha ng",
          "At Ca e c",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "CrowdTruth metrics",
        "text": [
          "Frame-Sentence Score (FSS): the degree with which a particular frame matches the sense of the word in the sentence",
          "Sentence Quality Score (SQS): overall worker agreement over one sentence, measured with cosine similarity",
          "Frame Quality Score (FQS): agreement over a frame in all sentences where the frame was picked at least once",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Frame Sentence Score FSS how clearly the frame is expressed in the sentence",
        "text": [
          "Example sentences with removing frame:",
          "Egypt has provided no evidence demonstrating the elimination of its biological weapons.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth",
          "The Syrian Mujahiddin asked Hussein to overthrow the regime of Hafiz Al Assad.",
          "change of leadership - FSS = 0.847",
          "Illegal skimming of profits is rampant."
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": []
      },
      "12": {
        "title": "Sentence Quality Score SQS how ambiguous the sentence is",
        "text": [
          "Example sentences with removing frame:",
          "Egypt has provided no evidence demonstrating the elimination of its biological weapons.",
          "The Syrian Mujahiddin asked Hussein to overthrow the regime of Hafiz Al Assad.",
          "change of leadership - FSS = 0.847",
          "Illegal skimming of profits is rampant.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Frame Quality Score FQS how ambiguous the frame is",
        "text": [
          "Concrete frames have high FQS.",
          "Abstract frames have low FQS.",
          "Frames with overlapping definitions have low FQS.",
          "e.g. objective influence subjective influence",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Ambiguity in the corpus",
        "text": [],
        "page_nums": [
          21,
          22
        ],
        "images": []
      },
      "15": {
        "title": "Why does ambiguity happen",
        "text": [
          "These Articles continue to direct the ethos of the Communion.",
          "process continue - FSS = 0.86",
          "SQS parent-child relation between frames",
          "Some aikido organizations use belts to distinguish practitioners grades",
          "distinctiveness - FSS = 0.703 SQS overlapping frame definitions",
          "Cornwallis prematurely abandoned his outer position, hastening his subsequent defeat.",
          "meaning of the word is a composition of frames self motion - FSS = 0.165 travel - FSS = 0.16 causation - FSS = 0.124 @anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "16": {
        "title": "Evaluation with CrowdTruth data",
        "text": [
          "OS: OpenSesame frame disambiguation classifier (Swayamdipta et al., 2017), results in 1 frame per sentence, cannot",
          "OS+: OpenSesame modified to perform multi-label classification, cannot classify Lexical Units not in FrameNet",
          "Framester: rule-based multi-class multi-label classification; works on an older version of FrameNet",
          "TC: top frame picked by the crowd",
          "Kendalls list ranking coefficient",
          "cosine similarity: distance between FSS-labeled crowd frames & frames predicted by the models",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "9000 sentences from FrameNet annotated with CrowdTruth",
          "Theres not only one right answer for each example, tolerate multiple outcomes",
          "Dont assume lexical resources are perfect",
          "Disagreement is a good indicator of ambiguity in sentences & frames.",
          "CrowdTruth metrics Python package: https://pypi.org/project/CrowdTruth/",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "18": {
        "title": "Crowd vs FrameNet experts ground truth",
        "text": [
          "Crowd performance is comparable to the experts."
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "19": {
        "title": "SQS and FQS vs Expert ground truth",
        "text": [
          "When the crowd workers agree with each other, they also agree with the expert.",
          "But disagreement can have a good reason!",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "20": {
        "title": "When crowd and expert disagree",
        "text": [
          "Crowd misunderstood the frame definition.",
          "Information in the sentence is incomplete.",
          "The investigation has been stymied, stopped, obstructions thrown every step of the way.",
          "Crowd: criminal investigation (FSS = 0.804)",
          "Does supersizing cause obesity?",
          "Expert: causation (FSS = 0.608) Crowd st ill picked the expert frame, but with lower FSS.",
          "@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth"
        ],
        "page_nums": [
          30
        ],
        "images": []
      }
    },
    "paper_title": "A Crowdsourced Frame Disambiguation Corpus with Ambiguity"
  },
  "989": {
    "slides": {
      "0": {
        "title": "Learning under Domain Shift",
        "text": [
          "State-of-the-art domain adaptation approaches",
          "evaluate on proprietary datasets or on a single benchmark",
          "Only compare against weak baselines",
          "Almost none evaluate against approaches from the extensive semi-supervised learning (SSL) literature"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "Revisiting Semi Supervised Learning",
        "text": [
          "Classics in a Neural World",
          "How do classics in SSL compare to recent advances?",
          "Can we combine the best of both worlds?",
          "How well do these approaches work on out-of-distribution data?"
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "Bootstrapping algorithms",
        "text": [],
        "page_nums": [
          11,
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "3": {
        "title": "Self training",
        "text": [
          "1. Train model on labeled data.",
          "2. Use confident predictions on unlabeled data as training examples. Repeat.",
          "- Er ror a mpli"
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "Self training variants",
        "text": [
          "Output probabilities in neural networks are poorly calibrated.",
          "Throttling (Abney, 2007), i.e. selecting the top n highest confidence unlabeled examples works best.",
          "Training until convergence on labeled data and then on unlabeled data works best."
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "5": {
        "title": "Tri training",
        "text": [
          "1. Train three models on bootstrapped samples.",
          "2. Use predictions on unlabeled data for third if two agree.",
          "Final prediction: majority voting"
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "6": {
        "title": "Tri training with disagreement",
        "text": [
          "1. Train three models on bootstrapped samples.",
          "2. Use predictions on unlabeled data for third if two agree and prediction differs.",
          "dependen t mo dels"
        ],
        "page_nums": [
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "7": {
        "title": "Tri training hyper parameters",
        "text": [
          "Producing predictions for all unlabeled examples is expensive",
          "Sample number of unlabeled examples",
          "Not effective for classic approaches, but essential for our method"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53,
          54
        ],
        "images": []
      },
      "8": {
        "title": "Multi task Tri training",
        "text": [
          "1. Train one model with 3 objective functions.",
          "2. Use predictions on unlabeled data for third if two agree.",
          "Restrict final layers to use different representations.",
          "Train third objective function only on pseudo labeled to bridge domain shift.",
          "m2 F orthogonality constraint (Bousmalis et al., 2016)",
          "Loss: L() = log Pmi(y h Lorth"
        ],
        "page_nums": [
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75
        ],
        "images": [
          "figure/image/989-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Data and Tasks",
        "text": [
          "Sentiment analysis on Amazon reviews dataset (Blitzer et al, 2006)",
          "POS tagging on SANCL 2012 dataset (Petrov and McDonald, 2012)"
        ],
        "page_nums": [
          76,
          77,
          78,
          79
        ],
        "images": []
      },
      "10": {
        "title": "Sentiment Analysis Results",
        "text": [
          "Avg over 4 target domains",
          "VFAE* Self-training DANN* Tri-training Asym* Tri-training-Disagr. Source only MT-Tri * result from Saito et al., (2017) Multi-task tri-training slightly outperforms tri-training, but has higher variance."
        ],
        "page_nums": [
          80,
          81,
          82,
          83,
          84
        ],
        "images": []
      },
      "11": {
        "title": "POS Tagging Results",
        "text": [
          "Trained on 10% labeled data (WSJ)",
          "Avg over 5 target domains",
          "Source (+embeds) Tri-training-Disagr. Self-training MT-Tri Tri-training",
          "Tri-training with disagreement works best with little data.",
          "Trained on full labeled data (WSJ)",
          "TnT Tri-training Stanford* Tri-training-Disagr. Source (+embeds) MT-Tri * result from Schnabel & Schutze (2014)",
          "Tri-training works best in the full data setting."
        ],
        "page_nums": [
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93
        ],
        "images": []
      },
      "12": {
        "title": "POS Tagging Analysis",
        "text": [
          "Accuracy on out-of-vocabulary (OOV) tokens",
          "Accuracy on OOV tokens",
          "Answers Emails Newsgroups Reviews Weblogs UWT rate Src Tri MT-Tri FLORS*",
          "OOV tokens Src Tri MT-Tri",
          "Classic tri-training works best on OOV tokens.",
          "MT-Tri does worse than source-only baseline on OOV.",
          "POS accuracy per binned log frequency",
          "Accuracy delta vs. src-only baseline",
          "Tri-training works best on low-frequency tokens (leftmost",
          "Accuracy on unknown word-tag (UWT) tokens",
          "% UWT tokens 2",
          "Accuracy on UWT tokens",
          "No bootstrapping method works well on unknown word- tag combinations. * result from Schnabel & Schutze (2014)",
          "icult ca very dif f ses",
          "Less lexicalized FLORS approach is superior."
        ],
        "page_nums": [
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107
        ],
        "images": []
      },
      "13": {
        "title": "Takeaways",
        "text": [
          "Classic tri-training works best: outperforms recent state-of-the-art methods for sentiment analysis.",
          "We address the drawback of tri-training (space & time complexity) via the proposed MT-Tri model",
          "MT-Tri works best on sentiment, but not for POS.",
          "Comparing neural methods to classics (strong baselines)",
          "Evaluation on multiple tasks domains"
        ],
        "page_nums": [
          108,
          109,
          110,
          111
        ],
        "images": [
          "figure/image/989-Figure1-1.png"
        ]
      }
    },
    "paper_title": "Strong Baselines for Neural Semi-Supervised Learning under Domain Shift"
  },
  "990": {
    "slides": {
      "0": {
        "title": "Contributions",
        "text": [
          "Question Answering (Q&A) and Spoken Language Understanding (SLU) under the same parsing framework:",
          "Public Q&A corpora (English)",
          "Proprietary Alexa SLU corpus (English)",
          "Transfer learning to learn parsers on low-resource domains, for both Q&A and SLU:"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "SLU Alexa Data",
        "text": [
          "Alexa data is annotated for intent/slot tagging:",
          "Which cinemas screen Star|Title Wars|Title tonight|Time",
          "Which we converted into trees:",
          "Tree parsing allows to make more complex requests:",
          "Add apples and oranges to shopping list and play music",
          "DOMAIN SIZE TER NT WORDS closet bookings cinema recipes search"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Q and A Data",
        "text": [
          "Questions annotated with Lambda DCS (Liang, 2013);",
          "Divided in 8 domains;",
          "Kobe Bryant num blocks",
          "How many blocks were made by Kobe Bryant?",
          "Questions about geographical facts;",
          "name Edinburgh amenity prison",
          "How many prisons does Edinburgh count?",
          "DATASET DOMAIN SIZE TER NT Words publications",
          "Overnight calendar housing recipes restaurants basketball blocks social",
          "Overnight publications calendar housing recipes restaurants basketball blocks social"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "3": {
        "title": "Parser",
        "text": [
          "Which cinemas screen Star Wars tonight?",
          "Time Title Title Time",
          "tonight Title Title Time",
          "Transition-based parser of Cheng et al. (2017) + character-level embeddings and copy mechanism:",
          "t0 tn x0 xn nt0 ntn"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "4": {
        "title": "Results",
        "text": [
          "DATA TASK DOMAIN ACCURACY",
          "Overnight Q&A publications calendar housing recipes restaurants basketball blocks social",
          "Alexa SLU search recipes cinema bookings closet",
          "DATA TASK DOMAIN BASELINE Copy",
          "DATA TASK DOMAIN BASELINE Attention"
        ],
        "page_nums": [
          25,
          26,
          27,
          29
        ],
        "images": []
      },
      "5": {
        "title": "Reminder Q and A Data",
        "text": [
          "DATASET DOMAIN SIZE TER NT Words",
          "Overnight publications calendar housing recipes restaurants basketball blocks social"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "6": {
        "title": "Transfer Learning Pretraining",
        "text": [
          "TER COPY NT t0 tn x0 xn nt0 ntn",
          "LOW-RESOURCE DOMAIN FEED-FORWARD LAYERS"
        ],
        "page_nums": [
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "7": {
        "title": "Transfer Learning Multi task Learning",
        "text": [
          "HR DOMAIN LR DOMAIN",
          "TER COPY TER COPY",
          "t0 tn x0 xn t0 tn x0 xn"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "8": {
        "title": "Trasfer Learning Multi task Learning",
        "text": [
          "HR DOMAIN LR DOMAIN",
          "TER COPY TER COPY",
          "t0 tn x0 xn t0 tn x0 xn"
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "9": {
        "title": "Transfer Learning Results on Overnight Q and A",
        "text": [
          "Q&A transfer learning helps for low-resource domains",
          "BASELINE MULTI-TASK LEARNING PRETRAING"
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "10": {
        "title": "Multi task Learning for Alexa SLU",
        "text": [
          "t0 tn x0 xn nt0 ntn"
        ],
        "page_nums": [
          38
        ],
        "images": []
      },
      "11": {
        "title": "Transfer Learning Results on Alexa SLU",
        "text": [
          "SLU transfer learning helps for low-resource domains:",
          "BASELINE MULTI-TASK LEARNING PRETRAING"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "12": {
        "title": "Transfer learning from SLU to Q and A",
        "text": [
          "Recipe domain exist in both Q&A and SLU;",
          "Pretrain with SLUs recipe for Q&As recipes;"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "13": {
        "title": "Takeaways",
        "text": [
          "Executable semantic parsing unifies Q&A and SLU;",
          "One model for all is fine but some choices must be revisited (e.g. attention, copy);",
          "Transfer learning for low-resource domains on Q&A and SLU."
        ],
        "page_nums": [
          41
        ],
        "images": []
      }
    },
    "paper_title": "Practical Semantic Parsing for Spoken Language Understanding"
  },
  "991": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I Bilingual transfer learning is important for overcoming data",
          "sparsity in the target language",
          "I Bilingual word embeddings eliminate the gap between source",
          "and target language vocabulary",
          "I Resources required for bilingual methods are often",
          "I Texts for embeddings",
          "I Source language training samples",
          "I We focused on domain-adaptation of word embeddings and",
          "better use of unlabeled data"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "I Cross-lingual sentiment analysis of tweets",
          "triste sad awful horrible bad malo super super",
          "mug jarra rojo hoy red today",
          "I Combination of two methods:",
          "I Domain adaptation of bilingual word embeddings",
          "I Semi-supervised system for exploiting unlabeled data",
          "I No additional annotated resource is needed:",
          "I Cross-lingual sentiment classification of tweets",
          "I Medical bilingual lexicon induction"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Word Embedding Adaptation",
        "text": [
          "Source Out-of-domain In-domain W2V MWE",
          "Target Out-of-domain In-domain W2V MWE BWE",
          "I Goal: domain-specific bilingual word embeddings with general",
          "Monolingual word embeddings on concatenated data",
          "I Easily accessible general (out-of-domain) data",
          "Map monolingual embeddings to a common space using",
          "I Small seed lexicon containing word pairs is needed",
          "I Simple and intuitive but crucial for the next step!"
        ],
        "page_nums": [
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "3": {
        "title": "Semi Supervised Approach",
        "text": [
          "I Goal: Unlabeled samples for training",
          "I Tailored system from computer vision to NLP (Hausser et al., 2017)",
          "I Labeled/unlabeled samples in the same class are similar",
          "I Sample representation is given by the n 1th layer",
          "I Walking cycles: labeled unlabeled labeled",
          "I Maximize the number of correct cycles",
          "I L Lclassification Lwalker Lvisit",
          "SL1 SL S L S L S L",
          "SU1 SU S U S U S U S U",
          "I Adapted bilingual word embeddings make the models able to",
          "ind f correct cycles at the beginning of the training and improve them later on."
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "4": {
        "title": "Cross Lingual Sentiment Analysis of Tweets",
        "text": [
          "I RepLab 2013 sentiment classification (+/0/-) of En/Es tweets",
          "I @churcaballero jajaja con lo bien que iba el volvo...",
          "I General domain data: 49.2M OpenSubtitles sentences",
          "I Twitter specific data:",
          "I 22M downloaded tweets",
          "I Seed lexicon: frequent English words from BNC (Kilgarriff, 1997)",
          "I Labeled data: RepLab En training set",
          "I Unlabeled data: RepLab Es training set",
          "I Our method is easily applicable to word embedding-based"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "5": {
        "title": "Medical Bilingual Lexicon Induction",
        "text": [
          "I Mine Dutch translations of English medical words",
          "I General domain data: 2M Europarl (v7) sentences",
          "I Medical data: 73.7K medical Wikipedia sentences",
          "I Medical seed lexicon (Heyman et al., 2017)",
          "En word in BNC 5 most similar and 5 random Du pair",
          "En word in medical lexicon 3 most similar Du",
          "I Classifier based approach",
          "I Word pairs as training set (negative sampling)",
          "I Character level LSTM to learn orthographic similarity",
          "a n a l o g u o s a n a l o o g <p> <p>",
          "I Word embeddings to learn semantic similarity",
          "I Dense-layer scores word pairs"
        ],
        "page_nums": [
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "6": {
        "title": "Results Sentiment Analysis",
        "text": [
          "labeled data unlabeled data",
          "Table 1: Accuracy on cross-lingual sentiment analysis of tweets"
        ],
        "page_nums": [
          22,
          23,
          24
        ],
        "images": []
      },
      "7": {
        "title": "Results Bilingual Lexicon Induction",
        "text": [
          "labeled lexicon unlabeled lexicon medical BNC medical medical medical",
          "Table 2: F1 scores of medical bilingual lexicon induction"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "8": {
        "title": "Conclusions",
        "text": [
          "I Bilingual transfer learning yield poor results when using",
          "I We showed that performance can be increased by using only",
          "additional unlabeled monolingual data",
          "I Delightfully simple approach to adapt embeddings",
          "I Broadly applicable method to exploit unlabeled data",
          "I Language and task independent approaches"
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "Two Methods for Domain Adaptation of Bilingual Tasks: Delightfully Simple and Broadly Applicable"
  },
  "992": {
    "slides": {
      "0": {
        "title": "Abstract Meaning Representation AMR",
        "text": [
          "He ate the pizza with his fingers."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "AMR to text generation English",
        "text": [
          "He ate the pizza with his fingers."
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Previous work",
        "text": [
          "Konstas et al. (2017): sequential encoder;"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "This work",
        "text": [
          "He ate the pizza with his fingers.",
          "Are improvements in graph encoders due to reentrancies?",
          "Graph: Graph Convolutional Network (GCN; Kipf and Welling, 2017)."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Sequential input Konstas et al 2017",
        "text": [
          ":arg0 he :arg1 pizza :instrument finger :part-of he eat-01",
          ":arg0 eat-01 he :arg1 pizza :instr. finger part-of he",
          "eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he"
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Tree structured input",
        "text": [
          "eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he",
          ":arg0 he :arg1 pizza :instr. finger part-of he eat-01"
        ],
        "page_nums": [
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Graph structured input",
        "text": [
          ":arg0 he :arg1 pizza :instrument finger :part-of he eat-01",
          "eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he",
          ":arg0 he :arg1 pizza :instr. finger part-of he eat-01"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "7": {
        "title": "Data",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "8": {
        "title": "Comparison between models dev set R1",
        "text": [
          "Seq TreeLSTM GCN-Tree GCN-Graph"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "9": {
        "title": "Comparison with previous work test set R1",
        "text": [
          "Konstas(seq) Song(graph) GCN-Tree GCN-Graph",
          "Konstas: sequential baseline, Konstas et al. (2017)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "10": {
        "title": "Comparison with previous work test set R2",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "11": {
        "title": "Reentrancies",
        "text": [
          "He ate the pizza with his fingers.",
          ":arg0 he :arg1 pizza :instrument finger :part-of he eat-01"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "Long range dependencies",
        "text": [
          "He ate the pizza with a fork.",
          "eat-01 :arg0 he :arg1 pizza :instrument fork",
          "Model Max dependency length"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Generation example",
        "text": [
          "communicate-01 lawyer significant-other ex",
          "REF tell your ex that all communication needs to go through the lawyer",
          "Seq tell that all the communication go through lawyer",
          "Tree tell your ex, tell your ex, the need for all the communication",
          "Graph tell your ex the need to go through a lawyer"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Conclusions",
        "text": [
          "Graph encoders based on GCN and BiLSTM gives best results for AMR-to-text generation;",
          "Reentrancies and long-range dependencies contribute to the improvements of graph encoders;",
          "Demo and source code: http://cohort.inf.ed.ac.uk/amrgen.html"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Do reentrancies help with generating pronouns",
        "text": [
          "He ate the pizza with his fingers He ate the pizza with he fingers",
          ":arg0 he :arg1 pizza :instrument finger :part-of he eat-01",
          "Contrastive pair analysis (Sennrich, 2017):",
          "Compute probability of a reference output sentence and the probability of a sentence containing a mistake;",
          "Compute accuracy of model in assigning a higher probability to the reference sentence.",
          "Model Antecedent Type Num. Gender"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "16": {
        "title": "More examples",
        "text": [
          "Graph i dont tell him but he finds out. i didnt tell him but he was out. i dont tell him but found out. i dont tell him but he found out.",
          "Graph if you tell people they can help you , if you tell him, you can help you ! if you tell person_name you, you can help you . if you tell them, you can help you .",
          "Graph i d recommend you go and see your doctor too. i recommend you go to see your doctor who is going to see your doctor. you recommend going to see your doctor too. i recommend you going to see your doctor too."
        ],
        "page_nums": [
          27,
          28,
          29,
          30
        ],
        "images": []
      }
    },
    "paper_title": "Structural Neural Encoders for AMR-to-text Generation"
  },
  "993": {
    "slides": {
      "0": {
        "title": "Sentence Summarization",
        "text": [
          "Generate a shorter version of a given sentence",
          "Preserve its original meaning",
          "Design or refine appealing headlines"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Seq2seq Summarization",
        "text": [
          "Require less human efforts",
          "Achieve the state-of-the-art performance"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Problems of Seq2seq Summarization",
        "text": [
          "Solely depend on the source text to generate summaries",
          "3% of summaries 3 words",
          "4 summaries repeat a word for 99 times",
          "Focus on extraction rather than abstraction"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Template based Summarization",
        "text": [
          "A traditional approach to abstractive summarization",
          "Fill an incomplete with the input text using the manually defined rules",
          "Be able to produce fluent and informative summaries",
          "Template [REGION] shares [open/close] [NUMBER] percent [lower/higher]",
          "Source hong kong shares closed down #.# percent on friday due to an absence of buyers and fresh incentives .",
          "Summary hong kong shares close #.# percent lower"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Problems of Template based Summarization",
        "text": [
          "Template construction is extremely time-consuming and requires a plenty of domain knowledge",
          "It is impossible to develop all templates for summaries in various domains"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Motivation",
        "text": [
          "Use actual summaries in the training datasets as soft templates to combine seq2seq and template-based summarization",
          "Seq2seq Guide the generation of seq2seq",
          "Template-based Automatically learn to rewrite from soft templates"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Proposed Method",
        "text": [
          "Re3Sum: consists of three modules: Retrieve, Rerank and",
          "Use Information Retrieval to find out candidate soft templates from the training dataset (Retrieve).",
          "Extend the seq2seq model to jointly learn template saliency measurement (Rerank) and final summary generation"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Contributions",
        "text": [
          "Introduce soft templates to improve the readability and stability in seq2seq",
          "Extend seq2seq to conduct template reranking and template-aware summary generation simultaneously",
          "Fuse the IR-based ranking technique and seq2seq-based generation technique, utilizing both supervisions",
          "Demonstrate potential to generate diversely"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Flow Chat",
        "text": [
          "Retrieve Search actual summaries as candidate soft templates",
          "Rerank Find out the most proper soft template from the candidates",
          "Rewrite Generate the summary based on source sentence and soft template",
          "Retrieve Rerank Rewrite Sentence Candidates Template Summary"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/993-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Retrieve",
        "text": [
          "Assumption: Similar sentences, similar summary patterns",
          "Output 30 actual summaries in the training dataset whose sources are the most similar to the input sentence"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Jointly Rerank and Rewrite",
        "text": [
          "Saliency Bilinear Decoder Summary"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Rerank",
        "text": [
          "Retrieve ranks templates according to the text similarity between sentences",
          "s(r, x) = sigmoid(hrWshT x bs)"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Rewrite",
        "text": [
          "A soft template accords with the facts in the input sentences",
          "Use Seq2seq to generate more faithful and informative summaries",
          "Concatenate the encoders of sentence and template",
          "Use attentive RNN decoder to generate summaries"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Learning",
        "text": [
          "Cross Entropy (CE) for Rerank",
          "Negative Log-Likelihood (NLL) for Rewrite",
          "Add the above two costs as the final loss"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Setting",
        "text": [
          "Dataset Gigaword (sentence, headline) pairs",
          "Dataset Train Dev. Test"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/993-Table1-1.png"
        ]
      },
      "15": {
        "title": "ROUGE Performance",
        "text": [
          "Re3Sum significantly outperforms other approaches",
          "Model ROUGE-1 ROUGE-2 ROUGE-L"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/993-Table3-1.png"
        ]
      },
      "16": {
        "title": "Linguistic Quality Performance",
        "text": [
          "Low LEN DIF and LESS 3 Stable",
          "Low NEW NE and NEW UP Faithful",
          "Item Template OpenNMT Re3Sum"
        ],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/993-Table5-1.png"
        ]
      },
      "17": {
        "title": "Effects of Template",
        "text": [
          "Performance highly relies on templates",
          "The rewriting ability is strong",
          "Type ROUGE-1 ROUGE-2 ROUGE-L"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/993-Table6-1.png"
        ]
      },
      "18": {
        "title": "Generation Diversity",
        "text": [
          "OpenNMT Beam search n-best outputs",
          "Re3Sum Provide different templates",
          "Source anny ainge said thursday he had two one-hour meetings with the new owners of the boston celtics but no deal has been completed for him to return to the franchise .",
          "Target ainge says no deal completed with celtics major says no deal with spain on gibraltar Templates roush racing completes deal with red sox owner",
          "Re3Sum ainge says no deal done with celtics ainge talks with new owners ainge talks with celtics owners OpenNMT ainge talks with new owners"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "19": {
        "title": "Conclusion",
        "text": [
          "Introduce soft templates as additional input to guide seq2seq summarization",
          "Combine IR-based ranking techniques and seq2seq-based generation techniques to utilize both supervisions",
          "Improve informativeness, stability, readability and diversity"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization"
  },
  "994": {
    "slides": {
      "0": {
        "title": "Text Simplification",
        "text": [
          "Last year I read the book John authored John wrote a book. I read the book.",
          "Original sentence One or several simpler sentences",
          "Multiple motivations Preprocessing for Natural Language Processing tasks",
          "e.g., machine translation, relation extraction, parsing",
          "Reading aids, Language Comprehension",
          "e.g., people with aphasia, dyslexia, 2nd language learners",
          "Multiple operations Word or phrase substitution Lexical"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "In this talk",
        "text": [
          "Compares favorably to the state-of-the-art in combined structural and lexical simplification.",
          "The first simplification system combining structural transformations, using semantic structures, and neural machine translation.",
          "Alleviates the over-conseratism of MT-based systems."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Current Approaches and Challenges",
        "text": [
          "Sentence simplification as monolingual machine translation"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "3": {
        "title": "Conservatism in MT Based Simplification",
        "text": [
          "In both SMT and NMT Text Simplification, a large proportion of the input sentences are not modified. (Alva-Manchego et al., 2017; on the Newsela corpus).",
          "It is confirmed in the present work (experiments on Wikipedia):",
          "of the input sentences remain unchanged.",
          "- None of the references are identical to the source.",
          "- According to automatic and human evaluation, the references are indeed simpler."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Sentence Splitting in Text Simplification",
        "text": [
          "Splitting in NMT-Based Simplification",
          "Sentence splitting is not addressed.",
          "Rareness of splittings in the simplification training corpora.",
          "Recently, corpus focusing on sentence splitting for the Split-and-Rephrase task",
          "(Narayan et al., 2017) where the other operations are not addressed.",
          "Directly modeling sentence splitting",
          "1. Hand-crafted syntactic rules:",
          "- Compilation and validation can be laborious (Shardlow, 2014)",
          "Many rules are often involved (e.g., 111 rules in Siddharthan and Angrosh,",
          "2014) for relative clauses, appositions, subordination and coordination).",
          "- Usually language specific.",
          "Noun phrase Relative clause Relative Pronoun",
          "One of the two rules for relative clauses in Siddharthan, 2004.",
          "2. Using semantics for determining potential splitting points",
          "Narayan and Gardent (2014) - HYBRID",
          "- Discourse Semantic Representation (DRS) structures for splitting and deletion.",
          "- Depends on the proportion of splittings in the training corpus.",
          "We here use an intermediate way:",
          "Simple algorithm to directly decompose the sentence into its semantic constituents."
        ],
        "page_nums": [
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "5": {
        "title": "Direct Semantic Splitting DSS",
        "text": [
          "A simple algorithm that directly decomposes the sentence into its semantic components, using 2 splitting rules.",
          "The splitting is directed by semantic parsing.",
          "The semantic annotation directly captures shared arguments.",
          "It can be used as a preprocessing step for other simplification operations.",
          "Input sentence Split sentence Output",
          "Sentence Splitting Deletions, Word substitutions"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "6": {
        "title": "The Semantic Structures",
        "text": [
          "Semantic Annotation: UCCA (Abend and Rappoport, 2013)",
          "- Based on typological and cognitive theories",
          "L A A and P",
          "He came back home played piano",
          "Parallel Scene (H) Linker (L) P surprised His Participant (A) Process (P) arrival",
          "E observed E C A A Parallel Scene (H) the planet R S C Participant (A) Process (P) State (S) E which has Center (C) Elaborator (E) Relator (R) satellites",
          "- Stable across translations (Sulem, Abend and Rappoport, 2015)",
          "- Used for the evaluation of MT, GEC and Text Simplification",
          "- Explicitly annotates semantic distinctions, abstracting away from syntax",
          "- Unlike AMR, semantic units are directly anchored in the text.",
          "Scenes evoked by a Main Relation (Process or State).",
          "- A Scene may contain one or several Participants.",
          "- A Scene can provide additional information on an established entity:",
          "it is then an Elaborator Scene.",
          "- A Scene may also be a Participant in another Scene:",
          "It is then a Participant Scene.",
          "- In the other cases, Scenes are annotated as Parallel Scenes.",
          "A Linker may be included."
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "7": {
        "title": "The Semantic Rules",
        "text": [
          "Placing each Scene in a different sentence.",
          "Fits with event-wise simplification (Glavas and Stajner, 2013)",
          "Here we only use semantic criteria.",
          "It was also investigated in the context of Text Simplification evaluation:",
          "SAMSA measure (Sulem, Abend and Rappoport, NAACL 2018)",
          "A A and He came back home and played piano.",
          "He came back home played piano",
          "A A P A A P He came back home. He played piano.",
          "A A P A Input sentence A P Input Scenes He played piano He came back home",
          "P He observed the planet which has 14 satellites.",
          "the R S planet",
          "E C which has",
          "P A He A He observed the planet. Planet has 14 satellites.",
          "observed S E C planet E C has the planet satellites",
          "A A the R S SSSciC iSc1Scn planet",
          "Input sentence A Elaborator Scenes A",
          "Input sentence without the Elaborator Scenes, preserving the Minimal Center has the planet satellites",
          "Grammatical errors resulting from the split are not addressed by the rules. e.g., no article regeneration.",
          "The output is directly fed into the NMT component.",
          "Participant Scenes are not separated here to avoid direct splitting in these cases:",
          "His arrival surprised Mary.",
          "He said John went to school.",
          "More transformations would be required for splitting in these cases."
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "8": {
        "title": "Combining DSS with Neural Text Simplification",
        "text": [
          "After DSS, the output is fed to an MT-based simplification system.",
          "We use a state-of-the-art NMT-Based TS system, NTS (Nisioi et al., 2017).",
          "The combined system is called SENTS.",
          "NTS was built using the OpenNMT (Klein et al., 2017) framework.",
          "We use the NTS-w2v provided model where word2vec embeddings are used for the initialization.",
          "Beam search is used during decoding. We explore both the highest (h1) and a lower ranked hypothesis (h4), which is less conservative.",
          "NTS model trained on the corpus of Hwang et al., 2015 (~280K sentence pairs).",
          "It was tuned on the corpus of Xu et al., 2016 (2000 sentences with 8 references)."
        ],
        "page_nums": [
          32,
          33
        ],
        "images": []
      },
      "9": {
        "title": "Experiments",
        "text": [
          "Test set of Xu et al., 2016: sentences, each with 8 references",
          "e.g., percentage of sentences copied from the input (%Same)",
          "First 70 sentences of the corpus",
          "3 annotators native English speakers",
          "4 questions for each input-output pair",
          "Is the output fluent and grammatical?",
          "Does the output preserve the meaning of the input?",
          "Qd Is the output simpler than the input, ignoring the complexity of the words?",
          "4 parameters: Grammaticality (G) Meaning Preservation (P) Simplicity (S) Structural Simplicity (StS)"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "10": {
        "title": "Results",
        "text": [
          "BLEU SARI G M S StS",
          "Automatic evaluation: BLEU, SARI",
          "Human evaluation (first 70 sentences):",
          "G Grammaticality: 1 to 5 scale S Simplicity: -2 to +2 scale",
          "P Meaning Preservation: 1 to 5 scale StS Structural Simplicity: -2 to +2 scale",
          "Identity gets the highest BLEU score and the lowest SARI scores.",
          "The two SENTS systems outperform HYBRID in terms of BLEU, SARI, G, M and S.",
          "SENTS-h1 has the best StS score.",
          "%Same SARI G M S StS",
          "Automatic evaluation: %Same, SARI",
          "Compared to NTS, SENTS reduces conservatism and increases simplicity.",
          "Compared to DSS, SENTS improves grammaticality and increases structural simplicity, since deletions are performed by the NTS component.",
          "Replacing NTS by Statistical MT",
          "Combination of DSS and Moses: SEMoses",
          "The behavior of SEMoses is similar to that of DSS, confirming the over-conservatism of Moses (Alva-Manchego et al., 2017) for simplification.",
          "All the splitting points from the DSS phase are preserved.",
          "Replacing the parser by manual annotation",
          "In the case of SEMoses, meaning preservation is improved. Simplicity degrades, possibly due to a larger number of annotated Scenes.",
          "In the case of SENTS-h1, high simplicity scores are obtained."
        ],
        "page_nums": [
          36,
          37,
          38,
          39,
          40
        ],
        "images": []
      },
      "11": {
        "title": "Human Evaluation Benchmark",
        "text": [],
        "page_nums": [
          41
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion 1",
        "text": [
          "We presented here the first simplification system combining semantic structures and neural machine translation.",
          "Our system compares favorably to the state-of-the-art in combined structural and lexical simplification.",
          "This approach addresses the conservatism of MT-based systems.",
          "Sentence splitting is performed without relying on a specialized corpus."
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "13": {
        "title": "Conclusion 2",
        "text": [
          "Sentence splitting is treated as the decomposition of the sentence into its Scenes (as in SAMSA evaluation measure;",
          "Sulem, Abend and Rappoport, NAACL 2018)",
          "Future work will leverage UCCAs cross-linguistic applicability to support multi-lingual text simplification and simplification pre-processing for MT."
        ],
        "page_nums": [
          43
        ],
        "images": []
      }
    },
    "paper_title": "Simple and Effective Text Simplification Using Semantic and Neural Methods"
  },
  "995": {
    "slides": {
      "0": {
        "title": "Conversational Agents",
        "text": [
          "Sorry, I dont understand what youre saying",
          "Data augmentation might help"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "Paraphrase Generation",
        "text": [
          "Rephrasing a given text in multiple ways",
          "Paraphrases how could i increase my height ? what should i do to increase body height ? what are the ways to increase height ? are there some ways to increase body height ?"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "2": {
        "title": "Current State",
        "text": [
          "Source how do i increase body height ?",
          "Synonym how do i grow body height ?",
          "Phrase how do i increase the body measurement vertically?",
          "Beam how do i increase my height ? how do i increase my body height how do i increase the height ? how would i increase my body height"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "3": {
        "title": "What can we do",
        "text": [
          "Source how do i increase body height ?",
          "Beam how do i increase my height ? how can i decrease my body weight ? what do i do to increase the height ? i am 17, what steps to take to decrease weight ?"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "4": {
        "title": "What we need",
        "text": [
          "Find k diverse paraphrases with high fidelity",
          "Method based on subset selection of candidate (sub)sequences"
        ],
        "page_nums": [
          30,
          31,
          32
        ],
        "images": []
      },
      "5": {
        "title": "Subset Selection",
        "text": [
          "how do i increase my how can i decrease the how can i grow the what ways exist to increase how would I increase the how do I decrease the",
          "how do i increase my how can i decrease the how can i grow the how do i increase my what ways exist to increase how can i grow the how would I increase the what ways exist to increase how do I decrease the are there ways to increase",
          "If F is sub modular + monotone = Greedy algo. with good bounds exists"
        ],
        "page_nums": [
          33,
          34,
          35,
          36
        ],
        "images": []
      },
      "6": {
        "title": "Sub modularity",
        "text": [
          "F = # Unique Coloured items"
        ],
        "page_nums": [
          37,
          38,
          39,
          40,
          41,
          42,
          43
        ],
        "images": []
      },
      "7": {
        "title": "Monotonicity",
        "text": [],
        "page_nums": [
          44
        ],
        "images": []
      },
      "8": {
        "title": "DiPS",
        "text": [
          "Induce Diversity while not compromising on Fidelity",
          "Diversity C omponents Fidelity Co mponents",
          "where can film I How find that that picture",
          "I get can I Where can I : 3k Candidate Subsequ ences Source Sentence",
          "Where can I find t h a t film? Where can I get t h a t movie?",
          "Rewards unique n-grams How can I get that picture?",
          "Where can I get that film?",
          "I find that picture",
          "Where can I get that movie?",
          "Where can I <eos> <sos> ENCODER DECODER",
          "Enc o d e r k- sequences",
          "Enc o d e r D e c o d er k- sequences",
          "How can I get that picture Fidelity"
        ],
        "page_nums": [
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          59,
          60
        ],
        "images": []
      },
      "9": {
        "title": "Diversity Components",
        "text": [
          "Rewards Structural Coverage where can film I How N find that that picture",
          "I get can I Where can I : 3k Candidate Subsequences Source Sentence",
          "n xngram : 3k Candidate Subse q uences Source Sentence",
          "Where can I n=1 xX find t h a t film? Where can I get t h a t movi Where can I get that movie? Rewards unique n-grams How can I get th at picture?",
          "Rewards unique n-grams How can I get that picture?",
          "Synonym (similar embeddings) W here can I get that film? S t r uct u r al C o v era g e Where can I find that pictu re Ho w can I g et that pictu re (x i, xj) k- sequences",
          "Where can I find that pictu re Ho w can I g et that pictu re k- sequences",
          "Rew ar ds Stru ct ural C over age xi V (t) xjX",
          "Where can I get that Where movie? can I <eos> <sos> ENCODER DECODER",
          ": 3k Candidate Subse q uences n xngram",
          "I get can I Where can I Source Sentence",
          "Where can I find t h a t film Where can I get t h a t movie",
          "(xi, xj) EditDistance(xi, xj)",
          "Where can I get that Where movie? can I <eos> <sos> |xi |xj"
        ],
        "page_nums": [
          56,
          57,
          58
        ],
        "images": []
      },
      "10": {
        "title": "Fidelity Components",
        "text": [
          "where can film I How find that that picture",
          "I get can I Where can I : 3k Candidate Subsequences Source Sentence N",
          "Where can I find t h a t film? Where can I get t h a t movie n |xn-gram sn-gram",
          "xX n=1 Rewards unique n-grams How can I get that picture?",
          "Where can I get that film? Embedding based Similarity",
          "Where can I find that picture",
          "wix Where can I get that movie?",
          "where can film I How Lexical Similarity find that that picture",
          "How can I get that picture (x, s)",
          "Rewards Structural Coverage xX"
        ],
        "page_nums": [
          61,
          62,
          63
        ],
        "images": []
      },
      "11": {
        "title": "DiPS Objective",
        "text": [
          "DDiivveerrssiittyy C Coommppoonneenntts s FFiiddeelliittyy CCoo mmppoonneenntts s",
          "where where can can film film I I How How find find that that that that picture picture",
          "I I get get can can I I Where Where can can I I : : 3k 3k Candidate Candidate Subsequences Subsequences Source Source Sentence Sentence",
          "Where Where can can I I find find t t h h a a t t film? film Where can I get t h a t movie Where can I get t h a t movie",
          "Rewards Rewards unique unique n-grams n-grams How can I get that picture? How can I get that picture?",
          "Synonym (similar embeddings) Synonym (similar embeddings) Where Where can can I I get get that that film? film?",
          "Where Where can can can can I I find find that that picture picture How How I I get get that that picture picture Rewards Rewards Structural Structural Coverage Coverage",
          "Where Where can can I I get get that that movie? movie?"
        ],
        "page_nums": [
          64,
          65,
          66,
          67
        ],
        "images": []
      },
      "12": {
        "title": "Fidelity and Diversity",
        "text": [
          "SBS DBS VAE-SVG DPP SSR DiPS (Ours) DiPS induces diversity without",
          "compro4m-Diisstininctg (D iovenrs itfiy) delity"
        ],
        "page_nums": [
          68,
          69,
          70,
          71
        ],
        "images": []
      },
      "13": {
        "title": "Data Augmentation Paraphrase Detection",
        "text": [
          "No Aug SBS DPP SSR DBS DiPS (Ours)",
          "Di PS data augmentation helps in paraphrase detection"
        ],
        "page_nums": [
          72,
          73
        ],
        "images": []
      },
      "14": {
        "title": "Data Augmentation for Intent Classification",
        "text": [
          "No. Aug SBS DBS Syn. Rep Cont. Aug DiPS (Ours)",
          "Da ta augmentation using DiPS improves inten t classification"
        ],
        "page_nums": [
          74,
          75,
          76,
          77
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "Without compromising on fidelity",
          "DiPS Seq2Seq + Diversity"
        ],
        "page_nums": [
          78,
          79,
          80,
          81
        ],
        "images": []
      }
    },
    "paper_title": "Submodular Optimization-based Diverse Paraphrasing and its Effectiveness in Data Augmentation"
  },
  "996": {
    "slides": {
      "0": {
        "title": "Neural Question Answering",
        "text": [
          "Question: What color is the sky?",
          "Passage: Air is made mainly from molecules of nitrogen and oxygen.",
          "These molecules scatter the blue colors of sunlight more effectively than the green and red colors. Therefore, a clean sky appears blue."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Fast Progress on Paragraph Datasets",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "What Next",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Open Question Answering",
        "text": [
          "Question: What color is the sky?",
          "Relevant Text Model Answer Span Document Retrieval"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Challenge Scaling Models to Documents",
        "text": [
          "Modern reading comprehension models have many layers and parameters",
          "The trend is continuing in this direction, for example with the use of large language models",
          "Reduced efficiency as the paragraph length increases due to long RNN chains or",
          "Limits the model to processing short paragraphs"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Two Possible Approaches",
        "text": [
          "Select a single paragraph from the input, and run the model on that paragraph",
          "Run the model on many paragraphs from the input, and have itassign a confidence score to its results on each paragraph"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "This Work",
        "text": [
          "Improve several of the key design decision that arise when training on document-level data",
          "Study ways to train models to produce correct confidence scores"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Pipeline Method Paragraph Selection",
        "text": [
          "Train a shallow linear model to select the best paragraphs",
          "Features include TF-IDF, word occurrences, and its position within the document",
          "If there is just one document TF-IDF alone is effective",
          "Improves change of selecting an answering-containing paragraph from 83.0 to"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Pipeline Method Noisy Supervision",
        "text": [
          "Document level data can be expected to be distantly supervised:",
          "Question: Which British general was killed at Khartoum in 1885?",
          "In February 1884 Gordon returned to the Sudan to evacuate Egyptian forces.",
          "Rebels broke into the city , killing Gordon and the other defenders. The British public reacted to his death by acclaiming ' Gordon of Khartoum , a saint.",
          "However, historians have since suggested that Gordon defied orders and.",
          "Need a training objective that can handle multiple (noisy) answer spans",
          "Use the summed objective from Kadlec et al (2016), that optimizes the log sum of",
          "the probability of all answer spans",
          "Remains agnostic to how probability mass is distributed among the answer spans"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "9": {
        "title": "Pipeline Method Model",
        "text": [
          "Construct a fast, competitive model",
          "Use some keys ideas from prior work,",
          "bidirectional-attention, self-attention, character- embeddings, variational dropout",
          "Also added learned tokens for document and",
          "< 5 hours to train for 26 epochs on SQuAD"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/996-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Confidence Methods",
        "text": [
          "We can derive confidence scores from the logit scores given to each span by the",
          "model, i.e., the scores given before the softmax operator is applied",
          "Without re-training this can work poorly"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Example from SQuAD",
        "text": [
          "Question: When is the Members Debate held?",
          "Model Extraction: ..majority of the Scottish electorate voted for it in a referendum to be held on 1 March 1979 that represented at least...",
          "Correct Answer: Immediately after Decision Time a Members Debate is held, which lasts for"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Learning Well Calibrated Confidence Scores",
        "text": [
          "Train the model on both answering-containing and non-answering containing",
          "paragraph and use a modified objective function",
          "Merge: Concatenate sampled paragraphs together",
          "No-Answer: Process paragraphs independently, and allow the model to place",
          "probability mass on a no-answer output",
          "Sigmoid: Assign an independent probability on each span using the sigmoid",
          "Shared-Norm: Process paragraphs independently, but compute the span",
          "probability across spans in all paragraphs"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Results",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Datasets",
        "text": [
          "Includes three setting, Web (a single document for each questions) Wiki (multiple wikipedia documents for each questions) and Unfiltered (Multiple documents for each questions)",
          "SQuAD: Turker-generated questions about Wikipedia articles",
          "We use the questions paired with the entire article",
          "Manual annotation shows most (90%) of questions are answerable as given the document it was generated from"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Pipeline Method Results on TriviaQA Web",
        "text": [
          "Uses BiDAF as the model",
          "Select paragraphs by truncating documents",
          "Select answer-spans randomly EM",
          "word embeddings (Peters et al., 2017)",
          "TriviaQA Baseline Our Baseline +TF-IDF +Sum +TF-IDF +Sum +Model +TF-IDF +Sum"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "16": {
        "title": "TriviaQA Leaderboard Exact Match Scores",
        "text": [
          "Model Web-All Web-Verified Wiki-All Wiki-Verified",
          "Best leaderboard entry (mingyan)",
          "Dynamic Integration of Background"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/996-Figure4-1.png"
        ]
      },
      "17": {
        "title": "Error Analysis",
        "text": [
          "Manually annotated 200 errors made by the TriviaQAWeb model",
          "40.5% are due to noise or lack of context in the relevant documents"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "18": {
        "title": "Building an Open Question Answering System",
        "text": [
          "Use Bing web search and a Wikipedia entity linker to locate relevant documents",
          "Extract the top 12 paragraphs, as found using the linear paragraph ranker",
          "Use the model trained for TriviaQA Unfiltered to find the final answer"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/996-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Demo",
        "text": [],
        "page_nums": [
          25
        ],
        "images": []
      },
      "20": {
        "title": "Curated Trec Results",
        "text": [],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Simple and Effective Multi-Paragraph Reading Comprehension"
  },
  "997": {
    "slides": {
      "0": {
        "title": "Multimodal Machine Translation MMT",
        "text": [
          "Better machine translation approaches by leveraging multiple modalities",
          "Multilingual extension of Flickr30K (Young et al., 2014)",
          "Images, English descriptions, French, German and Czech translations.",
          "Sense disambiguation river bank vs. financial bank"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Example grammatical gender",
        "text": [
          "Une joueuse de baseball en maillot noir vient de toucher une joueuse en maillot blanc.",
          "A baseball player in a black shirt just tagged a player in a white shirt. Un joueur de baseball en",
          "maillot noir vient de toucher Male baseball",
          "player un j oueur en maillot blanc.",
          "Visual context disambiguates the gender",
          "Ca ndidate Translations (FR)",
          "A baseball player in a black shirt just tagged a player in a white shirt. maillot noir vient de toucher une joueuse en maillot blanc."
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Where are we",
        "text": [
          "Benefit of current approaches is not evident - WMT18 (Barrault et al., 2018):",
          "Largest gain from external corpora, not from images (Gronroos et al., 2018)",
          "Adversarially attacking MMT marginally influences the scores",
          "METEOR (EN-DE) Congruent Incongruent"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Why dont images help",
        "text": [
          "Pre-trained CNN features may not be good enough for MMT",
          "ImageNet has very limited set of objects",
          "Current multimodal models may not be effective",
          "Multi30K dataset may be",
          "Too simple; language is enough",
          "Too small to generalise visual features"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "This paper",
        "text": [
          "We degrade source language",
          "Systematically mask source words at training and inference times",
          "Hypothesis 1: MMT models should perform better than text-only models if image is effectively taken into account",
          "Hypothesis 2: More sophisticated MMT models should perform better than simpler MMT models"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Types of degradation",
        "text": [
          "Source sentence a lady in a blue dress singing"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Types of degradation 1",
        "text": [
          "Source sentence a lady in a blue dress singing",
          "Color Masking a lady in a [v] dress singing",
          "of source words are removed"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Types of degradation 2",
        "text": [
          "Source sentence a lady in a blue dress singing",
          "Color Masking a lady in a [v] dress singing",
          "Entity Masking a [v] in a blue [v] singing",
          "Uses Flickr30K entity annotations (Plummer et al., 2015)",
          "of source words are removed (3.4 blanks / sent)"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Types of degradation 3",
        "text": [
          "Source sentence a lady in a blue dress singing",
          "Color Masking a lady in a [v] dress singing",
          "Entity Masking a [v] in a blue [v] singing",
          "Progressive Masking (k=4) a lady in a [v] [v] [v]",
          "Removal of any words",
          "MMT task becomes multimodal sentence completion/captioning"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Settings",
        "text": [
          "2-layer GRU-based encoder/decoder NMT",
          "400D hidden units, 200D embeddings",
          "Visual features ResNet-50 CNN pretrained on ImageNet",
          "2048D pooled vectoral representations",
          "2048x8x8 convolutional feature maps",
          "Primary language pair: English French"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "MMT methods",
        "text": [
          "Tied INITialization of encoders and decoders",
          "DIRECT fusion uses modality specific attention layers and concatenates their",
          "HIERarchical fusion applies a third attention layer instead of concatenation"
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation",
        "text": [
          "Mean and standard deviation (3 runs) of METEOR scores",
          "Statistical significance testing with MultEval (Clark et al., 2011)",
          "Adversarial evaluation Shuffled (incongruent) image features (Elliott 2018)",
          "Incongruent decoding: Incongruent features at inference time-only",
          "Blinding: Incongruent features at training and inference times"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Results",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Upper bound no masking",
        "text": [
          "MMTs slightly better than NMT on average"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "14": {
        "title": "Color masking",
        "text": [
          "Masked NMT suffers a substantial 2.2 drop",
          "Masked MMT significantly better than masked NMT",
          "Accuracy in color translation much better in attentive MMT"
        ],
        "page_nums": [
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "15": {
        "title": "Entity masking",
        "text": [
          "NMT suffers > 20 points drop",
          "Up to 4.2 METEOR recovered by MMT",
          "Models are visually sensitive: Up to ~10",
          "METEOR drop with incongruent decoding",
          "MMT is attentive, INC is"
        ],
        "page_nums": [
          24,
          25,
          26,
          30
        ],
        "images": [
          "figure/image/997-Figure1-1.png"
        ]
      },
      "16": {
        "title": "Entity masking all languages",
        "text": [
          "MMT Gain over NMT",
          "English INIT HIER DIRECT Average",
          "All languages benefit from visual context",
          "German French benefits the",
          "Multimodal attention better than INIT, Direct fusion slightly better than hierarchical"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "17": {
        "title": "Entity masking attention",
        "text": [
          "A typo in the source (song) - translated to chanson",
          "Visual attention barely changes",
          "mother, song and day are masked",
          "Textual attention is less confident, visual attention works!"
        ],
        "page_nums": [
          28,
          29
        ],
        "images": []
      },
      "18": {
        "title": "Progressive masking",
        "text": [
          "As more information is removed, all",
          "MMT models leverage visual context, up to 7 METEOR points",
          "Attentive models perform better than INIT",
          "Upper bound: ~7 METEOR when all words are masked",
          "Compare two degraded variants to original Multi30K",
          "MMT improves over NMT as linguistic information (k) is removed",
          "Incongruent Dec. (Relative to DIRECT MMT)",
          "It also becomes sensitive to the visual incongruence",
          "MMT that never sees correct features converges to text-only NMT",
          "MMT improvements are not random",
          "MMT is attentive, INC is"
        ],
        "page_nums": [
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
        ],
        "images": [
          "figure/image/997-Figure3-1.png"
        ]
      },
      "19": {
        "title": "Conclusion",
        "text": [
          "Hypothesis 1: MMT models should perform better than text-only models if image is effectively taken into account",
          "Visual info is taken into account if modalities are complementary",
          "Incorrect visual info harms performance substantially more",
          "Hypothesis 2: More sophisticated MMT models should perform better than simpler MMT models",
          "Attentive MMT better than simple INIT grounding",
          "Attentive MMT recovers more from impact of substantial masking"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "20": {
        "title": "Future work",
        "text": [
          "Grounding as a way to reduce biases and improve robustness to errors",
          "Better models to balance complementary and redundant information",
          "Multimodality to resolve unknown words",
          "The dachshund is running in the fields full of little white flowers.",
          "O UNK corre no campo cheio de florzinhas brancas.",
          "O cachorro corre no campo cheio de f lorzinhas brancas."
        ],
        "page_nums": [
          40
        ],
        "images": []
      }
    },
    "paper_title": "Probing the Need for Visual Context in Multimodal Machine Translation"
  },
  "998": {
    "slides": {
      "0": {
        "title": "Time Critical Events",
        "text": [
          "Disaster events (earthquake, flood) Urgent needs for affected people",
          "Information gathering in real-time is the most challenging part",
          "Relief operations Humanitarian organizations and local administration need information to help and launch response"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Artificial Intelligence for Digital Response AIDR",
        "text": [
          "Response time-line today Response time-line our target",
          "Delayed decision-making Delayed crisis response Target Early decision-making Rapid crisis response"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Artificial Intelligence for Digital Response",
        "text": [
          "Informative Not informative Dont know or cant judge Facilitates decision makers Hurricane Irma Hurricane Hurricane California Mexico Iraq & Iran Sri Lanka Harvey Maria wildfires earthquake earthquake f loods",
          "Small amount of labeled data and large amount of unlabeled data at the beginning of the event",
          "Labeled data from the past event. Can we use them?",
          "What about domain shift?"
        ],
        "page_nums": [
          3,
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Our Solutions Contributions",
        "text": [
          "How to use large amount of unlabeled data and small amount of labeled data from the same event?",
          "How to transfer knowledge from the past events",
          "=> Adversarial domain adaptions"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Domain Adaptation with Adversarial Training and Graph Embeddings",
        "text": [
          "We seek parameters that minimizes the classification loss of the class labels and maximizes domain discriminator loss",
          "{U,V} Convolution filters and dense layer parameters",
          "{Vc,W} Parameters specific to the supervised part",
          "{Vg,C} Parameters specific to the semi-supervised part",
          "{Vd,wd} Parameters specific to the domain discriminator part"
        ],
        "page_nums": [
          8,
          20,
          22
        ],
        "images": [
          "figure/image/998-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Supervised Learning",
        "text": [],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/998-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Semi Supervised Learning",
        "text": [
          "L: number of labeled instances (x1:L, y1:L)",
          "U: number of unlabeled instances (xL+1:L+U)",
          "Design a classifier f: x y"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": [
          "figure/image/998-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Graph based Semi Supervised Learning",
        "text": [
          "Nodes: Instances (labeled and unlabeled)",
          "Edges: n x n similarity matrix",
          "Each entry ai,j indicates a similarity between instance i and j",
          "We construct the graph using k-nearest neighbor (k=10)",
          "Requires n(n-1)/2 distance computation",
          "K-d tree data structure to reduce the computational complexity",
          "Feature Vector: taking the averaging of the word2vec vectors",
          "Semi-Supervised component: Loss function",
          "Learns the internal representations (embedding) by predicting a node in the graph context",
          "Two types of context",
          "1. Context is based on the graph to encode structural",
          "2. Context is based on the labels to inject label information into the embeddings",
          "{U,V} Convolution filters and dense layer parameters",
          "{Vc,W} Parameters specific to the supervised part",
          "{Vg,C} Parameters specific to the semi-supervised part"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "8": {
        "title": "Domain Adaptation with Adversarial Training",
        "text": [
          "Domain discriminator is defined by:",
          "Negative log probability of the discriminator loss:",
          "Domain adversary loss is defined by:",
          "d {0,1} represents the domain of the input tweet t",
          "{U,V} Convolution filters and dense layer parameters",
          "{Vd,wd} Parameters specific to the domain discriminator part"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "9": {
        "title": "Model Training",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "10": {
        "title": "Corpus",
        "text": [
          "A small part of the tweets has been annotated using crowdflower",
          "Relevant: injured or dead people, infrastructure damage, urgent needs of affected people, donation requests",
          "Dataset Relevant Irrelevant Train Dev Test",
          "Nepal earthquake: 50K Queensland flood: 21K"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "11": {
        "title": "Experiments and Results",
        "text": [
          "Model trained using Convolution Neural Network (CNN)",
          "Model trained using CNN were used to automatically label unlabeled data",
          "Instances with classifier confidence >=0.75 were used to retrain a new model",
          "Experiments AUC P R F1",
          "Domain Adaptation Baseline (Transfer Baseline):",
          "Trained CNN model on source (an event) and tested on target (another event)",
          "Source Target AUC P R F1",
          "Combining all the components of the network",
          "Domain Adversarial with Graph Embedding"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "12": {
        "title": "Summary",
        "text": [
          "We have seen how graph-embedding based semi-supervised approach can be useful for small labeled data scenario",
          "How can we use existing data and apply domain adaptation technique",
          "We propose how both techniques can be combined"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "13": {
        "title": "Limitation and Future Study",
        "text": [
          "Graph embedding is computationally expensive",
          "Graph constructed using averaged vector from word2vec",
          "Explored binary class problem",
          "Convoluted feature for graph construction",
          "Domain adaptation: labeled and unlabeled data from target"
        ],
        "page_nums": [
          31
        ],
        "images": []
      }
    },
    "paper_title": "Domain Adaptation with Adversarial Training and Graph Embeddings"
  },
  "999": {
    "slides": {
      "0": {
        "title": "The Rise of Open Access",
        "text": [
          "20 seconds 1 paper",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Information Overload scientific repositories",
        "text": [
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Sometimes between 2017 and 2021 more than half of the",
        "text": [
          "Lewis, David W. \"The inevitability of open access.\"",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "The peculiarities of research publications",
        "text": [
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Scientific publications claims",
        "text": [
          "In order to take full advantage of the knowledge present in scientific publications proper semantic indexing, search and content aggregation approaches, are required.",
          "Search of new information on specific scientific problems",
          "Semi-automatic assessment of papers and research proposals",
          "Tracking of scientific and technological advances",
          "Assisted report and review writing",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "The Scientific Knowledge Miner Project SKM",
        "text": [
          "Facilitate the extraction of knowledge from scientific publications across many disciplines.",
          "Improve a variety of use cases such as:",
          "KEY: Papers are enriched with structural, linguistic and semantic information",
          "The SKM approach to the analysis of scientific literature:",
          "Relies on a finer-grained analysis of the contents of publications",
          "Is grounded on the automated characterization of a varied set of semantic aspects of papers, including the rhetorical structure or the purpose of citations.",
          "Crawler Storage Indexing Analysis"
        ],
        "page_nums": [
          7,
          8,
          9,
          10,
          12,
          13,
          16,
          17,
          19,
          20
        ],
        "images": []
      },
      "6": {
        "title": "Crawling",
        "text": [
          "Title, author, conference, year, etc.",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Dr Inventor Text Mining Framework",
        "text": [
          "Integrate and customize textmining tools and on-line services to enable and ease a wide range of scientificpublicationanalyses",
          "Papers are enriched with structural, linguistic and semantic information",
          "Focused on textual content",
          "Relying on a shared data model (java classes) to representa paper",
          "Exposinga convenient API to access the mined information",
          "Based on to manage textual annotations",
          "The Scientific Knowledge Miner Project",
          "Web based reference parser",
          "Babelfy WSD and Entity Linker",
          "PDF to text converter"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "8": {
        "title": "Indexing",
        "text": [
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Analysis",
        "text": [
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "10": {
        "title": "Use Case 1 Citation Characterization",
        "text": [
          "Experiment new metrics: what do others say about one paper?",
          "Enrich citation counts with semantics",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "11": {
        "title": "Use Case 2 Citation Recommendation",
        "text": [
          "Recommend similar papers / authors",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "Use Case 3 Scientific Document Summarization",
        "text": [
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "13": {
        "title": "Conclusions and future work",
        "text": [
          "Scientific Knowledge Miner (SKM) aims at facilitating the extraction, aggregation and navigation of knowledge from scientific publications.",
          "Consolidate the SKM publication mining infrastructure",
          "Exploit the semantics of papers to perform large scale investigations of: o Alternative metrics to evaluate a paper based on citation semantics o Semantically motivated recommendation of scientific publications o Summarization of scientific literature",
          "The Scientific Knowledge Miner Project"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "14": {
        "title": "Making Sense of Massive Amounts of Scientific",
        "text": [
          "The Scientific Knowledge Miner Project",
          "{francesco.ronzano, ana.freire, diego.saez, horacio.saggion}@upf.edu"
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "Making Sense of Massive Amounts of Scientific Publications: the Scientific Knowledge Miner Project"
  },
  "1001": {
    "slides": {
      "0": {
        "title": "The flow chart of our proposed method",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "SMT Experiments",
        "text": [
          "Experimental results of SMT",
          "BLEU NIST WER TER RIBES baseline zh-ja + additional training data",
          "Table: Evaluation results for ChineseJapanese translation across two",
          "SMT systems (baseline and baseline + additional quasi-parallel data),",
          "Moses version: 1.0, segmentation tools: urheen and mecab."
        ],
        "page_nums": [
          2
        ],
        "images": []
      }
    },
    "paper_title": "Consistent Improvement in Translation Quality of Chinese-Japanese Technical Texts by Adding Additional Quasi-parallel Training Data"
  },
  "1004": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "There are tons of articles exploiting Wikipedia as a comparable corpus",
          "Little attention is paid to identifying a domain-specific high-quality comparable corpus",
          "Domain-specific corpora is a key factor in different tasks, including MT",
          "Wikipedia includes (somehow) all the information necessary to extract such a resource",
          "Our aim is to identify those domain-specific comparable corpora from"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "1": {
        "title": "Background Strategy Overview",
        "text": [
          "Identify comparable articles (easy)",
          "Build a characteristic vocabulary for the domain of interest (not so easy)",
          "Explore the Wikipedia categories graph to select the subset of categories in the domain (difficult)",
          "Brute-force sentence-wise comparison for parallel pairs identification"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "2": {
        "title": "Comparable Corpora",
        "text": [
          "Problem No large collections of comparable texts for all domains and language pairs exist",
          "Objective To extract high-quality comparable corpora on specific domains",
          "Pilot language pair EnglishSpanish",
          "Pilot domains Science, Computer Science, Sports",
          "Currently experimenting on more than 700 domains and 10 languages"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "3": {
        "title": "Comparable Corpora Characteristic Vocabulary",
        "text": [
          "Retrieve every article associated to the top category of the domain",
          "Merge the articles contents and apply standard and ad-hoc pre-processing",
          "Select the top-k tf-sorted tokens as the characteristic vocabulary",
          "(we consider 10% of the tokens)",
          "Articles Vocabulary en es en es"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "4": {
        "title": "Comparable Corpora Graph exploration",
        "text": [
          "Slice of the Spanish Wikipedia category graph departing from categories",
          "Sport and Science (as in Spring 2015)",
          "Scientific Sport Science disciplines",
          "Mountain Earth Sports sports sciencies",
          "Geology Mountains Mountaineering Geology by country",
          "Mountains by country Mountains of Andorra Mountain ran- ges of Spain Geology of Spain",
          "Mountains of the Pyrenees",
          "Perform a breadth-first search departing from the root category",
          "Visit nodes only once to avoid loops and repeating traversed paths",
          "Stop at the level when most categories do not belong to the domain",
          "Heuristic A category belongs to the domain if its title contains at least one term from the characteristic vocabulary",
          "Explore until a minimum percentage of the categories in a tree level belong to the domain",
          "Category pato in Spanish -literally \"duck\"- refers to a sport rather than an animal!!!",
          "Article pairs selected according to two criteria: 50% and 60%",
          "Articles Distance from the root",
          "en-es en-es en es en es"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23
        ],
        "images": [
          "figure/image/1004-Table3-1.png",
          "figure/image/1004-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Parallelisation Similarity Models",
        "text": [
          "Character 3-grams (cosine) [McNamee and Mayfield, 2004]",
          "Translated word 1-grams in both directions (cosine)",
          "Length factor [Pouliquen et al., 2003]",
          "Probable lengths of translations of d"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "6": {
        "title": "Parallelisation Corpus for Preliminary Evaluation",
        "text": [
          "30 article pairs (10 per domain)",
          "Annotated at sentence level",
          "Three classes: parallel, comparable, and other",
          "Each pair was annotated by 2 volunteers mean Cohens"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "7": {
        "title": "Parallelisation Threshold Definition",
        "text": [
          "c3g cog monoen monoes len",
          "S Slen S F1 S F1len"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": [
          "figure/image/1004-Table5-1.png"
        ]
      },
      "8": {
        "title": "Parallelisation Parallel Sentences",
        "text": [],
        "page_nums": [
          29
        ],
        "images": [
          "figure/image/1004-Table6-1.png"
        ]
      },
      "9": {
        "title": "Impact Corpora",
        "text": [
          "in domain out of domain",
          "Generation of the Wikipedia dev and test sets",
          "Select only sentences starting with a letter and longer than three tokens",
          "Compute the perplexity of each sentence pair (with respect to a",
          "Sort the pairs according to similarity and perplexity",
          "Manually select the first k parallel sentences"
        ],
        "page_nums": [
          31,
          32
        ],
        "images": []
      },
      "10": {
        "title": "Impact Corpora Statistics",
        "text": [
          "CS Sc Sp All"
        ],
        "page_nums": [
          33
        ],
        "images": [
          "figure/image/1004-Table7-1.png",
          "figure/image/1004-Table9-1.png"
        ]
      },
      "11": {
        "title": "Impact Phrase based SMT System",
        "text": [
          "Language model 5-gram interpolated Kneser-Ney discounting, SRILM",
          "Translation model Moses package",
          "Weights optimization MERT against BLEU"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "12": {
        "title": "Impact Experiments definition",
        "text": [
          "Out of domain Training Wikipedia and Europarl",
          "Test Wikipedia (+Gnome for CS)"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "13": {
        "title": "Impact Results on Wikipedia in domain",
        "text": [
          "CS Sc Sp Un"
        ],
        "page_nums": [
          36
        ],
        "images": [
          "figure/image/1004-Table11-1.png",
          "figure/image/1004-Table8-1.png",
          "figure/image/1004-Table12-1.png"
        ]
      },
      "14": {
        "title": "Impact Results on Gnome in domain",
        "text": [],
        "page_nums": [
          37
        ],
        "images": [
          "figure/image/1004-Table11-1.png",
          "figure/image/1004-Table12-1.png",
          "figure/image/1004-Table9-1.png"
        ]
      },
      "15": {
        "title": "Impact Translation Instances",
        "text": [
          "Source All internet packets have a source IP address and a destination",
          "EP Todos los paquetes de internet tienen un origen direccion IP y destino direccion IP.",
          "EP+union-CS Todos los paquetes de internet tienen una direccion IP de origen y una direccion IP de destino.",
          "Awareness of terms (possible overfitting?)",
          "Source Attack of the Killer Tomatoes is a 2D platform video game developed by Imagineering and released in 1991 for the NES.",
          "EP el ataque de los tomates es un asesino 2D plataforma video-juego desarrollados por Imagineering y liberados en",
          "Reference Attack of the Killer Tomatoes es un videojuego de plataformas en 2D desarrollado por Imagineering y lanzado en 1991 para el NES.",
          "Source Fractal compression is a lossy compression method for digital images, based on fractals.",
          "EP Fractal compresion es un metodo para lossy compresion digital imagenes , basada en fractals.",
          "EP+union-CS La compresion fractal es un metodo de compresion con perdida para imagenes digitales, basado en fractales."
        ],
        "page_nums": [
          38,
          39,
          40
        ],
        "images": []
      },
      "16": {
        "title": "Impact Results on News out of domain",
        "text": [
          "CS Sc Sp Un"
        ],
        "page_nums": [
          41
        ],
        "images": [
          "figure/image/1004-Table11-1.png",
          "figure/image/1004-Table12-1.png",
          "figure/image/1004-Table9-1.png"
        ]
      },
      "17": {
        "title": "Final Remarks",
        "text": [
          "A simple model to extract domain-specific comparable corpora from",
          "The domain-specific corpora showed to be useful to feed SMT systems, but other tasks are possible",
          "We are currently comparing our model against an IR-based system",
          "The platform currently operates in more language pairs, including",
          "French, Catalan, German, and Arabic; but it can operate in any language and domain",
          "The prototype is coded in Java (and depends on JWPL). We plan to release it in short!"
        ],
        "page_nums": [
          43,
          44,
          45
        ],
        "images": []
      }
    },
    "paper_title": "A Factory of Comparable Corpora from Wikipedia"
  },
  "1007": {
    "slides": {
      "0": {
        "title": "The quest for universal sentence embeddings",
        "text": [
          "*Courtesy: Thomas Wolf blogpost, Hugging Face"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Now famous Ray Mooneys quote",
        "text": [
          "Professor Raymond J. Mooney",
          "While not capturing meaning, we might still be able to build useful transferable sentence features",
          "But what can we actually cram into these vectors?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "The evaluation of universal sentence embeddings",
        "text": [
          "Transfer learning on many other tasks",
          "Learn a classifier on top of pretrained sentence embeddings for transfer tasks",
          "Downstream tasks are complex",
          "Hard to infer what information the embeddings really capture",
          "Probing tasks to the rescue!",
          "designed for inference evaluate simple isolated properties"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Probing tasks and downstream tasks",
        "text": [
          "Probing tasks are simpler and focused on a single property!",
          "Subject Number probing task",
          "Natural Language Inference downstream task",
          "Premise: A lot of people walking outside a row of shops with an older man with his",
          "Sentence: The hobbits waited patiently . hands in his pocket is closer to the camera .",
          "Label: Plural (NNS) Hypothesis: A lot of dogs barking outside a row of shops with a cat teasing them ."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Our contributions",
        "text": [
          "An extensive analysis of sentence embeddings using probing tasks",
          "We vary the architecture of the encoder (3) and the training task",
          "We open-source 10 horse-free classification probing tasks.",
          "Each task being designed to probe a single linguistic property",
          "Shi et al. (EMNLP 2016) Does string-based neural MT learn source syntax? Adi et al. (ICLR 2017) Fine-grained analysis of sentence embeddings using auxiliary prediction tasks"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Probing tasks",
        "text": [
          "What they have in common:",
          "Artificially-created datasets all framed as classification",
          "... but based on natural sentences extracted from the TBC (5-to-28 words)",
          "100k training set, 10k valid, 10k test, with balanced classes",
          "Carefully removed obvious biases (words highly predictive of a class, etc)",
          "Grouped in three categories:"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "6": {
        "title": "Probing tasks 1 10 Sentence Length",
        "text": [
          "She had not come all this way to let one stupid wagon turn all of that hard work",
          "into a waste !",
          "Goal: Predict the length range of the input sentence (6 bins)",
          "Question: Do embeddings preserve information about sentence length?"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Probing tasks 2 10 Word Content",
        "text": [
          "Helen took a pen from her purse and wrote something on her cocktail",
          "Goal: 1000 output words. Which one (only one) belongs to the sentence?",
          "Question: Do embeddings preserve information about words?",
          "Adi et al. (ICLR 2017) Fine-grained analysis of sentence embeddings using auxiliary prediction tasks Surface information"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Probing tasks 3 10 Top Constituents",
        "text": [
          "Slowly he lowered his head toward ADVP_NP_VP_. mine.",
          "The anger in his voice surprised even himself",
          "Goal: Predict top-constituents of parse-tree classes)",
          "Note: 19 most common top-constituent sequences + 1 category for others",
          "Question: Can we extract grammatical information from the embeddings?",
          "Shi et al. (EMNLP 2016) Does string-based neural MT learn source syntax?"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Probing tasks 4 10 Bigram Shift",
        "text": [
          "This new was information .",
          "We 're married getting .",
          "Goal: Predict whether a bigram has been shifted or not.",
          "Question: Are embeddings sensible to word order?"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Probing tasks 5 more",
        "text": [
          "Tree Depth (depth of the parse tree)",
          "Tense prediction (main clause tense, past or present)",
          "Object/Subject Number (singular or plural)",
          "Semantic Odd Man Out (noun/verb replaced by one with same"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Probing tasks 10 10 Coordination Inversion",
        "text": [
          "They might be only memories, but I can still feel each one",
          "I can still feel each one, but they might be only memories.",
          "Goal: Sentences made of two coordinate clauses: inverted (I) or not (O)?",
          "Note: human evaluation: 85%",
          "Question: Can extract sentence-model information?"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Experiments",
        "text": [
          "We analyse almost 30 encoders trained in different ways:",
          "Human evaluation, Length (1-dim vector)",
          "NB-uni and NB-uni/bi with TF-IDF",
          "CBOW (average of word embeddings)",
          "Three encoders: BiLSTM-last/max, and Gated ConvNet",
          "Our 7 training tasks:",
          "Auto-encoding, Seq2Tree, SkipThought, NLI",
          "Seq2seq NMT without attention En-Fr, En-De, En-Fi"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Experiments training tasks",
        "text": [
          "Source and target examples for seq2seq training tasks",
          "Sutskever et al. (NIPS 2014) Sequence to sequence learning with neural networks Kiros et al. (NIPS 2015) SkipThought vectors Vinyals et al. (NIPS 2015) Grammar as a Foreign Language"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1007-Table1-1.png"
        ]
      },
      "14": {
        "title": "Baselines and sanity checks",
        "text": [
          "Hum. Probing Eval. tasks NB-uni-tfidf evaluation NB-bi-tfidf baselines CBOW",
          "SentLen WC TopConst BShift ObjNum"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Impact of training tasks",
        "text": [
          "Probing tasks results for BiLSTM-last trained in different ways",
          "AutoEncoder NMT En-Fr NMT En-Fi Seq2Tree SkipThought",
          "SentLen WC TopConst BShift ObjNum"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Impact of model architecture",
        "text": [
          "Average accuracies for different models",
          "SentLen WC TopConst BShift ObjNum CoordInv"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "17": {
        "title": "Evolution during training",
        "text": [
          "Evaluation on probing tasks at each epoch of training",
          "What do embeddings encode along training?",
          "NMT: Most increase and converge rapidly (only",
          "SentLen decreases). WC correlated with BLEU."
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1007-Figure1-1.png"
        ]
      },
      "18": {
        "title": "Correlation with downstream tasks",
        "text": [
          "Strong correlation between WC and downstream tasks",
          "Correlation between probing and downstream tasks",
          "Blue=higher - Red=lower - Grey=not significant",
          "Word-level information important for downstream tasks (classification, NLI, STS)",
          "If WC good predictor -> maybe current downstream tasks are not the right ones?"
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1007-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Take home messages and future work",
        "text": [
          "Sentence embeddings need not be good on probing tasks",
          "Probing tasks are simply meant to understand what linguistic features are encoded and to designed to compare encoders.",
          "Understanding the impact of multi-task learning",
          "Studying the impact of language model pretraining (ELMO)",
          "Study other encoders (Transformer, RNNG)"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties"
  },
  "1009": {
    "slides": {
      "0": {
        "title": "Data is Limited",
        "text": [
          "Most of the popular models in NLP are data-driven",
          "We often need to operate in a specific scenario Limited data",
          "Take spoken language understanding as an example",
          "Need to be implemented for many domains Limited data",
          "Intent Detection flights from Boston to Tokyo intent: flight",
          "Slot Filling flights from Boston to Tokyo fromloc.city:Bostontoloc.city:Tokyo",
          "E.g., intelligent customer service robot",
          "What can we do with limited data?"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Regular Expression Rules",
        "text": [
          "When data is limited Use rule-based system",
          "Regular expression is the most commonly used rule in NLP",
          "Many regular expression rules in company",
          "Intent Detection flights from Boston to Tokyo intent: flight",
          "Slot Filling flights from Boston to Tokyo fromloc.city:Bostontoloc.city:Tokyo",
          "However, regular expressions are hard to generalize",
          "Neural networks are potentially good at generalization",
          "Can we combine the advantages of two worlds?",
          "Regular Expressions Pro: controllable, do not need data",
          "/^flights? from/ Con: need to specify every variation",
          "Neural Network Pro: semantic matching",
          "Con: need a lot of data"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Which Part of Regular Expression to Use",
        "text": [
          "Regular expression (RE) output is useful",
          "flights? from/ flights from Boston to Tokyo intent: flight",
          "flights from Boston to Tokyo fromloc.city:Bostontoloc.city:Tokyo",
          "RE contains clue words",
          "NN should attend to these clue words for prediction"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Method 1 RE Output As Features",
        "text": [
          "Embed the REtag, append to input",
          "REtag: flight Softmax Classifier",
          "RE feat s Attention",
          "Intent Detection h1 h2 h3 h4 h5",
          "BLSTM RE Instance x1 x2 x3 x4 x5",
          "flights from Boston to Miami /^flights? from/",
          "flights from Boston to Miami REtag: O O B-loc.city O B-loc.city"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Method 2 RE Output Fusion in Output",
        "text": [
          "is the NN output score for class k (before softmax)",
          ", whether regular expression predict class k",
          "Intent: flight logitk=l ogitk+ w kzk Softmax Classifier",
          "Intent Detection h1 h2 h3 h4 h5",
          "BLSTM RE Instance x1 x2 x3 x4 x5",
          "flights from Boston to Miami /^flights? from/",
          "Slot Filling h1 h2 h3 h4 h5",
          "flights from Boston to /from __CITY to Miami __CITY/"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": [
          "figure/image/1009-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Method 3 Clue Words Guide Attention",
        "text": [
          "Attention should match clue words",
          "BLSTM RE Instance x1 x2 x3 x4 x5",
          "flights from Boston to Miami Gold Att:",
          "Positive Regular Expressions (REs) Negative REs",
          "REs can indicate the input belong to class k, or does not belong to class k",
          "Correction of wrong predictions",
          "How long does it take to fly from LA to NYC? intent: abbreviation",
          "Corresponding to positive / negative REs",
          "Positive REs and Negative REs interconvertible",
          "A positive RE for one class can be negative RE for other classes",
          "flights from Boston to Tokyo intent: abbreviation"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "6": {
        "title": "Experiment Setup",
        "text": [
          "Written by a paid annotator",
          "We want to answer the following questions:",
          "Can regular expressions (REs) improve the neural network (NN) when",
          "data is limited (only use a small fraction of the training data)?",
          "Can REs still improve NN when using the full dataset?",
          "How does RE complexity influence the results?"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "7": {
        "title": "Few Shot Learning Experiment",
        "text": [
          "Using clue words to guide attention performs best for intent detection",
          "Using RE output as feature performs best for slot filling"
        ],
        "page_nums": [
          19,
          20,
          21,
          22
        ],
        "images": []
      },
      "8": {
        "title": "Full Dataset Experiment",
        "text": [
          "Use all the training data"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "9": {
        "title": "Complex RE vs Simple RE",
        "text": [
          "Complex RE: many semantically independant groups",
          "Complex RE: /(_AIRCRAFT_CODE) that fly/",
          "Complex Simple Complex Simple",
          "Complex REs yield better results",
          "Simple REs also clearly improves the baseline"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "Using REs can help to train of NN when data is limited",
          "Guiding attention is best for intent detection (sentence classification)",
          "RE output as feature is best for slot filling (sequence labeling)",
          "We can start with simple REs, and increase complexity gradually"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Marrying Up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding"
  },
  "1010": {
    "slides": {
      "0": {
        "title": "Time is important",
        "text": [
          "Understanding time is key to understanding events",
          "Timelines (in stories, clinical records), time-slot filling, Q&A, common sense",
          "[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh. As a boy, Chris lived in",
          "Cotchfield Farm. When he was three, his father wrote a poem about him. His father later wrote Winnie the Pooh in 1925.",
          "Where did Chris Robin live? Clearly, time sensitive.",
          "When was Chris Robin born? poem [Chris at age 3]",
          "Requires identifying relations between events, and temporal reasoning.",
          "Events are associated with time intervals:",
          "A happens BEFORE/AFTER B; Time is often expressed implicitly",
          "2 explicit time expressions per 100 tokens, but 12 temporal relations"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Example",
        "text": [
          "Friday in the middle of a group of men playing volleyball.",
          "Temporal question: Which one happens first?",
          "e1 appears first in text. Is it also earlier in time? e2 was on Friday, but we dont know when e1 happened.",
          "No explicit lexical markers, e.g., before, since, or during."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Example temporal determined by causal",
        "text": [
          "More than 10 people (e1: died), he said. A car (e2: exploded)",
          "Friday in the middle of a group of men playing volleyball.",
          "Temporal question: Which one happens first?",
          "Obviously, e2:exploded is the cause and e1:died is the effect.",
          "So, e2 happens first.",
          "In this example, the temporal relation is determined by the causal relation.",
          "Note also that the lexical information is important here; its likely that explode BERORE die, irrespective of the context."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Example causal determined by temporal",
        "text": [
          "People raged and took to the street the government",
          "Did the government stifle people because people raged?",
          "Or, people raged because the government stifled people?",
          "Both sound correct and we are not sure about the causality here.",
          "People raged and took to the street (after) the government",
          "Since stifled happened earlier, its obvious that the cause is stifled and the result is raged.",
          "In this example, the causal relation is determined by the temporal relation."
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "This paper",
        "text": [
          "Event relations: an essential step of event understanding, which",
          "supports applications such as story understanding/completion, summarization, and timeline construction.",
          "[There has been a lot of work on this; see Ning et al. ACL18, presented yesterday. for a discussion of the literature and the challenges.]",
          "This paper focuses on the joint extraction of temporal and",
          "A temporal relation (T-Link) specifies the relation between two events along the temporal dimension.",
          "A causal relation (C-Link) specifies the [cause effect] between two events."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Temporal and casual relations",
        "text": [
          "T-Link Example: John worked out after finishing his work.",
          "C-Link Example: He was released due to lack of evidence.",
          "Temporal and causal relations interact with each other.",
          "For example, there is also a T-Link between released and lack",
          "The decisions on the T-Link type and the C-link type depend on each other, suggesting that joint reasoning could help."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Related work",
        "text": [
          "Obviously, temporal and causal relations are closely related",
          "(were not the first who discovered this).",
          "NLP researchers have also started paying attention to this direction recently.",
          "CaTeRs: Mostafazadeh et al. (2016) proposed an annotation framework,",
          "CaTeRs, which captured both temporal and causal aspects of event relations in common sense stories.",
          "CATENA: Mirza and Tonelli (2016) proposed to extract both temporal and",
          "causal relations, but only by post-editing temporal relations based on causal predictions."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Contributions",
        "text": [
          "1. Proposed a novel joint inference framework for temporal and causal reasoning",
          "Assume the availability of a temporal extraction system and a causal extraction system",
          "Enforce declarative constraints originating from the physical nature of causality",
          "2. Constructed a new dataset with both temporal and causal relations.",
          "We augmented the EventCausality dataset (Do et al., 2011), which comes with causal relations, with new temporal annotations."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Temporal relation extraction an ilp approach",
        "text": [
          "--Event node set. are events.",
          "' --temporal relation label",
          "-Boolean variable is there a of relation r between \" -./ $? (Y/N)",
          "0*(+,)--score of event pair having relation",
          "Global assignment of relations: scores in this document",
          "'K--the relation dictated by 'F and 'G"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Proposed joint approach",
        "text": [
          "--Event node set. are events.",
          "' --temporal relation label",
          "-Boolean variable is there a of relation r between \" -./ $? (Y/N)",
          "0*(+,)--score of event pair having relation",
          "3 4--causal relation; with corresponding variables and",
          "T & C relations",
          "Cause must be before effect"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Scoring functions",
        "text": [
          "Two scoring functions are needed in the objective above",
          ":;(=>)--score of event pair having temporal relation",
          "AB(=>)--score of event pair having causal relation C",
          "We use the soft-max scores from temporal/causal classifiers (or the log of the soft- max scores)",
          "Choose your favorite model for the classifiers; here: sparse averaged perceptron",
          "Features for a pair of events:",
          "POS, token distance Can we use more than just this",
          "local information? modal verbs in-between (i.e., will, would, can, could, may and might)",
          "temporal connectives in-between (e.g., before, after and since)",
          "Whether the two verbs have a common synonym from their synsets in WordNet The head word of the preposition phrase that covers each verb"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Back to the example temporal determined by causal",
        "text": [
          "More than 10 people (e1: died), he said. A car (e2: exploded)",
          "Friday in the middle of a group of men playing volleyball.",
          "Temporal question: Which one happens first?",
          "Obviously, e2:exploded is the cause and e1:died is the effect.",
          "So, e2 happens first.",
          "In this example, the temporal relation is determined by the",
          "Note also that the lexical information is important here; its",
          "likely that explode BERORE die, irrespective of the context."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Temprob probabilistic knowledge base",
        "text": [
          "Preprocessing: Semantic Role Labeling & Temporal relations model",
          "Result: 51K semantic frames, 80M relations",
          "Then we simply count how many times one frame is before/after another frame, as follows. http://cogcomp.org/page/publication_view/830",
          "Frame 1 Frame 2 Before After"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Some interesting statistics in temprob",
        "text": [],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "14": {
        "title": "Scoring functions additional feature for causality",
        "text": [
          "Two scoring functions are needed in the objective above",
          ":;(=>)--score of event pair having temporal relation",
          "AB(=>)--score of event pair having causal relation C",
          "How to obtain the scoring functions",
          "We argue that this prior distribution based on TemProb is correlated with causal directionality, so it will be a useful feature when training AB(=>)."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "15": {
        "title": "Result on timebank dense",
        "text": [
          "TimeBank-Dense: A Benchmark Temporal Relation Dataset",
          "The performance of temporal relation extraction:",
          "CAEVO: the temporal system proposed along with TimeBank-Dense",
          "CATENA: the aforementioned work post-editing temporal relations based on causal predictions, retrained on TimeBank-Dense.",
          "System P R F1"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "16": {
        "title": "A new joint dataset",
        "text": [
          "TimeBank-Dense has only temporal relation annotations, so in the evaluations above, we only evaluated our temporal performance.",
          "EventCausality dataset has only causal relation annotations.",
          "To get a dataset with both temporal and causal relation annotations, we choose to augment the EventCausality dataset with temporal relations, using the annotation scheme we proposed in our paper [Ning et al., ACL18. A multi-axis annotation scheme for",
          "event temporal relation annotation.]",
          "Doc Event T-Link C-Link",
          "*due to re-definition of events"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "17": {
        "title": "Result on our new joint dataset",
        "text": [
          "P R F Acc.",
          "The temporal performance got strictly better in P, R, and F1.",
          "The causal performance also got improved by a large margin.",
          "Comparing to when gold temporal relations were used, we can see that theres still much room for causal improvement.",
          "Comparing to when gold causal relations were used, we can see that the current joint algorithm is very close to its best."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "18": {
        "title": "Conclusion",
        "text": [
          "We presented a novel joint inference framework, Temporal and",
          "Using an Integer Linear Programming (ILP) framework applied to the extraction problem of temporal and causal relations between events.",
          "To show the benefit of TCR, we have developed a new dataset that jointly annotates temporal and causal annotations",
          "Showed that TCR can improve both temporal and causal components"
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Joint Reasoning for Temporal and Causal Relations"
  },
  "1011": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "NLP tasks usually focus on segmented words",
          "Morphology is how words are composed with morphemes",
          "Usages of Chinese morphological structures",
          "Challenge for Chinese morphology",
          "o Lack of complete theories",
          "o Lack of category schema",
          "o Lack of toolkits"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Related Work",
        "text": [
          "Focus on longer unknown words",
          "Focus on the functionality of morphemic characters",
          "Focus on Chinese bi-character words",
          "o multi-character Chinese tokens are bi-character",
          "o analyze Chinese morphological types",
          "o developed a suite of classifiers for type prediction",
          "Issue: covers only a subset of Chinese content words and has limited scalability"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Morphological Type Scheme",
        "text": [
          "dup, pfx, sfx, neg, ec",
          "Compound a-head, conj, n-head, nsubj,",
          "Word v-head, vobj, vprt, els"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Derived Word",
        "text": [],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1011-Table1-1.png"
        ]
      },
      "4": {
        "title": "Compond Word",
        "text": [],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1011-Table2-1.png"
        ]
      },
      "5": {
        "title": "Morphological Type Classification",
        "text": [
          "Assumption: Chinese morphological structures are independent"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Derived Word Rule Based",
        "text": [
          "o a morphologically derived word can be recognized based on its",
          "o pattern matching rules",
          "o Data: Chinese Treebank 7.0",
          "o 2.9% of bi-char content words are annotated as derived words",
          "Rule-based methods are able to effectively recognizing derived words."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Compond Word ML Based",
        "text": [
          "o The characteristics of individual characters can help decide the",
          "type of compond words"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Classification Feature",
        "text": [
          "o Dict: Revised Mandarin Chinese Dictionary (MoE, 1994)"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1011-Table3-1.png"
        ]
      },
      "9": {
        "title": "ACBiMA Corpus 10",
        "text": [
          "o Extracted from CTB5",
          "o Annotated with difficulty level",
          "o Initial Set +"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1011-Table4-1.png"
        ]
      },
      "10": {
        "title": "Baseline Models",
        "text": [
          "o Step 1: assign the POS tags to each known character based",
          "o Step 2: assign the most frequent morphological type",
          "obtained from training data to each POS combination, e.g.,"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Experimental Result",
        "text": [
          "o Setting: 10-fold cross-validation",
          "o Metrics: Macro F-measure (MF), Accuracy (ACC)",
          "Approach nsubj v- head head head vprt vobj conj els MF ACC",
          "Tablular approaches perform better among all baselines.",
          "ML-based methods outperform all baselines, where SVM & RF perform best."
        ],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion and Future Work",
        "text": [
          "Propose a morphological type scheme",
          "Develop a corpus containing about 11K words",
          "Develop an effective morphological classifier",
          "Data and tool available",
          "Additional features for any Chinese task",
          "o Improve other NLP tasks by using ACBiMA"
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "ACBiMA: Advanced Chinese Bi-Character Word Morphological Analyzer"
  },
  "1012": {
    "slides": {
      "0": {
        "title": "Metrics Task in a Nutshell",
        "text": [],
        "page_nums": [
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "1": {
        "title": "QE as a Metric",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "2": {
        "title": "Updates in WMT19",
        "text": [
          "I reference-based human evaluation monolingual",
          "I reference-free human evaluation bilingual",
          "I standard reference-based metrics",
          "I reference-less metrics QE as a Metric",
          "I Hybrid supersampling was not needed for sys-level:",
          "I Sufficiently large numbers of MT systems serve as datapoints."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "3": {
        "title": "System and Segment Level Evaluation",
        "text": [
          "I Participants compute one",
          "score for the whole test set, as translated by each of the systems",
          "The new in The company m From Friday's joi \"The unification Cermak, which New common D",
          "I Segment Level Econo For exam The new in",
          "score for each sentence of each systems translation"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "4": {
        "title": "Past Metrics Tasks",
        "text": [
          "Rat. of Concord. Pairs",
          "Pearson Corr Coeff based on",
          "RR RR RR RR RR RR RR RR RR",
          "main and secondary score reported for the system-level evaluation. and are slightly different variants regarding ties.",
          "RR, DA, daRR are different golden truths.",
          "Increase in number of participating teams?",
          "I Baseline metrics: 9 + 2 reimplementations",
          "I sacreBLEU-BLEU and sacreBLEU-chrF.",
          "I Submitted metrics: 10 out of 24 are QE as a Metric."
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "5": {
        "title": "Data Overview This Year",
        "text": [
          "I Direct Assessment (DA) for sys-level.",
          "I Derived relative ranking (daRR) for seg-level.",
          "I Multiple languages (18 pairs):",
          "I English (en) to/from Czech (cs), German (de), Finnish (fi),",
          "Gujarati (gu), Kazakh (kk), Lithuanian (lt), Russian (ru), and",
          "Chinese (zh), but excluding cs-en.",
          "I German (de)Czech (cs) and German (de)French (fr)."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "6": {
        "title": "Baselines",
        "text": [
          "Metric Features Seg-L Sys-L sentBLEU",
          "CDER chrF chrF+ sacreBLEU-BLEU sacreBLEU-chrF n-grams n-grams n-grams",
          "Levenshtein distance edit distance, edit types edit distance, edit types edit distance, edit types character n-grams character n-grams n-grams n-grams",
          "We average ( ) seg-level scores."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "7": {
        "title": "Participating Metrics",
        "text": [
          "Features char. n-grams, permutation trees contextual word embeddings char. edit distance, edit types char. edit distance, edit types learned neural representations surface linguistic features surface linguistic features word alignments",
          "Meteor++ 2.0 (syntax+copy) word alignments",
          "YiSi-1 srl psuedo-references, paraphrases word mover distance semantic similarity semantic similarity semantic similarity",
          "Univ. of Amsterdam, ILCC",
          "Dublin City University, ADA",
          "We average ( ) their seg-level scores."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "8": {
        "title": "Participating QE Systems",
        "text": [
          "LM log probs., ibm1 lexicon contextual word emb., MT log prob. contextual word embeddings",
          "semantic similarity semantic similarity",
          "We average ( ) their seg-level scores."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation of System Level",
        "text": [],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "Golden Truth for Sys Level DA Pearson",
        "text": [
          "You have scored individual sentences: (Thank you!)",
          "News Task has filtered and standardized this (Ave z).",
          "We correlate it with the metric sys-level score.",
          "Ave z BLEU CUNI-Transformer uedin online-B online-A online-G"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation of Segment Level",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Segment Level News Task Evaluation",
        "text": [
          "You scored individual sentences: (Same data as above.)",
          "Standardized, averaged seg-level golden truth score.",
          "Could be correlated to metric seg-level scores.",
          "but there are not enough judgements for indiv. sentences."
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "13": {
        "title": "daRR Interpreting DA as RR",
        "text": [
          "I If score for candidate A better than B by more than 25 points",
          "infer the pairwise comparison: A B.",
          "I No ties in golden daRR.",
          "I Evaluate with the known Kendalls",
          "I On average, there are 319 of scored outputs per src segm.",
          "I From these, we generate 4k327k daRR pairs."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "14": {
        "title": "Results of News Domain System Level",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "15": {
        "title": "Sys Level into English Official",
        "text": [
          "de-en fi-en gu-en kk-en lt-en ru-en zh-en",
          "chrF chrF+ EED ESIM hLEPORa baseline hLEPORb baseline Meteor++ 2.0(syntax) Meteor++ 2.0(syntax+copy) NIST PER PReP sacreBLEU.BLEU sacreBLEU.chrF TER WER WMDO YiSi-0 YiSi-1 YiSi-1 srl QE as a Metric: ibm1-morpheme ibm1-pos4gram LASIM LP UNI UNI+ YiSi-2 YiSi-2 srl newstest2019",
          "I Top: Baselines and regular metrics. Bottom: QE as a metric.",
          "I Bold: not significantly outperformed by any others."
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "16": {
        "title": "Sys Level Results Into Out of Excl EN",
        "text": [
          "Correlation de-en fi-en gu-en kk-en lt-en ru-en zh-en",
          "CDER CharacTER chrF chrF+ EED ESIM hLEPORa baseline hLEPORb baseline Meteor++ 2.0(syntax) n",
          "Correlation en-cs en-de en-fi en-gu en-kk en-lt en-ru en-zh",
          "BEER n de-cs de-fr fr-de",
          "BEER BLEU CDER CharacTER chrF chrF+ EED ESIM NIST PER PReP sacreBLEU.BLEU sacreBLEU.chrF TER WER WMDO YiSi-0 YiSi-1 YiSi-1 srl",
          "Correlation |r |r |r",
          "sacreBLEU.BLEU sacreBLEU.chrF hLEPORa baseline hLEPORb baseline TER WER YiSi-0 YiSi-1",
          "NIST PER sacreBLEU-BLEU sacreBLEU-chrF YiSi-1 srl QE as a Metric: ibm1-morpheme ibm1-pos4gram LASIM LP UNI UNI+ USFD USFD-TL YiSi-2 YiSi-2 srl",
          "QE as a Metric: ibm1-morpheme ibm1-pos4gram LASIM LP UNI UNI+ YiSi-2 YiSi-2 srl",
          "TER WER YiSi-0 YiSi-1 YiSi-1 srl QE as a Metric: ibm1-morpheme ibm1-pos4gram YiSi-2 newstest2019",
          "I *-EN (except FI-EN) sufficiently discerning.",
          "I EN-* and pair excluding EN somewhat more mixed."
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "17": {
        "title": "Summary of Sys Level Wins Metrics",
        "text": [
          "LPs LPs LPs Corr Wins Overall wins",
          "BLEU PER sacreBLEU-BLEU BERTr Met++ 2.0(s.) Met++ 2.0(s.+copy) WMDO hLEPORb baseline PReP"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "18": {
        "title": "Summary of Sys Level Wins QE",
        "text": [
          "LPs LPs LPs Corr Wins ibm1-morpheme ibm1-pos4gram"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "19": {
        "title": "Results of News Domain Segment Level",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "20": {
        "title": "Seg Level Results Into Out of Excl EN",
        "text": [
          "Human Evaluation n de-en fi-en gu-en kk-en lt-en ru-en zh-en",
          "daRR daRR daRR daRR daRR daRR daRR daRR",
          "BERTr CharacTER chrF chrF+ EED ESIM hLEPORa baseline Meteor++ 2.0(syntax)",
          "Human Evaluation n en-cs en-de en-fi en-gu en-kk en-lt en-ru en-zh",
          "BEER CharacTER chrF chrF+ EED ESIM hLEPORa baseline sentBLEU YiSi-0 YiSi-1 YiSi-1 srl",
          "Human Evaluation n de-cs de-fr fr-de",
          "Meteor++ 2.0(syntax+copy) PReP sentBLEU WMDO YiSi-0 YiSi-1 YiSi-1 srl",
          "QE as a Metric: ibm1-morpheme ibm1-pos4gram LASIM LP UNI UNI+ USFD USFD-TL YiSi-2 YiSi-2 srl sentBLEU YiSi-0 YiSi-1 YiSi-1 srl QE as a Metric: ibm1-morpheme ibm1-pos4gram LASIM LP UNI UNI+ YiSi-2 YiSi-2 srl",
          "QE as a Metric: ibm1-morpheme ibm1-pos4gram YiSi-2 newstest2019",
          "I YiSi-1* win across the board and ESIM not far.",
          "I FR-DE is not discerning."
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "21": {
        "title": "Summary of Seg Level Wins Metrics",
        "text": [
          "LPs LPs LPs Corr Wins Tot"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "22": {
        "title": "Summary of Seg Level Wins QE",
        "text": [
          "LPs LPs LPs Corr Wins ibm1-morpheme ibm1-pos4gram"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "23": {
        "title": "Stability across MT Systems",
        "text": [
          "Top 4 Top 6 Top 8 Top 10 Top 12 Top 15 All systems",
          "I ENDE sys-level sacreBLEU-BLEU vs. golden truth.",
          "I One outlier makes the task for metrics too easy.",
          "I Get correlation when MT systems reduced to top-N ones. sacreBLEU-BLEU",
          "I Baseline metrics are plotted in grey.",
          "I In general, most metrics show a strong degrading pattern",
          "with the top-N systems across most language pairs.",
          "I Some QE as a metric have upward correlation trends."
        ],
        "page_nums": [
          34,
          35
        ],
        "images": [
          "figure/image/1012-Figure5-1.png"
        ]
      },
      "24": {
        "title": "Overall Status of MT Metrics",
        "text": [
          "I Sys-level very good overall:",
          "I Pearson Correlation >.90 mostly, best reach >95 or",
          "I Low pearsons exist but not many.",
          "I Correlations are heavily affected by the underlying set of MT",
          "I System-level correlations are much worse when based on only the better",
          "I No clear winners, but have a look at this years posters.",
          "I Seg-level much worse:",
          "I The top Kendalls only .59.",
          "I standard metrics correlations varies between 0.03 and 0.59.",
          "I QE a metric obtains even negative correlations.",
          "I Methods using embeddings are better:",
          "I YiSi-*: Word embeddings + other types of available resources.",
          "I ESIM: Sentence embeddings."
        ],
        "page_nums": [
          36,
          37
        ],
        "images": []
      },
      "25": {
        "title": "Next Metrics Task",
        "text": [
          "I Yes, we will run the task!",
          "I Big Challenge remains: References possibly worse than MT.",
          "I Yes, we like the QE as a metric track.",
          "I We will report the top-N plots.",
          "I We have to summarize them somehow, though.",
          "I Doc-level golden truth did not seem different from sys-level.",
          "I This may change We might run doc-level metrics."
        ],
        "page_nums": [
          38
        ],
        "images": []
      }
    },
    "paper_title": "Results of the WMT19 Metrics Shared Task: Segment-Level and Strong MT Systems Pose Big Challenges"
  },
  "1013": {
    "slides": {
      "0": {
        "title": "Research Context",
        "text": [
          "Domain Specific Diachronic Corpus",
          "Example: searching vegetarian in biblical scholarship archive",
          "Were All Men Vegetarians",
          "God instructed Adam saying,",
          "I have given you",
          "every herb that yields",
          "Of every tree of the garden",
          "thou mayest freely eat:",
          "and thou shalt eat the",
          "herb of the field;",
          "(King James Bible, Genesis)",
          "(by Eric Lyons, M.Min.)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Diachronic Thesaurus",
        "text": [
          "A useful tool for supporting searches in diachronic corpus",
          "Target term vegetarian modern",
          "Related terms tree of the garden herb of the field ancient",
          "Users are mostly aware of modern language",
          "Collecting relevant related terms",
          "For given thesaurus entries",
          "Collecting a relevant list of modern target terms"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Diachronic Thesaurus Our Task",
        "text": [
          "Utilize a given candidate list of modern terms as input",
          "Predict which candidates are relevant for the domain corpus"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Background Terminology Extraction TE",
        "text": [
          "1. Automatically extract prominent terms from a given corpus",
          "SSccoorree ccaannddiiddaattee tteerrmmss ffoorr ddoommaaiinn rreelleevvaannccyy",
          "Statistical measures for identifying prominent terms",
          "Frequencies in the target corpus (e.g. tf, tf-idf)",
          "Comparison with frequencies in a reference background corpus"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Supervised framework for TE",
        "text": [
          "Candidate target terms are learning instances",
          "Calculate a set of features for each candidate",
          "Classification predicts which candidates are suitable",
          "Features : state-of-the-art TE scoring measures"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Contributions",
        "text": [
          "Integrating Query Performance Prediction in term scoring",
          "2. Penetrating to ancient texts, via query expansion"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Contribution 1",
        "text": [
          "Integrating Query Performance Prediction",
          "Penetrating to ancient texts"
        ],
        "page_nums": [
          8,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Query Performance Prediction QPP",
        "text": [
          "Estimate the retrieval quality of search queries",
          "Assess quality of query results on the text collection.",
          "Our terminology scoring task",
          "QPP scoring measures are potentially useful may capture",
          "additional aspects of term relevancy for the collection",
          "term is relevant for a domain term is a good query",
          "Two types of statistical QPP methods",
          "Analyze query terms distribution within the corpus",
          "Additionally analyze the top search results",
          "Integrate QPP measures as additional features",
          "First integrated system (TE-QPPTerm)",
          "Applies the QPP measures to the candidate term as the query",
          "Utilizes these scores as additional classification features"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "8": {
        "title": "Penetrating to ancient periods",
        "text": [
          "In a diachronic corpus",
          "A candidate term might be rare in its original modern form,",
          "yet frequently referred to by archaic forms",
          "query term: vegetarian Of every tree of the garden",
          "thou mayest freely eat: every herb that yields",
          "Were All Men Vegetarians",
          "God instructed Adam saying, I have given you every herb that yields (Genesis 1:29) and thou shalt eat the",
          "and thou shalt eat the (King James Bible, Genesis) herb of the field;",
          "(by Eric Lyons, M.Min.)",
          "Baseline (TE) and First integrated system (TE-QPPTerm)",
          "Rely on corpus occurrences of the original candidate term",
          "Prioritize relatively frequent terms",
          "A post-retrieval QPP method",
          "Query Feedback measure (Zhou and Croft, 2007)",
          "Second integrated system (TE-QPPQE)",
          "Utilizes Pseudo Relevance Feedback Query Expansion",
          "QPP query QPP score"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation Setting",
        "text": [
          "Diachronic corpus: the Responsa Project",
          "Questions posed to rabbis along their detailed rabbinic answers",
          "Written over a period of about a thousand years",
          "Used for previous IR and NLP research",
          "Balanced for positive and negative examples",
          "Support Vector Machine with polynomial kernel"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Results",
        "text": [
          "Additional QPP features increase the classification accuracy",
          "Utilizing ancient documents, via query expansion, improves",
          "Improvement over baseline statistically significant"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Summary",
        "text": [
          "Task: target term selection for a diachronic thesaurus",
          "Integrating Query Performance Prediction in Term Scoring",
          "2. Penetrating to ancient texts via query expansion",
          "Utilize additional query expansion algorithms",
          "Investigate the selective query expansion approach"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Integrating Query Performance Prediction in Term Scoring for Diachronic Thesaurus"
  },
  "1014": {
    "slides": {
      "0": {
        "title": "Motivations",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Insufficient or even unavailable training data of emerging classes is a big",
          "challenge in real-world text classification.",
          "Zero-shot text classification recognising text documents of classes that",
          "have never been seen in the learning stage",
          "In this paper, we propose a two-phase framework together with data",
          "augmentation and feature augmentation to solve this problem."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Zero shot Text Classification",
        "text": [
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Let and be disjoint sets of seen and unseen classes of the classification",
          "In the learning stage, a training set is given where",
          "is the document containing a sequence of words",
          "is the class of",
          "In the inference stage, the goal is to predict the class of each document, , in",
          "Supportive semantic knowledge is needed to generally infer the features of unseen classes using patterns learned from seen classes."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Our Proposed Framework Overview",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "We integrate four kinds of semantic",
          "knowledge into our framework:",
          "Data augmentation technique helps the classifiers be aware of the existence of unseen classes without accessing their real data. Feature augmentation provides additional information which relates the document and the unseen classes to generalise the zero-shot reasoning."
        ],
        "page_nums": [
          4,
          5
        ],
        "images": [
          "figure/image/1014-Figure1-1.png",
          "figure/image/1014-Figure2-1.png"
        ]
      },
      "3": {
        "title": "Phase 1 Coarse grained Classification",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Each seen class has its own CNN text classifier to predict",
          "The classifier is trained with all documents of its class in the training set",
          "as positive examples and the rest as negative examples.",
          "For a test document , this phase computes for every seen",
          "If there exists a class such that > , it predicts",
          "is a classification threshold for the class , calculated based on the",
          "threshold adaptation method from (Shu et al., 2017)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Phase 1 Data Augmentation",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "We use the idea of Topic translation translating an original document",
          "from a seen class into an augmented document of an unseen class.",
          "Mitra perdulca is a species of sea",
          "snail a marine gastropod mollusk",
          "in the family Mitridae the miters or",
          "Mira perdulca is a swimmer of",
          "sailing sprinter an Olympian",
          "limpets gastropod in the basketball",
          "Middy the miters or miter skater.",
          "Using analogy questions, e.g., animal:species :: athlete:? ? = swimmer",
          "Solved by the 3CosMul method by Levy and Goldberg (2014)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Phase 2 Fine grained Classification",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "The traditional classifier is a multi-class classifier (|| classes) with a softmax",
          "output, so it requires only the word embeddings as an input.",
          "The zero-shot classifier is a binary classifier with a sigmoid output. It takes a text document and a class as inputs and predicts the confidence"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1014-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Phase 2 Zero shot Classifier",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "The zero-shot classifier predicts",
          "shows how the word and",
          "the class are related considering",
          "the relations in a general",
          "This classifier is trained with a training data from seen classes only."
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1014-Figure2-1.png"
        ]
      },
      "7": {
        "title": "Phase 2 Feature Augmentation",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Step 1: represent a class as three sets of nodes in ConceptNet",
          "If is the class Educational Institution",
          "(1) educational_institution, educational, institution",
          "(3) place, people, ages, education.",
          "Step 2: To construct , we consider whether the word is connected to",
          "the members of the three sets within hops."
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1014-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Experiments",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "DBpedia ontology : 14 classes",
          "20newsgroups : 20 classes"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1014-Table1-1.png"
        ]
      },
      "9": {
        "title": "An Experiments for Phase 1",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Compare with DOC a",
          "For seen classes, our",
          "DOC on both datasets.",
          "improved the accuracy of",
          "unseen classes clearly and led to higher overall accuracy in every setting."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "An Experiments for Phase 2",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Using only could not find",
          "out the correct unseen class",
          "accuracy of predicting unseen",
          "highest accuracy in all settings."
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1014-Table6-1.png",
          "figure/image/1014-Table5-1.png"
        ]
      },
      "11": {
        "title": "An Experiments for the Whole Framework",
        "text": [
          "Imperial College Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "London Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "Table 2: The accuracy of the whole framework compared with the baselines.",
          "Label RNN + FC",
          "Unseen / - Similarity RNN (Pushp and 5",
          "Dataset rate Yi Count-based (Sappadla Autoencoder Srivastava, CNN + FC Ours"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1014-Table2-1.png"
        ]
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
          "Jingqing Zhang, Piyawat Lertvittayakumjorn, and Yike Guo",
          "To tackle zero-shot text classification, we proposed a novel CNN-based two-",
          "phase framework together with data augmentation and feature augmentation.",
          "The experiments show that",
          "data augmentation improved the accuracy in detecting instances from unseen",
          "feature augmentation enabled knowledge transfer from seen to unseen classes",
          "our work achieved the highest overall accuracy compared with all the baselines",
          "and recent approaches in all settings.",
          "multi-label classification with a larger amount of data",
          "utilise semantic units defined by linguists in the zero-shot scenario"
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification"
  },
  "1015": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Most previous work on transliteration has focused on a single language",
          "English to Hindi, English to Japanese, Arabic to",
          "But data from other languages can be helpful",
          "Improve existing model's results using supplemental data"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Previous work",
        "text": [
          "- Discriminative, online, max-margin",
          "Sequitur + SMT combination (Finch and Sumita, 2010)",
          "- Sequitur is generative, joint n-gram",
          "Applying supplemental transliterations to G2P",
          "We apply this method verbatim",
          "Based on SVM re-ranking"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Test data overlap",
        "text": [
          "Language Test set size Test set overlap"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Re ranking",
        "text": [
          "SVM re-ranking using all other languages",
          "N-gram features based on character alignments",
          "Similarity features based on alignment scores",
          "Transliteration data are noisy; handled by:"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "EnHi transliteration re ranking",
        "text": [
          "Direc TE+ DirecTLE+ w/ supp. TES Best other"
        ],
        "page_nums": [
          8,
          9,
          10
        ],
        "images": []
      },
      "5": {
        "title": "Re ranking with Sequitur",
        "text": [
          "Use Sequitur's output for re-ranking"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "EnHi Sequitur re ranking",
        "text": [
          "Direc TE+ +Sequitur nS Best other"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "7": {
        "title": "Hindi romanization",
        "text": [
          "Devanagari alphabet has combined consonants",
          "We experiment with romanizing Hindi",
          "Gives DirecTL+ direct individual control",
          "e Use romanized Hindi for training DirecTL+, do testing, then convert outputs to Devanagari",
          "SMS (eR Ke Jqna patTarUcl"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "EnHi romanization",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Chinese alignment length",
        "text": [
          "DirecTL+ relies on many-to-many alignments",
          "We experiment with maximum alignment length"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "EnCh alignment length",
        "text": [],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "SVM re-ranking for transliteration",
          "Great improvements with supplemental",
          "e Also see improvements for system combination",
          "Didn't work for EnHi (unlike EnJa in 2010)",
          "Must be careful to choose a good value!"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Leveraging Transliterations from Multiple Languages"
  },
  "1017": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Most high-performance data-driven models rely on a large amount of labeled training data. However, a model trained on one language usually performs poorly on another language.",
          "Extend existing services to more languages:",
          "Collect, select, and pre-process data",
          "Compile guidelines for new languages",
          "Train annotators to qualify for annotation tasks",
          "Adjudicate annotations and assess the annotation quality and inter-annotator agreement",
          "Adjudicate annotations and assess inter-annotator agreement",
          "languages are spoken today",
          "Rapid and low-cost development of capabilities for low-resource languages.",
          "Disaster response and recovery"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "TRANSFER LEARNING and MULTI TASK LEARNING",
        "text": [
          "Leverage existing data of related languages and tasks and transfer knowledge to our target task.",
          "The Tasman Sea lies between lAustralie est separee de lAsie par les mers dArafuraet",
          "Australia and New Zealand. de Timor et de la Nouvelle-Zelande par la mer de Tasman",
          "Multi-task Learning (MTL) is an effective solution for knowledge transfer across tasks.",
          "In the context of neural network architectures, we usually perform MTL by sharing parameters across models.",
          "Task A Data Parameter Sharing: When optimizing model A , we update",
          "and hence . In this way, we can partially train model B as ."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Sequence labeling",
        "text": [
          "To illustrate our idea, we take sequence labeling as a case study.",
          "In the NLP context, the goal of sequence labeling is to assign a categorical label (e.g., Part-of-speech tag) to each token in a sentence.",
          "It underlies a range of fundamental NLP tasks, including POS Tagging, Name Tagging, and Chunking.",
          "Koalas are largely sedentary and sleep up to 20 hours a day.",
          "NNS VBP RB JJ CC VB IN TO CD NNS DT NN",
          "PER NAME TAGGING B-PER E-PER GPE GPE",
          "Itamar Rabinovich, who as Israel's ambassador to Washington conducted unfruitful negotiations with",
          "Syria, told Israel Radio it looked like Damascus wated to talk rather than fight.",
          "B-, I-, E-, S-: beginning of a mention, inside of a mention, the end of a mention and a single-token mention",
          "O: not part of any mention Although we only focus on sequence labeling in this work, our architecture can be adapted for many NLP tasks with slight modification."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Base model lstm crf chiu and nichols 2016",
        "text": [
          "The CRF layer models the dependencies between labels.",
          "The linear layer projects hidden states to label space.",
          "The Bidirectional LSTM (long-short term memory) processes the input sentence from both directional, encodeing each token and its context into a vector",
          "Input Sentence Each token in the given sentence is",
          "represented as the combination of its word embedding and character feature vector.",
          "Features Character- level CNN",
          "Word Embedding Character Embedding"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Previous transfer models for sequence labeling",
        "text": [
          "T-A: Cross-domain transfer T-B: Cross-domain transfer With disparate label T-C: Cross-lingual Transfer sets",
          "Yang et al. (2017) proposed three transfer learning architectures for different use cases.",
          "* Above figures are adapted from (Yang et al., 2017)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Our model multi lingual multi task architecture",
        "text": [
          "combines multi-lingual transfer and multi-task transfer is able to transfer knowledge from multiple sources"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1017-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Our model multi lingual multi task model",
        "text": [
          "Cross-task Transfer POS Tagging Name Tagging",
          "Cross-lingual Transfer English Spanish",
          "The bidirectional LSTM, character embeddings and character-level networks serve as the basis of the architecture. This level of parameter sharing aims to provide universal word representation and feature extraction capability for all tasks and languages"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "7": {
        "title": "Our model multi lingual multi task model cross lingual transfer",
        "text": [
          "For the same task, most components are shared between languages.",
          "Although our architecture does not require aligned cross-lingual word embeddings, we also evaluate it with aligned embeddings generated using MUSEs unsupervised model (Conneau et al. 2017)."
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1017-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Our model multi lingual multi task model linear layer",
        "text": [
          "English: improvement, development, payment,",
          "French: vraiment, completement, immediatement",
          "We combine the output of the shared linear layer and the output of the language-specific linear layer using",
          "where . and are optimized during training. is the LSTM hidden states. As is a square matrix, , , and have the same dimension",
          "We add a language-specific linear layer to allow the model to behave differently towards some features for different languages."
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1017-Figure2-1.png"
        ]
      },
      "9": {
        "title": "Our model multi lingual multi task model cross task transfer",
        "text": [
          "Linear layers and CRF layers are not shared between different tasks.",
          "Tasks of the same language use the same embedding matrix: mutually enhance word representations"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1017-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Alternating training",
        "text": [
          "To optimize multiple tasks within one model, we adopt the alternating training approach in (Luong et",
          "At each training step, we sample a task with probability:",
          "In our experiments, instead of tuning mixing rate , we estimate it by:",
          "where is the task coefficient, is the language coefficient, and is the number of training examples. (or ) takes the value 1 if the task (or language) of is the same as that of the target task; Otherwise it takes the value 0.1."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Experiments data sets",
        "text": [
          "Spanish and Dutch: CoNLL 2002",
          "Russian: LDC2016E95 (Russian Representative Language Pack)",
          "Chechen: TAC KBP 2017 10-Language EDL Pilot Evaluation Source Corpus",
          "Part-of-speech Tagging: CoNLL 2017 (Universal Dependencies)"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Experiments setup",
        "text": [
          "50-dimensional pre-trained word embeddings",
          "English, Spanish and Dutch: Wikipedia",
          "Chechen: TAC KBP 2017 10-Language EDL Pilot Evaluation Source Corpus",
          "Cross-lingual word embedding: we aligned mono-lingual pre-trained word embeddings with MUSE",
          "50-dimensional randomly initialized character embeddings",
          "Optimization: SGD with momentum (), gradient clipping (threshold: 5.0) and exponential learning rate decay.",
          "Highway Activation Function SeLU",
          "LSTM Hidden State Size"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Experiments comparison of different models",
        "text": [
          "Target task: Dutch Name Tagging",
          "Auxiliary task: Spanish POS Tagging, English Name Tagging, English POS Tagging",
          "Target task: Spanish Name Tagging",
          "Target task: Chechen Name Tagging",
          "Auxiliary task: Russian POS Tagging + Name Tagging or English POS Tagging + Name Tagging"
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": [
          "figure/image/1017-Figure4-1.png",
          "figure/image/1017-Figure5-1.png",
          "figure/image/1017-Figure3-1.png"
        ]
      },
      "14": {
        "title": "Experiments comparison with state of the art models",
        "text": [
          "Our Model We also compared our model with state-of-the-art models with all training data."
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "15": {
        "title": "Experiments cross task transfer vs cross lingual transfer",
        "text": [
          "With 100 Dutch training sentences:",
          "The baseline model misses the name",
          "The cross-task transfer model finds the name but assigns a wrong tag to Marx.",
          "The cross-lingual transfer model correctly identifies the whole name.",
          "The task-specific knowledge that B-PER",
          "S-PER is an invalid transition will not be learned in the POS Tagging model.",
          "The cross-lingual transfer model transfers such knowledge through the shared CRF layer."
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1017-Table5-1.png"
        ]
      },
      "16": {
        "title": "Experiments ablation studies",
        "text": [
          "C: Character embedding; L: Shared LSTM; S: Language-specific",
          "H: Highway Networks; D: Dropout",
          "Generally, all components improve the performance. Sharing the LSTM layer slightly hurts the performance in the high-resource setting. Language-specific Layer can impair the performance in extreme low-resource settings because this layer is trained only on the target task data."
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "Experiments effect of the amount of auxiliary task data",
        "text": [
          "Does our model heavily rely on the amount of auxiliary task data?",
          "The performance goes up when we increase the sample rate from 0 to 0.2 for auxiliary task data.",
          "However, we do not observe substantial improvement when we further increase the sample rate.",
          "Using only 1% auxiliary data, our model already obtains 3.7%-9.7% absolute F-score gains."
        ],
        "page_nums": [
          23,
          24
        ],
        "images": [
          "figure/image/1017-Figure7-1.png",
          "figure/image/1017-Figure3-1.png"
        ]
      }
    },
    "paper_title": "A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling"
  },
  "1018": {
    "slides": {
      "0": {
        "title": "Reasoning for Question Answering",
        "text": [
          "Reasoning is crucial for building systems that can dialogue with humans in natural language.",
          "Reasoning: The process of forming conclusions, judgments, or inferences from facts or premises.",
          "Inferential Reasoning: Premise 1, Premise 2 -> Conclusion",
          "John is in the kitchen, John has the ball -> The ball is in the kitchen",
          "Relational Reasoning: Reason about relations between entities and their properties (Santoro et al.)",
          "Causal Reasoning, Logical Reasoning,"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "bAbI Dataset",
        "text": [
          "One of the earliest datasets to measure Category 2: Two Supporting Facts. the reasoning abilities of ML systems.",
          "Mary went to the kitchen.",
          "Sandra journeyed to the office",
          "Mary got the football there. Is(Football, Garden)",
          "Mary travelled to the garden.",
          "Where is the football? garden",
          "Easy to evaluate different reasoning capabilities. Category 4: Path Finding.",
          "The bedroom is south of the hallway..",
          "Noiseless tasks: Separates The bathroom is east of the office. reasoning analysis from natural The kitchen is west of the garden. language understanding. The garden is south of the office.",
          "N, N The office is south of the bedroom.",
          "A thorough analysis can be found in How do you go from the garden to the bedroom?? n,n (Lee et al., 2016)"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Memory Augmented Neural Networks",
        "text": [
          "Process a set of inputs and store them in memory. Then, at each hop, an important part of the memory is retrieved and used to retrieve more memories. Finally, the last retrieved memory is used i to compute the answer. y",
          "01: Daniel went to the bathroom. 02: Sandra journeyed to the office. 03: Mary got the football there. 04: Mary travelled to the garden",
          "Daniel went to the bathroom. Sandra journeyed to the office. Mary got the football there. Mary travelled to the garden",
          "q:Where is the football. u Hop",
          "i Softmax(uTmi) o1 imi",
          "to compute the answer. o2 imi",
          "The attention mechanism is simple",
          "The attention mechanism relies on embeddings.",
          "It may be nice to separate embedding learning from attention learning (modularization, reusability).",
          "The answer computation is too simple, it only uses one retrieved memory. Hard to see how can produce more complex reasoning based on memories."
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "Relational Neural Networks",
        "text": [
          "Relation Networks (Santoro et al. 2017)",
          "Neural Network with an inductive bias to learn pairwise relations of the input objects and their properties. A type of Graph Neural Networks. L(y, y) yiln( yi)",
          "01: Daniel went to the bathroom.",
          "02: Sandra journeyed to the office.",
          "03: Mary got the football there.",
          "04: Mary travelled to the garden",
          "q:Where is the football. u oi,j g([mi; mj; u])",
          "memories memories pairs with question g",
          "q:Where is the football. u a f( oi,j)",
          "The model needs to process N2 pairs where N is the number of memories.",
          "500 memories would require 250k backward and forward computations!",
          "Can not filter out unuseful objects that can produce spurious relations."
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "4": {
        "title": "Working Memory Networks",
        "text": [
          "A Memory Network model with a new working memory buffer and relational reasoning module. Produces state-of-the-art results in reasoning tasks. Inspired by the Multi-component model of working memory.",
          "Short-term Memory Module Attention Module Reasoning Module",
          "01: Daniel went to the bathroom. 02: Sandra journeyed to the office. 03: Mary got the football there. 04: Mary travelled to the garden",
          "02: Sandra journeyed to the office. 03: Mary got the football there. 04: Mary travelled to the garden",
          "u Hop 1 q:Where is the football.",
          "li Softmax((uTmli d)) hl lj ml j",
          "Multi-head attention (Vaswani et al. 2017)",
          "A Memory Network model with a new working memory buffer and relational reasoning module. Produces li Softmax((( ft(o1) Tmli d)) state-of-the-art results in reasoning tasks. Inspired by the Multi-component model of working memory. hl lj ml j",
          "Short-term Memory Module o1 = [h1; h2; . . . ]Wo Attention Module"
        ],
        "page_nums": [
          17,
          18,
          19
        ],
        "images": []
      },
      "5": {
        "title": "Results Jointly trained bAbI 10k",
        "text": [
          "Note that EntNet (Henaff et al.) solves all tasks in the per-task version: A single model for each task.",
          "LSTM MemNN MemNN-S (Sukhbaatar et al.) (Sukhbaatar et al.) (Sukhbaatar et al.) RN (Santoro et al.) SDNC (Rae et al.) WMemNN (Pavez et al.) WMemNN* (Pavez et al.)"
        ],
        "page_nums": [
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "6": {
        "title": "Ablations",
        "text": [
          "complex attention patterns multiple relations",
          "2 supporting facts 3 supporting facts counting basic induction size reasoning positional reasoning path finding"
        ],
        "page_nums": [
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "7": {
        "title": "Time comparison",
        "text": [
          "For 30 memories there is a speedup of almost"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "8": {
        "title": "Conclusions",
        "text": [
          "We presented the Working Memory Neural Network, a Memory Network model augmented with a new working memory buffer and relational reasoning module.",
          "It retains the relational reasoning capabilities of the relation network while reducing it computation times considerably.",
          "We hope that this contribution may help applying the relation network in larger problems.",
          "It is a very general framework. We argue that it should include:",
          "Embedding + Short-term storage",
          "Embedding + Short-term Attentional controller + storage Working memory buffer",
          "Embedding + Short-term Attentional controller + Reasoning module storage Working memory buffer",
          "Multi-head attention Relational Reasoning",
          "There is exactly one black triangle not touching any edge GRU Module",
          "16. Why, what are YOUR shoes done with? 17. said the Gryphon. 18. I mean, what makes then so shiny? 19. Alice looked down at then, and considered a little before she gave her answer. 20. They are done with blacking, I believe .",
          "biGRU Scaled Dot-product Attention Sum",
          "biGRU Attention Reasoning Module q. Boots and shoes under the sea. the went in a deep voice, are done with a whiting.",
          "Elmo ResNet LSTM BiAtt GA AoA Attention Sum"
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
        ],
        "images": []
      }
    },
    "paper_title": "Working Memory Networks: Augmenting Memory Networks with a Relational Reasoning Module"
  },
  "1019": {
    "slides": {
      "0": {
        "title": "This talk in one slide",
        "text": [
          "Training semantic parsing with denotation-only supervision is challenging because of spuriousness: incorrect logical forms can yield correct denotations.",
          "Iterative training: Online search with initialization MML over offline search output",
          "Coverage during online search",
          "State-of-the-art single model performances:",
          "WikiTableQuestions with comparable supervision",
          "NLVR semantic parsing with significantly less supervision"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Semantic Parsing for Question Answering",
        "text": [
          "Question: Which athlete was from South Korea",
          "Get rows where Nation is South Korea",
          "Filter rows where value in Olympics",
          "Get value from Athlete column",
          "Kim Yu-na South Korea (KOR)",
          "south_korea) athlete) Patrick Chan Canada (CAN)",
          "WikiTableQuestions, Pasupat and Liang (2015)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Weakly Supervised Semantic Parsing",
        "text": [
          "xi: Which athlete was from South Korea after 2010?",
          "wi: Kim Yu-na South Korea",
          "Tenley Albright United States",
          "Test: Given find such that"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Challenge Spurious logical forms",
        "text": [
          "Which athletes are from South Korea after",
          "Logical forms that lead to answer:",
          "(reverse athlete)(and(nation s outh_korea)(year ((reverse date) Athlete from South Korea after 2010",
          "Plushenko Russia (RUS) (reverse athlete)(and(nation Athlete from South Korea with 2 medals s outh_korea)(medals 2)))",
          "Kim Yu-na South Korea (KOR) (reverse athlete)(row.index (min",
          "(reverse row.index) (medals 2))))) First athlete in the table with 2 medals",
          "Patrick Chan Canada (CAN)",
          "(reverse athlete) (row.index 4)) Athlete in row 4",
          "There is exactly one square touching the bottom of a box True",
          "Due to binary denot a ti ons, 50% of",
          "count_equals(s quare Count of squares touching bottom of boxes",
          "logical forms give co r r ect answer! touch_bottom a ll_objects)) 1) is 1",
          "count_equals (yellow (square a ll_objects)) 1) Count of yellow squares is 1",
          "object_exists (yellow (triangle There exists a yellow triangle all_objects))))",
          "object_exists all_objects) There exists an object",
          "Cornell Natural Language Visual Reasoning, Suhr et al., 2017"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "Training Objectives",
        "text": [
          "Maximum Marginal Likelihood Reward/Cost -based approaches",
          "Krishn amurthy et al. (2017), and others Proposal: Alternate between the two objectives while gradually and others",
          "increasing the s earch space!",
          "Maxim ize the marginal likelihood of an approximate set of logical forms",
          "Minimum Bayes Risk training: Minimize the expected value of a cost",
          "but we need a good set of approximate",
          "but random initialization can cause the search to get stuck in the exponential search space logical forms"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Spuriousness solution 1 Iterative search",
        "text": [
          "Limited depth exhaustive search",
          "Step 0: Get seed set of logical forms till depth k",
          "Max logical form depth = k + s",
          "Step 1: Train model using MML on seed set",
          "Step 2: Train using MBR on all data till a greater depth k + s",
          "Minimum Bayes Risk training till depth k + s",
          "Step 3: Replace offline search with trained MBR and update seed set",
          "Maximum Marginal Likelihood Iterate till dev. accuracy stops increasing"
        ],
        "page_nums": [
          7,
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "6": {
        "title": "Spuriousness Solution 2 Coverage guidance",
        "text": [
          "There is exactly one square touching the bottom of a box.",
          "(count_equals (square (touch_bottom all_objects))",
          "Insight: There is a significant amount of trivial overlap",
          "Solution: Use overlap as a measure guide search"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Training with Coverage Guidance",
        "text": [
          "Augment the reward-based objective:"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Results of training with iterative search on NLVR",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Results of training with iterative search on WikiTableQuestions",
        "text": [],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Results of using coverage guided training on NLVR",
        "text": [
          "Model does not learn without coverage! Coverage helps even with strong initialization",
          "when trained from scratch when model initialized from an MML model trained on a seed set of offline searched paths",
          "* using structured representations"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Comparison with previous approaches on NLVR",
        "text": [
          "MaxEnt, BiAttPonter are not semantic parsers",
          "Abs. supervision + Rerank uses manually labeled abstractions of utterance - logical form pairs to get training data for a supervised system, and reranking",
          "Our work outperforms Goldman et al., 2018 with fewer resources",
          "* using structured representations"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Comparison with previous approaches on WikiTableQuestions",
        "text": [
          "Non-neural models Reinforcement Learning Non-RL Neural Models models"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Summary",
        "text": [
          "Spuriousness is a challenge in training semantic parsers with weak supervision",
          "Iterative training: Online search with initialization MML over offline search output",
          "Coverage during online search",
          "SOTA single model performances:"
        ],
        "page_nums": [
          20
        ],
        "images": []
      }
    },
    "paper_title": "Iterative Search for Weakly Supervised Semantic Parsing"
  },
  "1020": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Goal",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Technical Details",
        "text": [],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Multilingual Word Embeddings",
        "text": [],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Mapping Two Views To a Shared Space Canonical Correlation Analysis CCA",
        "text": [],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Limitations of CCA",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Partial CCA PCCA",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "New model Deep Partial CCA DPCCA",
        "text": [
          "Can we develop a deep variant for Partial CCA?",
          "Partial CCA suffers from similar limitations to those of CCA",
          "A new stochastic optimization algorithm is required"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "The DPCCA Model",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Architecture of Deep Partial CCA DPCCA Variant A",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Architecture of Deep Partial CCA DPCCA Variant B",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Deep Partial CCA DPCCA",
        "text": [],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "12": {
        "title": "Deep Partial CCA DPCCA Optimization",
        "text": [
          "Optimization is not trivial",
          "We introduce new stochastic optimization algorithms for our DPCCA variants",
          "Full Pseudocode is given in the paper"
        ],
        "page_nums": [
          20,
          21,
          22
        ],
        "images": []
      },
      "13": {
        "title": "Experiments and Results",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "14": {
        "title": "Experimental Setup Tasks and Datasets",
        "text": [],
        "page_nums": [
          24,
          25,
          26
        ],
        "images": []
      },
      "15": {
        "title": "New Dataset Word Image Word WIW",
        "text": [
          "POS EN-DE EN-IT EN-RU"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "16": {
        "title": "Experimental Setup Baselines",
        "text": [
          "Nonparametric CCA (NCCA) (Michaeli et al., 2016) - T"
        ],
        "page_nums": [
          28,
          29
        ],
        "images": []
      },
      "17": {
        "title": "Main Results",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "18": {
        "title": "Cross lingual Image Description Retrieval",
        "text": [
          "Model English to German German to English",
          "DPCCA Variant B + DCCA NOI"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "19": {
        "title": "Multilingual Word Similarity",
        "text": [
          "Model EN - ADJ EN - Verbs EN - Nouns DE - ADJ DE Verbs DE - Nouns"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "20": {
        "title": "Summary",
        "text": [],
        "page_nums": [
          33,
          34
        ],
        "images": []
      },
      "21": {
        "title": "Future Work",
        "text": [],
        "page_nums": [
          35
        ],
        "images": []
      }
    },
    "paper_title": "Bridging Languages through Images with Deep Partial Canonical Correlation Analysis"
  },
  "1021": {
    "slides": {
      "0": {
        "title": "Image Captioning",
        "text": [
          "Two young kids with backpacks sitting on the porch."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Visual Storytelling",
        "text": [
          "The brother did not want to talk to his sister. The siblings made up.",
          "They started to talk and smile. Their parents showed up. They were happy to see them.",
          "The brother and sister were ready for the first day of school. They were excited to go to their first day and meet new friends. They told their mom how happy they were. They said they were going to make a lot of new friends. Then they got up and got ready to get in the car."
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Reinforcement Learning",
        "text": [
          "o Directly optimize the existing metrics",
          "BLEU, METEOR, ROUGE, CIDEr",
          "Rennie 2017, Self-critical Sequence Training for Image Captioning"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Inverse Reinforcement Learning",
        "text": [
          "R eward Reward Inverse Reinforcement Reinforcement O ptimal Optima l",
          "Fu nction Functio n Learning i (IRL) ( ) Policy Policy"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Adversarial REward Learning AREL",
        "text": [
          "Reward Model Story Policy Model"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Policy Model",
        "text": [
          "My brother recently graduated college.",
          "CNN It was a formal cap and gown event.",
          "My mom and dad attended.",
          "Later, my aunt and grandma showed up.",
          "When the event was over he even got congratulated by the mascot."
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1021-Figure3-1.png"
        ]
      },
      "6": {
        "title": "Reward Model",
        "text": [
          "my mom and dad attended",
          "Story Convolution Pooling FC layer",
          "Kim 2014, Convolutional Neural Networks for Sentence Classification"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1021-Figure4-1.png"
        ]
      },
      "7": {
        "title": "Associating Reward with Story",
        "text": [
          "Energy-based models associate an energy value with a sample modeling the data as a Boltzmann distribution",
          "Approximate data distribution Partition function",
          "Optimal reward function is achieved when",
          "LeCun et al. 2006, A tutorial on energy-based learning"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "AREL Objective",
        "text": [
          "Therefore, we define an adversarial objective with KL-divergence",
          "Empirical distribution Policy distribution",
          "The objective of Reward Model",
          "The objective of Policy Model"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Reward Visualization",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Automatic Evaluation",
        "text": [
          "Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr",
          "Seq2seq (Huang et al.)",
          "HierAttRNN (Yu et al.)",
          "ABL REUL E -(RoL urs)",
          "Huang et al. 2016, Visual Storytelling Yu et al. 2017, Hierarchically-Attentive RNN for Album Summarization and Storytelling"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Human Evaluation",
        "text": [
          "XE BLEU-RL CIDEr-RL GAN AREL",
          "Relevance: the story accurately describes what is happening in the photo stream and covers the main objects.",
          "Expressiveness: coherence, grammatically and semantically correct, no repetition, expressive language style.",
          "Concreteness: the story should narrate concretely what is in the images rather than giving very general descriptions."
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "12": {
        "title": "Takeaway",
        "text": [
          "o Generating and evaluating stories are both challenging due",
          "to the complicated nature of stories",
          "o No existing metrics are perfect for either training or testing o AREL is a better learning framework for visual storytelling",
          "Can be applied to other generation tasks o Our approach is model-agnostic",
          "Advanced models better performance"
        ],
        "page_nums": [
          20
        ],
        "images": []
      }
    },
    "paper_title": "No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling"
  },
  "1023": {
    "slides": {
      "0": {
        "title": "What is Natural Language Inference NLI",
        "text": [],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Applications",
        "text": [],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Discourse Marker",
        "text": [
          "A discourse marker is a word or a phrase that plays a role in managing the flow and structure of discourse.",
          "Examples: so, because, and, but, or"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Discourse Marker and NLI",
        "text": [
          "But Because If Although And So"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Related Works",
        "text": [
          "SOTA Neural Network Models",
          "Transfer Learning for NLI"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Discourse Marker Prediction DMP",
        "text": [
          "Its rainy outside But + We will not take the umbrella",
          "(S1, S2) Neural Networks M",
          "Max pooling over all the hidden states Prediction"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "6": {
        "title": "Discourse Marker Augmented Network NLI Model",
        "text": [
          "Glove Char POS NER EM BiLSTM",
          "Interaction ------ Similarity Matrix",
          "The sentence representation of the premise",
          "The sentence representation of the hypothesis",
          "The i-th word of the premise",
          "The j-th word of the hypothesis",
          "Modeling vector of the premise Attention",
          "Mechanism Modeling vector of the hypothesis"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "7": {
        "title": "Training",
        "text": [
          "Original Labels: neutral, neutral, entailment, entailment, neutral",
          "Previous action policy that predicts the label given P and H."
        ],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "8": {
        "title": "Experiments Datasets",
        "text": [
          "Stanford Natural Language Inference (SNLI) (Bowman et al., 2015)",
          "433k human annotated sentences pairs",
          "Multi-Genre Natural Language Inference",
          "6.5M pairs of sentences for 8 discourse markers"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1023-Table3-1.png"
        ]
      },
      "9": {
        "title": "Experiments Results",
        "text": [],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1023-Table4-1.png"
        ]
      },
      "10": {
        "title": "Experiments Analysis",
        "text": [
          "Premise: 3 young man in hoods standing in the middle of a quiet street facing the camera. Hypothesis: Three people sit by a busy street bare-headed."
        ],
        "page_nums": [
          19,
          20
        ],
        "images": [
          "figure/image/1023-Table5-1.png"
        ]
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "We solve the task of the natural language inference via transferring knowledge from another supervised task.",
          "We propose a new objective function to make full use of the labels information.",
          "In the future work, we would like to explore some other transfer learning sources."
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference"
  },
  "1024": {
    "slides": {
      "0": {
        "title": "Multimodal Machine Translation",
        "text": [
          "Practical application of machine translation",
          "Translate a source sentence along with related nonlinguistic information",
          "two young girls are sitting on the street eating corn .",
          "deux jeunes filles sont assises dans la rue , mangeant du mais .",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Issue of MMT",
        "text": [
          "Multi30k [Elliott et al., 2016] has only small mount of data",
          "Statistic of training data",
          "Hard to train rare word translation",
          "Tend to output synonyms guided by language model",
          "Source deux jeunes filles sont assises dans la rue , mangeant du mais .",
          "Reference two young girls are sitting on the street eating corn .",
          "NMT two young girls are sitting on the street eating food .",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Previous Solutions",
        "text": [
          "Parallel corpus without images [Elliott and Kadar, 2017; Gronroos et al., 2018]",
          "Pseudo in-domain data by filtering general domain data",
          "Back-translation of caption/monolingual data",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Motivation",
        "text": [
          "Introduce pretrained word embedding to MMT",
          "Improve rare word translation in MMT",
          "Pretrained word embeddings with conventional MMT?",
          "Pretrained Word Embedding in text-only NMT",
          "Initialize embedding layers in encoder/decoder [Qi et al., 2018]",
          "Improve overall performance in low-resource domain",
          "Search-based decoder with continuous output [Kumar and Tsvetkov, 2019]",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Baseline IMAGINATION",
        "text": [
          "While validating, testing Bahdanau et al., 2015",
          "Train both MT task and shared space learning task to improve the shared encoder.",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "MMT with Embedding Prediction",
        "text": [
          "1. Use embedding prediction",
          "While validating, testing in decoder",
          "2. Initialize embedding layers in encoder/decoder with pretrained word embeddings",
          "While training 3. Shift visual features to make the mean vector be a zero",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Embedding Prediction",
        "text": [
          "i.e. Continuous Output [Kumar and Tsvetkov, 2019]",
          "Predict a word embedding and search for the nearest word",
          "1. Predict a word embedding of next word.",
          "2. Compute cosine similarities with each word in pretrained word embedding.",
          "3. Find and output the most similar word as system output.",
          "Pretrained word embedding will NOT be updated during training.",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Embedding Layer Initialization",
        "text": [
          "Initialize embedding layer with pretrained word embedding",
          "Fine-tune the embedding layer in encoder",
          "DO NOT update the embedding layer in decoder",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Loss Function",
        "text": [
          "Model loss: Interpolation of each loss [Elliot and Kadaar, 2017]",
          "MT task: Max-margin with negative sampling [Lazaridou et al., 2015]",
          "Shared space learning task: Max-margin [Elliot and Kadaar, 2017]",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Hubness Problem",
        "text": [
          "Certain words (hubs) appear frequently in the neighbors of other words",
          "Even of the word that has entirely no relationship with hubs",
          "Prevent the embedding prediction model from searching for correct output words",
          "Incorrectly output the hub word",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "All but the Top",
        "text": [
          "Address hubness problem in other NLP tasks",
          "Debias a pretrained word embedding based on its global bias",
          "1. Shift all word embeddings to make their mean vector into a zero vector",
          "2. Subtract top 5 PCA components from each shifted word embedding",
          "Applied to pretrained word embeddings for encoder/decoder",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Implementation and Dataset",
        "text": [
          "Multi30k (French to English)",
          "Pretrained ResNet50 for visual encoder",
          "Trained on Common Crawl and Wikipedia",
          "Our code is here: https://github.com/toshohirasawa/nmtpytorch-emb-pred",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Hyper Parameters",
        "text": [
          "dimension of hidden state: 256",
          "RNN type: GRU dimension of word embedding: 300 dimension of shared space: 2048",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Word level F1 score",
        "text": [
          "Frequency in training data",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "14": {
        "title": "Ablation wrt Embedding Layers",
        "text": [
          "Encoder Decoder Fixed BLEU METEOR",
          "FastText FastText Yes random",
          "Encoder/Decoder: Initialize embedding layer with random values or FastText word embedding.",
          "Fixed (Yes/No): Whether fix the embedding layer in decoder or fine-tune that while training.",
          "Fixing the embedding layer in decoder is essential",
          "Keep word embeddings in input/output layers consistent",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "15": {
        "title": "Overall Performance",
        "text": [
          "Model (+ pretrained): Apply embedding layer initialization and All-but-the-Top debiasing.",
          "Our model performs better than baselines",
          "Even those with embedding layer initialization",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "16": {
        "title": "Ablation wrt Visual Features",
        "text": [
          "Visual Features BLEU METEOR",
          "Visual Features (Centered/Raw/No): Use centered visual features or raw visual features to train model.",
          "No show the result of text-only NMT with embedding prediction model.",
          "Centering visual features is required to train our model",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion and Future Works",
        "text": [
          "MMT with embedding prediction improves ...",
          "It is essential for embedding prediction model to ...",
          "Fix the embedding in decoder",
          "Debias the pretrained word embedding",
          "Center the visual feature for multitask learning",
          "Better training corpora for embedding learning in MMT domain",
          "Incorporate visual features into contextualized word embeddings",
          "NAACTL hSRaWn 20k1 9y, Moinune! apolis"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "18": {
        "title": "Translation Example",
        "text": [
          "un homme en velo pedale devant une voute .",
          "a man on a bicycle pedals through an archway .",
          "a man on a bicycle pedal past an arch .",
          "Source a man on a bicycle pedals outside a monument .",
          "IMAGINATION a man on a bicycle pedals in front of a archway .",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "19": {
        "title": "Translation Example long",
        "text": [
          "quatre hommes , dont trois portent des kippas , sont assis sur un tapis a motifs bleu et vert olive .",
          "four men , three of whom are wearing prayer caps , are sitting on a blue and olive green patterned mat .",
          "four men , three of whom are wearing aprons , are sitting on a blue and green speedo carpet .",
          "four men , three of them are wearing alaska , are sitting on a blue patterned carpet and green",
          "Reference green seating .",
          "four men , three are wearing these are wearing these are sitting on a blue and green patterned",
          "NAACL SRW 2019, Minneapolis"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Multimodal Machine Translation with Embedding Prediction"
  },
  "1025": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "- Cross-lingual transfer learning",
          "- Very good results - Even better results",
          "- Tested in favorable conditions - Fail in more challenging datasets",
          "Previous work This work",
          "- Adversarial learning - Self-learning",
          "- Tested in favorable conditions - Works in challenging datasets - Fail in more challenging datasets"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "1": {
        "title": "Cross lingual embedding mappings",
        "text": [
          "Basque English Training dictionary",
          "Basque arg min English",
          "= arg min min"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "2": {
        "title": "Artetxe et al ACL 2017",
        "text": [
          "= arg min min",
          "- 25 word pairs",
          "- num. * none 0 a | Iteration",
          "- Numeral list A"
        ],
        "page_nums": [
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68
        ],
        "images": []
      },
      "3": {
        "title": "Proposed method",
        "text": [
          "1) Fully unsupervised initialization",
          "for x in vocab:",
          "two due (two) cane (dog)",
          "= sorted = sorted",
          "- Stochastic dictionary induction",
          "- Frequency-based vocabulary cutoff",
          "- Bidirectional dictionary induction",
          "- Final symmetric re-weighting (Artetxe et al., 2018)"
        ],
        "page_nums": [
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91
        ],
        "images": [
          "figure/image/1025-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Experiments",
        "text": [
          "10 runs for each method",
          "Successful runs (>5% accuracy)",
          "Method ES-EN IT-EN TR-EN",
          "Number of successful runs",
          "(Hard) dataset by Dinu et al. (2016) + extensions",
          "Supervision Method EN-IT EN-DE EN-FI EN-ES"
        ],
        "page_nums": [
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127
        ],
        "images": []
      },
      "5": {
        "title": "Conclusions",
        "text": [
          "Not a solved problem!",
          "More robust and accurate than previous methods",
          "Future work: from bilingual to multilingual"
        ],
        "page_nums": [
          128,
          129,
          130,
          131,
          132,
          133,
          134
        ],
        "images": []
      }
    },
    "paper_title": "A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings"
  },
  "1026": {
    "slides": {
      "0": {
        "title": "Universal Conceptual Cognitive Annotation UCCA",
        "text": [
          "Cross-linguistically applicable semantic representation (Abend and Rappoport, 2013).",
          "Builds on Basic Linguistic Theory (R. M. W. Dixon).",
          "Stable in translation (Sulem et al., 2015).",
          "After graduation John moved to Paris",
          "P D L A A",
          "Intuitive annotation interface and guidelines (Abend et al., 2017).",
          "The Task: UCCA parsing in English, German and French in different domains."
        ],
        "page_nums": [
          1,
          2,
          3,
          5,
          6
        ],
        "images": [
          "figure/image/1026-Figure1-1.png"
        ]
      },
      "1": {
        "title": "Applications",
        "text": [
          "Machine translation (Birch et al., 2016)",
          "Sentence splitting for text simplification (Sulem et al., 2018b).",
          "Grammatical error correction (Choshen and Abend, 2018)",
          "He gve an apple for john",
          "He gave John an apple"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Graph Structure",
        "text": [
          "Labeled directed acyclic graphs (DAGs). Complex units are non-terminal nodes. Phrases may be discontinuous.",
          "They thought - - - remote edge",
          "R P D A",
          "taking a short break",
          "Remote edges enable reentrancy."
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": []
      },
      "3": {
        "title": "Baseline",
        "text": [
          "TUPA, a transition-based UCCA parser (Hershcovich et al., 2017).",
          "taking a short break NodeC",
          "LSTM LSTM LSTM LSTM LSTM LSTM LSTM",
          "They thought about taking a short break"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Data",
        "text": [
          "English Wikipedia articles (Wiki).",
          "English-French-German parallel corpus from",
          "Twenty Thousand Leagues Under the Sea (20K). sentences tokens"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Tracks",
        "text": [
          "French low-resource (only 15 training sentences)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "6": {
        "title": "Conversion",
        "text": [
          "graduate-01 name name op1 After",
          "SDP ARG2 G1 head ARG2 head",
          "ARG1 ARG1 ARG2 AR",
          "root obl obl obl CoNLL-U punct nsubj hea d obl case hea d p unct case case hea d case nsubj After graduation , John moved to Paris After graduation John moved to Paris"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Evaluation",
        "text": [
          "True (human-annotated) graph Automatically predicted graph for the same text",
          "L H U H L H U A",
          "A P A S A",
          "graduation John moved graduation A P F A",
          "John moved to Paris to Paris",
          "Match primary edges by terminal yield + label.",
          "Calculate precision, recall and F1 scores.",
          "Repeat for remote edges."
        ],
        "page_nums": [
          14,
          15
        ],
        "images": [
          "figure/image/1026-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Participating Systems",
        "text": [
          "8 groups in total:",
          "MaskParse@Deskin Orange Labs, Aix-Marseille University",
          "TuPa University of Tubingen",
          "UC Davis University of California, Davis",
          "GCN-Sem University of Wolverhampton",
          "CUNY-PekingU City University of New York, Peking University",
          "DANGNT@UIT.VNU-HCM University of Information Technology VNU-HCM"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "9": {
        "title": "Leaderboard",
        "text": [
          "Track 1st place 2nd place 3rd place baseline",
          "English-Wiki closed HLT@SUDA baseline Davis",
          "English-Wiki open HLT@SUDA CUNY-PekingU 0.800 TuPa",
          "English-20K closed HLT@SUDA baseline CUNY-PekingU 0.669",
          "English-20K open HLT@SUDA CUNY-PekingU 0.739 TuPa",
          "German-20K closed HLT@SUDA CUNY-PekingU 0.797 baseline",
          "German-20K open HLT@SUDA CUNY-PekingU 0.841 baseline",
          "French-20K open CUNY-PekingU 0.796 HLT@SUDA XLangMo"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "10": {
        "title": "Main Findings",
        "text": [
          "HLT@SUDA won 6/7 tracks:",
          "Neural constituency parser + multi-task + BERT",
          "French: trained on all languages, with language embedding",
          "CUNY-PekingU won the French (open) track:",
          "TUPA ensemble + synthetic data by machine translation",
          "Surprisingly, results in French were close to English and German",
          "Demonstrates viability of cross-lingual UCCA parsing",
          "Is this because of UCCAs stability in translation?"
        ],
        "page_nums": [
          19,
          20,
          21
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Substantial improvements to UCCA parsing",
          "High variety of methods",
          "Thanks! Annotators, organizers, participants",
          "Daniel Hershcovich, Leshem Choshen, Elior Sulem,",
          "Zohar Aizenbud, Ari Rappoport and Omri Abend",
          "Please participate in the CoNLL 2019 Shared Task:",
          "Cross-Framework Meaning Representation Parsing",
          "SDP, EDS, AMR and UCCA mrp.nlpl.eu"
        ],
        "page_nums": [
          22,
          23,
          24
        ],
        "images": []
      }
    },
    "paper_title": "SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA"
  },
  "1027": {
    "slides": {
      "0": {
        "title": "Leadership",
        "text": [
          "A process of social influence in which a person can enlist the aid and support of others in the accomplishment of a common task [Chemers. 2014]",
          "accomplishment of a common task [Chemers. 2014]",
          "Get them to do something significant",
          "Energizing people toward a goal [Mills. 2005]"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Leadership Styles",
        "text": [
          "Get little input from group members",
          "Control over all decisions",
          "Give little guidance to group members",
          "Leave them to decision-making",
          "Encourage group members to participate",
          "Retain the final say in the decision-making",
          "How about the kings in the old times?"
        ],
        "page_nums": [
          3,
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "2": {
        "title": "Autocratic",
        "text": [
          "Control over all decisions"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Research Questions",
        "text": [
          "1. Do kings show different kinds of leadership styles?"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "4": {
        "title": "Dataset",
        "text": [
          "What kinds of data are needed?",
          "Discussions with government officials",
          "Long and large dataset",
          "Requirements: records of kings official duty activities",
          "My answer: The Annals of the Joseon Dynasty"
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "5": {
        "title": "The Annals of the Joseon Dynasty",
        "text": [
          "National Institute of Korean History (http://www.history.go.kr)",
          "Translated it to modern Korean",
          "Category (political, economic, social and cultural)",
          "Entity (person, location, nation)",
          "Published on the web"
        ],
        "page_nums": [
          15,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "6": {
        "title": "The Joseon Dynasty",
        "text": [
          "King governs the nation",
          "King decides on official issues",
          "King discusses it with government officials King",
          "A screenshot of a historical drama - Yi san"
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "7": {
        "title": "Methodology",
        "text": [
          "Look at the kings words and decisions",
          "To avoid non-governmental affairs (e.g. observations)",
          "Identify kings final decisions in the article",
          "Build sixty candidate verbs",
          "Look at the verbs in kings last sentence and title",
          "Discover topics in each article",
          "LDA outputs a topic proportion for each article",
          "LDA outputs a multinomial word distribution for each topic",
          "Identify who said what",
          "To analyze the participants in the discussion",
          "Look at subjects and person tags in front of the sentence of each quote"
        ],
        "page_nums": [
          49,
          50,
          65,
          66
        ],
        "images": []
      },
      "8": {
        "title": "Ruling styles",
        "text": [
          "Discussion and Order (DO) example",
          "Discussion and Follow (DF) example",
          "No discussion with officials",
          "Orders, approves, or rejects at the end",
          "Arbitrary Decision (AD) example"
        ],
        "page_nums": [
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60
        ],
        "images": []
      },
      "9": {
        "title": "Research Question 1",
        "text": [
          "1. Do kings show different kinds of leadership styles?"
        ],
        "page_nums": [
          61
        ],
        "images": []
      },
      "10": {
        "title": "Results Among kings",
        "text": [
          "Tyrants (Yeonsangun, Gwanghaegun) show high value of AD"
        ],
        "page_nums": [
          62,
          63
        ],
        "images": [
          "figure/image/1027-Figure2-1.png"
        ]
      },
      "11": {
        "title": "Research Question 2",
        "text": [
          "2. What factors are related with kings leadership?"
        ],
        "page_nums": [
          64
        ],
        "images": []
      },
      "12": {
        "title": "Results Topics",
        "text": [
          "Investigate the effects of the topics",
          "Look at the difference between ruling styles overall and given a topic",
          "Different from overall Injo (Weak king)",
          "Remission of sins topic",
          "Kings act DO than overall",
          "Injo tends to DF",
          "Sejong the Great acts DF",
          "Injo tends to give grants to servants than overall"
        ],
        "page_nums": [
          67,
          68,
          69,
          70,
          71,
          72
        ],
        "images": []
      },
      "13": {
        "title": "Results Members",
        "text": [
          "Investigate the effects of the participants in a discussion",
          "Compute the mutual information among ruling styles",
          "Agency officials who remonstrate to the king"
        ],
        "page_nums": [
          73,
          74,
          75
        ],
        "images": []
      },
      "14": {
        "title": "Results Time",
        "text": [
          "Yeonsangun (Tyrant) Injo (Weak king)",
          "Look at the temporal difference of a king",
          "Investigate the changes over time",
          "Yeonsangun becomes more arbitrary over time",
          "Injo stays consistent in his ruling style"
        ],
        "page_nums": [
          76,
          77
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "Introduced the Annals of the Joseon Dynasty",
          "Long and large historical documents",
          "Translated and annotated corpus",
          "Measured the kings leadership styles",
          "Relationship with factors (Topics, Members, Time)"
        ],
        "page_nums": [
          78
        ],
        "images": []
      }
    },
    "paper_title": "Five Centuries of Monarchy in Korea: Mining the Text of the Annals of the Joseon Dynasty"
  },
  "1028": {
    "slides": {
      "0": {
        "title": "Problem",
        "text": [
          "Mental illnesses are underdiagnosed",
          "Explore the predictive power of demographic and personality based features.",
          "Find insights provided by each feature."
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Data",
        "text": [
          "I have been diagnosed with depression",
          "each user has avg. 3400 messages"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Study Setup",
        "text": [
          "age, gender, personality ication mental illness"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Age Gender",
        "text": [
          "Model from FB and Twitter data"
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": [
          "figure/image/1028-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Personality",
        "text": [
          "high on neuroticism more introverted less agreeable",
          "controlling for age and gender"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "5": {
        "title": "Age Gender Personality",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "6": {
        "title": "Affect and Intensity",
        "text": [
          "Model trained on 3000",
          "mentally ill users are less aroused and less positive"
        ],
        "page_nums": [
          15,
          16,
          17
        ],
        "images": [
          "figure/image/1028-Figure3-1.png"
        ]
      },
      "7": {
        "title": "Liwc",
        "text": [
          "standard psychologically inspired dictionaries",
          "64 categories such as:",
          "parts-of-speech topical categories emotions",
          "standard baseline for open vocabulary approaches"
        ],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": []
      },
      "8": {
        "title": "Topics",
        "text": [
          "Latent Dirichlet Allocation (LDA) underlying set of Facebook statues",
          "(same data as personality model)",
          "2000 topics in total",
          "7 features 64 features 2000 features"
        ],
        "page_nums": [
          21,
          22,
          23,
          30
        ],
        "images": []
      },
      "9": {
        "title": "Topics Depression",
        "text": [
          "Topics controlled for age and gender"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1028-Figure6-1.png"
        ]
      },
      "10": {
        "title": "Topics PTSD",
        "text": [
          "Topics controlled for age and gender"
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/1028-Figure7-1.png"
        ]
      },
      "11": {
        "title": "Topics PTSD Depression and Neuroticism",
        "text": [],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1028-Figure8-1.png"
        ]
      },
      "12": {
        "title": "1 3 grams",
        "text": [
          "@ Depressed vs. Control = PTSDvs.Control Depressed vs. PTSD",
          "Penn | World Well-Being Project",
          "a= Gender Age ae"
        ],
        "page_nums": [
          31,
          32
        ],
        "images": []
      },
      "13": {
        "title": "Other features",
        "text": [
          "use different word clusters",
          "Brown clustering, NPMI Spectral clustering, Word2Vec/GloVe embeddings",
          "linear ensemble of logistic regression classifiers",
          "Mental Illness detection at the World Well-Being Project for the CLPsych 2015 Shared Task",
          "D. Preotiuc-Pietro, M. Sap, H.A. Schwartz, L. Ungar"
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "14": {
        "title": "ROC Curve Depressed vs Controls",
        "text": [],
        "page_nums": [
          37
        ],
        "images": []
      },
      "15": {
        "title": "ROC Curve PTSD vs Controls",
        "text": [],
        "page_nums": [
          38
        ],
        "images": []
      },
      "16": {
        "title": "ROC Curve Depressed vs PTSD",
        "text": [],
        "page_nums": [
          39
        ],
        "images": []
      },
      "17": {
        "title": "Take Home",
        "text": [
          "Control the analysis for age & gender",
          "Personality plays an important role in mental illnesses",
          "Language use of depressed/PTSD reveals symptoms, emotions, and cognitive processes."
        ],
        "page_nums": [
          40,
          41,
          42
        ],
        "images": []
      }
    },
    "paper_title": "Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal The Role of Personality, Age and Gender in Tweeting about Mental Illnesses"
  },
  "1029": {
    "slides": {
      "0": {
        "title": "Translationese",
        "text": [
          "The differences do not indicate poor translation but rather a statistical",
          "Simpler, more homogeneous, more explicit, interference from source",
          "language, aka translation universals (Baker, 1993)"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Translationese in MT data sets",
        "text": [
          "What is the effect of translationese on MT?",
          "Mainly studied wrt training data (Kurokawa et al., 2009; Lembersky, 2013)",
          "(Sourceoriginal ,Targettranslationese) (Sourcetranslationese ,Targetoriginal)",
          "Also wrt dev data, in SMT (Stymne, 2017)",
          "Using tuning texts translated in the same original direction as the MT",
          "system tended to give a better score",
          "What about test data?"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "Translationese in Test",
        "text": [
          "Toral et al. (2018): translationese input favours MT systems, on Hassan",
          "Source (ZH) Reference (EN)",
          "ZHEN ENEN HT TRS MS",
          "zh en Original language of the source sentence",
          "Laubli et al. (2018) in similar fashion, show stronger preference for human",
          "translations over MT when evaluating documents compared to isolated",
          "Taking the two works above, Graham et al. (2019) found evidence that",
          "translationese compared to original text can potentially negatively impact",
          "the accuracy of machine translation evaluations"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": [
          "figure/image/1029-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Research Questions",
        "text": [
          "1. Does the use of translationese in the source side of MT test sets unfairly",
          "2. If the answer to RQ1 is yes, does this effect of translationese have an impact",
          "on WMTs system rankings?",
          "3. If the answer to RQ1 is yes, would some language pairs be more affected"
        ],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "This study",
        "text": [
          "Human evaluation: Direct Assessment (DA), by bilingual crowd workers",
          "Source (ZH) Reference (EN)",
          "WMT ZHEN TRS ENEN"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1029-Figure1-1.png"
        ]
      },
      "5": {
        "title": "RQ1 favouritism for translationese WMT16",
        "text": [
          "Score difference in DA, ORG = original",
          "input, TRS = translationese input",
          "Consistent trend over all language pairs",
          "cse n dee n fien rue n tre n roe n"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "6": {
        "title": "Wmt17",
        "text": [
          "Similar trend, TRS = inflation of scores,",
          "ORG = deflation of scores.",
          "ent r enl v enc s enr u enf i enz h end e cse n tre n zhe n fien dee n lve n rue n Language Pair"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "7": {
        "title": "Wmt18",
        "text": [
          "Again, same trend over all",
          "Does translationese unfairly favour",
          "enf i enr u enc s ent r dee n ete n ene t tre n enz h fien zhe n end e cse n rue n Language Pair"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "8": {
        "title": "RQ2 impact on WMTs system rankings eg ZH EN",
        "text": [],
        "page_nums": [
          27,
          28,
          29
        ],
        "images": []
      },
      "9": {
        "title": "Another example RU EN",
        "text": [
          "So would there be ranking changes?",
          "Yes, and clusters too!"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34,
          35
        ],
        "images": []
      },
      "10": {
        "title": "Research Question 3 is there a trend",
        "text": [
          "Relative difference between original input and source input 10 5 0",
          "Best system vs. relative difference",
          "eten enzh deen tre n",
          "Relative difference between WMT input and original input 10 5 0",
          "between WMT input and ORG input",
          "Similarity of the language pair using URIEL and lang2vec",
          "cs en ende zhe n",
          "Highest scoring system (with only",
          "ORG input) vs. relative difference",
          "High differences could be due to under-",
          "Score of the best system with original input"
        ],
        "page_nums": [
          37,
          38
        ],
        "images": [
          "figure/image/1029-Figure2-1.png",
          "figure/image/1029-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Translationese: if present, it inflates DA scores. If removed, it lowers DA",
          "Correlation between the effect of translationese and the translation quality",
          "attainable for translation directions.",
          "The effect of translationese tends to be high when an under-resourced",
          "Recommendations (?): the WMT organizers have addressed this issue by",
          "providing completely source-language native test sets for WMT19.",
          "Future work: characteristics of translationese in the WMT test sets."
        ],
        "page_nums": [
          40,
          41,
          42,
          43,
          44,
          45
        ],
        "images": []
      }
    },
    "paper_title": "The Effect of Translationese in Machine Translation Test Sets"
  },
  "1030": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Theoretical framework and methodology",
          "Conclusion and Future Work",
          "Aims of sentiment analysis:",
          "i) Document level sentiment classification. A positive or",
          "ii) Subjectivity classification at sentence level. A subjective or objective (factual) sentence [Wiebe et al., 1999]. iii) Aspect and entity level. Identification of the target of one positive or negative opinion [Hu and Liu, 2004]."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Related works",
        "text": [
          "Theoretical framework and methodology",
          "Conclusion and Future Work",
          "Author Theory Corpus Annotation Results",
          "[Refaee and Rieser, 2014] 8,868 tweetsin Arabic Semantic orientation",
          "Grammatical features Kappa: 0.84",
          "[Chardon et al., 2013] SDRT 211 texts (movie revies, news reactions)",
          "EDUs: subjectivity. Documents: subjectivity and discourse relations",
          "Discourse and subjectivity annotation Categorization: 95% Segmentation: 82%",
          "[Mittal et al., 2013] 662 reviewsin Hindi Violating expectation conjunctions. Negation."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Theoretical framework Rhetorical Structure Theory RST",
        "text": [
          "Introduction and Related Works",
          "Conclusion and Future Work"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1030-Figure1-1.png"
        ]
      },
      "3": {
        "title": "The Basque Opinion Corpus",
        "text": [
          "Introduction and Related Works",
          "Conclusion and Future Work",
          "240 opinion texts collected from different websites.",
          "Opinion texts of six different domains: sports, politics, music, movies, literature books and weather.",
          "Usefulness for sentiment analysis:",
          "The first person: 1.21% in a Basque objective corpus (Basque",
          "8.50% of the words correspond to adjectives in Basque",
          "Wikipedia and 9.82% in the corpus for study.",
          "Negation, irrealis blocking and discourse markers also are in the corpus."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Methodology steps",
        "text": [
          "Introduction and Related Works",
          "Conclusion and Future Work",
          "Set the stage for the annotating work.",
          "Annotation procedure and process.",
          "Following the annotation guidelines proposed by",
          "Weather texts were annotated in 20 minutes while movie and literature texts were annotated in one hour."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "RST annotation inter annotator agreement",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Conclusion and Future Work",
          "Results: subjectivity extraction from rhetorical relations",
          "Discussion: usefulness of the corpus for sentiment analysis",
          "Relation. The same type of rhetorical relation to the attachment point of two or more EDUs in order to get the same effect.",
          "Domain Agreement (%) Agreement (RR)",
          "Automatic evaluation in a more strict scenario (if and only if the central subconstituent is the same) following",
          "Constituent (C). All the EDUs that compose each discourse unit or span.",
          "Attachment point. The node in the RS-tree to which the relation is attached.",
          "N-S or nuclearity Specification of the compared relations regarding direction (NS, NS or NN)."
        ],
        "page_nums": [
          12,
          15
        ],
        "images": [
          "figure/image/1030-Table2-1.png"
        ]
      },
      "6": {
        "title": "Sentiment analysis sentiment valence of rhetorical relations",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Conclusion and Future Work",
          "Discussion: usefulness of the corpus for sentiment analysis",
          "We sum all the sentiment valence of words of CONCESSION and EVALUATION rhetorical relations.",
          "The results of the sum are given based on nuclearity.",
          "Sum of sentiment valences CONCESSION EVALUATION",
          "Nucleus Satellite Nucleus Satellite Weather Literature Movies Total"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Discussion relevant RR disagreement",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Results: subjectivity extraction from rhetorical relations",
          "Conclusion and Future Work",
          "Discussion: usefulness of the corpus for sentiment analysis"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1030-Table5-1.png"
        ]
      },
      "8": {
        "title": "Usefulness of the corpus for sentiment analysis",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Conclusion and Future Work",
          "Results: subjectivity extraction from rhetorical relations",
          "We can combine the subjectivity information with features of type of rhetorical relations to make a better sentiment analysis and classification.",
          "Subjectivity extraction: words with sentiment valence tend to appear more in satellites than in nuclei."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Conclusions",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Annotation of a part of the Basque Opinion Corpus using RST.",
          "The results of automatic tool regarding constituent and nuclearity are higher than 0.5 (inter-annotator agreement).",
          "The usefulness of the corpus for sentiment analysis.",
          "Useful to extract subjectivity information of different rhetorical relations.",
          "CONCESSION: the semantic orientation of the nucleus prevails.",
          "EVALUATION: words with sentiment valence concentrate on satellite."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "10": {
        "title": "Future Work",
        "text": [
          "Introduction and Related Works",
          "Theoretical framework and methodology",
          "Building of extended annotation guidelines to annotate the corpus with more reliability.",
          "Annotation of the entire corpus.",
          "Analysis regarding the distribution of the subjective information in relations."
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "Towards discourse annotation and sentiment analysis of the Basque Opinion Corpus"
  },
  "1031": {
    "slides": {
      "0": {
        "title": "Discourse coherence",
        "text": [
          "Recipe for whipped cream frosting:",
          "Put cream cheese and whipping cream into a bowl.",
          "Add sugar and vanilla.",
          "Beat the mixture until the cream can hold a stiff peak.",
          "Cover cakes with this frosting that won't melt at room temperature.",
          "beca u se? V Otherwise youll be left with soggy cupcakes.",
          "Some relations can be left implicit; others cant."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "This paper Recovering implicit relations",
        "text": [
          "The availability of implicit relations alongside explicit cues is a puzzle for existing models of coherence relations.",
          "Also a further challenge to discourse parsing.",
          "Evidence from Conjunction-insertion experiments",
          "Results show role for inference alongside explicit cues"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "A puzzle",
        "text": [
          "Deduction of implicit information from juxtaposed sentences",
          "It's too far to walk. Let's take the bus.",
          "Infer alternatives: walk/bus as means of transport",
          "Infer causal relation: too far, therefore bus",
          "It's too far to walk so let's take the bus.",
          "Assumption: A passage marks its coherence relation either explicitly or implicitly - i.e., if explicit connective is present, no need for further inference about additional relations.",
          "so? V It's too far to walk. Instead let's take the bus."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Back to the puzzle",
        "text": [
          "Suppose that assumption is wrong: It is not simply a choice of marking a coherence relations either explicitly or implicitly.",
          "Question: When should we posit an implicit relation alongside an explicit cue?",
          "Why? Establishing the possibility of multiple concurrent relations is a first step towards the related question of what leads people to see them."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Multiple types of multiplicity",
        "text": [
          "Multiple alternative analyses (Mann & Thompson 1988; inter alia)",
          "I sang. John danced.",
          "Multiple connectives for same relation (Fraser 2013)",
          "John made a fool of himself at the restaurant, so as a result, we avoid going there.",
          "Multiple relations from same connective (Miltsakaki et al. 2005;",
          "We avoid that restaurant since John made a fool of himself there.",
          "Multiple connectives for distinct relations (Asher & Lascarides",
          "I bought the apartment but then I rented it out.",
          "Multiple inferred relations (Prasad et al. 2008, 2014; Dunietz et",
          "Its too far to walk. Lets take the bus.",
          "so instea V d",
          "New result: Systematic inference of relations, distinct from ones explicitly cued.",
          "Its too far to walk. Instead lets take the bus. so V"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "5": {
        "title": "Experimental Design Conjunction insertion",
        "text": [
          "Judgments for 50 adverbials, each in 50+ passages, each passage judged by 28 people. 70,000+ data points"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Passages in dataset",
        "text": [
          "Materials: for each adverbial, 50+ passages (mostly) from",
          "NYTimes Annotated Corpus (Sandhaus, 2008)",
          "Nervous? No, my legs not shaking, said Griffey, who caused everyone to laugh // ______ indeed his right foot was shaking.",
          "Sellers are usually happy, too _______ after all they are the ones leaving with money.",
          "Adverbials include: ACTUALLY, AFTER ALL, FIRST OF ALL, FOR EXAMPLE, FOR INSTANCE, IN FACT, IN OTHER WORDS, INDEED, INSTEAD, NEVERTHELESS, NONETHELESS, ON THE ONE HAND, ON THE OTHER HAND, OTHERWISE, SPECIFICALLY, THEN, THEREFORE, THUS,"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Experimental Design Single Response",
        "text": [
          "Each passage viewed by 28 participants",
          "Find conjunction to best reflect meaning of connection between text spans",
          "You can lead a horse to water // you cant make it drink",
          "Variability within adverbials: Does the adverbial elicit the same conjunction for all passages?"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "8": {
        "title": "Experimental Results Implicit passages",
        "text": [
          "We saw some consistency in semantically related adverbial pairs, but also differences for a given adverbial."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Cases of disagreement",
        "text": [
          "Different conjunctions can reveal different attachments:",
          "Nervous? No, my legs not shaking, said Griffey, who caused everyone to laugh ______ indeed his right foot was shaking.",
          "We didnt intend to have such examples.",
          "Adverbial-specific patterns arise: e.g., Author~Participant divergence with otherwise",
          "The Ravitch camp has had about 25 fund-raisers and has scheduled 20 more. Thirty others are in various stages of planning, Ms. Marcus said. It has to be highly organized // ________ otherwise its total chaos, she added.",
          "Not evidence of ambiguity",
          "Improbable combinations, but perfectly fine"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "10": {
        "title": "Summary so far",
        "text": [
          "Multiple connectives: Establish necessity of entertaining implicit relations when adverbial is present",
          "Context sensitivity: Adverbial alone does not completely predict discourse relation",
          "Informative disagreement: Demonstrate possibility of divergent valid annotations and what they arise from."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "LexSem of Adverbials Inference",
        "text": [
          "Lexical semantics of adverbial licenses one conjunction",
          "Inference from passage content licenses another",
          "Gouges are deep scratches that must be filled as well as colored _____ otherwise they will collect dirt and become permanently discolored.",
          "otherwise encodes 'otherness' (OR) passage requires causal reasoning (BECAUSE)",
          "For the plane to Paris, there are only a few tickets left",
          "____ instead you could go via Amsterdam.",
          "instead encodes substitution (OR) passage may permit emphasis on contrast (BUT) passage may permit causal reasoning (SO)"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Lexical Semantics of Advs Inference",
        "text": [
          "in other words none other so or but before because and",
          "in other words instead none",
          "other so or but before because and none other so or but before because and",
          "Adverbial meaning of otherness from otherwise and instead",
          "Additional pragmatic inference from passage content",
          "Passages may elicit significantly different responses.",
          "Was this evidence of different analyses across annotators or would same annotator endorse more than one conjunction?"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1031-Figure3-1.png"
        ]
      },
      "13": {
        "title": "Experimental Design Multiple Responses",
        "text": [
          "48 passages with otherwise (to assess perceived functional role of the otherwise clause)",
          "16 passages with instead (minimal pairs to test parallel/ non-parallel readings)",
          "+ passages for in other words and after all",
          "Task 1: Identify best conjunction(s) for meaning of connection",
          "Task 2 (for otherwise): Identify a paraphrase of that meaning"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Otherwise passages with different roles",
        "text": [
          "argumentation Proper placement of the testing device is an important issue",
          "______ otherwise the test results will be inaccurate.",
          "Prediction: OR/BECAUSE #BUT a reason to place the test properly is to avoid inaccuracy",
          "enumeration A baked potato, plonked on a side plate with sour cream",
          "lecked f with chives, is the perfect accompaniment ______ otherwise you could serve a green salad and some good country bread.",
          "there Prediction: are two choices OR/BUT for #BECAUSE a side: potato or salad",
          "#a reason to have a potato is to avoid a salad",
          "exception Mr. Lurie and Mr. Jarmusch actually catch a shark, a thrashing",
          "10-footer _____ otherwise the action is light.",
          "Prediction: BUT #OR/BECAUSE shark catching is a special case; generally action is light",
          "#there are two choices for the film: sharks or light action"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Instead passages w different emphasis",
        "text": [
          "parallel There was no flight scheduled to Paris yesterday ______",
          "instead there were several to Amsterdam.",
          "There were too few flights scheduled to Paris yesterday ______ instead we went to Amsterdam."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Results Otherwise",
        "text": [
          "argumentation Proper placement of the testing device is an important issue",
          "______ otherwise the test results will be inaccurate.",
          "Prediction confirmed: OR & BECAUSE",
          "A B C D E F G H I J K L M N O P BUT",
          "OR,BUT OR,SO OR,AND OR,BECAUSE AND,OR,BUT",
          "first second first second first second first second first second first second first second first second first second first second first second first second first second first second first second first second",
          "AND,OR,SO AND,OR,SO,BUT [no connective]",
          "enumeration A baked potato, plonked on a side plate with sour cream",
          "f lecked with chives, is the perfect accompaniment ____ otherwise you could serve a green salad and some good country bread.",
          "OR OR,BUT SO,OR OR,AND",
          "AND,OR,SO BUT,AND [no connective]",
          "exception Mr. Lurie and Mr. Jarmusch actually catch a shark, a thrashing",
          "10-footer _____ otherwise the action is light.",
          "Prediction confirmed: BUT only",
          "Main effect of 3-way underlying category on BUT (p<0.001)"
        ],
        "page_nums": [
          21,
          22,
          23
        ],
        "images": [
          "figure/image/1031-Figure7-1.png",
          "figure/image/1031-Figure6-1.png",
          "figure/image/1031-Figure5-1.png"
        ]
      },
      "17": {
        "title": "Results Instead",
        "text": [
          "parallel There was no flight scheduled to Paris yesterday ______",
          "instead there were several to Amsterdam.",
          "non-parallel There were too few flights scheduled to Paris yesterday ______",
          "instead we went to Amsterdam.",
          "Prediction confirmed: main effect of condition on use of",
          "A B C D E F G H I J K L M N O BUT",
          "parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel parallel non_parallel"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1031-Figure8-1.png"
        ]
      },
      "18": {
        "title": "Summary Choosing among alternatives",
        "text": [
          "It's too far to walk. Let's take the bus.",
          "Inference even with explicit cues",
          "It's too far to walk. Instead let's take the bus.",
          "Better to take the bus or otherwise youll have to walk."
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "19": {
        "title": "Conclusion and Future Work",
        "text": [
          "What participants chose can be explained in terms of the lexical semantics of discourse adverbials and properties of the passages that lead to particular inferences.",
          "With otherwise, inference aligns with the perceived function of the passage: argumentation, enumeration, exception.",
          "What leads to this functional inference?",
          "With instead, inference seems to align in part with what licenses the adverbial.",
          "We know what can license instead but we have yet to fully correlate these possibilities with what is inferred."
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Discourse Coherence: Concurrent Explicit and Implicit Relations"
  },
  "1032": {
    "slides": {
      "0": {
        "title": "Executing Context Dependent Instructions",
        "text": [
          "Task: map a sequence of instructions to actions",
          "Modeling Context Learning from"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Executing a Sequence of Instructions",
        "text": [
          "Empty out the leftmost beaker of purple chemical",
          "Then, add the contents of the first beaker to the second",
          "Then, drain 1 unit from it",
          "Same for 1 more unit"
        ],
        "page_nums": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "2": {
        "title": "Problem Setup",
        "text": [
          "Task: follow sequence of instructions",
          "Learning from instructions and corresponding world states",
          "Empty out the leftmost beaker of purple chemical",
          "Then, add the contents of the first beaker to the second",
          "Then, drain 1 unit from it",
          "Same for 1 more unit"
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Miller et al. 1996, Zettlemoyer and",
          "Collins Suhr et al. 2018",
          "Environments that change over time while instructions are given",
          "Following instructions in isolation; varying levels of supervision"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "4": {
        "title": "Today",
        "text": [
          "1. Attention-based model for generating sequences of system actions that modify the environment",
          "2. Exploration-based learning procedure that avoids biases learned early in training"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "5": {
        "title": "System Actions",
        "text": [
          "Each beaker is a stack",
          "Actions are pop and push",
          "pop pop pop push brown; push brown; push brown;"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "6": {
        "title": "Meaning Representation",
        "text": [
          "push brown; push brown; push brown;"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "7": {
        "title": "Model",
        "text": [
          "P revious instructions Current instruction",
          "T hrow out first beaker Pour sixth beaker into last one It turns brown",
          "Output: a sequence of actions",
          "Attend over each input when generating actions",
          "I nitial state Attention Attention",
          "Attend over current instruction",
          "Attend over previous instructions",
          "Previous instructions MLP Current state Initial state",
          "Attend over initial state",
          "Attend over current state",
          "Execute action, update state",
          "Attend over new state",
          "Current state push 7 brown",
          "push brown push brown"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
        ],
        "images": []
      },
      "8": {
        "title": "Learning from World State Annotation",
        "text": [
          "Goal: learn a policy that maps from instructions and environment states to actions",
          "Empty out the leftmost beaker of purple chemical",
          "Then, add the contents of the first beaker to the second",
          "Then, drain 1 unit from it",
          "Same for 1 more unit",
          "Learn through exploring the environment and observing rewards",
          "Policy gradient with contextual bandit",
          "Challenge: overcome biases acquired early during learning"
        ],
        "page_nums": [
          37,
          38
        ],
        "images": []
      },
      "9": {
        "title": "Reward Function",
        "text": [
          "Source state s s0 Target state",
          "if if a stops the sequence and a stops the sequence and s0 s0 is the goal state is not the goal state",
          "is closer to the goal state than is closer to the goal state than s0"
        ],
        "page_nums": [
          39,
          40,
          41
        ],
        "images": []
      },
      "10": {
        "title": "Learning Example",
        "text": [
          "Add the third beaker to the first",
          "push 1 green; pop push 1 yellow;",
          "No positive reward for push actions",
          "push 1 green; pop push 1 green;",
          "Quickly learned a strong bias against push actions"
        ],
        "page_nums": [
          42,
          43,
          44,
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "11": {
        "title": "Learned Biases",
        "text": [
          "Early during learning, model learns it can get positive reward by predicting the pop actions",
          "Less likely to get positive reward with push action",
          "Becomes biased against push - during later exploration, push is never sampled!",
          "Compounding effect: never learns to generate push actions"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "12": {
        "title": "Single step Reward Observation",
        "text": [
          "Our approach: observe reward of all actions by looking one step ahead during exploration",
          "Observe reward for actions like push"
        ],
        "page_nums": [
          50
        ],
        "images": []
      },
      "13": {
        "title": "Learning Algorithm",
        "text": [
          "For each training example:",
          "Rollout: sample sequence of state- action pairs from the current policy",
          "For each state visited in the rollout,",
          "A. For each possible action, execute action and observe reward",
          "Update parameters based on observed rewards for all states and actions"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "14": {
        "title": "Simple Exploration",
        "text": [
          "Only observe states along sampled trajectory",
          "Observe sampled states and single-step ahead"
        ],
        "page_nums": [
          52,
          53,
          54,
          55,
          56,
          57,
          58
        ],
        "images": []
      },
      "15": {
        "title": "Single step Observation",
        "text": [
          "Add the third beaker to the first",
          "push 1 orange push 1 yellow"
        ],
        "page_nums": [
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70
        ],
        "images": []
      },
      "16": {
        "title": "Experimental Setup",
        "text": [
          "Training data: start state and a sequence of instructions and goal states",
          "Standard evaluation metric: after following a sequence of instructions, is the world state correct?"
        ],
        "page_nums": [
          71
        ],
        "images": []
      },
      "17": {
        "title": "Alchemy",
        "text": [
          "pop pop pop push brown; push brown; push brown;"
        ],
        "page_nums": [
          72
        ],
        "images": []
      },
      "18": {
        "title": "Scene",
        "text": [
          "T he person with a red shirt and a blue hat moves t o the right end",
          "remove_person remove_hat add_person red add_hat blue"
        ],
        "page_nums": [
          73
        ],
        "images": []
      },
      "19": {
        "title": "Tangrams",
        "text": [
          "Swap the third and fourth figures",
          "remove 4 insert 3 boat"
        ],
        "page_nums": [
          74
        ],
        "images": []
      },
      "20": {
        "title": "Results",
        "text": [
          "while mapping directly to system actions",
          "Performance is comparable to direct supervision"
        ],
        "page_nums": [
          75,
          76
        ],
        "images": []
      },
      "21": {
        "title": "Learning Methods",
        "text": [
          "Single-step observations overcome biases that get model stuck"
        ],
        "page_nums": [
          77
        ],
        "images": []
      },
      "22": {
        "title": "Ablations",
        "text": [
          "Without World State Context",
          "Need access to previous instructions",
          "Need access to world state"
        ],
        "page_nums": [
          78
        ],
        "images": []
      }
    },
    "paper_title": "Situated Mapping of Sequential Instructions to Actions with Single-step Reward Observation"
  },
  "1035": {
    "slides": {
      "0": {
        "title": "Machine Reading Comprehension MRC",
        "text": [
          "Passage: ... Tesla later approached Morgan to ask for more funds to build a more powerful transmitter. When asked where all the money had gone, Tesla responded by saying that he was affected by the Panic of 1901, which he",
          "(Morgan) had caused Morgan was shocked by the reminder of his part in the stock market ...",
          "Passage: Question: On what did",
          "Tesla blame for the loss of",
          "When asked where all the money the initial money?",
          "was affected by the Panic of 1901 Answer: Panic of 1901",
          "* Different types: cloze test, entity extraction, span extraction, multiple-choice ..."
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "Applying MRC to the Web",
        "text": [
          "how many teams will be in the 2022 world cup? u Q",
          "2022 FIFA World Cup - Wikipedia",
          "In the end, there were five bids for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea and e All of t h em seem rel evant.",
          "Teams: 32 (from 5 or 6 confederations) Dates: 21 November 18 December",
          "om 5 or 6 confederations) Dates: 21 November - 18 December country: Qatar Venue(s): 8 or 12 (in 5 or 8 host cities)",
          "2018 FIFA World Cup qualification - Wikipedia",
          "https://en.wikipedia.org/wiki/2018_FIFA_World_Cup_qualification v United Arab Emirates Ahmed Khalil (16 goals each). 2014 - 2022 . The 2018 FIFA World Cup qualification process was a series of tournaments organised by the six FIFA confederations to decide 31 of the 32 teams which will play in the 2018 FIFA World Cup, with .... the suspension of their football association by FIFA on 30 May 2015. Teams: 210 (from 6 confederations) Goals scored: 2,454 (2.81 per match) Matches played: 872",
          "Qataris considering a 48-team option for 2022 World Cup - The ... https:/Avww.washingtonpost.com/...team...2022-world-cup/.../64dae0e6-8214-118-b3b... 5 days ago - The organizers of the 2022 World Cup in Qatar are open to talks about a ... power it apparently gained is key to any progress on the tournament expansion. ... 32 nations from which 16 winners would join 16 seeded teams in a ...",
          "* Search engine is employed.",
          "Multiple passages are retrieved.",
          "|. WIKIDE dia. OFg/WIKI/ ZU A World_Cup_qualification v United Arab Emirates Ahmed Khalil (16 goals cock). 2014 - 2022 . The 2018 FIFA World Cup",
          "2022 FIFA World Cup - Wiki Wikipedia",
          "https://en. wikipedia. grgauikil202 Nay",
          "But they give different answers!",
          "5 days ago - The organizers o of the 2022 World cup i in Qatar are open to talks about a ... power it d agsess on the tournament expansion. ... 32 nations from which 16",
          "2022 FIFA World Cup ~ Wiki es",
          "https: //en. wikipedia. orgauilis20",
          "In the end, there werd re is for the FA World Cup} Australia, Japan, Qatar, South Korea and",
          "All of them seem relevant.",
          "Much more misleading candidates"
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "An Example from MS MARCO Dataset",
        "text": [
          "Question: What is the difference between a mixed and pure culture?",
          "1) Acculture is a societys total way of living and a society is a group that live in a defined territory and participate in common culture. While the answer given is...",
          "2) ...The mixed economy is a balance between socialism and capitalism. As a result, some institutions are owned and maintained by...",
          "6) A pure culture is one in which only one kind of microbial species is found whereas Vv C A in mixed culture two or more microbial species formed colonies. A pure culture... | orrect Answer",
          "4) ...A pure culture comprises a single species or strains. A mixed culture is taken from a source and may contain multiple strains or species. A contaminated ... Verify",
          "5) ... It will be at that time when we can truly obtain a pure culture. A pure culture is a culture consisting of only one strain. You can obtain a pure culture by picking...",
          "@ Incorrect = Partially Correct = Correct",
          "> Similar or same"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "3": {
        "title": "Overview of Our Model",
        "text": [
          "Question Passage | Passage 2 os Passage n",
          "Answer A, Answer A \\",
          "oe ere ae ~ \"\"\"eihteal =6COLtiietet~*e( weit LCC . Final",
          "Prediction Pstart) | P(end) Perera) P(end)",
          "poner nna pn pn an fn ap I t weighted . Final!",
          "Answer Content { A I Modeling ( nswer I"
        ],
        "page_nums": [
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "Input",
        "text": [
          "Question Passage 1 Passage 2"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "5": {
        "title": "Question and Passage Encoding",
        "text": [
          "Question Passage | Passage 2 on Passage n .",
          "Y v Y creo with Bi-LSTM:"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "6": {
        "title": "Question Passage Matching",
        "text": [
          "Question Passage 1 Passage 2 os Passage n",
          "uP uP: UPa * Bi-directional Attention Flow"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "7": {
        "title": "Answer Boundary Prediction",
        "text": [
          "Question Passage 1 Passage 2 os Passage n",
          "Start and end pointer:",
          "Cc = Mit ative"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "8": {
        "title": "Answer Content Modeling",
        "text": [
          "Question Passage 1 Passage 2 os Passage n",
          "* Content score for each",
          "Answer A, Answer Az",
          "He | ye | ae"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "9": {
        "title": "Cross Passage Answer Verification",
        "text": [
          "7 rit -r4y, otherwise"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "10": {
        "title": "Joint Training and Prediction",
        "text": [
          "Finding the boundary of the answer",
          "Predicting whether each word should be included in the answer",
          "* Selecting the best answer from all the candidates",
          "Lioint = Lpounaary + P1 content + B2L verify",
          "Score = Shoundary X Scontent * Sverify"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "11": {
        "title": "Experiments Setup",
        "text": [
          "* Datasets: MS-MARCOF! and DuReader!7!:",
          "eee Search CoV erst Ce MUU) CoV erst Ce MUU) ai aay ala Multi Annotated Answers Multi Answer Spans",
          "eee Search Questions with Questions with",
          "Hyper-parameters (tuned on the dev set):",
          "Glove Random cies aan a"
        ],
        "page_nums": [
          28,
          29,
          30
        ],
        "images": []
      },
      "12": {
        "title": "Main Results",
        "text": [
          "Tab 1. Performance on MS-MARCO test set"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "13": {
        "title": "Ablation Study on MS MARCO Dev Set",
        "text": [],
        "page_nums": [
          32
        ],
        "images": []
      },
      "14": {
        "title": "Quantitative Analysis the Predicted Scores",
        "text": [
          "Question: What is the difference between a mixed and pure culture",
          "[1] A culture is a societys total way of living and a society is a group...",
          "[2] The mixed economy is a balance between socialism and capitalism.",
          "[6] A pure culture is one in which only one kind of microbial species... | 5.8 x 107",
          "[4] A pure culture comprises a single species or strains. A mixed ... 2.7 x 1073",
          "[5] A pure culture is a culture consisting of only one strain. 5.8 x 1074",
          "Boundary / content / verification scores are usually positively relevant",
          "Answer Candidates: Boundary Content Verification"
        ],
        "page_nums": [
          33,
          34,
          35,
          36
        ],
        "images": [
          "figure/image/1035-Table6-1.png"
        ]
      },
      "15": {
        "title": "Necessity of the Content Model",
        "text": [
          "zB se pasn yun asivyo oyur",
          "yory aa A0J ou au) pue",
          "asuas sey yun asivyo unou oul ~e- unou -aaT- yun asivyo",
          "end probability start probability",
          "pasn yun asieyd oyur",
          "IT sey yun asieyd unou oul ~e- unou -aaT- yun asieyd",
          "start probability end probability content probability",
          "re oe eee . oe 1 oe . Ed SEHE RZ ZECEATESESCHREERSZZS SEDe ts 4e8 sm BStset 5 a= gaa 42 eegarac Bs Z S 2 2a 2 al Fs 2 a HE z 35 = 5 i 3 5 oe 5 o 5 s 2 2 o 3",
          "When the answer is long, boundary words carry little information.",
          "a> SMOT yorya 40y aun aw pue",
          "Content words reflect the real semantics of this answer."
        ],
        "page_nums": [
          38,
          39,
          41,
          42
        ],
        "images": [
          "figure/image/1035-Figure2-1.png"
        ]
      },
      "16": {
        "title": "Visualization of the Probability Distribution",
        "text": [
          "content probability end probability start probability",
          "zB se pasn yun asaey oyur",
          "-mM- SMOT yorya 40y au aw pue",
          "sey yun asaey unou ouL -aad- unou -aaT- yun asaey"
        ],
        "page_nums": [
          40
        ],
        "images": [
          "figure/image/1035-Figure2-1.png"
        ]
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "* Multi-passage MRC: much more misleading answers",
          "* End-to-end model for multi-passage MRC:",
          "Find the answer boundary",
          "* Model the answer content",
          "* Cross-passage answer verification",
          "Joint training and prediction",
          "SOTA performance on two datasets created from real-world web data:"
        ],
        "page_nums": [
          43
        ],
        "images": []
      }
    },
    "paper_title": "Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification"
  },
  "1036": {
    "slides": {
      "0": {
        "title": "Why the affective analysis is necessary",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Progress of Affective Computing",
        "text": [
          "Emotion Recognition Sentiment Analysis"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Is multi modality needed",
        "text": [
          "Oh you dont like that you are west-sider",
          "I love this city! I hate this city!"
        ],
        "page_nums": [
          3,
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Challenges Feature Extraction",
        "text": [
          "Gap between features and actual affective states",
          "Lack of high-level associations",
          "Not all parts contribute equally"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Challenges Modality Fusion",
        "text": [
          "Lack of mutual association learning",
          "Fail to learn time-dependent interactions"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Proposed Solutions",
        "text": [
          "Hierarchical attention based bidirectional GRUs",
          "Word-level fusion with attention",
          "An End-to-End multimodal network"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Data Pre processing",
        "text": [
          "Mel-frequency spectral coefficients (MFSCs)"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Word level Fusion",
        "text": [
          "(a) Horizontal Fusion (b) Vertical Fusion (c) Fine-tuning Attention Fusion",
          "Word-level acoustic attention distribution Word-level textual attention distribution Word-level acoustic contextual state Word-level textual contextual state"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Baselines",
        "text": [],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Sentiment Analysis Result",
        "text": [
          "Weighted Accuracy Weighted F1"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Emotion Recognition Result",
        "text": [
          "Weighted Accuracy Unweighted Accuracy"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Multimodal architecture is needed",
        "text": [
          "T A T+A Weighted Accuracy Weighted F1"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Generalization",
        "text": [
          "Weighted Accuracy Weighted F1"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Attention Visualization",
        "text": [
          "Carry representative information in both text and audio",
          "Successfully combine both textual and acoustic attentions",
          "What about the business what the hell is this",
          "Word-level acoustic attention distribution Word-level textual attention distribution Shared attention distribution Fine-tuning attention distribution",
          "Capture emphasis and importance variation",
          "Oh you dont like that youre west-sider"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "14": {
        "title": "Summary",
        "text": [
          "A hierarchical attention based multimodal structure",
          "The word-level fusion strategies"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment"
  },
  "1037": {
    "slides": {
      "0": {
        "title": "Semantic Role Labelling",
        "text": [
          "Subject Manner Verb Object Time",
          "John surreptitiously ate the burrito at 2am.",
          "Applied to improve state-of-the-art in NLP tasks such as Question Answering",
          "Commonly used interface to facilitate Data Exploration and Information Extraction [Stanovsky et al 2018] [Chiticariu et al. 2018]",
          "Considerable interest in general-purpose SRL parsers"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Qa srl",
        "text": [
          "Subject Manner Verb Object Time",
          "John surreptitiously ate the burrito at 2am.",
          "ng ing ea ten",
          "teso methi aten? thi ng ea ten",
          "Who a was s ometh",
          "How When was some",
          "Wh Aux Subj Verb Obj Prep Obj2",
          "How did didnt might will someone something stem past past participle present someone something on to by from someone something",
          "didnt might will stem someone What Where When Why How someone something past something on to by from someone something past participle present",
          "What did someone eat? the burrito",
          "Who someone stem What did",
          "Where When Why How didnt might will something past someone something on to by from someone something past participle present",
          "Who ate something? John"
        ],
        "page_nums": [
          5,
          6,
          17,
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "2": {
        "title": "Goal",
        "text": [
          "A high-quality, large-scale parser for QA-SRL"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Challenges",
        "text": [
          "1. Scale up QA-SRL data annotation",
          "75k sentence dataset in 9 days",
          "2. Train a QA-SRL Parser",
          "A much larger super eruption in Colorado produced over 5,000 cubic kilometers of material.",
          "What produced something? A much larger super eruption Produced Where did something produce something? in Colorado What did something produce? over 5,000 cubic kilometers of material Where didnt someone appear to do something? In the video Who didnt appear to do something? the perpetrators appeared When did someone appear? never In the video, the perpetrators never appeared to look at the camera. look at the camera What didnt someone appear to do? to look at the camera Where didn't someone look at something? In the video look Who didnt look? the perpetrators What didnt someone look at? the camera Some of the vegetarians Who met someone? vegetarians met Some of the vegetarians he met were members of the Theosophical Society, which had been founded in 1875 to further universal brotherhood, and which was devoted to the study of Buddhist and Hindu literature.",
          "Who met? he What did someone meet? members of the Theosophical Society members of the Theosophical Society What had been founded? the Theosophical Society founded in 1875 When was something founded? Why has something been founded? to further universal brotherhood What was devoted to something? members of the Theosophical Society"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13
        ],
        "images": [
          "figure/image/1037-Table8-1.png"
        ]
      },
      "4": {
        "title": "Large scale QA SRL",
        "text": [
          "1. Scale up QA-SRL data annotation",
          "2. Train a QA-SRL Parser"
        ],
        "page_nums": [
          15,
          37
        ],
        "images": []
      },
      "5": {
        "title": "Easier Annotation",
        "text": [
          "UCCA ~6k sentences 4 Trained Annotators",
          "Semantic Proto-roles ~7k sentences MTurk [Reisinger et al. 2015]",
          "Groningen Meaning Bank ~40k sentences [Basile et al. 2012]",
          "QASRL 1.0 ~3k sentences Trained annotators [He et al. 2015]",
          "QA-SRL 2.0 75k sentences MTurk"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "6": {
        "title": "Annotation Pipeline",
        "text": [
          "x John surreptitiously ate the burrito at 2am",
          "Predicate detection Identify verbs with POS + heuristics",
          "One worker writes as many QA-SRL questions as possible, and provides the answer",
          "Validation 2 workers are shows questions, provide answers or mark as invalid"
        ],
        "page_nums": [
          24,
          25,
          26,
          77,
          78
        ],
        "images": []
      },
      "7": {
        "title": "Question Annotation",
        "text": [],
        "page_nums": [
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "8": {
        "title": "Validation Interface",
        "text": [],
        "page_nums": [
          31
        ],
        "images": []
      },
      "9": {
        "title": "Dataset",
        "text": [
          "1 annotator provides questions",
          "2 annotators validate -> 3 spans / question",
          "Question invalid if any annotator marks invalid",
          "Additional 3 validators for small dense dev and test set",
          "3000 sentences 75k sentences",
          "Several weeks 9 days",
          "2.43 questions / verb questions / verb"
        ],
        "page_nums": [
          32,
          33
        ],
        "images": [
          "figure/image/1037-Table2-1.png"
        ]
      },
      "10": {
        "title": "QA SRL Parser",
        "text": [],
        "page_nums": [
          38,
          39,
          40
        ],
        "images": []
      },
      "11": {
        "title": "QA SRL Parsing",
        "text": [
          "Argument detection John surreptitiously the burrito at 2pm",
          "Local Question generation Sequential Who ate something? How did someone eat something? What did someone eat? When did someone eat something?",
          "Span-based Model John surreptitiously the burrito at 2pm"
        ],
        "page_nums": [
          41,
          42,
          43,
          44,
          45,
          46,
          47
        ],
        "images": []
      },
      "12": {
        "title": "Argument Detection BIO Model",
        "text": [
          "Alternating Bi-LSTM with Highway Connections and Recurrent Dropout [He et al 2017]",
          "Input includes predicate indicator",
          "John surreptitiously ate the burrito at 2pm",
          "B B O B I B I",
          "John surreptitiously the burrito at 2pm"
        ],
        "page_nums": [
          48,
          49,
          50
        ],
        "images": []
      },
      "13": {
        "title": "Argument Detection Span Model",
        "text": [
          "Form a representation of every possible span",
          "John surreptitiously ate the burrito at 2pm",
          "John John surreptitiously surreptitiously ate the the burrito the burrito at at 2pm"
        ],
        "page_nums": [
          51,
          52,
          53,
          54,
          55,
          56
        ],
        "images": []
      },
      "14": {
        "title": "Argument Detection",
        "text": [
          "4 layer Alternating Bi-LSTM with Highway Connections and",
          "Recurrent Dropout [He et al 2017]",
          "Trained to maximize log-likelihood"
        ],
        "page_nums": [
          57,
          58
        ],
        "images": []
      },
      "15": {
        "title": "Question Generation",
        "text": [
          "Wh Aux Subj Verb Obj Prep Obj2",
          "How did didnt might will someone something stem someone past something past participle present on to by from someone something",
          "4 layer Alternating Bi-LSTM with Highway Connections and",
          "Recurrent Dropout [He et al 2017]",
          "Trained to maximize log-likelihood",
          "Slot Accuracy Exact Match"
        ],
        "page_nums": [
          59,
          60,
          68,
          71
        ],
        "images": []
      },
      "16": {
        "title": "Question Generation Local",
        "text": [
          "John surreptitiously the burrito at 2pm",
          "John surreptitiously ate the burrito at 2pm",
          "Wh Aux Subj Verb Obj1 Prep Obj2",
          "What did someone past-tense"
        ],
        "page_nums": [
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "17": {
        "title": "Question Generation Sequential",
        "text": [
          "Wh Aux Subj Verb Obj1 Prep Obj2",
          "What did someone past-tense"
        ],
        "page_nums": [
          65,
          66,
          67
        ],
        "images": []
      },
      "18": {
        "title": "Evaluation Questions",
        "text": [
          "Who ate something? Who eaten was something by?",
          "Exact Match (full question)"
        ],
        "page_nums": [
          69,
          70
        ],
        "images": []
      },
      "19": {
        "title": "Full Parsing Accuracy",
        "text": [
          "Exact match f-score (Span & Question)"
        ],
        "page_nums": [
          72
        ],
        "images": []
      },
      "20": {
        "title": "Large scale QA SRL Parsing",
        "text": [
          "1. Scale up QA-SRL data annotation",
          "2. Train a QA-SRL Parser"
        ],
        "page_nums": [
          73
        ],
        "images": []
      },
      "21": {
        "title": "Data Expansion",
        "text": [
          "Overgenerate questions with low span threshold",
          "Span Detection (F-score) Question Generation (Exact Match) Full Parsing (Exact Match)"
        ],
        "page_nums": [
          79,
          80
        ],
        "images": []
      },
      "22": {
        "title": "Evaluation",
        "text": [
          "Exact Match for Question Generation is overly harsh",
          "Who ate something? Who eaten was something by?",
          "Penalizes correct predictions missing from data"
        ],
        "page_nums": [
          81
        ],
        "images": []
      },
      "23": {
        "title": "Human Evaluation",
        "text": [
          "Validate model predictions with 6 annotators",
          "Generated Question valid if 5 out of 6 annotators provided answers",
          "Predicted span correct if exactly matches any annotators answer"
        ],
        "page_nums": [
          82
        ],
        "images": []
      },
      "24": {
        "title": "Human Eval Questions",
        "text": [],
        "page_nums": [
          83,
          84
        ],
        "images": []
      },
      "25": {
        "title": "Human Eval Arguments",
        "text": [],
        "page_nums": [
          85
        ],
        "images": []
      },
      "26": {
        "title": "Example Output",
        "text": [
          "Some of the vegetarians he met were members of the Theosophical Society, which had been founded in 1875 to further universal brotherhood, and which was devoted to the study of Buddhist and Hindu literature.",
          "Who met someone? Some of the vegetarians met Who met? he",
          "What did someone meet? members of the Theosophical Society members of the Theosophical Society What had been founded? the Theosophical Society founded When was something founded? in 1875",
          "Why has something been founded? to further universal brotherhood",
          "What was devoted to something? members of the Theosophical Society devoted What was something devoted to? the study of Buddhist and Hindu literature"
        ],
        "page_nums": [
          86
        ],
        "images": []
      },
      "27": {
        "title": "Conclusion",
        "text": [
          "Large crowdsourced dataset of QA-SRL annotations",
          "High quality QA-SRL Parser",
          "Techniques for data expansion"
        ],
        "page_nums": [
          87
        ],
        "images": []
      }
    },
    "paper_title": "Large-Scale QA-SRL Parsing"
  },
  "1038": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Well describe the Linear A/Minoan digital corpus and the approaches we applied to develop it",
          "Why we should develop a Linear A Corpus and the reasons for which we chose XML-TEI EpiDoc",
          "Available resources and developing process",
          "The Linear A Corpus as Cultural Heritage",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Linear A and Minoan",
        "text": [
          "The Linear A script was used by the Minoan Civilization (Crete, 2500",
          "1450 BC) and it still remains undeciphered",
          "Many symbols are shared by both Linear A and Linear B and are assumed to have phonetic values. The others are probably logograms:",
          "Linear A/B Linear A symbols value syllable logogram",
          "Linear B has been deciphered (during the 50s) and found to be used to write an Ancient Greek dialect, so many scholars are trying to decipher Linear A too",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Lack in digital resources",
        "text": [
          "After decades no deciphering attempts have been successful",
          "No heavy computational approaches have been attempted",
          "Only John G. Younger, in his website, provides a complete digital collection",
          "Nevertheless, it is stored in two simple HTML pages with not strict structure and transcribed as transliterations",
          "A new digital corpus in a suitable format and well organized may be a useful resource",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Available resources",
        "text": [
          "(about 2 A4 pages of text at 11pt)",
          "GORILA paper collection of inscriptions and transcriptions",
          "John G. Youngers website",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Gorila",
        "text": [
          "a catalog of symbols/numeric codes documents indexes with information about original place and type of support (these indexes were defined in the first place by Pope&Raison) indexed documents descriptions including pictures, drawings and handmade transcriptions",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "John G Youngers website",
        "text": [
          "two HTML pages, one for Haghia Triadas documents, one for all the other places of origin",
          "1,077 transcriptions, with Linear B phonetics and GORILA code numbers (75.5% of the total amount of existing documents listed in",
          "GORILA) a conversion table: GORILA code numbers to syllables",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "From Youngers syllables to Unicode",
        "text": [
          "The Unicode set of characters for Linear A was released in June 2014",
          "The 1,077 documents represented on Youngers website have been automatically converted",
          "from the syllable transcription (coexisting alongside GORILA code numbers for symbols not included in Linear B) to the full GORILA code numbers transcription from GORILA code numbers to Unicode",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1038-Table4-1.png"
        ]
      },
      "7": {
        "title": "Segmentation issues",
        "text": [
          "Separation is mainly indicated in two ways:",
          "by isolating sign groups with numbers or logograms, thereby implying a separation dots between sign groups, always used if there are long sign groups strings",
          "Example: This is a Linear A line:",
          "is a number (it is assumed to be a number 5) so and are assumed to be separated sign groups",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Corpus data format",
        "text": [
          "XML provides important advantages metadata on several levels of annotation elements and entities for unsupported glyphs or symbols",
          "EpiDoc is a TEI DTD with customization for Epigraphy",
          "TEI-using community can provide support a wide range of best-practice examples are available online",
          "The old Leiden system annotation task, familiar to epigraphers, is quite similar to the XML TEI EpiDoc annotation process",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Corpus data format example",
        "text": [
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Unsupported glyphs handling",
        "text": [
          "Inside the EncodingDesc>CharDecl elements, glyph elements can be defined",
          "g elements referring to glyphs can be used to represent unsupported",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Corpus size",
        "text": [
          "GORILA: 1,427 Linear A documents",
          "John G. Youngers website: 1,077 Linear A transcriptions (75.5% of the total)",
          "Our corpus will contain up to 1,077 Linear A XML TEI EpiDoc documents",
          "The Unicode conversions of John G. Youngers transcriptions have been converted in XML in an automatic way but the tagging has been only partially carried out",
          "The main remaing work (still in progress) is manually checking the data with the GORILA volumes",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "John Younger ttf",
        "text": [
          "Before the release of Unicode 7.0, there was no way to visualize",
          "The traditional Linear A font, LA.ttf, included wrong Unicode positions",
          "We developed a new Linear A font, named after John Younger to show our appreciation for his work: John_Younger.ttf (available at",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "From Linear A to Minoan culture",
        "text": [
          "The Linear A corpus is an important cultural monument, storing information about tradition, knowledge and lifestyle of Minoan people",
          "Even without a full understanding of transcriptions some cultural features can be inferred",
          "Economics and commerce: as some ideograms for basic commodities are similar to their Linear B counterparts, we can compare types and amounts of commodities",
          "Religion: there are around thirty libation formulas transcribed on various supports",
          "Petrolito, Winterstein, Perono Cacciafoco Linear A Corpus 30 July 2015"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Minoan linguistic resources: The Linear A Digital Corpus"
  },
  "1040": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Chinese spelling checkers are difficult",
          "No word delimiters exist among Chinese words",
          "A Chinese word can contain only",
          "character or mulGple characters",
          "More than 13 thousand characters",
          "The spelling checker is expected to idenGfy all possible spelling errors, highlight their locaGons and suggest possible correcGons",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Chinese Spelling Check Evaluations",
        "text": [
          "The 1st Chinese Spelling Check Bake-off",
          "SIGHAN-2013 workshop @ Nagoya, Japan",
          "Chinese as a foreign language learners",
          "CIPS-SIGHAN joint CLP-2014 conference @ Wuhan",
          "SIGHAN-2015 workshop @ Beijing, China",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Task Description",
        "text": [
          "The input instance is given a unique passage number PID",
          "Each character or punctuaGon mark occupies 1 spot for counGng locaGon",
          "If the passage contains no spelling errors, the checker should return PID, 0",
          "If an input passage contains at least one spelling error, the output format is PID, [, locaGon, correcGon]+",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Testing Examples",
        "text": [
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Data Preparation",
        "text": [
          "The essay secGon of the computer-based Test of Chinese as a Foreign Language (TOCFL)",
          "The spelling errors were manually annotated by trained naGve Chinese speakers, who also provided correcGons corresponding to each error.",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Training Set",
        "text": [
          "This set included selected essays with a total of spelling errors.",
          "Each essay is shown in terms of format",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1040-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Dryrun Set",
        "text": [
          "A total of 39 passages were given to parGcipants to familiarize themselves with the f inal tesGng process.",
          "The purpose is to validate the submiked output format only, and no dryrun outcomes were considered in the official evaluaGon",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Test Set",
        "text": [
          "This set consists of 1,100 tesGng passages. Half of these passages contained no spelling errors, while the other half included at least one spelling error",
          "Open test policy: employing any linguisGc and computaGonal resources to detect and correct spelling errors are allowed.",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Performance Metrics",
        "text": [
          "Correctness is determined at two levels",
          "False posiGve rate (FPR) = FP / (FP+TP)",
          "Precision = TP / (TP+FP)",
          "F1 = 2 * Precision * Recall / (Precision+Recall)",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1040-Table1-1.png"
        ]
      },
      "9": {
        "title": "Evaluation Examples",
        "text": [
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "9 Participants and 15 Runs",
        "text": [
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1040-Table2-1.png"
        ]
      },
      "11": {
        "title": "Testing Results",
        "text": [
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "A Summary of Developed Systems",
        "text": [
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1040-Table4-1.png"
        ]
      },
      "13": {
        "title": "Conclusions and Future Work",
        "text": [
          "All submissions contribute to the knowledge in search for an effecGve Chinese spell checkers",
          "The individual reports in the Bake-off proceedings provide useful insight into Chinese language processing",
          "The future direcGon focuses on the development of Chinese grammaGcal error correcGon",
          "SIGHAN 2015 @ Beijing, China"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Introduction to SIGHAN 2015 Bake-off for Chinese Spelling Check"
  },
  "1041": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Language exhibits hierarchical structure",
          "[[The cat [that he adopted]] [sleeps]]",
          "but LSTMs work so well without explicit notions of structure.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Number Agreement",
        "text": [
          "Num ber agreement example with",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/1041-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Number Agreement is Sensitive to Syntactic Structure",
        "text": [
          "Number agreement reflects the dependency relation between subjects and verbs",
          "Models that can capture headedness should do better at number agreement",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Number Agreement Dataset Overview",
        "text": [
          "Number agreement dataset is derived from dependency-parsed",
          "All intervening nouns must be of the same number n=2",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)",
          "The vast majority of number agreement dependencies are sequential"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": [
          "figure/image/1041-Figure1-1.png"
        ]
      },
      "4": {
        "title": "First Part Can LSTMs Learn Number Agreement Well",
        "text": [
          "The model is trained with language modelling objectives",
          "Revisit the same question as Linzen et al. (2016):",
          "To what extent are LSTMs able to learn non-local syntax-sensitive dependencies in natural language?",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1041-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Linzen et al LSTM Number Agreement Error Rates",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Small LSTM Number Agreement Error Rates",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Larger LSTM Number Agreement Error Rates",
        "text": [
          "Capacity matters for capturing non-local structural dependencies",
          "Despite this, relatively minor perplexity",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "LSTM Number Agreement Error Rates",
        "text": [
          "Capacity and size of training corpus are not the full story",
          "Domain and training settings matter too",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Can Character LSTMs Learn Number Agreement Well",
        "text": [
          "Character LSTMs have been used in various tasks, including machine translation, language modelling, and many others.",
          "It is easier to exploit morphological cues.",
          "Model has to resolve dependencies between sequences of tokens.",
          "The sequential dependencies are much longer.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Character LSTM Agreement Error Rates",
        "text": [
          "model on Hutter Prize, with 27M parameters.",
          "Trained, validated, and tested on the same data.",
          "Strong character LSTM model performs much worse for multiple attractor cases",
          "Consistent with earlier work",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "First Part Quick Recap",
        "text": [
          "LSTM language models are able to learn number agreement to a much larger extent than suggested by earlier work.",
          "Independently confirmed by Gulordava et al. (2018).",
          "We further identify model capacity as one of the reasons for the discrepancy.",
          "Model tuning is important.",
          "A strong character LSTM language model performs much worse for number agreement with multiple attractors.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Two Ways of Modelling Sentences",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Three Concrete Alternatives for Modeling Sentences",
        "text": [
          "Sequential LSTMs without Syntax",
          "Sequential LSTMs with Syntax (Choe and Charniak, 2016)",
          "RNNG (Dyer et al., 2016) Hier archical inductive bias",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Evidence of Headedness in the Composition Function",
        "text": [
          "Kuncoro et al. (2017) found evidence of syntactic headedness in RNNGs",
          "The discovery of syntactic heads would be useful for number agreement",
          "Inspection of composed representation through the attention weights",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "15": {
        "title": "Experimental Settings",
        "text": [
          "All models are trained, validated, and tested on the same dataset.",
          "On the training split, the syntactic models are trained using predicted phrase-structure trees from the Stanford parser.",
          "At test time, we run the incremental beam search (Stern et al., 2017) procedure up to the main verb for both verb forms, and take the highest-scoring tree.",
          "The most probable tree might potentially be different for the correct/incorrect verbs",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "16": {
        "title": "Experimental Findings",
        "text": [
          "error rate reductions for n=4 and",
          "Performance differences are significant (p <",
          "Lo wer is better",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "17": {
        "title": "Perplexity",
        "text": [
          "RNNGs LSTM LM has the best perplexity",
          "despite worse number agreement performance",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "18": {
        "title": "Further Remarks Confound in the Dataset",
        "text": [
          "LSTM language models largely succeed in number agreement",
          "In around of cases with multiple attractors, the agreement controller coincides with the first noun.",
          "Key question: How do LSTMs succeed in this task?",
          "Identifying the syntactic structure Memorising the first noun",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1041-Figure1-1.png"
        ]
      },
      "19": {
        "title": "Control Condition Experiments for LSTM LM",
        "text": [
          "Con trol condition breaks the corre lation between the first noun and agreement controller",
          "Confounded by first nouns",
          "Much less likely to affect human experiments",
          "LSTMs Ca n Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "20": {
        "title": "Control Condition Experiments for RNNG",
        "text": [
          "Control for cues that artificial learners can exploit in a cognitive task.",
          "Adversarial evaluation can better distinguish between models with correct generalisation and those that overfit to surface cues.",
          "Same y-axis scale as LSTM LM",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "21": {
        "title": "Related Work",
        "text": [
          "Augmenting our models with a hierarchical inductive bias is not the only way to achieve better number agreement.",
          "Another alternative is to make relevant past information more salient, such as through memory architectures or attention mechanism.",
          "Yogatama et al. (2018) found that both attention mechanism and memory architectures outperform standard LSTMs.",
          "They found that a model with a stack-structured memory performs best, also demonstrating that a hierarchical, nested inductive bias is important for capturing syntactic dependencies.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "22": {
        "title": "Second Part Quick Recap",
        "text": [
          "RNNGs considerably outperform LSTM language model and sequential syntactic LSTM for number agreement with multiple attractors.",
          "Syntactic annotation alone has little impact on number agreement accuracy.",
          "RNNGs success is due to the hierarchical inductive bias.",
          "The RNNGs performance is a new state of the art on this dataset",
          "Perplexity is only loosely correlated with number agreement.",
          "Independently confirm the finding of Tran et al. (2018).",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "23": {
        "title": "Different Tree Traversals",
        "text": [
          "RNNGs operate according to a top-down, left-to-right traversal",
          "Here we propose two alternative tree construction orders for RNNGs: left-corner and bottom-up traversals.",
          "x: the flowers in the vase are/is [blooming]",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "24": {
        "title": "Quick Illustration of the Differences Top Down",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "25": {
        "title": "Quick Illustration of the Differences Left Corner",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "26": {
        "title": "Quick Illustration of the Differences Bottom Up",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          35,
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "27": {
        "title": "Why Does The Build Order Matter",
        "text": [
          "The three different strategies yield different intermediate states during the generation process and impose different biases on the learner.",
          "Earlier work in parsing has characterised the strategies plausibility in",
          "Resnik, 1992). We evaluate these strategies as models of generation",
          "(Manning and Carpenter, 1997) in terms of number agreement accuracy.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "28": {
        "title": "Bottom up Traversal",
        "text": [
          "x, y: (S (NP the hungry cat) (VP meows))",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          41
        ],
        "images": []
      },
      "29": {
        "title": "Bottom Up Traversal",
        "text": [
          "x, y: (S (NP the hungry cat) (VP meows))",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)",
          "Action: REDUCE-1-VP Topmost stack element"
        ],
        "page_nums": [
          42,
          43,
          44
        ],
        "images": []
      },
      "30": {
        "title": "Bottom Up Traversal After REDUCE 1 VP",
        "text": [
          "x, y: (S (NP the hungry cat) (VP meows))",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "31": {
        "title": "Bottom Up Parameterisation of Constituent Extent",
        "text": [
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          46
        ],
        "images": [
          "figure/image/1041-Figure5-1.png"
        ]
      },
      "32": {
        "title": "Summary Statistics",
        "text": [
          "Near-identical perplexity for each variant",
          "Bottom-up has the shortest stack depth",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          47
        ],
        "images": []
      },
      "33": {
        "title": "Different Traversal Number Agreement Error Rates",
        "text": [
          "Top-down performs best for n=3 and n=4",
          "Bottom-Up For n=4 this is",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "34": {
        "title": "Part Three Recap and Outlook",
        "text": [
          "We proposed two new RNNG variants with different tree construction orders: left-corner and bottom-up RNNGs.",
          "Top-down construction still performs best in number agreement.",
          "It is the most anticipatory (Marslen-Wilson, 1973; Tanenhaus et al.,",
          "We can apply the three strategies to parsing and as linking hypothesis to human brain signal during comprehension (Hale et al., 2018).",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "35": {
        "title": "Conclusion",
        "text": [
          "LSTM language models with enough capacity can learn number agreement well, while a strong character LSTM performs much worse.",
          "Explicitly modelling the syntactic structure with RNNGs that have a hierarchical inductive bias leads to much better number agreement.",
          "Syntactic annotation alone does not help if the model is still sequential.",
          "Top-down construction order outperforms left-corner and bottom-up variants in difficult number agreement cases.",
          "Perplexity does not completely correlate with number agreement.",
          "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better - Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ],
        "page_nums": [
          50
        ],
        "images": []
      }
    },
    "paper_title": "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better"
  },
  "1043": {
    "slides": {
      "0": {
        "title": "Multiple word alignment",
        "text": [
          "Given multiple words, align them all to each other",
          "Our approach: Profile HMMs, used in biological sequence analysis",
          "Use match, insert, and delete states to model changes",
          "Evaluate on cognate set matching",
          "Beat baselines of average and minimum edit distance"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "What you can expect",
        "text": [
          "Profile hidden Markov models",
          "Conclusions & future work"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Introduction",
        "text": [
          "Take a set of words",
          "Generate some alignment of these words",
          "Similar and equivalent characters should be aligned together",
          "Pairwise alignment gets us:",
          "String similarity and word distances",
          "Extending to multiple words gets us:",
          "String similarity with multiple words",
          "We propose Profile HMMs for multiple alignment",
          "Test on cognate set matching"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Profile hidden Markov models",
        "text": [
          "Match states are defaults",
          "Insert states are used to represent insert symbols",
          "Delete states are used to represent the absence of symbols",
          "In this sample DNA alignment, dashes represent deletes and periods represent skipped inserts",
          "To construct a Profile HMM from unaligned sequences:",
          "Determine which columns are match columns and which are insert columns, then estimate transition and emission probabilities directly from counts",
          "Choose a model length, initialize the model, then train it to the sequences using Baum-Welch",
          "Evaluating a sequence for membership in a family",
          "Use the forward algorithm to get the probability",
          "Use Viterbi to align the sequences",
          "Multiple alignment of unaligned sequences",
          "Construct & train a Profile HMM",
          "Profile HMMs are generalizations of Pair HMMs",
          "Word similarity and cognate identification",
          "Unlike Pair HMMs, Profile HMMs are position- specific",
          "Each model is constructed from a specific family of sequences",
          "Pair HMMs are trained over many pairs of words"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "images": [
          "figure/image/1043-Figure1-1.png",
          "figure/image/1043-Figure2-1.png"
        ]
      },
      "4": {
        "title": "Profile HMMs for words",
        "text": [
          "Words are also sequences!",
          "Similar to their use for biological sequences, we apply Profile HMMs to multiple word alignment",
          "We also test Profile HMMs on matching words to cognate sets",
          "We made our own implementation and investigated several parameters"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "5": {
        "title": "Profile HMMs parameters",
        "text": [
          "Constant-value, background frequency, substitution matrix",
          "Pseudocounts added during Baum-Welch"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "6": {
        "title": "Experiments Data",
        "text": [
          "Comparative Indoeuropean Data Corpus",
          "Cognation data for words in 95 languages corresponding to 200 meanings",
          "Each meaning reorganized into disjoint cognate sets"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "7": {
        "title": "Experiments Multiple cognate alignment",
        "text": [
          "Parameters determined from cognate set matching experiments (later)",
          "Pseudocount weight set to 100 to bias the model using a substitution matrix",
          "Highly-conserved columns are aligned correctly",
          "Similar-sounding characters are aligned also correctly, thanks to the substitution matrix method",
          "Insert columns should not be considered aligned",
          "Problems with multi-character phonemes",
          "An expected problem when using the English alphabet instead of e.g. IPA"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "8": {
        "title": "Experiments Cognate set matching",
        "text": [
          "How can we evaluate the alignments in a principled way? There is no gold standard!",
          "We emulate the biological sequence analysis task of matching a sequence to a family; we match a word to a cognate set",
          "The task is to correctly identify the cognate set to which a word belongs given a number of cognate sets having the same meaning as the word; we choose the model yielding the highest score",
          "Development set of 10 meanings (~5% of the data)",
          "Substitution matrix derived from Pair HMM method",
          "Use substitution matrix pseudocount",
          "Use 0.5 for pseudocount weight",
          "Add pseudocounts during Baum-Welch",
          "Average Edit Distance Minimum Edit Distance Profile HMM",
          "Accuracy better than both average and minimum edit distance",
          "Why so close to MED?",
          "Many sets had duplicate words (same orthographic representation for different languages)"
        ],
        "page_nums": [
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "9": {
        "title": "Conclusions",
        "text": [
          "Profile HMMs can work for word-related tasks",
          "Multiple alignments are reasonable",
          "Cognate set matching performance exceeds minimum and average edit distance",
          "If multiple words need to be considered, Profile",
          "HMMs present a viable method"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "10": {
        "title": "Future work",
        "text": [
          "Better model construction from aligned sequences",
          "Better initial models for unaligned sequences"
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "for Computational Linguistics Multiple Word Alignment with Profile Hidden Markov Models"
  },
  "1044": {
    "slides": {
      "0": {
        "title": "Math Word Problem",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "$10. How many notebooks can h e buy after buying pens?",
          "Reasonin g & Solving"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Prior Work",
        "text": [
          "Non-neural approaches Deep learning",
          "M I U L A B",
          "(Kushman et al., Upadhyay and Chang) (W ang et al., Ling et al.)",
          "Rely on hand-crafted features! Do es not use the structure of math expression.",
          "Our model is end-to-end and structural!"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Overview of the Proposed Model",
        "text": [
          "M I U L A B",
          "stack action stack action stack action stack action",
          "Each notebook takes $0.5 and each pen takes $1. Decoder",
          "Tom has $10. How many notebooks can he buy after buying 5 pens?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Look Again at the Problem",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "$10. How many notebooks can h e buy after buying pens?"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Semantic Meaning of the Operands",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "M I U L A B",
          "$10. How many notebooks can h e buy after buying pens?",
          "The amount of money Tom has Price of a notebook",
          "Price of a pen Number of pens bought"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Symbolic World Semantic World",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Preprocess",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "$10. How many notebooks can h e buy after buying pens?"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Symbol Encoding",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "M I U L A B",
          "How many notebooks can h e buy after buying pens?",
          "Symbolic Part Semantic Part"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Inside Encoder",
        "text": [
          "Each notebook takes and"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Semantic Generation for Unknown",
        "text": [
          "M I U L A B",
          "Each notebook takes and",
          "* This part is actually done when decoding, but is present at this place for illustration. Check our paper for more information."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Operands and Their Semantics",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "$10. How many notebooks can h e buy after buying pens?",
          "Symbolic Part x Semantic Part"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Intuition of Using Semantics",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "M I U L A B",
          "How many notebooks can h e buy after buying pens?",
          "Number of pens bough t.",
          "Price of a pen."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Equation Generation in Postfix",
        "text": [
          "Each notebook takes $0.5 and each pen takes $1. Tom has",
          "$10. How many notebooks can h e buy after buying pens?"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1044-Figure4-1.png"
        ]
      },
      "13": {
        "title": "Equation Generation by Stack Actions",
        "text": [
          "M I U L A B",
          "The decoder generates stack actions.",
          "An equation is generated",
          "stack action stack action stack action stack action",
          "with actions on stack.",
          "GGeGenen enraerat rated ted Ad AcActictoitonions n:s s:x :x 1x Generated Acti ons: x",
          "GeneraGt Ged en nAerarc ateitoed d nAsA:c cx titoi1on0 nss:1 :x x Generated Acti ons: x"
        ],
        "page_nums": [
          14,
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "14": {
        "title": "Action Selection in Each Step",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "15": {
        "title": "Training Process",
        "text": [
          "Target equation is given.",
          "M I U L A B",
          "Each notebook takes $0.5 and each pen takes $1. Tom has $10. How many notebooks can he buy after buying 5 pens? <bos> x"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "17": {
        "title": "Results",
        "text": [
          "Acc. Retrieval Template Generation Ensemble",
          "Retrieval BLSTM Self-Attention Seq2Seq w/SNI Proposed Hybrid"
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1044-Figure4-1.png"
        ]
      },
      "18": {
        "title": "Ablation Test",
        "text": [
          "Char-Based Word-Based Word-Based Word-Based"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "19": {
        "title": "Self Attention for Qualitative Analysis",
        "text": [
          "Each notebook takes and"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "20": {
        "title": "Attention for Operand Semantics",
        "text": [
          "The attention focuses on:",
          "o gain, get, fill, etc.",
          "o every, how many, etc."
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "21": {
        "title": "Conclusion",
        "text": [
          "M I U L A B",
          "Approach: equation generatio n with stack",
          "Originality: automatic extracti on of operand semantics",
          "Performance: a SOTA end-to-e nd neural model on Math23k"
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems"
  },
  "1045": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "What action causes this?",
          "What is the result state of open box?"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": [
          "figure/image/1045-Figure1-1.png"
        ]
      },
      "1": {
        "title": "Understanding Cause Effect",
        "text": [
          "From: cde.ca.gov. (California Department of Education)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Naive Physical Action Effect Prediction",
        "text": [
          "(peel-carrot) x Action x"
        ],
        "page_nums": [
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Most existing studies focus on the causal relations between high-level events.",
          "E.g., the collapse of the housing bubble causes the effect of stock prices to",
          "This paper studies the basic cause-effect knowledge related to concrete actions and their effects to the world.",
          "Recent advances in Computer Vision and Robotics",
          "Object physical state prediction (Zhou and Berg, 2016; Wu et al., 2017)",
          "Action recognition through detection of state changes (Yang et al., 2013)",
          "Robot following natural language commands (She et al, 2014; Misra et al., 2015)"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "This Work",
        "text": [
          "Introduce a new task on physical action-effect prediction and create a dataset for this task.",
          "Data collection and analysis",
          "Propose an approach that harnesses the large amount of image data available on the web with minimum supervision.",
          "Automatic prediction of effect knowledge for novel actions."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Action Effect Data",
        "text": [
          "62 unique verbs (e.g., bend, boil, chop, crack, fold, grind, ignite, kick, peel, soak, trim)",
          "39 unique nouns (e.g., apple, baseball, book, car, chair, cup, flower, orange, shoe)",
          "Effects described in language",
          "Effects depicted by images"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Effects Described in Language",
        "text": [
          "Action effect is often presupposed in our communication and not explicitly stated.",
          "Workers were shown a verb-noun pair, and were asked to describe what changes might occur to the object as a result of the action.",
          "1400 effect descriptions (10 for each verb-noun pair)"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1045-Table1-1.png"
        ]
      },
      "7": {
        "title": "Effects Depicted by Images",
        "text": [
          "Human labeled image set: 4163 images",
          "(Data available on the project webpage.)",
          "Positive images are those capturing the resulting world state of the action.",
          "Negative images are those deemed to capture some state of the related nouns, but are not the resulting state of the corresponding action."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Web Search Images",
        "text": [
          "Searching keywords: phrases extracted from language effect descriptions",
          "Phrases were extracted using syntactic patterns:",
          "book\u0001 book is on fire\u0001 book is set aflame\u0001"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1045-Table2-1.png",
          "figure/image/1045-Figure3-1.png"
        ]
      },
      "9": {
        "title": "Bootstrapping Approach",
        "text": [
          "Web Search Images Prediction",
          "Bootstrapping cross-entropy loss: (Reed et al., 2014)"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1045-Figure4-1.png"
        ]
      },
      "10": {
        "title": "Evaluations",
        "text": [
          "Human annotated image data: use 10% as seeding images (training), 30% for development and 60% for test.",
          "On average, each verb-noun pair only has 3 seeding images",
          "Web search images: over 60,000 images were downloaded using around 2,000 effect phrases as searching keywords.",
          "BS: bootstrapping approach; Seed: seed images;",
          "Act: web images downloaded using verb-noun as keywords;",
          "Eff: web images downloaded using effect phrases as keywords."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation Results",
        "text": [
          "MAP Top 5 Accuracy",
          "Micro F1 Score Macro F1 Score",
          "pEff: web images downloaded using the predicted effect phrases."
        ],
        "page_nums": [
          16,
          23
        ],
        "images": []
      },
      "12": {
        "title": "Examples",
        "text": [
          "Predictions bite apple background cut apple peel apple fry egg background crack egg mix eggs",
          "background chop carrot grate carrot peel carrot background insert key close drawer fasten door",
          "background cut potato fry potato mash potato pile books background wrap book roll paper",
          "Predictions bite apple background cut apple peel apple apple is eaten apple is being cut apple is chewed apple in tiny pieces fry egg background crack egg mix eggs egg into a harder substance cup into smaller pieces egg edible",
          "background chop carrot grate carrot peel carrot carrot into tiny pieces carrot is being cut carrot into many smaller pieces background insert key close drawer fasten door key in the keyhole drawer without a key door is locked door is being bolted",
          "background cut potato fry potato mash potato potato into a pot potato is being sliced potato for potato edible pile books background wrap book roll paper books in a stack book on books in a large stack books in a pile",
          "beat eggs pile boxes bite apple slice onion",
          "Action AP shirt stain shirt crack glass lock drawer stain shirt window close window close window"
        ],
        "page_nums": [
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "13": {
        "title": "Handling Unseen Verb Noun Pairs",
        "text": [
          "Generalize effect knowledge to new verb-noun pairs through an embedding model.",
          "Action-Effect Embedding trained from seed knowledge",
          "A New Action Effect phrases",
          "(ignite-paper) paper is being charred, paper is being burned, paper is set, paper is being destroyed, paper is lit",
          "Web Search Images Prediction ResNet Action 1 Action 2 Action C Bootstrapping Cross-Entropy Loss",
          "Action 1 Action 2 Action C Cross-Entropy Loss"
        ],
        "page_nums": [
          21,
          22
        ],
        "images": [
          "figure/image/1045-Figure4-1.png",
          "figure/image/1045-Figure6-1.png"
        ]
      },
      "14": {
        "title": "Action Effect Embedding Space",
        "text": [
          "GloVe Verb GloVe Verb + Noun Action-Effect",
          "coil bind lock lock fasten trim coil g rate lock bend bend fasten grind crack trim crack crack grind twist break bend twist break tear tear knot knot knot trim bindcoil",
          "grind twist bend twist knot knot knot bindcoil",
          "twist break fasten grate grind grate",
          "crop twist break crop fasten grate grind grate"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "15": {
        "title": "Learning from a few examples",
        "text": [
          "Goal: learn from a few examples to make it possible for humans to teach agents for",
          "(the potatoes are brown and crispy) Harness web",
          "symbolic representation of action and effect (verb, noun) (Effect phrases) (ve(rvbe +rb a,r gnuomune) nt) (ve(rvbe +rb a,r gnuomune) nt) (Ef(fEefcfet ccta ptehgroarsieess) ) (veArbc t+i oarn gument) (Ef(fEefcfet Effect ccta ptehgroarsieess) ) (Effect categories) (verbnoun) (categories, descriptions, phrases, predicate calculus)",
          "seed physical causality knowledge of action verbs Incremental acquisition and update Web 2-4 annotated images physical action and effect states Positive examples Negative examples Seed Knowledge"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "16": {
        "title": "Action Effect Prediction in Interactive Task Learning",
        "text": [],
        "page_nums": [
          31,
          32
        ],
        "images": []
      },
      "17": {
        "title": "Summary",
        "text": [
          "Presented an initial investigation on action-effect prediction.",
          "Explored method using web image data to facilitate the training of action-effect prediction models.",
          "Explored using semantic embedding space to extend effect knowledge to new verb-noun pairs.",
          "Develop better models to improve task performance",
          "Extend action-effect prediction to video data"
        ],
        "page_nums": [
          33
        ],
        "images": []
      }
    },
    "paper_title": "What Action Causes This? Towards Naive Physical Action-Effect Prediction"
  },
  "1046": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "o a form of verbal irony that is intended to express contempt or",
          "ridicule (The Free Dictionary)",
          "o commonly manifests on social communities (e.g. Twitter, Reddit)",
          "Prior work considered sarcasm to be a contrast between a positive and negative sentiment (Riloff et al., 2013)",
          "I love to be ignored!",
          "Perfect movie for people who cant fall asleep",
          "Scope of this work: sarcasm detection based on documents content and commonsense knowledge but not external knowledge, or users profile and context",
          "I love to solve math problem everyday",
          "Cool. It took me 10 hours to flight from Sydney to Melbourne."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "State-of-the-art sarcasm detection systems mainly rely on deep and sequential neural networks (Ghosh and Veale,",
          "o compositional encoders (GRU, LSTM) are often employed, with",
          "the input document being parsed one word at a time",
          "o no explicit interaction between word pairs hampers ability to",
          "explicitly model contrast, incongruity or juxtaposition of situations",
          "o difficult to capture long-range dependencies"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Proposed approach",
        "text": [
          "Our idea: modeling contrast in order to reason with sarcasm",
          "o either between positive-negative sentiments or between literal-",
          "o looking in-between: propose a multi-dimensional intra-attention",
          "recurrent network capture both word-word relationship and long-range dependency",
          "I absolutely love to be ignored!",
          "Perfect movie for people who cant fall asleep"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Architecture",
        "text": [],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1046-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1046-Table1-1.png"
        ]
      },
      "5": {
        "title": "Experimental results",
        "text": [],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": [
          "figure/image/1046-Table3-1.png",
          "figure/image/1046-Table4-1.png"
        ]
      },
      "6": {
        "title": "Visualization of attention weights",
        "text": [],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1046-Table5-1.png"
        ]
      },
      "7": {
        "title": "Conclusion",
        "text": [
          "We proposed a new neural network architecture for sarcasm detection",
          "o incorporates a multi-dimensional intra-attention component that",
          "learns an intra-attentive representation of the sentence",
          "o enabling it to detect contrastive sentiment, situations and",
          "outperforms strong state-of-the-art baselines such as",
          "GRNN and CNN-LSTM-DNN over six public benchmarks",
          "Able to learns highly interpretable attention weights paving the way for more explainable neural sarcasm detection methods."
        ],
        "page_nums": [
          10
        ],
        "images": []
      }
    },
    "paper_title": "Reasoning with Sarcasm by Reading In-between"
  },
  "1047": {
    "slides": {
      "0": {
        "title": "Contrastive Estimation",
        "text": [
          "Many Machine Learning models learn by trying to separate positive examples from negative examples.",
          "Positive Examples are taken from observed real data distribution",
          "Negative Examples are any other configurations that are not observed",
          "Data is in the form of tuples or triplets (x+, y+) and (x+, y) are positive and negative data points respectively."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Easy Negative Examples with NCE",
        "text": [
          "Noise Constrastive Estimation samples negatives by taking p(y|x+) to be some unconditional pnce(y). Whats wrong with this?",
          "Negative y in (x y) is not tailored toward x",
          "Difficult to choose hard negatives as training progresses",
          "Model doesnt learn discriminating features between positive and hard negative examples",
          "NCE negatives are easy !!!"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Hard Negative Examples",
        "text": [
          "Hard Negatives result to higher losses and thus more more informative gradients",
          "Not necessarily closest to a positive datapoint in embedding space"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Technical Contributions",
        "text": [
          "Adversarial Contrastive Estimation: A general technique for hard negative mining using a Conditional GAN like setup.",
          "A novel entropy regularizer that prevents generator mode collapse and has good empirical benefits",
          "A strategy for handling false negative examples that allows training to progress",
          "Empirical validation across 3 different embedding tasks with state of the art results on some metrics"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Adversarial Contrastive Estimation",
        "text": [
          "We want to generate negatives that ... fool a discriminative model into misclassifying.",
          "Use a Conditional GAN to sample hard negatives given x+. We can augment NCE with an adversarial sampler, pnce(y) + (1 )g(y |x)."
        ],
        "page_nums": [
          5,
          7
        ],
        "images": []
      },
      "5": {
        "title": "Conditional GAN",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "The ACE Generator",
        "text": [
          "Picking a negative example is a discrete choice and not differentiable",
          "Simplest way to train via Policy Gradients is the REINFORCE gradient estimator",
          "Learning is done via a GAN style min-max game"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Technical Contributions for effective training",
        "text": [
          "GAN training can suffer from mode collapse? What happens if the generator collapses on its favorite few negative examples?",
          "Add a entropy regularizer term to the generators loss:",
          "H(g(y |x)) is the entropy of the categorical distribution",
          "c = log(k) is the entropy of a uniform distribution over k choices",
          "The Generator can sample false negatives gradient cancellation",
          "Apply an additional two-step technique, whenever computationally feasible.",
          "Maintain an in memory hash map of the training data and",
          "Discriminator filters out false negatives",
          "Generator receives a penalty for producing the false negative",
          "Entropy Regularizer spreads out the probability mass",
          "REINFORCE is known to have extremely high variance.",
          "Reduce Variance using the self-critical baseline. Other baselines and gradient estimators are also good options.",
          "The generator is not learning from the NCE samples.",
          "Use Importance Sampling. Generator can leverage NCE samples for exploration in an off-policy scheme. The modified reward now looks like"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Related Work",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Contemporary Work",
        "text": [
          "GANs for NLP that are close to our work",
          "MaskGAN Fedus et. al 2018",
          "Incorporating GAN for Negative Sampling in Knowledge",
          "Representation Learning Wang et. al 2018",
          "KBGAN Cai and Wang 2017"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Example Knowledge Graph Embeddings",
        "text": [
          "Data in the form of triplets (head entity, relation, tail entity). For example",
          "{United states of America, partially contained by ocean, Pacific}",
          "Basic Idea: The embeddings for h, r t should roughly satisfy h r t",
          "Goal is to learn from observed positive entity relations and predict missing links."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "ACE for Knowledge Graph Embeddings",
        "text": [
          "Negative Triplet: Either negative head or tail is sampled i.e.",
          "ACE Generator: g(t |r+, h+) or g(h|r+, t+) parametrized by a feed forward neural net."
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      },
      "12": {
        "title": "Experimental Result Ablation Study",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "ACE for Order Embeddings",
        "text": [
          "Hypernym Prediction: A hypernym pair is a pair of concepts where the irst f concept is a specialization or an instance of the second.",
          "Learning embeddings that are hierarchy preserving. The Root Node is at the origin and all other embeddings lie on the positive semi-space",
          "Constraint enforces the magnitude of the parents embedding to be smaller than childs in every dimension",
          "Sibling nodes are not subjected to this constraint."
        ],
        "page_nums": [
          21,
          23
        ],
        "images": []
      },
      "14": {
        "title": "Order Embeddings Vendrov et al 2016",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "ACE for Word Embeddings WordSim353",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "16": {
        "title": "ACE for Word Embeddings Stanford Rare Word",
        "text": [],
        "page_nums": [
          25
        ],
        "images": []
      },
      "17": {
        "title": "Discriminator Loss on NCE vs Adversarial Examples",
        "text": [],
        "page_nums": [
          26
        ],
        "images": []
      },
      "18": {
        "title": "Nearest Neighbors for NCE vs ACE",
        "text": [],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1047-Table1-1.png"
        ]
      }
    },
    "paper_title": "Adversarial Contrastive Estimation"
  },
  "1048": {
    "slides": {
      "0": {
        "title": "Summary",
        "text": [
          "Address short title generation for a news aggregation service,",
          "where editors create short titles to introduce important articles",
          "Show a practical use case of neural headline generation",
          "Most news articles basically already have headlines",
          "Propose an encoder-decoder model with multiple encoders",
          "Deploy our model to an editing support tool",
          "and show the results of comparing the editors behavior",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Yahoo News",
        "text": [
          "Biggest news portal in Japan",
          "delivered by providers Editors choice feature Professional editors",
          "2. Put a new",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Short title generation as editing support",
        "text": [
          "Purpose: To generate short title candidates to help editors",
          "Task: Translation from (headline, lead) to short title",
          "Lead is a short version (summary) of the article",
          "Selected news article List of news articles Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Example of short title headline lead",
        "text": [
          "different Short title generation task is not so easy",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Encoder decoder model with attention",
        "text": [
          "Conditional language model consisting of two RNNs",
          "Described by three components (encoder, attention, decoder)",
          "Encoder RNN Decoder RNN",
          "Attention calculates a context from the encoders states",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Proposed method GateFusion",
        "text": [
          "Combine headline and lead contexts w/ gating mechanism",
          "Gating mechanism: ve ctor weights",
          "used an attention mechanism",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Baselines with multiple encoders",
        "text": [
          "(main source) Headline Enc. Atten. Decoder",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Training dataset",
        "text": [
          "263K triples of (headline, lead, short title) in Yahoo! News",
          "Headline Lead Short title",
          "Extractively solvable instances: 20%",
          "Characters in each short title are completely covered by the headline",
          "Edit distance of headlines and short titles: 23.74",
          "Short titles cannot be easily created only from headlines",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Model and training settings",
        "text": [
          "To reduce the computational time",
          "Ensemble of 10 models",
          "Hyper-parameter settings are listed in the right table",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Human evaluation by crowdsourcing",
        "text": [
          "Two crowdsourcing tasks for readability and usefulness",
          "Average score of 10 workers for each of 1,000 outputs",
          "How readable a short title was",
          "How useful a short title was compared to the headline",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Evaluation results 1 2",
        "text": [
          "Our model performed well for the usefulness measure",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation results 2 2",
        "text": [
          "Our model performed well for the usefulness measure",
          "Co pyright 2019 Yahoo Japan Corporation. All Rights Reserved. generate headline-style outputs"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Editing support tool",
        "text": [
          "Editors can check candidates when creating short titles",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Functionalities in the tool",
        "text": [
          "To keep the system quality",
          "To display various outputs Cutoff Hilight",
          "If not in the article",
          "To encourage fact checking",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Effect of the tool release",
        "text": [
          "Editors behavior in three weeks before/after the release",
          "Rate at which an editors title matches the generated one by X%",
          "Rate of 100% match titles Rate of 80+% match titles",
          "Before After Before After",
          "Editors began to refer to generated outputs after the release",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "Short titles were successfully generated for editing support",
          "Editors began to refer to generated titles of our system",
          "Verify how much our model can affect click-through rate",
          "Need a much safer model to avoid generating fake titles",
          "We would like to thank editors and engineers in the news service who continuously supported our experiments",
          "Copyright 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "A Case Study on Neural Headline Generation for Editing Support"
  },
  "1049": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Target-Oriented Sentiment Classification (TOSC) is to detect the overall opinions / sentiments of the user review towards the given opinion target.",
          "TOSC is a supporting task of Target / Aspect-based Sentiment",
          "TOSC has been investigated extensively in other names:",
          "Targeted Sentiment Prediction [6, 14].",
          "Target-Dependent Sentiment Classification [2, 9]."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Problem Formulation",
        "text": [
          "TOSC is a typical classification task but the input texts come from two sources:",
          "Target: explicitly mentioned phrase of opinion target, also called aspect term or aspect.",
          "Context: the original review sentence or the sentence without target phrase.",
          "TOSC is to predict the overall sentiment of the context towards the target.",
          "[Boot time] is super fast, around anywhere from 35 seconds to 1 minute.",
          "This review conveys positive sentiment over the input Boot time.",
          "Great [food] but the [service] is dreadful.",
          "Given the target food, the sentiment polarity is positive while if the input target is service, it becomes negative."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Motivation",
        "text": [
          "Convolutional Neural Network (CNN) is more suitable for this task",
          "Sentiments towards the targets are usually determined by key phrases.",
          "Example: This [dish] is my favorite and I always get it and never get tired of it.",
          "CNN whose aim is to capture the most informative n-grams (e.g., is my favorite) in the sentence should be a suitable model.",
          "Attention-based weighted combination of the entire word-level features may introduce some noises (e.g., never and tired in above sentence).",
          "We employ proximity-based CNN rather than attention-based RNN as the top-most feature extractor.",
          "CNN likely fails in cases where a sentence expresses different sentiments over multiple targets.",
          "Example: great [food] but the [service] was dreadful!",
          "CNN cannot fully explore the target information via vector concatenation.",
          "Combining context information and word embedding is an effective way to represent a word in the convolution-based architecture [4]",
          "(i) We propose a Target-Specific Transformation (TST) component to better consolidate the target information with word representations.",
          "(ii) We design two context-preserving mechanisms Adaptive Scaling",
          "(AS) and Loseless Forwarding (LF) to combine the contextualized representations and the transformed representations.",
          "Most of the existing works do not discriminate different words in the same target phrase",
          "In the target phrase, different words would not contribute equally to the target representation.",
          "For example, in amd turin processor, phrase head processor is more important than amd and turin.",
          "Our TST solves this problem in two steps:",
          "(i) Explicitly calculating the importance scores of the target words.",
          "(ii) Conducting word-level association between the target and its context."
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": []
      },
      "3": {
        "title": "Model Overview",
        "text": [
          "onvoCuretectrchin AiatoTransformM rayeLnlutio STirectional Li-dB",
          "CPT TST CPT CPT fully-connected",
          "Figure: Architecture of TNet.",
          "The proposed TNet consists of the following three components:",
          "(BOTTOM) Bi-directional LSTM for memory building",
          "Generating contextualized word representations.",
          "(MIDDLE) Deep Transformation architecture for learning target-specific word representations",
          "Refining word-level representations with the input target and the contextual information.",
          "(TOP) Proximity-based convolutional feature extractor.",
          "Introducing position information to detect the most salient features more accurately."
        ],
        "page_nums": [
          11,
          12
        ],
        "images": [
          "figure/image/1049-Figure2-1.png",
          "figure/image/1049-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Deep Transformation Architecture",
        "text": [
          "Deeper network helps to learn more abstract features (He et al.,"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "5": {
        "title": "CPT Layer",
        "text": [
          "The functions of the CPT layer are two folds:",
          "Incorporating opinion target information into the word-level representations.",
          "Generating context-aware target representations ri conditioned on the i-th",
          "(l) word representation h fed to the l-th layer:",
          "ri (l) hj F(h i h j",
          "Obtaining target-specific word representations (l) h i",
          "Preserving context information for the upper layers",
          "We design two Context-Preserving Mechanisms to add context",
          "information back to the transformed word features hi",
          "(i) Adaptive Scaling (AS) (Similar to Highway Connection [8]):",
          "(l) (Wtransh i btrans),",
          "(ii) Lossless Forwarding (LF) (Similar to Residual Connection [3]):"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "6": {
        "title": "Proximity based Convolutional Feature Extractor",
        "text": [
          "This component aims to capture the most salient feature w.r.t. the current target for sentiment prediction.",
          "information is effective for better locating the salient features.",
          "Basic idea: Up-weighting the words close to the target and down-weighting those far away from the target.",
          "Convolutional neural network (Kim, 2014) is used to extract features from the weighted word representations."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "7": {
        "title": "Settings",
        "text": [
          "LAPTOP, REST: datasets from SemEval14 ABSA challenge, containing",
          "the user reviews from laptop domain and restaurant domain respectively.",
          "TWITTER: a dataset built in (Dong et al., 2014), containing twitter",
          "posts and the opinion targets are annotated."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "8": {
        "title": "Main Results",
        "text": [
          "ACC Macro-F1 ACC Macro-F1 ACC Macro-F1",
          "The proposed TNet-LF and TNet-AS consistently outperform the baselines.",
          "TNet variants perform well on both user reviews (LAPTOP REST) and twitter posts (TWITTER)."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "9": {
        "title": "Ablation Experiment",
        "text": [
          "ACC Macro-F1 ACC Macro-F1 ACC Macro-F1",
          "Using attention (ATT) and fully-connected layer (FC) to replace CPT layer makes the performance worse.",
          "Each component / element in TNet contributes to the overall performance improvement."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "10": {
        "title": "Impact of CPT layer number",
        "text": [
          "We conduct experiments on the held-out training data of LAPTOP and vary layer number L from 2 to 10, increased by 2.",
          "Increasing the layer number can increase the performance but the results will go down when L 4 due to the limited training data."
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1049-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Case Study",
        "text": [
          "Sentence BILSTM-ATT-G RAM TNet-LF TNet-AS",
          "3. Sure it s not light and slim but the [features]P make N7 N7 P P up for it 100% .",
          "4. Not only did they have amazing , [sandwiches]P",
          "are out of this world !",
          "[startup times]N are incredibly long : over two minutes P7 P7 N N",
          "6. I am pleased with the fast [log on]P speedy [wifi (P, P, P) (P, P, P) (P, P, P) (P, P, P) connection]P and the long [battery life]P 6 hrs ) .",
          "7. The [staff]N should be a bit more friendly . P P7 P7 P7",
          "Our TNet can make correct predictions when the opinion is target specific, e.g., long in the 5th and the 6th example.",
          "TNet can capture the salient features for target sentiment prediction accurately."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "Summary",
        "text": [
          "Our TNet employs CNN as feature extractor to detect the salient features, avoiding introducing the noises.",
          "Armed with target-specific word representation and proximity information, the TNet variants can predict the sentiment w.r.t. the target more accurately."
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Transformation Networks for Target-Oriented Sentiment Classification *"
  },
  "1050": {
    "slides": {
      "0": {
        "title": "Summary Usefulness",
        "text": [
          "(CNN) It looks like the Republicans in Congress have failed again. House Republicans defeated a plan pushed by Senate",
          "Majority Leader Mitch McConnell to fund the Department of Homeland Security, money that congressional Republicans have been holding hostage in their effort to overturn President Obama's executive order on immigration.",
          "McConnell proposed that there would be a separate vote on the immigration issue. When Speaker John Boehner proposed an even narrower compromise, funding the Department for only three more weeks, his caucus said no. The final bill provides funding for one more week, at which point Congress needs to take up the issue again. []",
          "GOP hogs the spotlight with funding deadlines like the battle over money for the Department of Homeland Security.",
          "He says the continual crises deprive _______ of the chance to move his agenda forward even slightly.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Extractive Summarization",
        "text": [
          "Our system seeks to identify salient and consecutive sequences of words from the source document to assist users in comprehending lengthy documents.",
          "We hypothesize that quality extractive summaries should contain informative content so that they can be used as document surrogates.",
          "We investigate a new strategy that seeks to better utilize human abstracts to guide the extraction of summary text units.",
          "To accomplish this we utilize a reinforcement learning framework to explore the space of possible extractive summaries to answer important questions."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Representing an Extraction Unit",
        "text": [
          "We obtain text chunks by breaking down constituent parse tree until each fragment governs at most 5 words.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Bidirectional Recurrent Encoder",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Constructing an Extractive Summary",
        "text": [
          "It is desirable to first develop a supervised framework for identifying summary- worthy text segments from a source article.",
          "The task can be formulated as a sequence labeling problem.",
          "We build a framework to extract summary units where the importance of the t-th source unit is characterized by",
          "position in the document",
          "relationship with the partial summary",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Summary Encoding",
        "text": [
          "position in the document:",
          "relationship with the partial summary:",
          "We employ a multilayer perceptron to predict how likely the unit is to be included in the summary.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Question Answering",
        "text": [
          "Question-answer (QA) pairs can be conveniently developed from human abstracts.",
          "For any sentence in the human abstract, we identify an answer token from it, then replace the answer token with a blank to create a cloze-style QA pair.",
          "We set an answer token to be either a salient word or a named entity to limit the space of potential answers."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Question Answering Model",
        "text": [
          "Given an extractive summary containing a set of source text units, and a collection of question-answer pairs we develop a mechanism leveraging the summary to answer these questions (Chen et al. 2016).",
          "With an attention driven system, an extractive summary can be used to answer multiple questions related to the document.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "A Reinforcement Learning Framework",
        "text": [
          "We introduce a reinforcement learning framework to explore the space of possible extractive summaries and present a novel reward function.",
          "The reward promotes summaries that are adequate, fluent, restricted in length, and competent in question answering.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019",
          "Training the system with policy gradient involves repeatedly sampling an extractive summary from the source document (Lei et al. 2016).",
          "At time t, the agent takes an action by sampling a decision based on indicating whether the t-th source text unit is to be included in the summary."
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "9": {
        "title": "Recap",
        "text": [
          "1. Representing an extraction unit.",
          "2. A framework for extractive summarization.",
          "3. Question answering as a task.",
          "4. Combined reinforcement learning framework.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "Experimental Results CNN",
        "text": [
          "Models outperform the counterpart QASumm (No QA) that makes no use of the",
          "QA pairs by a substantial margin.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "Experimental Results Daily Mail",
        "text": [
          "We conjecture that maintaining a moderate number of answers is important to maximize performance.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Question Answering Results",
        "text": [
          "No T ext QASumm (no QA) Gold S umm Full Text",
          "Answer Type Train Dev Train Dev Train Dev Train Dev",
          "We observe that question-answering with Gold Summ performs the best for all",
          "The results suggest that extractive summaries with even modest ROUGE scores can prove useful for question-answering.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "13": {
        "title": "Human Evaluation",
        "text": [
          "We conducted a human evaluation to assess whether the highlighted summaries contribute to document understanding. (Amazon Mechanical Turk)",
          "We presented each participant with the document and fill-in-the-blank questions created from the human abstracts.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019",
          "We compare our reinforced extracted summary (presented as a bold overlay to the document), against our supervised method, abstractive summaries generated by See et al. (2017), and the human abstracts in full.",
          "Additionally we asked the participants to rate the quality of the summary presented (1-5, with 5 being most informative).",
          "Summary Type Time Acc. Inform.",
          "Although participants rated the informativeness of the summaries to be the same our systems yielded a higher performance."
        ],
        "page_nums": [
          23,
          24,
          25
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion",
        "text": [
          "We exploited an extractive summarization framework using deep reinforcement learning to identify word sequences from a document to form a summary.",
          "Our reward function promotes fluent summaries that can serve as document surrogates to answer important questions.",
          "Experimental results on benchmark data demonstrated the efficacy of our proposed method, assessed by both automatic metrics and human evaluators.",
          "Kristjan Arumae and Fei Liu Guiding Extractive Summarization with Question-Answering Rewards - NAACL 2019"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Guiding Extractive Summarization with Question-Answering Rewards"
  },
  "1051": {
    "slides": {
      "0": {
        "title": "Task definition",
        "text": [
          "Given a name, what is its language?",
          "Same script (no diacritics)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Improving letter-to-phoneme performance (Font",
          "Improving machine transliteration performance",
          "Adjusting for different semantic transliteration rules"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Previous approaches",
        "text": [
          "Character language models (Cavnar and Trenkle, 1994)",
          "Construct models for each language, then choose the language with the most similar model to the test data",
          "accuracy given >300 characters & 14 languages",
          "Given 50 bytes (and 17 languages), language models give",
          "Between 13 languages, average F1 on last names is full names gives (Konstantopoulos, 2007)",
          "Easier with more dissimilar languages: English vs.",
          "Chinese vs. Japanese (same script) gives (Li et al.,"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Using SVMs",
        "text": [
          "Substrings (n-grams) of length n for n=1 to 5",
          "Include special characters at the beginning and the end to account for prefixes and suffixes",
          "Other kernels (polynomial, string kernels) did not work well"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Evaluation Transfermarkt corpus",
        "text": [
          "European national soccer player names",
          "(Konstantopoulos, 2007) from 13 national languages",
          "~15k full names (average length 14.8 characters)",
          "~12k last names (average length 7.8 characters)",
          "e.g. Dario Dakovic born in Bosnia but plays for Austria, so annotated as German",
          "Last names Full names",
          "cs da de en es fr it nl no pl pt se yu Recall cs da de en es fr it nl no pl pt se yu"
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation CEJ corpus",
        "text": [
          "Japanese names (Li et",
          "~97k total names, average length 7.6 characters",
          "Demonstrates a higher baseline with dissimilar languages",
          "Linear SVM only (RBF and sigmoid were slow)"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Application to machine transliteration",
        "text": [
          "Language origin knowledge may help machine transliteration systems pick appropriate rules",
          "To test, we manually annotated data",
          "English-Hindi transliteration data set from the NEWS 2009",
          "454 Indian names, 546 non-Indian names",
          "Average length 7 characters",
          "SVM gives 84% language identification accuracy",
          "Basic idea: use language identification to split data into two language-specific sets",
          "Train two separate transliteration models (with less data per model), then combine",
          "We use DirecTL (Jiampojamarn et al., 2009)",
          "Baseline comparison: random split",
          "DirecTL with random split (Random)",
          "DirecTL with language identificationinformed split (LangID)"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Conclusion",
        "text": [
          "Language identification of names is difficult",
          "SVMs with n-grams as features work better than language models",
          "No significant effect on machine transliteration",
          "But there does seem to be some useful information"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Future work",
        "text": [
          "Other ways of incorporating language information for machine transliteration",
          "Direct use as a feature"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Language identification of names with SVMs"
  },
  "1052": {
    "slides": {
      "0": {
        "title": "Figure 2 Proportion of journals issuing corrections or retractions amongst all journals covered by the Web of Science database by year",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Background",
        "text": [
          "There are two types of citations to retracted articles: Citations that a retracted article received prior to its retraction and citations that are received post retraction and despite retraction notices.",
          "In this study we sought out to find the context around post-retraction citations with the main purpose of finding out whether they are negatively, positively or neutrally mentioned."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Data Collection",
        "text": [
          "ScienceDirect, Elseviers full text database was accessed in October 2014. The database was queried for the term RETRACTED in the article title and its retraction notice.",
          "For this study we selected the five top articles that were found to be highly cited since 2015. This ensured that the papers all cite retracted articles",
          "A total of 1,203 results retrieved from which 988 were retracted articles. The results excluded were retraction notices, duplicates and papers whose original titles included the word \"retracted\"."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Case study",
        "text": [
          "For each article we extracted the citing documents and analyzed the ones appearing in 2015 and 2016. Overall, we analyzed 120 citing documents.",
          "Each mention was categorized as follows:",
          "Positive: A positive citation indicates that the retracted article was cited as legitimate prior work and its findings used to corroborate the author/s current study.",
          "Negative: A negative citations indicates that the authors mentioned the retracted article as such and its findings as inappropriate.",
          "Neutral: A neutral citation indicates that the retracted article was mentioned as a publication that appears in the literature and does not include judgement on its validity."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Citations in Context",
        "text": [
          "This article was cited 109 times since its publication in 2012 with",
          "28 citations tracked after 2014",
          "More citations are seen to be negative, the positive and neutral ones are also present",
          "The negative citations mostly point to the media frenzy around the results.",
          "The study was republished in 2014 by Environmental Sciences Europe. The republished article received 17 citations in 2015 and 2016. The vast majority of them being positive mentions",
          "NA Negative Neutral Positive"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Conclusions",
        "text": [
          "Retracted articles continue to be cited years after retraction and despite retraction notices being posted on publishers platforms.",
          "This could be the result of general interest by the public or media.",
          "In other cases, the reason for retraction does not deter others from citing the article.",
          "We recommend that publishers use reference checks to all submitted articles to detect citations of retracted articles and remove them or at least request an explanation from the authors for citing a retracted paper in a positive or neutral manner"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "Post Retraction Citations in Context"
  },
  "1053": {
    "slides": {
      "0": {
        "title": "Dependency Parsing",
        "text": [
          "But there were no buyers"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Transition based Parsing",
        "text": [
          "Process the input sequentially in order",
          "Use actions that build up a tree",
          "Choose which actions to apply with a classifier"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Example Arc standard Parsing",
        "text": [
          "Actions: Shift, reduce-right, reduce-left",
          "ROOT I saw a girl ROOT I saw a girl",
          "Support vector machines [Nivre+ 2004]",
          "Feed-forward neural networks [Chen+ 2014]",
          "Recurrent neural networks [Dyer+ 2015]"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Our Proposal Stack pointer Networks StackPtr",
        "text": [
          "But there were no buyers",
          "were there were were but were",
          "Actions: \"Point\" to the next word to choose as a child",
          "Model: A neural network, based on \"pointer networks\"",
          "Top-down parsing maintains a global view of the sentence",
          "Can maintain full history, low asymptotic running time (c.f. graph-based)"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1053-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Background Pointer Network Vinyals 2015",
        "text": [
          "Output sequence with elements that are discrete tokens corresponding to positions in an input sequence",
          "Use attention as a pointer to select a member of the input sequence as the output",
          "s and h are the hidden states of encoder and decoder, and score() is the attention scoring function, e.g. bi-affine attention [Luong+ 2015; Dozat+ 2017]"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Variable Definitions",
        "text": [
          "each of which is a sequence of words from root to a leaf w1 w2 w3 w4"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Transition System",
        "text": [
          "List (): of words whose head has not been selected",
          "Stack (): of partially processed head words whose children have not been fully selected",
          "Stack is initialized with the root symbol",
          "At each decoding step t",
          "receive the top element of stack as head word wh, and generate the hidden state ht",
          "compute the attention vector at using ht and encoder hidden states s",
          "generate an arc: choose a specific word (wc) from as the child of wh , remove wc from and push it onto",
          "complete a head: pop wh out of"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Features for the Classifier",
        "text": [
          "Utilize higher-order information at each step of the top- down decoding procedure",
          "Sibling and Grandchild structures",
          "proven beneficial for parsing performance (McDonald and",
          "Use element-wise sum of the encoder hidden states instead of concatenation",
          "- does not increase the dimension of t",
          "\u0000t sh sg ss"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Example",
        "text": [
          "But there were no buyers",
          "were there were were but were"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": [
          "figure/image/1053-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Learning StackPtr",
        "text": [
          "Factorize into sequence of top-down paths",
          "Pre-defined inside-out order for children of each head word",
          "Enables parser to utilize higher-order sibling information",
          "Train separate classifier for dependency label prediction",
          "Use head word and child information [Dozat+ 2017]"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "10": {
        "title": "Experiment 1 Main Results and Analysis",
        "text": [
          "English PTB, Chinese PTB, German CoNLL 2009 shared task",
          "Parsing models for comparison",
          "Baseline: Deep Biaffine (BiAF) parser (Dozat et al., 2017), augmented with character-level information",
          "Four versions of StackPtr:",
          "Org: utilizes only head word information",
          "+gpar: augment Org with grandparent information",
          "+sib: augment Org with sibling information",
          "Full: include all the three information",
          "Unlabeled Attachment Score (UAS), Labeled Attachment",
          "Score (LAS), Unlabeled Complete Match (UCM), Labeled",
          "Complete Match (LCM), Root Accuracy (RA)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "11": {
        "title": "Main Results",
        "text": [],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1053-Figure2-1.png"
        ]
      },
      "12": {
        "title": "Parsing Performance on Test Data wrt Sentence Length",
        "text": [
          "StackPtr tends to perform better on shorter sentences, consistent with transition-based/graph-based"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "13": {
        "title": "Parsing Performance wrt Dependency Length",
        "text": [
          "The gap between Stack-Ptr and BiAF is marginal, graph- based BiAF still performs better for longer arcs"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "14": {
        "title": "Parsing Performance wrt Root Distance",
        "text": [
          "Different from McDonald and Nivre (2011), StackPtr and",
          "BiAf similar regardless of root distance"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "15": {
        "title": "Effect of POS Embedding",
        "text": [
          "Gold: Parser with gold-standard POS tags",
          "Pred: Parser with predicted POS tags (97.3% accuracy)",
          "None: Parser without POS tags"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "16": {
        "title": "Experiment 2 Universal Dependency Treebanks",
        "text": [
          "Universal Dependency Treebanks (V2.2)",
          "Languages: Bulgarian, Catalan, Czech, Dutch,",
          "English, French, German, Italian,",
          "Norwegian, Romanian, Russian and Spanish",
          "Note: we also ran experiments on 14 CoNLL Treebanks.",
          "(see the paper for details)"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "17": {
        "title": "LAS on UD Treebanks",
        "text": [
          "bg ca cs de en es fr it nl no ro ru"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "18": {
        "title": "Conclusion and Future Work",
        "text": [
          "Stack-Pointer network for dependency parsing",
          "A transition-based neural network architecture",
          "Top-down, depth-first decoding procedure",
          "State-of-the-art performance on 21 out of 29 treebanks",
          "- Learn an optimal order for the children of head words, instead of using a pre-defined fixed order"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "19": {
        "title": "Model Details",
        "text": [
          "Bi-directional LSTM-CNN (Chiu and Nichols 2016; Ma and Hovy",
          "Three input embeddings: word, character and POS",
          "CNN encodes character-level information",
          "3-layer LSTM with recurrent dropout (Gal et al., 2016)",
          "- Use encoder hidden states as input instead of word embeddings"
        ],
        "page_nums": [
          33
        ],
        "images": []
      }
    },
    "paper_title": "Stack-Pointer Networks for Dependency Parsing"
  },
  "1054": {
    "slides": {
      "0": {
        "title": "Revisiting Six Challenges",
        "text": [
          "attention is not word alignment",
          "large beam does not help",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "A Model Interpretation Problem",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Related Findings Outside MT",
        "text": [
          "Attention is not Explanation",
          "[Jain and Wallace NAACL 2019]",
          "Is Attention Interpretable? (Spoiler: No)",
          "[Serrano and Smith ACL 2019]",
          "We also have empirical results that corroborate these findings.",
          "and we have method that works better!",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Recap",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "4": {
        "title": "Focus on solten",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Perturbation",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "6": {
        "title": "Assumption",
        "text": [
          "The output score is more sensitive to perturbations in important features.",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Eg",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": []
      },
      "8": {
        "title": "Saliency",
        "text": [],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": []
      },
      "9": {
        "title": "Whats good about this",
        "text": [
          "Derivatives are easy to obtain for any DL toolkit",
          "Adapts with the choice of output words",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "Prior Work on Saliency",
        "text": [
          "Widely used and studied in Computer Vision!",
          "Also in a few NLP work for qualitative analysis",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "SmoothGrad",
        "text": [
          "Gradients are very local measure of sensitivity.",
          "Highly non-linear models may have pathological points where the gradients are noisy.",
          "Solution: calculate saliency for multiple copies of the same input corrupted with gaussian noise, and average the saliency of copies.",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Establishing Saliency",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "13": {
        "title": "Feature in Computer Vision",
        "text": [
          "Photo Credit: Hainan Xu",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "14": {
        "title": "Feature in NLP",
        "text": [
          "Its straight-forward to compute saliency for a single dimension of the word embedding.",
          "Saliency-driven Word Alignment Interpretation for NMT",
          "But how to compose the saliency of each dimension into the saliency of a word?"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "15": {
        "title": "Our Proposal",
        "text": [
          "Consider word embedding look-up as a dot product between the embedding matrix and an one-hot vector.",
          "Saliency-driven Word Alignment Interpretation for NMT",
          "The in the one-hot vector denotes the identity of the input word.",
          "Lets perturb that like a real value! i.e. take gradients with regard to the"
        ],
        "page_nums": [
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "16": {
        "title": "Experiment",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "17": {
        "title": "Evaluation",
        "text": [
          "Fortunately, theres human judgments to rely on.",
          "Need to do force decoding with NMT model.",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "18": {
        "title": "Setup",
        "text": [
          "Architecture: Convolutional S2S, LSTM,",
          "Transformer (with fairseq default hyper- parameters)",
          "Dataset: Following Zenkel et al. [2019], which covers de-en, fr-en and ro-en.",
          "SmoothGrad hyper-parameters: N=30 and",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "19": {
        "title": "Baselines",
        "text": [
          "Smoothed Attention: forward pass on multiple corrupted input samples, then average the attention weights over samples",
          "[Li et al. 2016]: compute element-wise absolute value of embedding gradients, then average over embedding dimensions",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "20": {
        "title": "Convolutional S2S on de en",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "21": {
        "title": "Attention on de en",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "22": {
        "title": "OursSmoothGrad on de en",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "23": {
        "title": "Li vs Ours",
        "text": [
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          37,
          38
        ],
        "images": []
      },
      "24": {
        "title": "Conclusion",
        "text": [
          "Saliency + proper word-level score formulation is a better interpretation method than attention",
          "NMT models do learn interpretable alignments. We just need to properly uncover them!",
          "Saliency-driven Word Alignment Interpretation for NMT"
        ],
        "page_nums": [
          39,
          40
        ],
        "images": []
      }
    },
    "paper_title": "Saliency-driven Word Alignment Interpretation for Neural Machine Translation"
  },
  "1055": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Task: Topic-Based Chinese Message Polarity Classification",
          "Classify the message into positive, negative, or neutral sentiment",
          "towards the given topic.",
          "For messages conveying both a positive and negative",
          "sentiment towards the topic, whichever is the stronger",
          "sentiment should be chosen.",
          "Real and noise data",
          "Imbalance data between classes",
          "Short but meaningful message",
          "Galaxy S6# GALAXY S6",
          "Framework of our model",
          "Data preprocessing: rule-based process",
          "Word feature based SVM classifier: unigram + bigram +",
          "CNN-based SVM classifier: word embedding + convolutional",
          "Integrated strategy: multi-classifier results fusion",
          "Training and testing data"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "Data preprocessing",
        "text": [
          "Sharing news with personal comments",
          "Galaxy S6# GALAXY S6",
          "Removing information sources S6 iPhone6 MWC2015 @youtube http://t.cn/RwHQzJ8"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "2": {
        "title": "Word Feature based Classifier",
        "text": [
          "Sentiment Lexicon expansion: To expand existing sentiment lexicon, POS tags, word frequency, mutual information and context entropy are used to mine the new sentiment word from twenty million microblog text.",
          "Positive Words Negative Words",
          "Word features: unigram, bigram, uni-part-of-speech, bi-part-of- speech, sentiment lexicons",
          "Features Selection Methods: CHI-test, TF-IDF",
          "Imbalance Data Problem: use SMOTE algorithm to undersampling the major class and oversampling the minor classes.",
          "Classifier: SVM with linear kernel"
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": [
          "figure/image/1055-Figure1-1.png"
        ]
      },
      "3": {
        "title": "CNN based SVM Classifier",
        "text": [
          "Train the CBOW model",
          "using 16GB Chinese microblog text",
          "Input: a matrix which is composed of the word embeddings of microblogs",
          "Features: use CNN to constitute the distributed paragraph feature representation",
          "Classifier: SVM with linear kernel"
        ],
        "page_nums": [
          10,
          11,
          12,
          13
        ],
        "images": [
          "figure/image/1055-Figure2-1.png"
        ]
      },
      "4": {
        "title": "Outputs merging",
        "text": [
          "Two classification outputs are the same",
          "=>The final output is the same",
          "Two classification outputs are different",
          "=>The final result is determined from the merge rules",
          "These rules are based on the statistical analysis on the individual classifier performances on training dataset.",
          "Final result Classifier 1 Classifier 2"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "5": {
        "title": "Experiments",
        "text": [
          "Training data: 4905 microblogs (394 positive, 538 negative and",
          "Testing data: 19469 microblogs, 20 topics",
          "P r ecision SystemCorrect",
          "F Pr ecision Re call",
          "Performances in unrestricted resource subtask",
          "Team Name Precision Recall F1 Precision Recall F1 Precision Recall F1",
          "Performances by different classifiers in unrestricted resource subtask",
          "Approach Precision Recall F1 Precision Recall F1 Precision Recall F1"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "6": {
        "title": "Conclusion",
        "text": [
          "Word feature based SVM classifier",
          "Second rank on micro average F1 value",
          "Fourth rank on macro average F1 value"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "A Joint Model for Chinese Microblog Sentiment Analysis"
  },
  "1056": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "The NLP-TEA 2015 shared task features a",
          "Chinese Gramma%cal Error Diagnosis (CGED) task, providing an evalua%on plaMorm for the development and implementa%on of NLP tools for computer-assisted Chinese learning"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Shared Task Description",
        "text": [
          "The developed tool is expected to iden%fy the error types and its posi%on at which it occurs in the sentence",
          "Four PADS error types are modifica%on taxonomy included in the target",
          "For the sake of simplicity, the input sentence is selected to contain one defined error types"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Testing Examples",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Data Preparation",
        "text": [
          "The essay sec%on of the computer-based Test of Chinese as a Foreign Language (TOCFL)",
          "Na%ve Chinese speakers were trained to manually annotate gramma%cal errors and provide error correc%ons corresponding to each"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Training Set",
        "text": [
          "This set included 2,205 selected sentences",
          "Error types were categorized as redundant (430",
          "Each sentence is represented in SGML format"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1056-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Dryrun Set",
        "text": [
          "A total of 55 sentences were given to par%cipants to familiarize themselves with the f inal tes%ng process.",
          "The purpose is output format valida%on only",
          "No macer which performance can be achieved that will not be official evalua%on. included in our"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Test Set",
        "text": [
          "This set consists of 1,000 tes%ng sentences",
          "Half of these sentences gramma%cal errors, while contained the other no half included a single defined gramma%cal error: redundant (132 instances), missing"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Performance Metric",
        "text": [
          "Correctness is determined at three levels",
          "False posi%ve rate (FPR) = FP / (FP+TP)",
          "Precision = TP / (TP+FP)",
          "F1 = 2 * Precision * Recall / (Precision+Recall)"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Evaluation Examples",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "13 Participants and 18 Submitted Runs",
        "text": [
          "13 Par%cipants and 18 Submiced Runs"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1056-Table2-1.png"
        ]
      },
      "10": {
        "title": "Testing Results",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Summary",
        "text": [
          "It is a really difficult task to develop the computer-assisted Chinese learning tool, since there are only target sentences without the help of their context",
          "None of superior the submiced performance. systems provided",
          "In general, this research problem s%ll has long way to go."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "All submissions contribute to the common effort to produce an effec%ve Chinese gramma%cal diagnosis tool",
          "The individual reports proceedings provide in the useful shared insight task into"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Future Work",
        "text": [
          "NLP-TEA-3 Workshop in COLING 2016",
          "Chinese Gramma%cal Error Diagnosis"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Overview of the NLP-TEA 2015 Shared Task for Chinese Grammatical Error Diagnosis"
  },
  "1057": {
    "slides": {
      "0": {
        "title": "Semantic Role Labeling SRL",
        "text": [
          "SRL - a shallow semantic parsing task: recognize the predicate-argument",
          "structure, such as who did what to whom, where and when, etc.",
          "Predicate identification and disambiguation",
          "Argument identification and classification"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "SRL Example",
        "text": [
          "Two formulizations of predicate-argument structure:",
          "Span-based (i.e., phrase or constituent)",
          "Marry borrowed a book from john last week",
          "Dependency-based: head of arguments"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Related Work",
        "text": [
          "Pradhan et al. (2005) utilized a SVM classifier",
          "Roth and Yih (2005) employed CRF with integer linear programming",
          "Punyakanok et al. (2008) enforced global consistency with ILP",
          "Zhao et al. (2009) proposed a huge feature engineering method",
          "Zhou and Xu (2015) introduced deep bi- directional RNN model",
          "Roth and Lapata (2016) proposed PathLSTM modeling approach",
          "He et al. (2017) used deep highway BiLSTM with constrained decoding",
          "Marcheggiani et al. (2017) presented a simple BiLSTM model",
          "Marcheggiani and Titov (2017) proposed a"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Focus Dependency SRL",
        "text": [
          "Maximum entropy model (Zhao et al., 2009)",
          "Path embedding (Roth and Lapata, 2016)",
          "Graph convolutional network (Marcheggiani and Titov, 2017)",
          "The simple BiLSTM (Marcheggiani et al., 2017)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Method Overview",
        "text": [
          "Predicate Disambiguation & Argument Labeling",
          "Sequence labeling: BiLSTM - MLP"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "k order argument pruning",
        "text": [
          "Initialization: Set the marked predicate as the current node;",
          "1. Collect all its descendant node as argument candidates,",
          "which is at most k syntactically distant from the current node.",
          "2. Reset the current node to its syntactic head and repeat step 1",
          "until the root is reached.",
          "3. Collect the root and stop."
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1057-Figure2-1.png"
        ]
      },
      "6": {
        "title": "syntax aware syntax agnostic",
        "text": [
          "CoNLL-2009 English training set CoNLL-2009 English development set"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1057-Figure3-1.png",
          "figure/image/1057-Figure4-1.png"
        ]
      },
      "7": {
        "title": "CoNLL 2009 Results",
        "text": [
          "Models English Chinese OOD",
          "NN syntax-aware Roth and Lapata, 2016",
          "Marcheggiani and Titov, 2017",
          "Results on CoNLL-2009 English, Chinese and out-of-domain (OOD) test set."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "End to end SRL",
        "text": [
          "Integrate predicate disambiguation and argument labeling",
          "Results of end-to-end model on the CoNLL-2009 data."
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1057-Figure5-1.png"
        ]
      },
      "9": {
        "title": "CoNLL 2008 Results",
        "text": [
          "Indispensable task: predicate identification",
          "Johansson and Nugues, 2008",
          "Results on the CoNLL-2008 in-domain test set."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Syntactic Role",
        "text": [
          "Different syntax-aware SRL models may adopt different syntactic parser",
          "PathLSTM SRL (Roth and Lapata, 2016): mate-tools",
          "GCN-based SRL (Marcheggiani and Titov, 2017): BIST Parser",
          "How to quantitatively evaluate the syntactic contribution to SRL?",
          "Evaluation Measure: the Sem-F1 / LAS ratio",
          "Sem-F1: the labeled F1 score for semantic dependencies",
          "LAS: the labeled attachment score for syntactic dependencies",
          "Reference: Surdeanu et al., CoNLL-2008 Shared Task"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Performance Comparison",
        "text": [
          "Models LAS Sem-F1 Sem-F1/LAS",
          "Marcheggiani and Titov, 2017",
          "Ours + CoNLL-2009 predicted",
          "Ours + Auto syntax",
          "Ours + Gold syntax",
          "Sem-F1/LAS ratio on CoNLL-2009 English test set."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Faulty Syntactic Tree Generator",
        "text": [
          "How to obtain syntactic input of different quality?",
          "Produce random errors in the output parse tree",
          "Given an input error probability distribution",
          "Modify the syntactic heads of nodes"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Sem F1 LAS Curve",
        "text": [
          "Syntactic inputs generated from STG",
          "The 10th-order SRL gives quite stable",
          "results regardless of syntactic quality",
          "The 1st-order SRL model yields overall",
          "Better syntax could result in better SRL",
          "1st and 10th-order SRL on CoNLL-2009 English test set."
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1057-Figure6-1.png"
        ]
      },
      "14": {
        "title": "Conclusion and Future Work",
        "text": [
          "We present an effective model for dependency SRL with extended k-order pruning.",
          "The gap between syntax-enhanced and -agnostic SRL has been greatly reduced,",
          "from as high as to only performance loss.",
          "High-quality syntactic parses indeed enhance SRL.",
          "Develop a more effective syntax-agnostic SRL system.",
          "Explore syntactic integration method based on high-quality syntax."
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Syntax for Semantic Role Labeling, To Be, Or Not To Be"
  },
  "1058": {
    "slides": {
      "0": {
        "title": "Artificial Intelligence",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Sentiment and Emotion Analysis",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Multimodal Sentiment and Emotion Analysis",
        "text": [
          "Speakers behaviors Sentiment Intensity",
          "This movie is sick",
          "Cross-modal Interactions Multimodal Representation",
          "Computational Efficiency (Multimodal Fusion)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Multimodal Fusion using Tensor Representation",
        "text": [
          "This movie is sick",
          "Computational efficiency Tensor Fusion Network for Multimodal Sentiment Analysis by Zadeh, A., et, al. (2017)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Low rank",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "From Tensor Representation to Low rank Fusion",
        "text": [
          "Rearrange the computation of",
          "Decomposition of input tensor",
          "Language Tensor Fusion Networks"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1058-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Canonical Polyadic CP Decomposition of tensors",
        "text": [
          "Rank of tesrmi no nimum number of vector tuples needed for exact reconstruction"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Canonical Polyadic CP Decomposition of 3D tensors",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Modality specific Decomposition",
        "text": [
          "Retain the dimension for the multimodal representation during decomposition"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Decomposition of weight tensor",
        "text": [],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1058-Figure2-1.png",
          "figure/image/1058-Figure3-1.png"
        ]
      },
      "10": {
        "title": "Decomposition of weight tensor W",
        "text": [],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1058-Figure2-1.png",
          "figure/image/1058-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Decomposition of",
        "text": [],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1058-Figure2-1.png",
          "figure/image/1058-Figure3-1.png"
        ]
      },
      "12": {
        "title": "Rearranging computation",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Low rank Multimodal Fusion",
        "text": [],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1058-Figure1-1.png"
        ]
      },
      "14": {
        "title": "Easily scales to more modalities",
        "text": [],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1058-Figure1-1.png"
        ]
      },
      "15": {
        "title": "Datasets",
        "text": [
          "Sentiment Analysis Speaker Trait Recognition Emotion Recognition",
          "From 93 Movie reviews",
          "1000 full video clips",
          "Segment level annotations Video level annotations Segment level annotations",
          "16 types of speaker traits",
          "10 classes of emotions"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "16": {
        "title": "Compare to full rank tensor fusion",
        "text": [
          "MAE Correlation Acc-2 F1 Acc-7",
          "MAE Correlation MAE Correlation F1-Happy F1-Sad"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "17": {
        "title": "Compare with State of the Art Approaches",
        "text": [
          "Mean Average Error (MAE)",
          "Deep Fusion (Nojavanasghari, et al., 2016) Deep Fusion"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "18": {
        "title": "Compare with Top 2 State of the Art Approaches",
        "text": [
          "MAE Correlation MAE Correlation F1-Angry F1-Sad"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "19": {
        "title": "Efficiency Improvement",
        "text": [
          "Efficiency Metric: Number of data samples processed per second",
          "Training - samples/s Testing - samples/s"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1058-Figure1-1.png"
        ]
      }
    },
    "paper_title": "Efficient Low-rank Multimodal Fusion with Modality-Specific Factors"
  },
  "1060": {
    "slides": {
      "0": {
        "title": "A NLG system Architecture",
        "text": [
          "Communicative Goal Document Plans Sentence Plans Surface Text",
          "Ehud Reiter and Robert Dale, Building Natural Language",
          "Generation Systems, Cambridge University Press, 2000.",
          "In this paper, we study surface realization, i.e. mapping meaning representations to natural language sentences."
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Meaning Representation",
        "text": [
          "Logic form, e.g. lambda calculus"
        ],
        "page_nums": [
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Graph Structured Meaning Representation",
        "text": [
          "Different kinds of graph-structured semantic representations:",
          "Semantic Dependency Graphs (SDP)",
          "Abstract Meaning Representations (AMR)",
          "Dependency-based Minimal Recursion Semantics (DMRS)",
          "Elementary Dependency Structures (EDS)",
          "BV ARG1 ARG2 BV"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "3": {
        "title": "Type Logical Semantic Graph",
        "text": [
          "EDS graphs are grounded under type-logical semantics. They are usually very flat and multi-rooted graphs.",
          "BV ARG1 ARG2 BV",
          "The boy wants the girl to believe him."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "4": {
        "title": "Previous Work",
        "text": [
          "Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, and",
          "Luke Zettlemoyer. 2017. Neural AMR: Sequence-to-sequence models for parsing and generation.",
          "Synchronous Node Replacement Grammar. (AMR-to-text)",
          "Linfeng Song, Xiaochang Peng, Yue Zhang, Zhiguo Wang, and",
          "Daniel Gildea. 2017. AMR-to-text generation with synchronous node replacement grammar.",
          "Other Unification grammar-based methods",
          "Carroll, John and Oepen, Stephan 2005. High efficiency realization for a wide-coverage unification grammar"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": []
      },
      "5": {
        "title": "Formalisms for Strings Trees and Graphs",
        "text": [
          "Chomsky hierarchy Grammar Abstract machines",
          "Manipulating Graphs: Graph Grammar and DAG Automata."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "6": {
        "title": "Existing System",
        "text": [
          "David Chiang, Frank Drewes, Daniel Gildea, Adam Lopez and",
          "Giorgio Satta. Weighted DAG Automata for Semantic Graphs.",
          "the longest NLP paper that Ive ever read",
          "Daniel Quernheim and Kevin Knight. 2012. Towards probabilistic acceptors and transducers for feature structures"
        ],
        "page_nums": [
          18,
          29
        ],
        "images": []
      },
      "7": {
        "title": "DAG Automata",
        "text": [
          "A weighted DAG automaton is a tuple",
          "A run of M on DAG D V,E, is an edge labeling function",
          "The weight of is the product of all weight of local transitions:"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "8": {
        "title": "DAG Automata Toy Example",
        "text": [
          "John wants to go. {} _want_v_",
          "named(John) } named(John Failed !",
          "Accept ! } named(John"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28
        ],
        "images": [
          "figure/image/1060-Figure2-1.png"
        ]
      },
      "9": {
        "title": "DAG to Tree Transducer",
        "text": [
          "WANT qnomb want s qinfb qnomb want s INF INF",
          "BOY GIRL BOY GIRL",
          "qnomb want s INF INF",
          "BE LIE VE BE LIE VE qaccg to believe qaccb NP NP NP",
          "qaccg qaccb NP NP NP to believe",
          "t he b oy want s t he gir l t o b elieve him BOY G IR L BOY G IR L BOY G IR L",
          "q S S S",
          "Challenges for DAG-to-tree transduction on EDS graphs:",
          "Cannot easily reverse the directions of edges",
          "Cannot easily handle multiple roots"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "10": {
        "title": "Our DAG to program transducer",
        "text": [
          "Rewritting: directly generating a new data structure piece by piece, during recognizing an input DAG.",
          "Obtaining target structures based on side effects of the",
          "States: The output of our transducer is a program:",
          "John wants to go.",
          "S John want to go"
        ],
        "page_nums": [
          36,
          37,
          38,
          39,
          40,
          41,
          42
        ],
        "images": [
          "figure/image/1060-Figure2-1.png"
        ]
      },
      "11": {
        "title": "Transducation Rules",
        "text": [
          "A valid DAG Automata transition",
          "We use parameterized states:",
          "The range of direction: unchanged, empty, reversed."
        ],
        "page_nums": [
          43,
          44,
          45
        ],
        "images": []
      },
      "12": {
        "title": "Toy Example",
        "text": [
          "Rule For Recognition For Generation",
          "Recognition: To find an edge labeling function . The red dashed edges make up an intermediate graph T().",
          "of edge ei with variable xij and L with the output string in the statement templates."
        ],
        "page_nums": [
          46,
          47,
          48,
          49,
          50,
          51
        ],
        "images": [
          "figure/image/1060-Figure2-1.png",
          "figure/image/1060-Figure3-1.png",
          "figure/image/1060-Table1-1.png"
        ]
      },
      "13": {
        "title": "DAG Transduction based NLG",
        "text": [
          "DAG Transducer Seq2seq Model",
          "Semantic Graph Sequential Lemmas Surface string"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "14": {
        "title": "Inducing Transduction Rules",
        "text": [
          "the decline is even steeper than in September, he said.",
          "Finding intermediate tree Assigning spans Assigning labels Generating statement templates"
        ],
        "page_nums": [
          54,
          55,
          56,
          57,
          58,
          59,
          60
        ],
        "images": []
      },
      "15": {
        "title": "NLG via DAG transduction",
        "text": [
          "Data: DeepBank + Wikiwoods",
          "Decoder: Beam search (beam size = 128)",
          "About 37,000 induced rules are directly obtained from",
          "DeepBank training dataset by a group of heuristic rules.",
          "Disambiguation: global linear model",
          "Transducer Lemmas Sentences Coverage induced rules induced and exteneded rules induced, exteneded and dynamic rules"
        ],
        "page_nums": [
          61,
          64,
          66
        ],
        "images": []
      },
      "16": {
        "title": "Fine to coarse Transduction",
        "text": [
          "To deal with data sparseness problem, we use some heuristic rules to generate extened rules by slightly changing an induced rule.",
          "Given a induced rule:",
          "New rule generated by deleting:",
          "New rule generated by copying:"
        ],
        "page_nums": [
          62,
          63
        ],
        "images": []
      },
      "17": {
        "title": "Fine to coarse transduction",
        "text": [
          "During decoding, when neither induced nor extended rule is applicable, we use markov model to create a dynamic rule",
          "C {q1, qm},D represents the context. r1, rn denotes the outgoing states."
        ],
        "page_nums": [
          65
        ],
        "images": []
      },
      "18": {
        "title": "Conclusion and Future Work",
        "text": [
          "English Resouce Semantics is fantastic!",
          "Formalism works for graph-to-string mapping, not surprisingly or surprisingly",
          "Is the decoder perfect? No, not even close",
          "Is the disambiguation model a neural one? No, graph embedding is non-trivial."
        ],
        "page_nums": [
          67
        ],
        "images": []
      }
    },
    "paper_title": "Language Generation via DAG Transduction"
  },
  "1061": {
    "slides": {
      "0": {
        "title": "Main Components of Spoken Dialogue Systems",
        "text": [
          "Semantic decoding and belief tracking require different type of label led data",
          "Combining these two units, reduces the amount of l abelled data required and avoid possibilit y of information l oss in the SD"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Belief Tracking",
        "text": [],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Limitations of Current Belief Trackers",
        "text": [
          "1. The model parameters increase wit h the size of the ontol ogy",
          "2. Many approaches rely on the delexicalization except for Neural",
          "Belief Tracker (NBT), Mrksic et al 2017",
          "3. Current multidomain models do not handle mixed domains",
          "within a single dialogue",
          "This causes a bottleneck in scaling the belief tracker to larger domains and complex dial ogues"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "Problem Formulation",
        "text": [
          "1. What is in the dial ogue ontol ogy?",
          "2. What does the system output refer to?",
          "3. What does the user input refer to?",
          "4. How do we track the dial ogue context?",
          "5. How do we handle many domains?"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "4": {
        "title": "Belief Tracking with Knowledge Sharing",
        "text": [],
        "page_nums": [
          17,
          18,
          19,
          20,
          21,
          22
        ],
        "images": [
          "figure/image/1061-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Belief State Update",
        "text": [
          "Use a statistical belief update mechanism modelled by a RNN"
        ],
        "page_nums": [
          23,
          24,
          25
        ],
        "images": []
      },
      "6": {
        "title": "Datasets",
        "text": [
          "Wizard of Oz framework for col l ecting data for bel ief tracking",
          "Amazon MTurk users given tasks to compl ete, access to the database",
          "They produce dialogues and annotate them",
          "Singledomain dataset WOZ 2.0 (Wen et al 2016)",
          "New multidomain dataset Mul tiWOZ"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": []
      },
      "7": {
        "title": "Results",
        "text": [
          "1. Singl edomain Dialogues:"
        ],
        "page_nums": [
          28,
          29
        ],
        "images": [
          "figure/image/1061-Table1-1.png",
          "figure/image/1061-Table2-1.png"
        ]
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "1. We proposed a model with ontologyindependent parameters",
          "2. It also achieves stateoftheart results in singledomain",
          "3. The model demonstrates also great capability in handling mixed",
          "Future work is to test the model on outofdomain tracking",
          "The data collection was funded through Google Faculty Award"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34
        ],
        "images": []
      }
    },
    "paper_title": "Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing"
  },
  "1062": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I Attention-based neural translation models",
          "attend to specific positions on the source side to generate translation improvements over pure encoder-decoder sequence-to-sequence approach",
          "I Neural HMM has been successfully applied on top of SMT systems",
          "I This work explores its application in standalone decoding",
          "end-to-end, only with neural networks NMT",
          "LSTM structures outperform FFNN variants in [Wang & Alkhouli+"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Neural Hidden Markov Model",
        "text": [
          "alignment i j bi",
          "I Model translation using an alignment model and a lexicon model:",
          "bI1 i=1 lexicon model alignment model",
          "predicts the jump i bi bi1",
          "I Neural network based lexicon model",
          "I Neural network based alignment model (j bi1)"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Training",
        "text": [
          "I Derivative for a single sentence pair (F,E) = (fJ1 , eI",
          "the HMM posterior weights the local gradients (backpropagation)",
          "I Entire training procedure: backpropagation in an EM framework",
          "2. update neural network weights"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Decoding",
        "text": [
          "I Search over all possible target strings",
          "I Extending partial hypothesis from ei10 to ei0",
          "argmax Q(i; ei0) select several candidates ei",
          "I No explicit coverage constraints",
          "one-to-many alignment cases and unaligned source words",
          "I Search space in decoding",
          "neural HMM: consists of both alignment and translation decisions attention model: consists only of translation decisions",
          "neural HMM: O(J2 I) attention model: O(J I) in practice, neural HMM 3 times slower than attention model"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Experimental Setup",
        "text": [
          "I WMT 2017 GermanEnglish and ChineseEnglish translation tasks",
          "I Quality measured with case sensitive BLEU and TER on newstests2017",
          "I Moses tokenizer and truecasing scripts [Koehn & Hoang+",
          "I Jieba1 segmenter for Chinese data",
          "I 20K byte pair encoding (BPE) operations [Sennrich & Haddow+",
          "joint for GermanEnglish and separate for ChineseEnglish",
          "I Attention-based system are trained with Sockeye [Hieber & Domhan+",
          "encoder and decoder embedding layer size 620 a bidirectional encoder layer with 1000 LSTMs with peephole connections",
          "Adam [Kingma & Ba 15] as optimizer with a learning rate of 0.001",
          "beam search with beam size 12 model weights averaging",
          "1https://github.com/fxsjy/jieba W. Wang: Neural HMM for MT July 17th, 2018",
          "I Neural hidden markov model implemented in TensorFlow [Abadi & Agarwal+",
          "three hidden layers of sizes 1000, 1000 and 500 respectively normal softmax layer lexicon model: large output layer with roughly 25K nodes alignment model: small output layer with 201 nodes"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Experimental Results",
        "text": [
          "I Attention-based neural network: [Bahdanau & Cho+",
          "I FFNN-based neural HMM: [Wang & Alkhouli+ 17] applied in decoding",
          "I LSTM-based neural HMM: this work",
          "I All models trained without synthetic data",
          "I Single model used for decoding",
          "I LSTM models improve FFNN-based system by up to 1.3% BLEU and 1.8% TER",
          "I Comparable performance with attention-based system"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Summary",
        "text": [
          "I Apply NNs to conventional HMM for MT",
          "I End-to-end with a stand-alone decoder",
          "I Comparable performance with the standard attention-based system",
          "significantly outperforms the feed-forward variant",
          "Speed up training and decoding",
          "Application in automatic post editing",
          "Combination with attention or transformer [Vaswani & Shazeer+ 17] model"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Appendix Motivation",
        "text": [
          "I Neural HMM compared to attention-based systems",
          "recurrent encoder and decoder without attention component replacing attention mechanism by a first-order HMM alignment model attention levels: deterministic normalized similarity scores",
          "HMM alignments: discrete random variables and must be marginalized separating the alignment model from the lexicon model",
          "more flexibility in modeling and training",
          "avoids propagating errors from one model to another implies an extended degree of interpretability and control over the model"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Appendix Analysis",
        "text": [
          "Attention-based NMT Neural HMM",
          "he he er wollte nie an irgendeiner A rt von A useinandersetzung teilnehm en er wollte nie an irgendeiner A rt von A useinandersetzung teilnehm en",
          "I Attention weight and alignment matrices visualized in heat map form",
          "I Generated by attention NMT baseline and neural HMM",
          "28-year-old cook found dead in San Francisco Mall source reference attention NMT neural HMM",
          "28-jahriger Koch in San Francisco Mall tot aufgefunden",
          "28-Year-Old Chef Found Dead at San Francisco Mall",
          "28-year-old cook in San Francisco Mall found dead",
          "Frankie hat in GB bereits fast 30 Jahre Gewinner geritten , was toll ist .",
          "Frankie s been riding winners in the UK for the best part of 30 years which is great to see .",
          "Frankie has ridden winners in the UK for almost 30 years , which is great . source reference attention NMT neural HMM",
          "Wer baut Braunschweigs gunstige Wohnungen ?",
          "Who is going to build Braunschweig s low-cost housing ?",
          "Who does Braunschweig build cheap apartments ?",
          "Who builds Braunschweig s cheap apartments ?",
          "I Sample translations from the WMT GermanEnglish newstest2017 set",
          "underline source words of interest italicize correct translations bold-face for incorrect translations"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      }
    },
    "paper_title": "Neural Hidden Markov Model for Machine Translation"
  },
  "1063": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Aim",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Data Acquisition",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved. . : Engineering"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Data Processing",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Features",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Prediction",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved.",
          "Tweet Length Tweet Type Tweet Time Tweet Impact LIWC Word2Vec Clusters Unigrams Combined"
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "6": {
        "title": "Analysis",
        "text": [
          "* All differences between means significant at p .001, Mann-Whitne",
          "2019 Bloomberg Finance L.P. All rights reserved.",
          "- Congratulations, condolences and support",
          "- More personal pronouns",
          "- More function words",
          "- More positive and negative sentiment",
          "No features are correlated with unsigned tweets: @-Reply",
          "- More generic usage Sent on Weekends",
          "Other feature analysis in paper # Retweets"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "7": {
        "title": "Takeaways",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Analyzing Linguistic Differences between Owner and Staff Attributed Tweets"
  },
  "1064": {
    "slides": {
      "0": {
        "title": "Background i",
        "text": [
          "Humor Detection is about telling if a text is humorous",
          "My grandpa came to America looking for freedom, but it didnt work out, in the next flight my grandma was coming."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Background ii",
        "text": [
          "Some previous work, such as Barbieri and Saggion (2014),",
          "Mihalcea and Strapparava (2005), and Sjobergh and Araki",
          "(2007), created binary Humor Classifiers for short texts written in English.",
          "They extracted one-liners from the Internet and from",
          "Beauty is in the eye of the beer holder.",
          "Castro et al. (2016) worked on Spanish tweets since our group is interested in leveraging tools for Spanish.",
          "Back then, we conceived the first and only Spanish dataset to study Humor."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Background iii",
        "text": [
          "Castro et al. (2016) corpus provided 40k tweets from 18 accounts, with 34k annotations. The annotators decided if the tweets were humorous or not, and if so they rated them from 1 to 5.",
          "However, the dataset has some issues:",
          "1. low inter-annotator agreement (Fleiss",
          "2. limited variety of sources (humorous: 9 Twitter accounts, non-humorous: 3 about news accounts, 3 about inspirational thoughts and 3 about curious facts)",
          "3. very few annotations per tweet (less than 2 in average, around 500 with 5 annotations)",
          "4. only 6k were considered humorous by the crowd"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Background iv",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Related work",
        "text": [
          "Potash, Romanov, and Rumshisky (2017) built a corpus based on tweets in English that aims to distinguish the degree of funniness in a given tweet. They used the tweet set issued in response to a TV game show, labeling which tweets were considered humorous by the show. Used in SemEval 2017 Task"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Extraction i",
        "text": [
          "1. We wanted to have at least 20k tweets as balanced as possible, at least 5 annotations each.",
          "2. We fetched tweets from 50 humorous accounts from",
          "Spanish speaking countries, taking 12k at random.",
          "3. We fetched tweet samples written in Spanish throughout"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Extraction ii",
        "text": [
          "4. As expected, both sources contained a mix of humorous and non-humorous tweets."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Annotation i",
        "text": [
          "We built a web page, similar to the one used by Castro et al."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Annotation ii Clasifica tweets y divertite",
        "text": [],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1064-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Annotation iii",
        "text": [
          "Tweets were randomly shown to annotators, but avoiding duplicates (by using web cookies).",
          "We wanted UI to be the more intuitive and self-explanatory as possible, trying not to induce any bias on users and letting them come up with their own definition of humor.",
          "The simple and friendly interface is meant to keep the users engaged and having fun while classifying tweets."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Annotation iv",
        "text": [
          "People annotated from March 8th to 27th, 2018.",
          "The first tweets shown to every session were the same: 3 tweets for which we know a clear answer.",
          "During the annotation process, we added around 4,500 tweets coming from humorous accounts to help the balance."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Dataset i",
        "text": [
          "The dataset consists of two CSV files: tweets and annotations.",
          "tweet ID session ID date value"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Dataset ii",
        "text": [
          "high quality annotations (excluding skips)"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Annotation Distribution",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Class Distribution",
        "text": [],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1064-Figure3-1.png"
        ]
      },
      "15": {
        "title": "Annotators Distribution",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Agreement",
        "text": [
          "If we include the low quality,",
          "If we only consider the 11 annotators who tagged more",
          "humor and funniness agreement are respectively 0.6345"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "We created a better version of a dataset to study Humor in",
          "Spanish. 27,282 tweets coming from multiple sources, with",
          "107,634 annotations high quality annotations.",
          "Significant inter-annotator agreement value.",
          "It is also a first step to study subjectivity. Although more annotations per tweet would be appropriate, there is a subset of a thousand tweets with at least six annotations that could be used to study peoples opinion on the same instances."
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "18": {
        "title": "HAHA Task",
        "text": [
          "Two subtasks: Humor Classification and Funniness",
          "Subset of 20k tweets.",
          "7 and 2 submissions respectively."
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "19": {
        "title": "Analysis",
        "text": [],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "A Crowd-Annotated Spanish Corpus for Humor Analysis"
  },
  "1065": {
    "slides": {
      "0": {
        "title": "Dependency to String Grammar",
        "text": [
          "HDR rules: the source side is generalized HDR fragments and the",
          "target side is strings. H rules: the source side is a word and the target side is words or strings."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Rule Acquisition",
        "text": [
          "Annotate the necessary information on each",
          "node of dependency trees for translation rule",
          "Identification of acceptable HDR fragments",
          "Identify HDR fragments from the annotated",
          "trees for HDR rules generation",
          "Generate a set of HDR rules according to the",
          "identified acceptable HDR fragments"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Decoding",
        "text": [
          "Bottom up chart parsing",
          "Find the best derivation among all possible",
          "Apply H rules when n is leaf node",
          "Apply HDR rules when n is an internal node",
          "Generate the candidate translation for n by"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Experiment and Evaluation",
        "text": [
          "SRI Language Modeling Toolkit",
          "System Rule # BLEU RIBES",
          "Baseline: MOSES PBSMT system",
          "Ours performed better although using only a small",
          "size of translation rules"
        ],
        "page_nums": [
          4
        ],
        "images": []
      }
    },
    "paper_title": "A Dependency-to-String Model for Chinese-Japanese SMT System"
  },
  "1068": {
    "slides": {
      "0": {
        "title": "What do we want to do",
        "text": [
          "To test several extremely simple techniques",
          "which, are reported to be efficient in previous researches and, WAT offers valuable human evaluation",
          "if they work, they should be used more widely"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "As a result",
        "text": [
          "reverse pre-reordering for Japanese-to-English translation character-based Korean-to-Japanese translation"
        ],
        "page_nums": [
          2
        ],
        "images": []
      }
    },
    "paper_title": "NICT at WAT 2015"
  },
  "1069": {
    "slides": {
      "0": {
        "title": "Transition Based Parsing with Arc Hybrid",
        "text": [
          "Drive your friend home root"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "1": {
        "title": "Static Oracle for Arc Hybrid",
        "text": [
          "[Drive your friend home **root**]",
          "Drive [friend home **root**]"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "2": {
        "title": "Dynamic Oracle for Arc Hybrid",
        "text": [
          "Drive your friend home **root**]",
          "Drive friend home **root**]"
        ],
        "page_nums": [
          23,
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "3": {
        "title": "Arc Hybrid Parsing with Reordering",
        "text": [
          "Drive your friend home root"
        ],
        "page_nums": [
          31,
          32,
          33
        ],
        "images": []
      },
      "4": {
        "title": "Hyrid Parsing with Reordering",
        "text": [
          "found best example ever",
          "Thanks Carlos Gomez-Rodriguez for the example!"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "5": {
        "title": "Arc Hyrid Parsing with Reordering",
        "text": [
          "found best example ever",
          "found1 best2 example4 ever3",
          "found1 best2 ever3 example4"
        ],
        "page_nums": [
          35,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47
        ],
        "images": []
      },
      "6": {
        "title": "found best example ever",
        "text": [],
        "page_nums": [
          36
        ],
        "images": []
      },
      "7": {
        "title": "A Sta ynamic Oracl",
        "text": [
          "found best example ever",
          "found1 best2] example4 ever3"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "8": {
        "title": "A Static Dynamic Oracle",
        "text": [
          "found best example ever"
        ],
        "page_nums": [
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "9": {
        "title": "Transition Based Parsing using BiLSTM",
        "text": [
          "the brown fox jumped root",
          "Vthe Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "LSTM f LSTM f LSTM f LSTM f LSTM f",
          "X the X brown X fox X jumped X root",
          "t h e b r o w n f o x j u m p e d e(the) e(brown) e(fox) e(jumped) pe(the) pe(brown) pe(fox) pe(jumped)"
        ],
        "page_nums": [
          55
        ],
        "images": []
      },
      "10": {
        "title": "Transition Based Parsing using BiLSTMs",
        "text": [
          "X the X brown X fox X jumped X root",
          "Vthe Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "LSTM f LSTM f LSTM f LSTM f LSTM f"
        ],
        "page_nums": [
          56,
          57,
          58,
          60,
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "11": {
        "title": "Xth",
        "text": [],
        "page_nums": [
          59
        ],
        "images": []
      },
      "12": {
        "title": "Experiments",
        "text": [
          "Miryam de Lhoneux, Sara Stymne and Joakim Nivre Non-Projective Parsing with a Static-Dynamic Oracle 19",
          "os 03 =e English Arabic Portuguese Basque _Ancient-Greek",
          "Miryam de Lhoneux, Sara Stymne and Joakim Nivre eee nn a ence ity",
          "Miryam de Lhoneux, Sara Stymne and Joakim Nivre Sree enins ha Static-Dynamic Oracle",
          ") Stat Ml Static-Dynamic",
          "Ancient-Greek Basque Portuguese English",
          "Stat Static-Dynamic ME Pproj Mm Proj",
          "Vien caren nnGient meen ac NO enn Re ann ae"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75
        ],
        "images": []
      },
      "13": {
        "title": "Conclusion",
        "text": [
          "Miryam de Lhoneux, Sara Stymne and Joakim Nivre Non-Projective Parsing with a Static-Dynamic Oracle PT)",
          "Miryam de Lhoneux, Sara Stymne and Joakim Nivre Re eenaainnt OY PT)",
          "We integrated a swap transition into arc-hybrid",
          "We defined an oracle that is partially dynamic for this system",
          "Our system benefits from error exploration",
          "A fully dynamic oracle?"
        ],
        "page_nums": [
          76,
          77,
          78,
          79,
          80,
          82,
          83
        ],
        "images": []
      },
      "14": {
        "title": "Conclusio",
        "text": [
          "We integrated a swap transition into arc-hybrid",
          "We defined an oracle that is partially dynamic for this system",
          "Our system benefits from error exploration"
        ],
        "page_nums": [
          81
        ],
        "images": []
      }
    },
    "paper_title": "Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle"
  },
  "1071": {
    "slides": {
      "0": {
        "title": "Document Sentiment Example",
        "text": [
          "Rude service, medicore food...there are tons of restaurants in NY...stay",
          "away from this one (Pontiki et al., 2015)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Aspect Based Sentiment Analysis ABSA Example",
        "text": [
          "Rude service, medicore food...there are tons of restaurants in NY...stay",
          "away from this one (Pontiki et al., 2015)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Target Dependent Sentiment Analysis TDSA Example",
        "text": [
          "Rude service, medicore food...there are tons of restaurants in NY...stay",
          "away from this one (Pontiki et al., 2015)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Generalisability",
        "text": [
          "1. Domain Restaurant, Laptop",
          "2. Type Social Media, Reviews",
          "3. Medium Written, Spoken",
          "4. Data Set Size",
          "5. Data Set Characteristics number of targets in a sentence."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Generalisability within TDSA",
        "text": [
          "Table 1: Methods and Datasets",
          "Social Media Reviews News Not Applicable"
        ],
        "page_nums": [
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Why Reproduce",
        "text": [
          "Authors Code with paper",
          "Original Re-used the same code Re-implemented"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Vo et al 2015 Method",
        "text": [
          "Pooling (Max, Min, Prod, Std, Avg)",
          "Left Context Target Context Right Context"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Vo et al 2015 Reproduction Result",
        "text": [
          "Scaling features is important - 15-25% difference"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Tang et al 2016b Method",
        "text": [
          "hr1 hl+1 LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM h1 hl1 hl hl+1 hr2 hl+2 hr1 hr hr+1 hn",
          "Left Context Target Context Target Context Right Context"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Tang et al 2016b Reproduction Result",
        "text": [
          "Methods O R (Max) R (Mean)",
          "Repeating experiments with different seed values is important."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Mass Evaluation Datasets",
        "text": [
          "Dataset Domain Type Size Medium ATS",
          "SemEval 14 L L RE W",
          "SemEval 14 R R RE W",
          "Mitchel G S W",
          "Dong Twitter G S W",
          "Election Twitter P S W",
          "YouTuBean MP RE/S SP",
          "L=Laptop, R=Restaurant, G=General, P=Politics, MP=Mobile Phones,",
          "RE=Review, S=Social Media, W=Written, SP=Spoken, ATS=Average"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Mass Evaluation",
        "text": [],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "12": {
        "title": "Contributions",
        "text": [
          "Generalisability: First to report results across across three different",
          "dataset properties: 1. Domain, 2. Type, 3. Medium.",
          "Reproduction: Open source TDSA framework with three different",
          "Code, documentation, Jupyter notebook examples, and model zoo:"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Bringing replication and reproduction together with generalisability in NLP: Three reproduction studies for Target Dependent Sentiment Analysis"
  },
  "1072": {
    "slides": {
      "0": {
        "title": "Question Answering with Knowledge Base",
        "text": [
          "Large-scale Knowledge Base 5",
          "Properties of billions of entities papa BO. mreebace",
          "- Plus relations among them barack Obama",
          "Ea sea Matsbaopane YAGO",
          ": : child-o child-of",
          "* Question Answering _ | OpenlE/ReVerb",
          "What are the names of Obamas daughters? Microsoft Satori",
          "Ax. parent(Obama, x) A gender(x, Female)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Search Engine QA Engine",
        "text": [
          "who was Katy Perry's husband second tallest mountain in england|",
          "who was tom cruise's first wife",
          "Wet Web Shopping Maps News Images More + Search tools",
          "Web News Images Shopping",
          "C7 when did minnesota becor",
          "Minnesota - Scafell Pike"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Generic Semantic Parsing eg Kwiatkowski 13",
        "text": [
          "Who is Justin Biebers sister?",
          ". sibling_of(justin_bieber, x) gender(x, female)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "KB Specitic Semantic Parsing eg Berant 13",
        "text": [
          "Who is Justin Biebers sister?",
          ". sibling_of(justin_bieber, x) gender(x, female)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Key Challenges",
        "text": [
          "What was the date that Minnesota became a state?",
          "When was the state Minnesota created?",
          "Minnesota's date it entered the union?"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Staged Query Graph Generation",
        "text": [
          "(1) Link Topic Entity",
          "(2) Identify Core Inferential Chain",
          "Family Guy cast y actor x",
          "Family Guy Family Guy writer y start x",
          "Family Guy genre x",
          "s7 argmin Meg Griffin",
          "Family Guy y x"
        ],
        "page_nums": [
          6,
          7,
          12,
          13,
          14
        ],
        "images": [
          "figure/image/1072-Figure7-1.png",
          "figure/image/1072-Figure5-1.png",
          "figure/image/1072-Figure4-1.png"
        ]
      },
      "6": {
        "title": "Knowledge Base",
        "text": [
          "Family Guy cvt2 Lacey Chabert"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1072-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Query Graph",
        "text": [
          "topic entity core infe rential chain",
          "Family Guy cast y x"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1072-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Link Topic Entity",
        "text": [],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1072-Figure4-1.png"
        ]
      },
      "9": {
        "title": "Identity Core Inferential Chain",
        "text": [
          "Family Guy cast y actor x",
          "Family Guy Family Guy writer y start x",
          "Family Guy genre x",
          "Who first voiced Meg on Family Guy?"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1072-Figure5-1.png",
          "figure/image/1072-Figure4-1.png"
        ]
      },
      "10": {
        "title": "Relation Matching using Deep Convolutional Neural Networks DSSM Shen 14",
        "text": [
          "Input is mapped to two -dimensional vectors",
          "R R max max max",
          "who voiced meg on castactor <s> w1 w2 wT </s>"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1072-Figure6-1.png"
        ]
      },
      "11": {
        "title": "Augment Constraints",
        "text": [
          "Family Guy cast y actor x Family Guy y x",
          "Who voiced Family Guy",
          "One or more constraint nodes can be added to or",
          ": Additional property of this event (e.g., character MegGriffin",
          ": Additional property of the answer entity (e.g., gender)"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1072-Figure5-1.png",
          "figure/image/1072-Figure2-1.png",
          "figure/image/1072-Figure7-1.png"
        ]
      },
      "12": {
        "title": "Learning Reward Function y",
        "text": [
          "Who first voiced Meg on Family Guy?",
          "Family Guy cast y actor x",
          "s4 Family Guy writer y start x",
          "Family Guy y x"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": [
          "figure/image/1072-Figure5-1.png",
          "figure/image/1072-Figure2-1.png",
          "figure/image/1072-Figure4-1.png",
          "figure/image/1072-Figure7-1.png"
        ]
      },
      "13": {
        "title": "Learning Reward Function Features",
        "text": [
          "=Who first voiced Meg on Family Guy?",
          "Family Guy cast y x"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1072-Figure5-1.png",
          "figure/image/1072-Figure2-1.png",
          "figure/image/1072-Figure4-1.png",
          "figure/image/1072-Figure7-1.png"
        ]
      },
      "14": {
        "title": "WebQuestions Dataset Berant 13",
        "text": [
          "What character did Natalie Portman play in Star Wars? Padme Amidala",
          "What currency do you use in Costa Rica? Costa Rican colon",
          "What did Obama study in school? political science",
          "What do Michelle Obama do for a living? writer, lawyer",
          "What killed Sammy Davis Jr? throat cancer [Examples from Berant]"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "15": {
        "title": "Creating Training Data trom Q A Pairs",
        "text": [
          "Relation Matching (Identifying Core Inferential Chain)",
          "what was <e> known for people.person.profession",
          "what kind of government does <e> have location.country.form_of_government",
          "what year were the <e> established sports.sports_team.founded",
          "what city was <e> born in people.person.place_of_birth",
          "what did <e> die from people.deceased_person.cause_of_death",
          "who married <e> people.person.spouse_s"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "16": {
        "title": "Avg F1 Accuracy on WebQuestions Test Set",
        "text": [],
        "page_nums": [
          26
        ],
        "images": []
      },
      "17": {
        "title": "Contribution from Entity Linking",
        "text": [
          "Method #Entities Covered Ques. Labeled Ent."
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "18": {
        "title": "Contribution from Relation Matching",
        "text": [
          "Fy score of query graphs that have only a core inferential",
          "Questions trom search engine users are short & simple",
          "Even if the correct parse requires more constraints, the less constrained graph still gets a partial score"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "19": {
        "title": "Error Analysis",
        "text": [
          "A random sample of 100 incorrectly answered questions"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions 1 2",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "21": {
        "title": "Conclusions 2 2",
        "text": [],
        "page_nums": [
          31
        ],
        "images": []
      }
    },
    "paper_title": "Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base"
  },
  "1074": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "User attribute prediction from text is successful:",
          "I Gender (Burger et al. 2011 EMNLP)",
          "I Location (Eisenstein et al. 2011 EMNLP)",
          "I Personality (Schwartz et al. 2013 PLoS One)",
          "I Impact (Lampos et al. 2014 EACL)",
          "I Political orientation (Volkova et al. 2014 ACL)",
          "I Mental illness (Coppersmith et al. 2014 ACL)",
          "Downstream applications are benefiting from this:",
          "I Sentiment analysis (Volkova et al. 2013 EMNLP)",
          "I Text classification (Hovy 2015 ACL)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "However",
        "text": [
          "Socio-economic factors (occupation, social class, education, income) play a vital role in language use",
          "No large scale user level dataset to date",
          "I sociological analysis of language use",
          "I embedding to downstream tasks (e.g. controlling for"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "At a Glance",
        "text": [
          "I Predicting new user attribute: occupation",
          "I New dataset: user occupation",
          "I Gaussian Process classification for NLP tasks",
          "I Feature ranking and analysis using non-linear methods"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Standard Occupational Classification",
        "text": [
          "Standardised job classification taxonomy",
          "Developed and used by the UK Office for National Statistics",
          "Jobs grouped by skill requirements",
          "C1 Managers, Directors and Senior Officials",
          "I 11 Corporate Managers and Directors",
          "I 1115 Chief Executives and Senior Officials",
          "Job: chief executive, bank manager",
          "I 1116 Elected Officers and Representatives",
          "I 112 Production Managers and Directors",
          "I 113 Functional Managers and Directors",
          "I 115 Financial Institution Managers and Directors",
          "I 116 Managers and Directors in Transport and Logistics",
          "I 117 Senior Officers in Protective Services",
          "I 118 Health and Social Services Managers and Directors",
          "I 119 Managers and Directors in Retail and Wholesale",
          "I 12 Other Managers and Proprietors",
          "Job: mechanical engineer, pediatrist, postdoctoral researcher",
          "C3 Associate Professional and Technical Occupations",
          "Job: system administrator, dispensing optician",
          "C4 Administrative and Secretarial Occupations",
          "Job: legal clerk, company secretary",
          "C5 Skilled Trades Occupations",
          "Job: electrical fitter, tailor",
          "C6 Caring, Leisure, Other Service Occupations",
          "Job: school assistant, hairdresser",
          "C7 Sales and Customer Service Occupations",
          "Job: sales assistant, telephonist",
          "C8 Process, Plant and Machine Operatives",
          "Job: factory worker, van driver",
          "Job: shelf stacker, bartender"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Data",
        "text": [
          "Users collected by self-disclosure of job title in profile",
          "Manually filtered by the authors",
          "10M tweets, average 94.4 users per 3-digit group",
          "Here we classify only at the 1-digit top level group (9 classes)",
          "Feature representation and labels available online",
          "Raw data available for research purposes on request (per"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Features",
        "text": [
          "User Level features (18), such as:",
          "Focus on interpretable features for analysis",
          "Compute over reference corpus of 400M tweets:",
          "I SVD embeddings and clusters",
          "I Word2Vec (W2V) embeddings and clusters"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "6": {
        "title": "SVD Features",
        "text": [
          "Compute word word similarity matrix",
          "Similarity metric is Normalized PMI (Bouma 2009) using the entire tweet as context",
          "User is represented by summing its word representations",
          "The low-dimensional features offer no interpretability",
          "Spectral clustering to get hard clusters of words (30, 50, 100, 200 clusters)",
          "Each cluster consists of distributionally similar words topic",
          "User is represented by the number of times he uses a word from each cluster."
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Word2Vec Features",
        "text": [
          "Trained Word2Vec (layer size 50) on our Twitter reference corpus",
          "Spectral clustering on the word word similiarity matrix (30,",
          "Similarity is cosine similarity of words in the embedding space"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Gaussian Processes",
        "text": [
          "Brings together several key ideas in one framework:",
          "Elegant and powerful framework, with growing popularity in machine learning and application domains"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Gaussian Process Graphical Model View",
        "text": [
          "I f RD R is a latent",
          "I y is a noisy realisation",
          "I k is the covariance",
          "I m and are learnt"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Gaussian Process Classification",
        "text": [
          "Pass latent function through logistic function to squash the input from (,) to obtain probability, (x) p(yi fi)",
          "(similar to logistic regression)",
          "The likelihood is non-Gaussian and solution is not analytical",
          "Inference using Expectation propagation (EP)",
          "FITC approximation for large data",
          "ARD kernel learns feature importance features most discriminative between classes",
          "We learn 9 one-vs-all binary classifiers",
          "This way, we find the most predictive features consistent for all classes"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "11": {
        "title": "Gaussian Process Resources",
        "text": [
          "I GPs for Natural Language Processing tutorial (ACL 2014)",
          "I GP Schools in Sheffield and roadshows in Kampala,",
          "I Annotated bibliography and other materials",
          "I GPy Toolkit (Python)"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      },
      "12": {
        "title": "Prediction",
        "text": [
          "LR SVM-RBF GP Baseline",
          "Stratified 10 fold cross-validation"
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "13": {
        "title": "Prediction Analysis",
        "text": [
          "User level features have no predictive value",
          "Word2Vec features are better than SVD/NPMI for prediction",
          "Non-linear methods (SVM-RBF and GP) significantly outperform linear methods",
          "52.7% accuracy for 9-class classification is decent"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "14": {
        "title": "Class Comparison",
        "text": [
          "Jensen-Shannon Divergence between topic distributions across occupational classes",
          "Some clusters of occupations are observable"
        ],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1074-Figure3-1.png"
        ]
      },
      "15": {
        "title": "Feature Analysis",
        "text": [
          "Rank Manual Label Topic (most frequent words)",
          "Arts art, design, print, collection, poster, painting, custom, logo, printing, drawing",
          "Health risk, cancer, mental, stress, pa- tients, treatment, surgery, dis- ease, drugs, doctor",
          "Beauty Care beauty, natural, dry, skin, mas- sage, plastic, spray, facial, treat- ments, soap",
          "Higher Education students, research, board, stu- dent, college, education, library, schools, teaching, teachers",
          "Software Engineering service, data, system, services, access, security, development, software, testing, standard",
          "Most predictive Word2Vec 200 clusters as given by Gaussian",
          "Football van, foster, cole, winger, terry, reckons, youngster, f ielding, kenny rooney,",
          "Corporate patent, industry, reports, global,",
          "Cooking recipe, meat, salad, egg, soup, sauce, beef, served, pork, rice",
          "Elongated Words wait, till, til, yay, ahhh, hoo, woo, woot, whoop, woohoo",
          "Politics human, culture, justice, religion, democracy, religious, humanity, tradition, ancient, racism",
          "Comparison of mean topic usage between supersets of"
        ],
        "page_nums": [
          27,
          28,
          32
        ],
        "images": []
      },
      "16": {
        "title": "Feature Analysis Cumulative density functions",
        "text": [
          "Topic more prevalent CDF line closer to bottom-right corner"
        ],
        "page_nums": [
          29,
          30,
          31
        ],
        "images": []
      },
      "17": {
        "title": "Take Aways",
        "text": [
          "User occupation influences language use in social media",
          "Non-linear methods (Gaussian Processes) obtain significant gains over linear methods",
          "Topic (clusters) features are both predictive and interpretable",
          "New dataset available for research"
        ],
        "page_nums": [
          33
        ],
        "images": []
      }
    },
    "paper_title": "An analysis of the user occupational class through Twitter content"
  },
  "1075": {
    "slides": {
      "0": {
        "title": "Two approaches to summarization",
        "text": [
          "Extractive Summarization Abstractive Summarization",
          "Select parts (typically sentences) of the original text to form a summary.",
          "Generate novel sentences using natural language generation techniques.",
          "Too restrictive (no paraphrasing)",
          "Most past work is extractive",
          "More flexible and human",
          "Necessary for future progress"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Cnn Daily Mail dataset",
        "text": [
          "The papal bill Pope Francis insisted on paying himself... before catching the bus home after winning the election",
          "also chose to use a bus instead of a chauffeur driven car",
          "+ The 76-year-old has eschewed ceremonial traditions for a more humble approach",
          "Pope Francis insisted on returning to his hotel to settle the bi",
          "With the spiritual wellbeing of the worlds 1.2 billion Catholics is on his shoulders he must have quite a to-do list.",
          "responsibilities, Francis did not forget to stop off - between engagements - to",
          "Staff at the central Rome priests residence where Bergoglio was staying before the conclave, were astonished when the newly elected Pope strolled in to collect his luggage and settle the bil",
          "Comers Pope Franci ted on returning to the hotel to collect settling the hotel bill himself Inged to set a good example he joked He was driven to the hotel in a simple car and The Rev. Pawel Rytel-Andrianok, who teaches at tho nearby Pontifical Holy Cross University and is staying at the residence, said that workers at the hotel were touched by the Pope's decision to retum and bid them farewell",
          "\"He wanted to come here because he wanted to thank the personnel, people who work in this",
          "house, he said. 'He greeted them one by one, no rush, the whole staff, one by one. Mr Rytel-",
          "Andrianek added that Francis apparently knew everyone by name.",
          "A Vatican spokesman said: 'He wanted to get his luggage and the bags. He had left everything",
          "\"He then stopped in the office, greeted everyone and decided to pay the bill for the room... because he was concerned about giving a good exampie of what priests and bishops should do.",
          "{or official business. And ever ardinals back to their lodgings,",
          "Meeting cardinals yesterday on his second day of Papal business he eschewed protocol in favour of Kissing on two cheeks, shaking hands and hugging.",
          "Francis is already winning piaudits for hi",
          "us, saying: | came on the bus, so Igo home on the bus,",
          "He told his deputies that old people like himself are like good wine, getting better with age, before urging them to impart their wisdom to the young,",
          "Francis began his reign irjunorthodox fashion)as he shunned public events in order to pray to the Virgin Mary.",
          "Speaking in Italian without notes, he said: We can walk all we want, we can build many things, but if we dont proclaim Jesus Christ. something is wrong. We would become a compassionate NGO and not a Church which is the bride of Christ. \"He who does not pray to the Lord prays to the devil. When we don't proclaim Jesus Christ, we proclaim the worldliness of the devil, the worldliness of the demon. We must always wakk in the presence of the Lord, in the light of the Lord, always trying to live in an ireprehensible way,\" he said in a heartfelt homily of a parish priest, loaded with biblical references, and simple imagery. 'When we walk without the cross, when we build without the cross and when we proclaim Christ without the cross, we are not disciples of the Lord. We are worldly.\" he said We may be bishops, priests, cardinals, popes, all of this, but we are not disciples of the Lord, he said."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Sequence to sequence attention model",
        "text": [
          "Germany emerge victorious in win against Argentina on Saturday <START > G ermany",
          "Source Text Partial Summary",
          "German y beat A rgentin a STOP>"
        ],
        "page_nums": [
          3,
          4,
          5
        ],
        "images": [
          "figure/image/1075-Figure2-1.png",
          "figure/image/1075-Figure3-1.png"
        ]
      },
      "3": {
        "title": "Two Problems",
        "text": [
          "Problem 1: The summaries sometimes reproduce factual details inaccurately.",
          "e.g. Germany beat Argentina Incorrect rare or",
          "Problem 2: The summaries sometimes repeat themselves.",
          "e.g. Germany beat Germany beat Germany beat",
          "Solution: Use a pointer to copy words.",
          "Solution: Penalize repeatedly attending to same parts of the source text."
        ],
        "page_nums": [
          6,
          7,
          11,
          12
        ],
        "images": []
      },
      "4": {
        "title": "Get to the point",
        "text": [
          "Germany emerge victorious in win against Argentina on Saturday Best of both worlds:",
          "extraction abstraction Source Text",
          "Incorporating copying mechanism in sequence-to-sequence learning. Gu et al., 2016. Language as a latent variable: Discrete generative models for sentence compression. Miao and Blunsom, 2016."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Pointer generator network",
        "text": [
          "Germany emerge victorious in win against Argentina on Saturday <START > G ermany beat",
          "Source Text Partial Summary"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1075-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Improvements",
        "text": [
          "UNK UNK was expelled from the dubai open chess tournament gaioz nigalidze was expelled from the dubai open chess tournament",
          "the rio olympic games the rio olympic games"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Reducing repetition with coverage",
        "text": [
          "Coverage = cumulative attention = what has been covered so far",
          "Modeling coverage for neural machine translation. Tu et al., 2016, Coverage embedding models for neural machine translation. Mi et al., 2016 Distraction-based neural networks for modeling documents. Chen et al., 2016.",
          "Use coverage as extra input to attention mechanism.",
          "Penalize attending to things that have already been covered.",
          "Result: repetition rate reduced to",
          "level similar to human summaries"
        ],
        "page_nums": [
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "8": {
        "title": "Summaries are still mostly extractive",
        "text": [],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Results",
        "text": [
          "ROUGE compares the machine-generated summary to the human-written reference summary and counts co-occurrence of 1-grams, 2-grams, and longest common sequence.",
          "Nallapati et al. 2016 Previous best abstractive result",
          "Ours (pointer-generator) Our improvements",
          "Ours (pointer-generator + coverage)",
          "Paulus et al. 2017 (hybrid RL approach) worse ROUGE; better human eval",
          "Paulus et al. 2017 (RL-only approach) better ROUGE; worse human eval"
        ],
        "page_nums": [
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "10": {
        "title": "The difficulty of evaluating summarization",
        "text": [
          "There are many correct ways to summarize",
          "ROUGE is based on strict comparison to a reference summary",
          "Take first 3 sentences as summary higher ROUGE than (almost) any published system",
          "Partially due to news article structure"
        ],
        "page_nums": [
          22,
          23,
          24
        ],
        "images": []
      },
      "11": {
        "title": "First sentences not always a good summary",
        "text": [
          "A crowd gathers near the entrance of Tokyo's u pscale Mitsukoshi Department Store, which traces it s roots to a kimono shop in the late 17th century.",
          "Fitting with the store's history, the new greeter wears a traditional Japanese kimono while delivering information to the growing crowd, whose expressions vary from amusement to bewilderment. Irrelevant",
          "It's hard to imagine the store's founders in the late",
          "1600's could have imagined this kind of employee.",
          "That's because the greeter is not a human -- it's a robot.",
          "Aiko Chihira is an android manufactured by Toshiba, designed to look and move like a real person.",
          "Our system starts here"
        ],
        "page_nums": [
          25
        ],
        "images": []
      }
    },
    "paper_title": "Get To The Point: Summarization with Pointer-Generator Networks"
  },
  "1076": {
    "slides": {
      "0": {
        "title": "TUPA Transition based UCCA Parser",
        "text": [
          "The first parser to support the combination of three properties:",
          "Non-terminal nodes - entities and events over the text",
          "take a long bath",
          "Reentrancy - allow argument sharing",
          "Discontinuity - conceptual units are split",
          "- needed for many semantic schemes (e.g. AMR, UCCA)."
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Introduction",
        "text": [],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Linguistic Structure Annotation Schemes",
        "text": [
          "Semantic dependencies (Oepen et al., 2016)",
          "You want to take a long bath",
          "ARG2 BV top ARG2 ARG1 Semantic (DM)",
          "Semantic role labeling (PropBank, FrameNet)",
          "UCCA (Abend and Rappoport, 2013)",
          "Other semantic representation schemes1",
          "Semantic representation schemes attempt to abstract away from syntactic detail that does not affect meaning:",
          "1See recent survey (Abend and Rappoport, 2017)"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "The UCCA Semantic Representation Scheme",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Universal Conceptual Cognitive Annotation UCCA",
        "text": [
          "Cross-linguistically applicable (Abend and Rappoport, 2013).",
          "Stable in translation (Sulem et al., 2015).",
          "Rapid and intuitive annotation interface (Abend et al., 2017).",
          "Usable by non-experts. ucca-demo.cs.huji.ac.il",
          "Facilitates semantics-based human evaluation of machine"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Graph Structure",
        "text": [
          "UCCA generates a directed acyclic graph (DAG).",
          "Text tokens are terminals, complex units are non-terminal nodes.",
          "Remote edges enable reentrancy for argument sharing.",
          "Phrases may be discontinuous (e.g., multi-word expressions).",
          "- - - remote edge",
          "D adverbial F function You want to take a long bath"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Transition based UCCA Parsing",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Transition Based Parsing",
        "text": [
          "First used for dependency parsing (Nivre, 2004).",
          "Parse text w1 wn to graph G incrementally by applying transitions to the parser state: stack, buffer and constructed graph.",
          "You want to take a long bath",
          "{Shift, Reduce, NodeX , Left-EdgeX , Right-EdgeX",
          "Left-RemoteX , Right-RemoteX , Swap, Finish}",
          "Support non-terminal nodes, reentrancy and discontinuity."
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Example",
        "text": [
          "You want to take a long bath",
          "to A C F C",
          "want You to take a long bath",
          "You take a long bath",
          "You a long bath"
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47
        ],
        "images": []
      },
      "9": {
        "title": "Training",
        "text": [
          "An oracle provides the transition sequence given the correct graph:",
          "take a long bath",
          "Shift, Right-EdgeA, Shift, Swap, Right-EdgeP Reduce, Shift,",
          "Shift, NodeF Reduce, Shift, Shift, NodeC Reduce, Shift, Right-EdgeP Shift, Right-EdgeF Reduce, Shift, Swap, Right-EdgeD Reduce, Swap, Right-EdgeA, Reduce, Reduce, Shift, Shift, Left-RemoteA, Shift, Right-EdgeC Finish"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "10": {
        "title": "TUPA Model",
        "text": [
          "Learn to greedily predict transition based on current state.",
          "Experimenting with three classifiers:",
          "Sparse Perceptron with sparse features (Zhang and Nivre, 2011).",
          "MLP Embeddings + feedforward NN (Chen and Manning, 2014).",
          "BiLSTM Embeddings + deep bidirectional LSTM + MLP",
          "Features: words, POS, syntactic dependencies, existing edge labels from the stack and buffer + parents, children, grandchildren; ordinal features (height, number of parents and children)",
          "Effective lookahead encoded in the representation.",
          "LSTM LSTM LSTM LSTM LSTM L STM LSTM",
          "You want to take a long bath"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "11": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          55
        ],
        "images": []
      },
      "12": {
        "title": "Experimental Setup",
        "text": [
          "Out-of-domain: English part of English-French parallel corpus,",
          "Twenty Thousand Leagues Under the Sea (506 sentences)."
        ],
        "page_nums": [
          56
        ],
        "images": []
      },
      "13": {
        "title": "Baselines",
        "text": [
          "No existing UCCA parsers conversion-based approximation.",
          "Bilexical DAG parsers (allow reentrancy):",
          "DAGParser (Ribeyre et al., 2014): transition-based.",
          "TurboParser (Almeida and Martins, 2015): graph-based.",
          "Tree parsers (all transition-based):",
          "MaltParser (Nivre et al., 2007): bilexical tree parser.",
          "Stack LSTM Parser (Dyer et al., 2015): bilexical tree parser. uparse (Maier, 2015): allows non-terminals, discontinuity.",
          "You want to take a long bath",
          "UCCA bilexical DAG approximation (for tree, delete remote edges)."
        ],
        "page_nums": [
          57
        ],
        "images": []
      },
      "14": {
        "title": "Bilexical Graph Approximation",
        "text": [
          "Convert UCCA to bilexical dependencies.",
          "Train bilexical parsers and apply to test sentences.",
          "Reconstruct UCCA graphs and compare with gold standard.",
          "L H U H",
          "A P A P A",
          "A A to Paris",
          "L U A R",
          "After graduation Joe moved to Paris"
        ],
        "page_nums": [
          58
        ],
        "images": [
          "figure/image/1076-Figure5-1.png"
        ]
      },
      "15": {
        "title": "Evaluation",
        "text": [
          "Comparing graphs over the same sequence of tokens,",
          "Match edges by their terminal yield and label.",
          "Calculate labeled precision, recall and F1 scores.",
          "Separate primary and remote edges.",
          "L H U H L H U",
          "A P A P A S A",
          "graduation Joe moved graduation A P F A",
          "R C Joe moved to Paris",
          "Primary: LF6 LP LR Remote: LF1 LP LR"
        ],
        "page_nums": [
          59
        ],
        "images": []
      },
      "16": {
        "title": "Results",
        "text": [
          "TUPABiLSTM obtains the highest F-scores in all metrics:",
          "Primary edges Remote edges",
          "LP LR LF LP LR LF",
          "Comparable on out-of-domain test set:"
        ],
        "page_nums": [
          60,
          61
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "UCCAs semantic distinctions require a graph structure including non-terminals, reentrancy and discontinuity.",
          "TUPA is an accurate transition-based UCCA parser, and the f irst to support UCCA and any DAG over the text tokens.",
          "Outperforms strong conversion-based baselines.",
          "More languages (German corpus construction is underway).",
          "Parsing other schemes, such as AMR.",
          "Compare semantic representations through conversion.",
          "Text simplification, MT evaluation and other applications."
        ],
        "page_nums": [
          62,
          63,
          64
        ],
        "images": []
      }
    },
    "paper_title": "A Transition-Based Directed Acyclic Graph Parser for UCCA"
  },
  "1077": {
    "slides": {
      "0": {
        "title": "A popular robot baymax",
        "text": [
          "Baymax is capable of maintaining a good spoken dialogue system and learning new knowledge for better understanding and interacting with people.",
          "Big Hero 6 -- Video content owned and licensed by Disney Entertainment, Marvel Entertainment, LLC, etc"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Spoken dialogue system sds",
        "text": [
          "Spoken dialogue systems are the intelligent agents that are able to help users finish tasks more efficiently via speech interactions.",
          "Spoken dialogue systems are being incorporated into various devices",
          "(smart-phones, smart TVs, in-car navigating system, etc).",
          "Apple s Siri Microsofts Cortana Microsofts XBOX Kinect Amazon s Echo Samsungs SMART TV Google Now",
          "https://www.apple.com/ios/siri/ http://www.windowsphone.com/en-us/how-to/wp8/cortana/meet-cortana http://www.xbox.com/en-US/ http://www.amazon.com/oc/echo/ http://www.samsung.com/us/experience/smart-tv/ https://www.google.com/landing/now/"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Large smart device population",
        "text": [
          "The number of global smartphone users will surpass 2 billion in 2016.",
          "As of 2012, there are 1.1 billion automobiles on the earth.",
          "The more natural and convenient input of the devices evolves towards speech"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Challenges for sds",
        "text": [
          "An SDS in a new domain requires",
          "A hand-crafted domain ontology",
          "Utterances labeled with semantic representations",
          "An SLU component for mapping utterances into semantic representations",
          "With increasing spoken interactions, building domain ontologies and annotating utterances cost a lot so that the data does not scale up.",
          "The goal is to enable an SDS to automatically learn this knowledge so that open domain requests can be handled."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Interaction example",
        "text": [
          "find an inexpensive eating place for taiwanese food",
          "Inexpensive Taiwanese eating places include Din Tai",
          "Fung, etc. What do you want to choose? I can help you go there.",
          "Q: How does a dialogue system process this request? Intelligent Agent"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Sds process",
        "text": [
          "find an inexpensive eating place for taiwanese food",
          "seeking=find target=eating place price=inexpensive food=taiwanese food Intelligent Agent Organized Domain Knowledge",
          "Ontology Induction (semantic slot)",
          "Structure Learning (inter-slot relation) PREP_FOR seeking",
          "SPOKEN LANGUAGE UNDERSTANDING (SLU)",
          "SELECT restaurant { restaurant.price=inexpensive restaurant.food=taiwanese food",
          "Intelligent Agent Inexpensive Taiwanese eating places include Din Tai Fung, Boiling Point, etc. What do you want to choose? I can help you go there. (navigation)"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Goals",
        "text": [
          "find an inexpensive eating place for taiwanese food",
          "1. Ontology Induction (semantic slot)",
          "3. Spoken Language Understanding price food AMOD",
          "SELECT restaurant restaurant.price=inexpensive restaurant.food=taiwanese food",
          "4. Behavior Prediction 2. Structure Learning",
          "Knowledge Acquisition SLU Modeling"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "7": {
        "title": "Spoken language understanding",
        "text": [
          "Output: the domain-specific semantic concepts included in each utterance",
          "SLU Modeling by Matrix Factorization",
          "can I have a cheap restaurant",
          "Frame-Semantic Parsing Fw Fs Rw",
          "Unlabeled Collection Word Relation Model Rs SLU Model",
          "Structure Lexical KG Feature Model Knowledge Graph Propagation Model Learning",
          "Slot Relation Model Semantic Semantic KG KG target=restaurant price=cheap",
          "Y.-N. Chen et al., \"Matrix Factorization with Knowledge Graph Propagation for Unsupervised Spoken Language Understanding,\" in Proc. of ACL-IJCNLP, 2015."
        ],
        "page_nums": [
          15,
          19
        ],
        "images": []
      },
      "8": {
        "title": "Probabilistic frame semantic parsing",
        "text": [
          "a linguistically semantic resource, based on the frame-semantics theory",
          "words/phrases can be represented as frames",
          "low fat milk milk evokes the food frame;",
          "low fat fills the descriptor frame element",
          "a state-of-the-art frame-semantics parser, trained on manually annotated FrameNet sentences",
          "Baker et al., \"The berkeley framenet project,\" in Proc. of International Conference on Computational linguistics, 1998. Das et al., \" Frame-semantic parsing,\" in Proc. of Computational Linguistics, 2014."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Frame semantic parsing for utterances",
        "text": [
          "can i have a cheap restaurant Good!",
          "FT LU: can FE LU: i",
          "FT LU: cheap Frame: locale by use",
          "FT: Frame Target; FE: Frame Element; LU: Lexical Unit",
          "1st Issue: adapting generic frames to domain-specific settings for SDSs"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "10": {
        "title": "Knowledge graph propogation model",
        "text": [
          "1ST ISSUE: HOW TO ADAPT GENERIC SLOTS TO DOMAIN-SPECIFIC SETTING?",
          "Assumption: The domain-specific words/slots have more dependency to each other.",
          "Word Observation Slot Candidate i like cheap food restaurant expensiveness food locale_by_use capability Utterance 1 i would like a cheap restaurant Train",
          "Utterance 2 find a restaurant with chinese food",
          "Test Utterance show me a list of cheap restaurants Test",
          "slot relation matrix Word Relation Model Slot Induction Slot Relation Model",
          "Relation matrices allow each node to propagate scores to its neighbors in the knowledge graph, so that domain-specific words/slots have higher scores after matrix multiplication."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "11": {
        "title": "Knowledge graph construction",
        "text": [
          "Syntactic dependency parsing on utterances",
          "nsubj dobj det amod",
          "can i have a cheap restaurant",
          "Slot-based semantic knowledge graph capability s locale_by_use expensiveness",
          "can w Word-based lexical knowledge graph",
          "The edge between a node pair is weighted as relation importance to propagate the scores via a relation matrix",
          "How to decide the weights to represent relation importance?"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": []
      },
      "12": {
        "title": "Weight measurement by embeddings",
        "text": [
          "can = have =",
          "nsubj dobj det amod",
          "can i have a cheap restaurant",
          "capability have a expensiveness locale_by_use",
          "Levy and Goldberg, \" Dependency-Based Word Embeddings,\" in Proc. of ACL, 2014.",
          "Compute edge weights to represent relation importance",
          "Slot-to-slot semantic relation : similarity between slot embeddings",
          "Slot-to-slot dependency relation : dependency score between slot embeddings",
          "Word-to-word semantic relation : similarity between word embeddings",
          ": dependency score between word Word-to-word dependency relation embeddings",
          "Y.-N. Chen et al., Jointly Modeling Inter-Slot Relations by Random Walk on Knowledge Graphs for Unsupervised Spoken Language Understanding,\" in Proc. of NAACL, 2015."
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "13": {
        "title": "Knowledge graph propagation model",
        "text": [
          "Word Observation Slot Candidate",
          "cheap food restaurant expensiveness food locale_by_use",
          "Word Relation Model Slot Induction Slot Relation Model"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "14": {
        "title": "Feature model",
        "text": [
          "Word Observation Slot Candidate cheap food restaurant Utterance 1 expensiveness food locale_by_use",
          "i would like a cheap restaurant",
          "find a restaurant with chinese food",
          "Test Utterance hidden semantics",
          "show me a list of cheap restaurants Test",
          "Slot Induction 2nd Issue: unobserved hidden semantics may benefit understanding"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "15": {
        "title": "Matrix factorization mf",
        "text": [
          "2ND ISSUE: HOW TO LEARN IMPLICIT SEMANTICS?",
          "cheap food restaurant expensiveness food locale_by_use",
          "Word Relation Model Slot Induction Slot Relation Model",
          "Reasoning with Matrix Factorization",
          "MF method completes a partially-missing matrix based on a low-rank latent semantics assumption.",
          "The decomposed matrices represent low-rank latent semantics for utterances and words/slots respectively",
          "The product of two matrices fills the probability of hidden semantics",
          "Word Observation Slot Candidate"
        ],
        "page_nums": [
          29,
          30,
          32
        ],
        "images": []
      },
      "16": {
        "title": "Bayesian personalized ranking for mf",
        "text": [
          "not treat unobserved facts as negative samples (true or false)",
          "give observed facts higher scores than unobserved facts",
          "The objective is to learn a set of well-ranked semantic slots per utterance."
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "17": {
        "title": "Experimental setup",
        "text": [
          "Cambridge University SLU corpus [Henderson, 2012]",
          "Restaurant recommendation in an in-car setting in Cambridge",
          "dialogue slot: addr, area, food, name,",
          "phone, postcode, price range, The mapping table between induced and reference slots task, type",
          "Henderson et al., \"Discriminative spoken language understanding using word confusion networks,\" in Proc. of SLT, 2012."
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "18": {
        "title": "Experiment 1 quality of semantics estimation",
        "text": [
          "Metric: Mean Average Precision (MAP) of all estimated slot probabilities for each utterance",
          "ASR Manual Approach w/o w/ Explicit w/o w/ Explicit",
          "Support Vector Machine Explicit Multinomial Logistic Regression",
          "Random Modeling Implicit Semantics",
          "MF Feature Model + Knowledge Graph Propagation",
          "The MF approach effectively models hidden semantics to improve SLU.",
          "Adding a knowledge graph propagation model further improves performance."
        ],
        "page_nums": [
          35,
          36,
          37,
          38
        ],
        "images": []
      },
      "19": {
        "title": "Experiment 2 effectiveness of relations",
        "text": [
          "All types of relations are useful to infer hidden semantics.",
          "Combining different relations further improves the performance."
        ],
        "page_nums": [
          39,
          40
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [
          "Ontology induction and knowledge graph construction enable systems to automatically acquire open domain knowledge.",
          "MF for SLU provides a principle model that is able to",
          "unify the automatically acquired knowledge",
          "adapt to a domain-specific setting",
          "and then allows systems to consider implicit semantics for better understanding.",
          "The work shows the feasibility and the potential of improving generalization, maintenance, efficiency, and scalability of SDSs.",
          "The proposed unsupervised SLU achieves 43% of MAP on ASR-transcribed conversations."
        ],
        "page_nums": [
          42
        ],
        "images": []
      }
    },
    "paper_title": "Unsupervised Learning and Modeling of Knowledge and Intent for Spoken Dialogue Systems"
  },
  "1078": {
    "slides": {
      "0": {
        "title": "The Multilingual FrameNet Project",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Organize and align existing FrameNet-like projects in 8-10 languages",
          "Provide a multilingual language resource to NLP research, language teachers, etc.",
          "Improve access to and understanding of FrameNet data from all languages (both lexicon and annotated texts)",
          "What data structures are appropriate for the new resource?",
          "How universal are semantic frames? What are implications for MT, cross-linguistic IE & IR, etc.?",
          "How can graph methods help us achieve these goals? We hope to receive suggestions from the TextGraph community"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Frames Frame elements Lemmas and Lexical units",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Frames and Frame Elements (FEs)",
          "Frames and Lexical Units (LUs)",
          "Take place of: admire.v, contempt.n, stigmatize.v, reverence.n",
          "replace.v, replacement.n, take place of.v"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Frames Frame elements Lemmas and Lexical units as a graph",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "Frame relations",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Perspective on (full example)",
          "Causative of, Inchoative of"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Perspective on frame relations",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Note that reality is more complex; Quitting and Firing are not the same kind of event, there are many ways employment can end: resigning under pressure, retirement, etc."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Frame Grapher",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Graph of FrameNet semantic types partial",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Artifact Living_thing Location Body_part Container",
          "Structure Animate_being Region Point Line"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1078-Figure1-1.png"
        ]
      },
      "7": {
        "title": "FN Annotation Annotators view",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Grammatical Function Phrase Type and Other layers",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Construction Grammar is presupposed in FN syntactic analysis, but not fully explicit in the annotation.",
          "NP, VPto, AdjP, etc."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "An English sentence for analysis",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "We will be looking at (a clause from) a sentence from a TED talk by Ken Robinson: Do Schools Kill Creativity?:",
          "The thing they were good at at school was not valued or was actually stigmatized."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Frame shifts in translation",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "We examined frames in two different semantic domains, in two documents with different styles of translation:",
          "Sherlock Holmes, The Hound of the Baskervilles",
          "(professional, literary translation) Motion events",
          "TED, Do Schools Kill Creativity? (volunteer, literal translation) Motion and Communication events",
          "Source Langs Domain Same Partial Diff. Total"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "11": {
        "title": "Uses of Graph methods with Frame Semantic Annotation and Parsing",
        "text": [
          "The FrameNet lexical database as a set of graphs FN annotation Sentences Conclusions References",
          "Visualize of complex relations, including cross-lingual relations",
          "Query with graph expressions (e.g. using Neo4j DB)",
          "Express constraints as graph unification ( Construction grammar)",
          "Summarize valences (Kernel Dependency Graphs, cf.",
          "S or VP Judgement",
          "Ext Cognizer T Obj Dep Evaluee Reason",
          "NP admire NP PPing"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "The current XML format is too close to the DB structure, less than optimal for both humans and machines",
          "A more perspicuous representation would help collaboration in Multilingual FrameNet and NLP research more generally",
          "Graphs can serve this purpose",
          "We welcome your suggestions about how we can make better use of graph representations!"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Graph Methods for Multilingual FrameNets"
  },
  "1080": {
    "slides": {
      "0": {
        "title": "Community Question Answering Service",
        "text": [
          "A dog kept in the next house barks from morning to night.",
          "Post Question Answer of User B",
          "No solution other than moving.",
          "How can I effectively manage this problem?",
          "Please contact the public health center.",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Push Notification in CQA",
        "text": [
          "Push Notification obtain quick answers Push Notification of Question",
          "Directly linked to the quality of CQA",
          "Contents of Posted Question",
          "Notification Headline of Posted Question",
          "Yahoo! Chiebukuro Respondent Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Snippet Extraction Makes Headline Informative",
        "text": [
          "Extract a mid-substring as a snippet",
          "Nice to meet you, thank you in advance. I'm a man in my thirties.",
          "...A dog kept in the next house barks from morning...",
          "to night. Neighbors have given the owner cautions against it,",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Contributions",
        "text": [
          "Show empirical evidence that snippet headlines are more effective than prefix headlines",
          "Propose extractive headline generation method based on learning to rank",
          "Create Japanese dataset including headline candidates with",
          "\"headline-ness\" scores by crowdsourcing",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Advantages of Snippet Headlines",
        "text": [
          "Snippet headlines never include generative errors",
          "Headline accept generative errors",
          "A/B testing on Yahoo! Chiebukuro push notifications of smartphones completely avoid generative",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Related Work of Headline Generation and CQA",
        "text": [
          "Our research is first attempt to address extractive headline generation for",
          "CQA service with substring of question based on learning to rank",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Overview of Our Proposed Method",
        "text": [
          "Nice to meet you, thank you in advance. I'm a man in my thirties.",
          "...A dog kept in the next house barks from morning to night...",
          "Question Candidates Ranked Headline Candidate Generation Candidate Ranking",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Candidate Generation",
        "text": [
          "C ut subsequent s entences if over 20",
          "Nice to meet you, thank you in advance, I'm a... J apanese characters",
          "Ellips is Elli psis",
          "... Advice please. A dog kept in the next house ...",
          "... A dog kept in the next house barks from morning",
          "Make sentence which starts from beginning of each sentences of question.",
          "Cut subsequent sentences if it has over 20 Japanese characters.",
          "Put ellipsis at front and end of substring.",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Candidate Ranking",
        "text": [
          "Pairwise Learning to Rank",
          "L2-regularized L2-loss linear rankSVM",
          "[Lee 2014] Lee, ChingPei and Lin, ChihJen: Largescale Linear Ranksvm. Neural Computation, 26(4)",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Data Creation Crowdsourcing",
        "text": [
          "Select the best option from the list so that users can guess the content of the question and distinguish it from other ones.",
          "Randomly Sorted Headline Candidate score",
          "Neighbors have given the owner cautions against",
          "This area has only private houses, not rented ...",
          "How can I effectively manage this problem?",
          "However, I will go crazy if I have to keep enduring",
          "A dog kept in the next house barks from morning",
          "Nice to meet you, thank you in advance, I'm a ...",
          "... Advice please. A dog kept in the next house ...",
          "Number of votes by",
          "10 workers per question",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Crowdsourcing Results",
        "text": [
          "Ratio of questions whose prefix headlines were most voted",
          "Room for improvement for prefix headline was up to",
          "Improve uninformative headlines of 38.2%",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Features for Ranking Model",
        "text": [
          "Bag-of-Words: 30,820 dimension sparse vector based on tf-idf",
          "Embedding: 100 dimension dense vector based on doc2vec",
          "Position: 10 dimension binary vector representing candidate position",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Compared Methods",
        "text": [
          "Prefix: Select first candidate",
          "DictDel: Delete uninformative sentence with rule (Used in A/B testing)",
          "ImpTfidf: Select most important candidate with highest tf-idf value",
          "SimTfidf: Select most similar candidate to original question with cosine similarity",
          "LexRank: Select candidate with highest score based on LexRank (Erkan&Radev 2004)",
          "SVM: Select candidate with highest confidence learned as classification task SVR: Select candidate with highest predicted votes learned as regression task",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Evaluation Metrics",
        "text": [
          "Measures how appropriate candidates selected by each method",
          "Determines the overall performance of each method",
          "Measures how much each method changed the default prefix headline",
          "Determines the impact of application to actual CQA service.",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Results Quantitative Analysis",
        "text": [
          "Method Avarage Votes Change Rate",
          "MLRank(ours) performed the best among all methods.",
          "Prefix(First sentence) can be a good summary.",
          "Random DictDel(Rule-Based) was more useful than Prefix. ImpTfidf",
          "Change rate of DictDel was small, which means small impact on service. SVM",
          "SVR Change rates of unsupervised",
          "methods were high, but the overall performances were low",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Results Qualitative Analysis",
        "text": [
          "Examples of prefix headline and snippet headline",
          "Prefix Headline Snippet Headline",
          "I I am am sorry sorry if if the the category category is is wrong. wrong. ... Now, my wallet is torn, and Im and Im",
          "Now, my wallet is torn having having a a hard hard time. time. A A new new one one",
          "I I am am a a 27-year-old 27-year-old woman. woman. Owing to ... Owing to my environment, there is my environment, there is little chance of little chance of new encounters with encounters with men men",
          "Uninformative expressions are successfully excluded, and informative experssions are added",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "Addressed a snippet headline generation task for push notifications of CQA",
          "Showed empirical evidence that snippet headlines are more effective than prefix headlines 2.4 times in average answer rate",
          "Proposed extractive headline generation method based on learning to rank",
          "Created dataset including headline candidates with \"headline-ness\" scores by crowdsourcing",
          "Investigate effectiveness in practical situations on web service.",
          "Make the dataset publicly available.",
          "Copyright (C) 2019 Yahoo Japan Corporation. All Rights Reserved."
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "Extractive Headline Generation Based on Learning to Rank for Community Question Answering"
  },
  "1083": {
    "slides": {
      "0": {
        "title": "What is this presentation about",
        "text": [
          "Summarize the history and current state of efforts related to the",
          "Illustrate the challenges of maintaining a community Project",
          "Invite the community to extend the capabilities of the Anthology",
          "Call you to join the Anthology team",
          "Summary History Future-proofing Upcoming Future"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "The Anthology in summary",
        "text": [
          "Open access service for all",
          "Also hosts posters and additional data",
          "Paper search and author pages",
          "45K papers and 4.5K daily hits",
          "New papers added in collaboration with proceedings editors",
          "History Future-proofing Upcoming Future"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "A brief History of the Anthology",
        "text": [
          "Proposed in 2001 by Steven Bird",
          "First version online in 2002, with Steven Bird as editor",
          "Min-Yen Kan becomes the",
          "A new version of the Anthology with extra functionality is released in 2012",
          "Steven Bird Min-Yen Kan",
          "Hosting of the Anthology moves from the National University of Singapore to Saarland University",
          "Summary Future-proofing Upcoming Future"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "How to Future proof the Anthology",
        "text": [
          "Limited resources for day-to-day code maintenance",
          "Docker container for easier set-up and sandboxing",
          "Collaborative documentation efforts to ease onboarding",
          "Migration plan on the pipeline, including upgrades and test cases",
          "Summary History Upcoming Future"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Upcoming major steps",
        "text": [
          "Hosting the Anthology within the main ACL website",
          "Recruit a new Anthology editor",
          "(possibly) pay for extra support for the Anthology",
          "Summary History Future-proofing Future"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Exercise Importing of your slides",
        "text": [
          "We import slides, datasets, videos from your own",
          "Currently done by email",
          "(try it yourself! yes, now)",
          "Better workflow: pull request against the",
          "Anthology XML (a la csrankings.org)",
          "Summary History Future-proofing Future"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Possible future directions",
        "text": [
          "Contains useful information both for CL researchers and about CL researchers. Useful for identifying suitable reviewers.",
          "Move focus from day-to-day operations towards development",
          "Establish a network of mirrors",
          "Summary History Future-proofing Upcoming"
        ],
        "page_nums": [
          7
        ],
        "images": []
      }
    },
    "paper_title": "The ACL Anthology: Current State and Future Directions"
  },
  "1085": {
    "slides": {
      "0": {
        "title": "Motivations",
        "text": [
          "Rule-Based Machine Translation (RBMT)",
          "We have been developed RBMT for more than 30 years.",
          "Large technical dictionaries and translation rules",
          "Pre-ordering SMT and Tree/Forest to String",
          "Effective solutions for Asian language translation (WAT2014)",
          "But, pre-ordering rules and parsers are needed.",
          "Statistical Post Editing (SPE) (same as WAT2014)",
          "Verify effectiveness in all tasks",
          "System combination between SPE and SMT (new in WAT2015)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Statistical Post Editing SPE",
        "text": [
          "Translating RBMT results to post-edited results.",
          "1) We first translate source Parallel Corpus",
          "sentences by RBMT. RB M T (ASPEC / JPC)",
          "Translated Sentence 2) We train SPE model by",
          "RBMT TM LM (ja -> ja)",
          "Input Sentence Translated Sentence SPE Model SPE Result"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Features of SPE",
        "text": [
          "Correct mistranslations / Translate unknown words",
          "Phrase-level correction (domain adaptation)",
          "Use of more fluent expressions",
          "From SMTs standpoint SPE:",
          "Reduction of NULL alignment (subject/particle)",
          "Use of syntax information (polarity/aspect)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "SPR for Patent Translation",
        "text": [
          "Corpus: JPO-NICT patent corpus",
          "# of automatic evaluation: 2,000",
          "# of human evaluation: 200",
          "RBMT SMT SPE RBMT SMT SPE RBMT SMT SPE",
          "en-ja en-ja zh-ja zh-ja ko-ja ko-ja",
          "SPE shows: Automatic evaluation for en-ja/zh-ja/ko-ja",
          "- Better scores than PB-SMT in automatic evaluation",
          "- Improvements of understandable level (>=C in acceptability)",
          "A AA RBMT SMT SPE RBMT SMT SPE Human evaluation for zh-ja"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "System Combination",
        "text": [
          "Selection based on SMT scores and/or other features.",
          "Selection based on estimated score (Adequacy? Fluency? )",
          "Need data to learn the relationship",
          "Our approach in WAT2015:",
          "Merge n-best candidates and rescore them.",
          "We used RNNLM for reranking.",
          "SPE Merge and Rescore Final translation"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "RNNLM reranking and Tuning",
        "text": [
          "Reranking on the log-linear model",
          "Adding RNNLM score to default features of Moses.",
          "RNNLM trained by rnnlm toolkit (Mikolov 12).",
          "500,000 sentences for each language",
          "Using tuned weights without RNNLM, we ran only 1 iteration.",
          "(to reduce tuning time)",
          "Wlm=0.2 Ad ding RNNLM Linear interpolation SMT Wtrans=0.3",
          "Wlm=0.3 Default Tuned Wtrans=0.2 features weights MERT Dev Wrnnlm=0.0",
          "SPE Wlm=0.4 Wtrans=0.1 New features Initial weights Tuned weights",
          "Default Tuned features weights 2015 Toshiba Corporation"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Experimental Results",
        "text": [
          "*SMT and SPE are 1-best results.",
          "SMT SPE COMB ja-en SMT SPE COMB en-ja SMT ja-zh SPE COMB SMT zh-ja SPE COMB",
          "ja-en en-ja ja-zh zh-ja",
          "SMT JPOzh-ja SPE COMB SMT JPOko-ja SPE COMB JPCzh-ja JPCko-ja 2015 Toshiba Corporation",
          "BLEU RIBES BLEU RIBES BLEU RIBES BLEU RIBES",
          "System Combination (COMB) achieved",
          "improvements of BLEU and RIBES score than SPE.",
          "COMB is the best system except JPCko-ja task.",
          "JPCzh-ja JPCko-ja Systems Rerank BLEU RIBES BLEU RIBES",
          "SMT No Yes SPE No Yes COMB Yes 2015 Toshiba Corporation"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "7": {
        "title": "Which systems did the combination selected",
        "text": [
          "SAME SAME SMT SAME SAME",
          "ja-en en-ja ja-zh zh-ja",
          "ja-en/en-ja/zh-ja: about 80% translations come from SPE.",
          "ja-zh and JPCzh-ja: COMB selected SPE and SMT, equivalently.",
          "(Because RBMT couldnt translate well, % of SMT increased. )",
          "SPE SPE SMT SMT",
          "JPCzh-ja JPCko-ja same means that COMB results were included both SMT and SPE. 2015 Toshiba Corporation"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Toshiba MT system of WAT2015",
        "text": [
          "We additionally applied some pre/post processing.",
          "Technical Term English Word KATAKANA",
          "frequent notations for .",
          "+ JPO patent dictionary",
          "for JPCzh-ja) continous -> continuous"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Official Results",
        "text": [
          "SPE and SMT ranked in the top 3 HUMAN in ja-en/ja-zh/JPCzh-ja.",
          "ja-en en-ja ja-zh zh-ja",
          "BLEU RIBES HUMAN BLEU RIBES HUMAN BLEU RIBES HUMAN BLEU RIBES HUMAN",
          "JPCzh-ja JPCko-ja System BLEU RIBES HUMAN BLEU RIBES HUMAN",
          "The correlation between BLEU/RIEBES and HUMAN is not clear in our"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Crowdsourcing Evaluation",
        "text": [
          "Analysis of JPCko-ja result (COMB vs Online A)",
          "In in-house evaluation, COMB is better than Online A.",
          "Baseline COMB Online A",
          "Effected by differences in number expressions !?",
          "SRC : Online A:",
          "Equally evaluated in-house evaluation.",
          "Crowd-workers should be provided an evaluation guideline by",
          "which such a difference is considered."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Summary",
        "text": [
          "Toshiba MT system achieved a combination method",
          "between SMT and SPE by RNNLM reranking.",
          "Our system ranked the top 3 HUMAN score in ja-en/ja-",
          "We will aim for practical MT system by more effective",
          "combination systems (SMT, SPE , RBMT and more...)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      }
    },
    "paper_title": "Toshiba MT System Description for the WAT2015 Workshop"
  },
  "1086": {
    "slides": {
      "0": {
        "title": "SMT Experiments",
        "text": [
          "Experimental results of SMT",
          "st Moses Aligner BLEU RIBES Training time",
          "Table: Evaluation results by using different aligner (GIZA++ and MGIZA) based on the",
          "Anymalign + Cutnalign BLEU Training time Timeout (s) i",
          "zh-ja zh-ja zh-ja zh-ja",
          "Table: Evaluation results by using the alignment method of combining sampling-based",
          "alignment and bilingual hierarchical sub-sentential alignment methods."
        ],
        "page_nums": [
          1
        ],
        "images": [
          "figure/image/1086-Table5-1.png"
        ]
      }
    },
    "paper_title": "Sampling-based Alignment and Hierarchical Sub-sentential Alignment in Chinese-Japanese Translation of Patents"
  },
  "1089": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Whats the largest difference in 2010 2019",
          "eh ae ee ey ad",
          "DT ge Re Re a tg Dee ee nd",
          "omy pa oees Os 8",
          "PD De en ny are rig ee",
          "Re come) com) me 8",
          "ee eR Seen pede = Cn ded On Qax Om GB",
          "bi dienellces io =) 5",
          "eee ieee eee vs Sl a gy te ad ed : a i eel eee nl biel ae al ea teal Oe ome) com) ve) |] De ae Pe rey Cd ee Rh Sen ny a Ck ee ee at Cee eo ee DE ed Pate fom cea] vie 8 Cad Dee oh een - bAceell dieeeae2 Ce eT be Rid r=) Corey R. Lowandowsid @ 9 Closcecoesti un 14 ova eo Os 8 eo re td es",
          "2019 Bloomberg Finance L.P. All rights reserved. Engineering"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "Applications",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "Data Task Definition Text Task",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "3": {
        "title": "Data Task Definition Image Task",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Data Annotation",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Data Collection",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "6": {
        "title": "Data Distribution",
        "text": [
          "Image does not add & Text not represented",
          "Image does not add & Some text represented",
          "Image adds & Text not represented",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Analysis Text Task",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Analysis Image Task",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Prediction Methods",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Prediction Baseline Methods",
        "text": [
          "Image Task (Image adds to meaning) Text Task (Text is represented) Image + Text Task",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Prediction Text based Methods",
        "text": [
          "Image Task (Image adds to meaning) Text Task (Text is represented) Image + Text Task",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Prediction Image based Methods",
        "text": [
          "Image Task (Image adds to meaning) Text Task (Text is represented) Image + Text Task",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Prediction Joint Text Image Methods",
        "text": [
          "Image Task (Image adds to meaning) Text Task (Text is represented) Image + Text Task",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Takeaways",
        "text": [
          "Text does not always describe the image",
          "The image does not always illustrate text",
          "Best results on each subtask are obtained by methods using different modalities (text or",
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Categorizing and Inferring the Relationship between the Text and Image of Twitter Posts"
  },
  "1090": {
    "slides": {
      "0": {
        "title": "Gender Prediction",
        "text": [
          "The task of predicting gender based only on text.",
          "SVM with word/char n-grams performs best!",
          "I Winner PAN 2017 shared task on author profiling:",
          "I Characters: 3-6 grams"
        ],
        "page_nums": [
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "However how would this lexicalized approach work across different",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "2": {
        "title": "Cross lingual Gender Prediction",
        "text": [
          "I Train a model on source language(s) and evaluate on",
          "I Dataset: TwiSty corpus (Verhoeven et al., 2016) +",
          "FR EN NL PT ES Test Language",
          "USER Jaaa moeten we zeker doen"
        ],
        "page_nums": [
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "3": {
        "title": "Bleaching Text",
        "text": [
          "Original Massacred a bag of Doritos for lunch!",
          "PunctC w w w w w w w!",
          "PunctA w w w w w w w w w w w wp jjjj",
          "Shape w w ull w w w w w w w w l ll ll ull w wp ll llx jjjj xx",
          "Vowels w w ull w w w w l ll w w w w ll ull w w ll wp llx cvccvccvc v cvc vc cvcvcvc cvc cvccco",
          "I Replace usernames and URLs",
          "I Use concatenation of the bleached representations",
          "I 5-grams perform best",
          "FR EN NL PT ES Test Language",
          "Trained on all other languages:",
          "EN NL FR PT ES Test Language",
          "W W W W W USER E W W W",
          "W W W W ?",
          "E W W W W",
          "W W, W W W? LL LL LL LL LX",
          "PP W W W W",
          "LL LL LL LL LUU",
          "W W W W JJJ",
          "W W W W &W;W",
          "J W W W W"
        ],
        "page_nums": [
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26
        ],
        "images": [
          "figure/image/1090-Table4-1.png"
        ]
      },
      "4": {
        "title": "Human Experiments",
        "text": [
          "I Are humans able to predict gender based only on text for",
          "I 20 tweets per user (instead of 200)",
          "I 6 annotators per language pair",
          "I Each annotating 100 users",
          "I 200 users per language pair, so 3 predictions per user",
          "Auser has posted the following tweets:",
          "pelo amor de deus cai na realidade URL",
          "a versao de REALITi do album e tao ruim ne eu to ate meio assim",
          "meu rosto tinha tdo pra ser ok mas nao eu tive que nascer com esse nariz horroroso e esses olhos cagados",
          "eu nunca ouvi nada tao lindo URL",
          "o mundo precisa ouvir isso URL",
          "USER GENTE?2???77??7? eu apenas conciliei elas com a situaao atual da minha vida e jd to todo em choque aqui pq to bateu",
          "meu deus eu desci o nivel da timeline dum jeito q a gente ja se encontra no pre sal moral",
          "quando a pessoa e tao mediocre que te chama de nerd debochando pq ve disse que gosta de ler",
          "USER bom.....eu num sei de nda",
          "USER eu to com 0 olho chei de agua sua mae eh tao linda vwv eu definitivamente nao aguento mais URL",
          "Rindo Muito De Meu Proprio Tweet",
          "USER USER sempre contribuindo para a arte de minhas amigas",
          "que saudade de camiliquia USER as arvores da minha casa tinham 70 ano!",
          "USER o suprassumo da diferentona ANAO pagueia lingua, pin e a terceira melhor musica do album, que musica maravilhosa USER USER USER qual a intencdo em cmpartilhar fotos explicitas de criancas sendo abusadas? aminha mae reclama de absolutamente tudo ela nao para de reclamar 1 segundo, ela nunca ta de bom humor, ela nunca acha USER melissa do ceu como assim explica cortaram >todas< por causa dos canos do vizinho",
          "eee emer reer errr evr ee",
          "Do you think that the poster of these tweets is male or female? (required) Male Female @ Please use your intuition.",
          "NL NL NL PT FR NL",
          "(note that the classifier had acces to 200 tweets)"
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "5": {
        "title": "Conclusions",
        "text": [
          "I Lexical models break down when used cross-language",
          "I Bleaching text improves cross-lingual performance",
          "I Humans performance is on par with our bleached"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "6": {
        "title": "Cross lingual Embeddings",
        "text": [
          "EN NL FR PT ES Test Language"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "7": {
        "title": "Lexicalized Cross language",
        "text": [
          "Test EN NL FR PT ES"
        ],
        "page_nums": [
          35
        ],
        "images": [
          "figure/image/1090-Table3-1.png"
        ]
      },
      "8": {
        "title": "In language performance",
        "text": [
          "EN NL FR PT ES Test Language"
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "9": {
        "title": "Bleached Lexicalized",
        "text": [
          "EN NL FR PT ES"
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "10": {
        "title": "Unigrams vs fivegrams",
        "text": [
          "EN NL FR PT ES"
        ],
        "page_nums": [
          38
        ],
        "images": []
      },
      "11": {
        "title": "Number of unique unigrams for Dutch",
        "text": [],
        "page_nums": [
          39
        ],
        "images": []
      },
      "12": {
        "title": "Language to language feature analysis",
        "text": [
          "EN NL FR PT ES",
          "Le ge nd v ow els s hap e p un ctC p un ctA le ngth frequency all"
        ],
        "page_nums": [
          40
        ],
        "images": []
      }
    },
    "paper_title": "Bleaching Text: Abstract Features for Cross-lingual Gender Prediction"
  },
  "1092": {
    "slides": {
      "0": {
        "title": "Adequacy in Neural Machine Translation",
        "text": [
          "Source: und wir benutzen dieses wort mit solcher verachtung",
          "Repetitions Reference: and we say that word with such contempt",
          "Translation: and we use this word with such contempt contempt",
          "Ein 28-jahriger Koch, der kurzlich nach Pittsburgh gezogen war, wurde diese Woche im Treppenhaus eines ortlichen Einkaufszentrums tot aufgefunden .",
          "Translation: A 28-year-old chef who recently moved to Pittsburgh was found dead in the staircase this week .",
          "Pittsburgh was found dead in the staircase of a local shopping mall this week ."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Previous Work",
        "text": [
          "Conditioning on coverage vectors to track",
          "Gating architectures and adaptive attention to control",
          "Coverage penalty during decoding (Wu, 2016)."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Main Contributions",
        "text": [
          "J'ai mange le sandwich",
          "1. Fertility-based Neural Machine Translation Model",
          "(Bounds on source attention weights)",
          "2. Novel attention transform function: Constrained Sparsemax",
          "3. Evaluation Metrics: REP-Score and DROP-Score"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Attention Transform Functions",
        "text": [
          "Sparsemax: Euclidean projection of z provides sparse probability distributions.",
          "Constrained Softmax: Returns the distribution closest to softmax whose attention probabilities are bounded by upper bounds u."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "sparse and Constrained",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Constrained Sparsemax",
        "text": [
          "Provides sparse and bounded probability distributions.",
          "This transformation has two levels of sparsity: over time steps & over attended words at each step.",
          "Efficient linear and sublinear time algorithms for forward and backward propagation."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Visualization Attention transform functions",
        "text": [
          "csparsemax provides sparse and constrained probabilities."
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1092-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Fertility based NMT",
        "text": [
          "Allocate fertilities for each source word as attention budgets that exhaust over decoding.",
          "Fertility Predictor : Train biLSTM model supervised by fertilities from fast_align (IBM Model 2).",
          "Exhaustion strategy to encourage more attention for words with larger credit remaining:"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "8": {
        "title": "Experiments",
        "text": [
          "Joint BPE with 32K merge operations.",
          "Default hyperparameter settings in OpenNMT-Py.",
          "Baselines: Softmax, + CovPenalty (Wu, 2016) and"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation Metrics REP Score and DROP Score",
        "text": [
          "Penalizes n-gram repetitions in predicted translations.",
          "Normalize by number of words in reference corpus.",
          "Find word alignments from source to reference & source to predicted.",
          "% of source words aligned with some word in reference, but not with any word in predicted translation."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Results",
        "text": [
          "softmax softmax+CovPenalty softmax+CovVector csparsemax"
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "Sparse and Constrained Attention for Neural Machine Translation"
  },
  "1093": {
    "slides": {
      "0": {
        "title": "Task retrieval based chatbots",
        "text": [
          "Given a message, find most suitable responses",
          "Large repository of message-response pairs",
          "Take it as a search problem",
          "Retrieval Feature generation Ranking",
          "Context-response matching Learning to rank"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Related Work",
        "text": [
          "Previous works focus on network architectures.",
          "CNN, RNN, syntactic based neural networks .",
          "CNN, RNN, attention mechanism",
          "These models are data hungry, so they are trained on large scale State-of-the-art multi-turn architecture (Wu et al. ACL 2017) negative sampled dataset."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Background Loss Function",
        "text": [
          "Cross Entropy Loss (Pointwise loss) Hinge Loss (Pairwise loss)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Background traditional training method",
        "text": [
          "Given a (Q,R) pair, we first randomly sampled N instances",
          "Update the designed model with the use of point-wise cross entropy loss.",
          "Test model on human annotation data.",
          "1. Most of the randomly sampled responses are far from the semantics of the messages or the contexts.",
          "2. Some of randomly sampled responses are false negatives which pollute the training data as noise."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Challenges of Response Selection in Chatbots",
        "text": [
          "Negative sampling oversimplifies response selection task in the training phrase.",
          "Train: Given a utterance, positive responses are collected from human conversations, but negative ones are negative sampled.",
          "Test: Given a utterance, a bunch of responses are returned by a search engine. Human annotators are asked to label these responses.",
          "Human labeling is expensive and exhausting, one cannot have large scale labeled data for model training."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Our Idea",
        "text": [
          "The margin in our loss is dynamic.",
          "R is the ground-truth response, and R_i is a retrieved instance. is a confidence score for each instance. Our method encourages the model to be more confident to classify a response with a high as a negative one."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "How to calculate the dynamic margin",
        "text": [
          "We employ a Seq2Seq model to compute",
          "Seq2Seq model is a unsupervised model.",
          "It is able to compute a conditional probability likelihood without human annotation."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "A new training method",
        "text": [
          "Pre-train the matching model with negative sampling and cross entropy loss.",
          "Given a (Q,R) pair, retrieve N instances from a",
          "Update the designed model with the dynamic hinge loss.",
          "Test model on human annotation da pre-defined index.",
          "The pre-training process enables the matching model to distinguish semantically far away responses.",
          "1. Oversimplification problem of the negative sampling approach can be partially mitigated. 2. We can avoid false negative examples and true negative examples are treated equally during training"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Dataset",
        "text": [
          "Over 4 million post-response pairs (true response) in Weibo for training.",
          "The test set consists of 422 posts with each one associated with around 30 responses labeled by human annotators in good and bad.",
          "Douban Conversation Corpus (Wu et al., 2017)",
          "0.5 million context-response (true response) pairs for training",
          "In the test set, every context has 10 response candidates, and each of the response has a label good or bad judged by human annotators."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation Results",
        "text": [],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1093-Table1-1.png",
          "figure/image/1093-Table2-1.png"
        ]
      },
      "10": {
        "title": "Ablation Test",
        "text": [
          "+WSrand: negative samples are randomly generated.",
          "+const: the marginal in the loss function is a static number.",
          "+WS: Our full model"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1093-Table3-1.png"
        ]
      },
      "11": {
        "title": "More Findings",
        "text": [
          "Updating the Seq2Seq model is not beneficial to the discriminator.",
          "The number of negative instances is an important hyper- parameter for our model."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "We study a less explored problem in retrieval-based chatbots.",
          "We propose of a new method that can leverage unlabeled data to learn matching models for retrieval-based chatbots.",
          "We empirically verify the effectiveness of the method on public data sets."
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "Learning Matching Models with Weak Supervision for Response Selection in Retrieval-based Chatbots"
  },
  "1094": {
    "slides": {
      "0": {
        "title": "Problem",
        "text": [
          "The amount of labeled training data",
          "You will need at least 100k training records to surpass classical",
          "Large-scale labeled datasets of document classification",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Previous Work",
        "text": [
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne",
          "Sequence autoencoder (Dai and Le 2015)"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Our Contributions",
        "text": [
          "Pretraining strategy with unlabeled dialog data",
          "Pretrain an encoder-decoder model for sentiment classifiers",
          "Outperform other semi-supervised methods",
          "Distant supervision with emoji and emoticons",
          "Case study based on...",
          "Costly labeled sentiment dataset of 99.5K items",
          "Large-scale unlabeled dialog dataset of 22.3M utterance- response pairs",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Key Idea",
        "text": [
          "Emotional conversations in a dialog dataset",
          "Implicitly learn sentiment-handling capabilities through learning a dialog model",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Overview of the Proposed Method",
        "text": [
          "Large-scale dialog corpus: a set of a large number of unlabeled utterance-response tweet pairs",
          "Labeled dataset: a set of a moderate number of tweets with a sentiment label",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Data Preparation",
        "text": [
          "Extract 22.3M pairs of an utterance tweet and its response tweet from Twitter Firehose data",
          "training validation test total",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Model Dialog Model",
        "text": [
          "Embedding layer: 4000 tokens, 256 elements",
          "Representation which encoder gives: 1024 elements",
          "Decoder's readout layer: 256 elements",
          "Decoder's output layer: 4000 tokens",
          "LSTMs of the encoder and decoder share the parameter",
          "LSTM-RNN dist. repr. LSTM-RNN",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne",
          "token ID yt output layer ot",
          "embed ding layer recurrent layer htdec",
          "dec embedd ing layer",
          "dec token ID xt",
          "encoder RNN decoder RNN"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "7": {
        "title": "Model Classification Model",
        "text": [
          "The architecture of the encoder RNN part is identical to that of the dialog model",
          "Produce a probability distribution over sentiment classes by a fully-connected layer and softmax function",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Training Dialog Model",
        "text": [
          "Model pretraining with the dialog data",
          "Evaluate validation costs 10 times per epoch and pick up the best model",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Training Classification Model",
        "text": [
          "Classifier model training with the sentiment data",
          "Apply 5 different data sizes for each method",
          "5 runs for each method/data size with varying random seeds",
          "Evaluate the results by the average of f-measure scores",
          "Adjust the duration so that the cost surely converges",
          "Pretrained models converge very quickly but those trained from scratch converge slowly",
          "The other aspects are the same with pretraining",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Proposed Method",
        "text": [
          "The proposed method: Dial",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Baselines with LSTM RNNs",
        "text": [
          "Directly trained by the sentiment data",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne",
          "Pretrain an LSTM-RNNs as a language model",
          "Pretrain an LSTM-RNNs as a sequence autoencoder",
          "Emoji and emoticon-based distant supervision",
          "Prepare large-scale datasets utilizing emoticons or emoji as",
          "Pretrain models as classifier models using pseudo-labeled data"
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "12": {
        "title": "Baselines with Linear Models",
        "text": [
          "Use only the sentiment data",
          "Segment text with a defact-standard morphological analyzer, MeCab",
          "+233 emoji and emoticons",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Results F measure",
        "text": [
          "= e > Default",
          "LL ey tk Dial",
          "22 / # of training records"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion",
        "text": [
          "Effectiveness of the pretraining strategy using paired dialog data for sentiment analysis",
          "Even more effective in extremely low-resource situations",
          "Explore combinations of a large-scale unlabeled dataset and a supervised task",
          "Exploit other kinds of structures",
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "Pretraining Sentiment Classifiers with Unlabeled Dialog Data"
  },
  "1095": {
    "slides": {
      "0": {
        "title": "Direct Transfer for NER",
        "text": [
          "Input: Unlabelled sentences in the target language encoded with cross-lingual embeddings",
          "O B-PER O O B-LOC O O O B-PER O O O O O O O B-LOC O",
          "kailangan namin ng mas maraming dugo sa Pagasanjan. k ailangan namin ng mas maraming d ugo sa Pagasanjan. kailangan namin ng mas maraming dugo sa Pagasanjan."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "1": {
        "title": "Direct Transfer Results NER F1 score WIkiANN",
        "text": [
          "ae a fae} pL]",
          "= TopeEn4aMV Target Language"
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "Voting and English are often poor",
        "text": [
          "ra a oe sd om e +79 = ae ye IP S me | op om ne 4 so",
          "a ae | ye",
          "= Tope En4MV Target Language"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "3": {
        "title": "General findings",
        "text": [
          "Transfer strongest within language family",
          "Asymmetry between use as source vs target language (Slavic-Cyr,",
          "But lots of odd results & overall highly noisy"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1095-Figure5-1.png"
        ]
      },
      "4": {
        "title": "Problem Statement",
        "text": [
          "N black-box source models",
          "Unlabelled data in target language",
          "Little or no labelled data (few shot and zero shot)",
          "Good predictions in the target language"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Model 1 Few Shot Ranking and Retraining RaRe",
        "text": [
          "Source Model AR F1AR",
          "Source Model EN F1EN",
          "Source Model VI F1VI",
          "Source Model AR Dataset AR",
          "20k unlabelled sents in Tagalog",
          "Source Model EN Dataset EN",
          "Source Model VI Dataset VI",
          "N training sets in Tagalo g",
          "Final training set, a mixture of distilled knowledge",
          "1. Train an NER model on the mixture datasets.",
          "2. Fine-tune on 100 gold samples.",
          "Zero-shot variant: uniform sampling without fine-tuning"
        ],
        "page_nums": [
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "6": {
        "title": "Hierarchical BiLSTM CRF as model",
        "text": [
          "Our method is independent of model choice."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "7": {
        "title": "Model 2 Zero Shot Transfer BEA",
        "text": [
          "What if no gold labels are available?",
          "Treat gold labels Z as hidden variables",
          "Estimate Z that best explains all the observed predictions",
          "Re-estimate the quality of source models",
          "Inspired by Kim and Ghahramani (2012)",
          "True label of instance i",
          "variational mean- field approx."
        ],
        "page_nums": [
          17,
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": [
          "figure/image/1095-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Extensions to BEA",
        "text": [
          "After running BEA, estimate source model qualities and remove bottom k, run BEA again (BEAunsx2)",
          "2. Few shot scenario:",
          "Given 100 gold sentences, estimate source model confusion matrices, then run BEA (BEAsup)",
          "3. Token vs Entity application"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "9": {
        "title": "Benchmark BWET Xie et al 2018",
        "text": [
          "Single source annotation projection with bilingual dictionaries from cross-lingual word embeddings",
          "Transfer english training data to German, Dutch, and",
          "Train a transformer NER on the projected training data.",
          "State-of-the-art onzero-shotNER transfer (orthogonal to this)"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "10": {
        "title": "CoNLL Results avg F1 over de nl es",
        "text": [
          "Nothman et al. (2013) Use parallel data,",
          "AVG F1 over de, nl and es 27",
          "RaRe uns Zero shot",
          "=> mam OOO nr el YS oS oc LS &",
          "Bait une Zero shot",
          "hsup B - High-resource"
        ],
        "page_nums": [
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "11": {
        "title": "WIKIANN NER Datasets Pan et al 2017",
        "text": [
          "Silver annotations from Wikipedia for languages.",
          "We picked languages based on availability of bilingual dictionaries.",
          "Created balanced training/dev/test partitions",
          "(varying size of training according to data availability)"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "12": {
        "title": "Word representation FastText MUSE",
        "text": [
          "Use fasttext monolingual wiki embeddings mapped to",
          "English space using Identical Character Strings."
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "13": {
        "title": "Results WikiANN",
        "text": [
          "MV between top 3 sources"
        ],
        "page_nums": [
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43
        ],
        "images": []
      },
      "14": {
        "title": "Effect of increasing source languages",
        "text": [
          "Methods robust to many varying quality source languages.",
          "Even better with few-shot supervision."
        ],
        "page_nums": [
          44
        ],
        "images": [
          "figure/image/1095-Figure4-1.png"
        ]
      },
      "15": {
        "title": "Takeawauys I",
        "text": [
          "Transfer from multiple source languages helps because for many languages we dont know the best source language.",
          "takeaway / noun [uk/aus/nz]: a meal cooked and bought at a shop or restaurant but taken somewhere else... Cambridge English Dictionary"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "16": {
        "title": "Takeawauys II",
        "text": [
          "With multiple source languages, you need to estimate their qualities because uniform voting doesnt perform well.",
          "takeaway / noun [uk/aus/nz]: a meal cooked and bought at a shop or restaurant but taken somewhere else... Cambridge English Dictionary"
        ],
        "page_nums": [
          46
        ],
        "images": []
      },
      "17": {
        "title": "Takeaways III",
        "text": [
          "A small training set in target language helps, and can be done cheaply and quickly",
          "takeaway / noun [uk/aus/nz]: a meal cooked and bought at a shop or restaurant but taken somewhere else... Cambridge English Dictionary"
        ],
        "page_nums": [
          47
        ],
        "images": []
      },
      "18": {
        "title": "Future Work",
        "text": [
          "Map all scripts to IPA or Roman alphabet",
          "(good for shared embeddings and character-level transfer)",
          "Can we estimate the quality of source models/languages for a specific target language based on language",
          "Technique should apply beyond NER to other tasks."
        ],
        "page_nums": [
          49
        ],
        "images": []
      }
    },
    "paper_title": "Massively Multilingual Transfer for NER"
  },
  "1096": {
    "slides": {
      "0": {
        "title": "Introduction Darknet",
        "text": [
          "Used interchangeably in this work:",
          "Tor network (Tor: an encrypted browser)",
          "Onion network (.onion top-level domain)",
          "Hosts: onion services (hidden services)."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Introduction Darknet Markets",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Introduction Drugs",
        "text": [
          "Finest organic cannabis grown by proffessional growers in the netherlands.",
          "We double seal all packages for odor less delivery.",
          "Shipping within 24 hours!",
          "EUR = X Buy now",
          "5g Banana Daniel Hershcovich Kush 45 EUR = 0.075 X Buy now"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Introduction Language of the Darknet",
        "text": [
          "How well do NLP tools work on Darknet text?",
          "Can we automatically identify illegal activity?",
          "Disclaimer: variations among legal systems, societies and groups."
        ],
        "page_nums": [
          5,
          6,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Data DUTA 10K",
        "text": [
          "Dataset of 10367 Onion Services text pages [Al Nabki et al., 2019].",
          "Classified by needs of Spanish law enforcement agencies.",
          "20% categorized as illegal and 48% as legal (32% unavailable).",
          "Of the illegal websites, 23% concern illegal drugs."
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Data Control Data eBay",
        "text": [
          "Product descriptions acquired by searching drug-related terms.",
          "Do not sell actual drugs, but rather drug-related products.",
          "3 Layers Chip Style Herb Herbal Tobacco Grinder Weed Grinders",
          "Type : Tobacco Crusher"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "6": {
        "title": "Data",
        "text": [
          "Public Web Dark Web"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Cleaning",
        "text": [
          "Filter out non-English pages.",
          "Remove non-linguistic content: buttons, URLs...",
          "Split to paragraphs, join to single lines, remove duplicates.",
          "Sampled 571 paragraphs from each, for comparable size."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Domain Differences Vocabulary",
        "text": [
          "Distance between word distributions, measured by:",
          "to the of is and",
          "Small self-distances by splitting each in half, but the different domains are about equidistant."
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": []
      },
      "9": {
        "title": "Domain Differences Characteristics of Darknet Data",
        "text": [
          "Legal and illegal Onion should be considered different domains.",
          "Diverse: sub-domains are distinguishable.",
          "Unique: distinguishable from other domains."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "10": {
        "title": "Domain Differences Named Entities and Wikification",
        "text": [
          "NE extraction [spaCy] + Wikification [Bunescu and Pasca, 2006].",
          "% (of detected NEs) Wikifiable eBay",
          "By manual inspection, low NE precision and recall for Illegal Onion.",
          "Slang words for drugs (e.g., kush) falsely picked up as NEs.",
          "Standard NLP is not suited for this domain."
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1096-Table2-1.png"
        ]
      },
      "11": {
        "title": "Classification Classes",
        "text": [
          "We identified three domains. Two binary classification settings: eBay, Legal Onion",
          "Legal Onion, Illegal Onion",
          "What are the linguistic features distinguishing them?"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "12": {
        "title": "Classification Classifiers",
        "text": [
          "NB: Naive Bayes (bag of words)",
          "SVM: Support Vector Machine",
          "BoE: sum/average GloVe + MLP",
          "seq2vec: BiLSTM + MLP",
          "attention: ELMo + BCN (self-attention)"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "13": {
        "title": "Classification Manipulations",
        "text": [
          "To find what linguistic cues are used for classification. Conditions:",
          "Drop content words Replace content words with their POS",
          "Drop function words Replace function words with their POS",
          "Content POS: {adj, adv, noun, propn, verb, x, num}",
          "Generic Viagra ( Oral Jelly ) is used for Erectile Dysfunction",
          "propn propn propn propn verb verb for propn propn",
          "Welcome to SnowKings Good Quality Cocaine",
          "verb to propn propn propn propn"
        ],
        "page_nums": [
          22,
          23,
          24
        ],
        "images": []
      },
      "14": {
        "title": "Classification Results",
        "text": [
          "eBay vs. Legal Onion drugs:",
          "Illegal Onion drugs: full drop content drop function pos content pos function"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "15": {
        "title": "Cross Domain Classification Darknet Forums",
        "text": [
          "Can we generalize beyond drugs?",
          "DUTA-10K also contain Legal Forums and Illegal Forums."
        ],
        "page_nums": [
          27,
          28
        ],
        "images": []
      },
      "16": {
        "title": "Cross Domain Classification Results",
        "text": [
          "Illegal Onion forums: full drop content drop function pos content pos function",
          "Trained on drugs, evaluated on forums (Legal vs. Illegal): full drop content drop function pos content pos function"
        ],
        "page_nums": [
          29,
          30
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "Language of legalillegal Darknet is different:",
          "As different as Darknet vs. eBay. eBay",
          "Can be distinguished just by POS. Legal",
          "Observed through multiple lenses:"
        ],
        "page_nums": [
          31,
          32,
          33,
          34
        ],
        "images": []
      }
    },
    "paper_title": "The Language of Legal and Illegal Activity on the Darknet"
  },
  "1097": {
    "slides": {
      "0": {
        "title": "Empirically evaluate various models in EJ task",
        "text": [
          "multi-layer encoder-decoder model soft-attention model",
          "Three recurrent units Two kinds of training data",
          "LSTM, GRU, IRNN naturally-ordered, pre-reordered"
        ],
        "page_nums": [
          1
        ],
        "images": [
          "figure/image/1097-Figure5-1.png",
          "figure/image/1097-Figure6-1.png"
        ]
      },
      "1": {
        "title": "Results perplexities",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Results evaluation scores",
        "text": [
          "Baseline hierarchical phrase-based SMT",
          "Submitted system 2 (NMT + System combination)",
          "Best competitor 1: NAIST (Travatar System with NeuralMT Reranking)",
          "Best competitor 2: naver (SMT t2s + Spell correction + NMT reranking)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Finding and Insights",
        "text": [
          "Soft-attention models outperforms multi-layer encoder-decoder models",
          "Training models on pre-reordered data hurts the performance",
          "NMT models tend to make grammatically valid but incomplete translations"
        ],
        "page_nums": [
          4
        ],
        "images": []
      }
    },
    "paper_title": "Evaluating Neural Machine Translation in English-Japanese Task"
  },
  "1103": {
    "slides": {
      "0": {
        "title": "The weighted parsing problem",
        "text": [
          "e.g., English sentences ( )",
          "e.g., Fruit flies like bananas",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "e.g., abstract syntax trees (ASTs)",
          "value in a weight algebra parse syntactic object",
          "parse Fruit flies max",
          "Semiring parsing (Goodman 1999)",
          "recognition string probability probability of best derivation derivation forest best derivation(s) best derivation(s)",
          "Parsing with superior grammars (Knuth 1977; Nederhof 2003)",
          "Algebraic dynamic programming (Giegerich, Meyer, and Steffen 2004)",
          "minimum edit distance matrix chain multiplication",
          "Reduct of a grammar and a syntactic object (cf. Bar-Hillel, Perles, and"
        ],
        "page_nums": [
          1,
          2,
          3,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
        ],
        "images": []
      },
      "1": {
        "title": "Regular tree grammars RTG",
        "text": [
          "T abstract syntax tree AST()",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "2": {
        "title": "Language algebras",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "interpretation of as operations on the set of syntactic objects",
          "T (terms) (syntactic objects) factors(Fruit flies like bananas) = {Fruit, like bananas, }",
          "Fruit flies S (NP,VP)"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "3": {
        "title": "Semirings",
        "text": [
          "Algebraic structure is used to evaluate an AST to a weight accumulates the weights of several ASTs",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "Examples false, true) the Boolean semiring with = {false, true} the semiring of natural numbers"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": []
      },
      "4": {
        "title": "Multioperator monoids M monoids",
        "text": [
          "binary set of -ary operations (here: distributive)",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "Minimum edit distance M-monoid },min ,,med)"
        ],
        "page_nums": [
          28,
          29,
          30
        ],
        "images": []
      },
      "5": {
        "title": "Weight algebras",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "wt: (set of rules) (set of operations)",
          "T (terms) (weight algebra)"
        ],
        "page_nums": [
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
        ],
        "images": []
      },
      "6": {
        "title": "Weighted RTG based language models",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "A wRTG-LM is a tuple wt",
          "RTG language algebra M-monoid wt:"
        ],
        "page_nums": [
          39,
          40
        ],
        "images": []
      },
      "7": {
        "title": "Weighted parsing algorithm",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "- wRTG-LM canonical weighted deduction system wRTG-LM"
        ],
        "page_nums": [
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          65
        ],
        "images": []
      },
      "8": {
        "title": "Canonical weighted deduction system",
        "text": [
          "Parsing as deduction (Shieber, Schabes, and Pereira 1995)",
          "is a rule factors()",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)"
        ],
        "page_nums": [
          59,
          60,
          61,
          62,
          63,
          64,
          118,
          119,
          120,
          121
        ],
        "images": []
      },
      "9": {
        "title": "Value computation algorithm",
        "text": [
          "Input: a wRTG-LM wt with",
          "Output: for each do",
          "for each do new for each in do",
          "if () = new then",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)"
        ],
        "page_nums": [
          66
        ],
        "images": []
      },
      "10": {
        "title": "Value computation algorithm example",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)"
        ],
        "page_nums": [
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105
        ],
        "images": []
      },
      "11": {
        "title": "Termination and correctness",
        "text": [
          "- wRTG-LM canonical weighted deduction system wRTG-LM",
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "closed value computation algorithm",
          "closed weight preserving value computation algorithm",
          "Sufficient: ((,),,wt is closed or nonlooping e.g., acyclic RTGs, superior M-monoids, algebraic dynamic programming"
        ],
        "page_nums": [
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115
        ],
        "images": []
      },
      "12": {
        "title": "Closed wRTG LMs",
        "text": [
          "Richard Morbitz, Heiko Vogler: Weighted parsing for grammar-based language models (FSMNLP 2019)",
          "Let . A wRTG-LM = ((,),,wt is -closed if is distributive and d-complete, and for each T and cyclic string the following holds: if there is a (, )-cyclic path in , then",
          "at most times closed, distributive, d-complete",
          "For every and -closed wRTG-LM ((,),,wt the following holds:"
        ],
        "page_nums": [
          122,
          123
        ],
        "images": []
      }
    },
    "paper_title": "Weighted parsing for grammar-based language models"
  },
  "1105": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Attention vs. multi-task learning",
          "What is historical text normalization?",
          "Sample of a manuscript from Early New High German",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "A corpus of Early New High German",
        "text": [
          "Attention vs. multi-task learning",
          "What is historical text normalization?",
          "I Medieval religious treatise",
          "Interrogatio Sancti Anselmi de Passione Domini",
          "I 50 manuscripts and",
          "Sample from an Anselm manuscript",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Examples for historical spellings",
        "text": [
          "Attention vs. multi-task learning",
          "What is historical text normalization?",
          "Frau (woman) fraw, frawe, frawe, frauwe, frauwe, frow, frouw, vraw, vrow, vorwe, vrauwe, vrouwe",
          "Kind (child) chind, chinde, chindt, chint, kind, kinde, kindi, kindt, kint, kinth, kynde, kynt",
          "Mutter (mother) moder, moeder, mueter, mueter, muoter, muotter, muter, mutter, mvoter, mvter, mweter",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce",
          "Normalization as the mapping of historical spellings to their modern-day equivalents."
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Previous work",
        "text": [
          "Attention vs. multi-task learning",
          "What is historical text normalization?",
          "I Character-based statistical machine translation (CSMT)",
          "I Sequence labelling with neural networks",
          "I Bollmann and Sgaard (2016)",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce",
          "I Now: Character-based neural machine translation"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "An encoder decoder model",
        "text": [
          "Attention vs. multi-task learning",
          "k i n d E",
          "Embeddings S k i n d",
          "Embeddings c h i n t",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce",
          "Evaluation on 43 texts from the Anselm corpus"
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "5": {
        "title": "Attentional model",
        "text": [
          "Attention vs. multi-task learning",
          "k i n d E",
          "S k i n d",
          "c h i n t",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce",
          "Beam + Filter + Attention",
          "Evaluation on 43 texts from the Anselm corpus"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Learning to pronounce",
        "text": [
          "Attention vs. multi-task learning",
          "Can we improve results with multi-task learning?",
          "I Idea: grapheme-to-phoneme mapping as auxiliary task",
          "I CELEX 2 lexical database (Baayen et al., 1995)",
          "I Sample mappings for German:",
          "Abend nicht ab@nt nIxt"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "7": {
        "title": "Multi task learning",
        "text": [
          "Prediction layer for CELEX task",
          "k i n d E",
          "Prediction layer for historical task",
          "S k i n d",
          "c h i n t",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce",
          "n I x t E",
          "S n I x t",
          "n i c h t",
          "Beam + Filter + Attention"
        ],
        "page_nums": [
          15,
          16,
          17
        ],
        "images": []
      },
      "8": {
        "title": "Why does MTL not improve with attention",
        "text": [
          "Attention vs. multi-task learning",
          "Attention and MTL learn similar functions of the input data.",
          "MTL can be used to coerce the learner to attend to patterns in the input it would otherwise ignore. This is done by forcing it to learn internal representations to support related tasks that depend on such patterns.",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Comparing the model outputs",
        "text": [
          "Attention vs. multi-task learning",
          "Base model prandert pranget gewarnt uberbroch uberbrache uber ubergebe sollt sollt sollt sollte",
          "B gewarntet gewarntet gewarnt gewand uberbeh ubereube ubergebe uber sollte sollte sollte sollte",
          "Target gewarnt uberhob sollte",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "Saliency plots",
        "text": [
          "Attention vs. multi-task learning",
          "for words 7 characters, Attention/MTL correlate most",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/1105-Figure5-1.png"
        ]
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Attention vs. multi-task learning",
          "I Encoder/decoder models for historical text normalization",
          "I Beam search & attention improve results further",
          "I MTL with grapheme-to-phoneme task helps",
          "I Attention and MTL have a similar effect",
          "I Can this be reproduced on other tasks?",
          "I What factors affect this (choice of attention",
          "mechanism/auxiliary task/. . . )?",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Dealing with spelling variation",
        "text": [
          "The problems. . . Normalization. . .",
          "I Difficult to annotate with",
          "tools aimed at modern data",
          "I High variance in spelling",
          "I None/very little training",
          "I Enables re-using of",
          "I Useful annotation layer",
          "(e.g. for corpus query)",
          "Normalization as the mapping of historical spellings to their modern-day equivalents.",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "13": {
        "title": "Attention mechanism details",
        "text": [
          "I Attention mechanism follows Xu et al. (2015)",
          "ct ft ht ot ct1 it gt tanh(ct)",
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1105-Figure2-1.png"
        ]
      },
      "14": {
        "title": "Differences of learned parameters",
        "text": [
          "Marcel Bollmann, Joachim Bingel, Anders Sgaard Learning attention for hist. normalization by learning to pronounce"
        ],
        "page_nums": [
          28
        ],
        "images": [
          "figure/image/1105-Figure4-1.png"
        ]
      }
    },
    "paper_title": "Learning attention for historical text normalization by learning to pronounce"
  },
  "1106": {
    "slides": {
      "0": {
        "title": "AMR graph",
        "text": [
          "Parse to AMR Generate from AMR"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Abstract Meaning Representation",
        "text": [
          "Rooted Directed Acyclic Graph",
          "Nodes: concepts (nouns, verbs, named entities, etc)",
          "Edges: Semantic Role Labels",
          "I have known a planet that was inhabited by a lazy man. inhabit",
          "ARG0 ARG1 I knew a planet that was inhabited by a lazy man. I planet ARG1-of",
          "Generate from AMR inhabit",
          "man I know a planet. It is inhabited by a lazy man. mod",
          "Parse to AMR inhabit"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "Applications",
        "text": [
          "Text Summarization (Liu et al., 2015)",
          "Parse sentences: summary sentence",
          "AMR graphs: AMR graph:",
          "Source The children told that lie Target sono uso-wa kodomo-tachi-ga tsui-ta that lie-TOP child-and others-NOM breathe out-PAST Machine Translation (Jones et al., 2012)",
          "child lie ARG0-of that Parse AMR graph:",
          "ARG0 ARG1 ARG1 ARG0",
          "child lie Graph-to-graph transformation: tachi kodomo ARG0-of ARG0-of",
          "that sono Parse AMR graph: Generate translation:"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "3": {
        "title": "Existing Approaches",
        "text": [
          "Barzdins and Gosko 2016, Peng et al. 2017, Noord and Bos 2017, Buys and Blunsom"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "4": {
        "title": "Sequence to sequence model",
        "text": [
          "A know knew planet a planet man inhabit inhabited was",
          "input Encoder Decoder output",
          "know ARG0 I ARG1 planet ARG1-of inhabit <s> I know the planet of"
        ],
        "page_nums": [
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "5": {
        "title": "Linearization",
        "text": [
          "Graph -> Depth First Search (Human-authored annotation)",
          "ARG0 ARG1 time location",
          "person meet date-entity city",
          "ARG0-of ARG0 year month name have-role",
          "person ARG1 ARG2 New York ARG1-of ARG2-of country official",
          "name expert group United States",
          "US officials held an expert group meeting in January 2002 in New York ."
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "6": {
        "title": "Pre processing",
        "text": [
          "ARG0 ARG1 time location",
          "person meet date-entity city",
          "ARG0-of ARG0 year month name have-role",
          "person ARG1 ARG2 New York ARG1-of ARG2-of country official",
          "name expert group United States",
          "US officials held an expert group meeting in January 2002 in New York .",
          "loc_0 officials held an expert group meeting in month_0 year_0 in loc_1"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37
        ],
        "images": []
      },
      "7": {
        "title": "Experimental Setup",
        "text": [
          "Hand annotated MR graphs: newswire, forums",
          "~16k training / 1k development / 1k test pairs",
          "BLEU n-gram precision (Generation)"
        ],
        "page_nums": [
          38
        ],
        "images": []
      },
      "8": {
        "title": "Experiments",
        "text": [
          "Limited Language Model Capacity"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "9": {
        "title": "First Attempt Generation",
        "text": [
          "TreeToStr: Flanigan et al, NAACL TSP: Song et al, EMNLP 2016 PBMT: Pourdamaghani and Knight, INLG 2016 (Sennrich et al., ACL 2016)",
          "Language trained large systems",
          "We will emulate via data augmentation."
        ],
        "page_nums": [
          40,
          41,
          42,
          43
        ],
        "images": []
      },
      "10": {
        "title": "What went wrong",
        "text": [
          "US officials held an expert group meeting in January",
          "United States officials held held a meeting in",
          "Coverage a) Sparsity b) Avg sent length: 20 words c) Limited Language"
        ],
        "page_nums": [
          44,
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "11": {
        "title": "Data Augmentation",
        "text": [
          "Original Dataset: ~16k graph-sentence pairs",
          "Gigaword: ~183M sentences *only*",
          "Sample sentences with vocabulary overlap",
          "Parse to AMR Generate from AMR"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53,
          54,
          55
        ],
        "images": []
      },
      "12": {
        "title": "Semi supervised Learning",
        "text": [
          "Sogaard and Rishoj, 2010"
        ],
        "page_nums": [
          56
        ],
        "images": []
      },
      "13": {
        "title": "Paired Training",
        "text": [
          "Train AMR Parser P on Original Dataset",
          "Si =Sample k 10i sentences from Gigaword",
          "Parse Si sentences with P",
          "Re-train AMR Parser P on Si",
          "Train Generator G on SN"
        ],
        "page_nums": [
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "14": {
        "title": "Training AMR Parser",
        "text": [
          "Fine-tune: init parameters from previous step and train on Original Dataset",
          "Original Dataset sentences from Gigaword",
          "Original Dataset Parse S1 with P",
          "Train P on S2=2M"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75
        ],
        "images": []
      },
      "15": {
        "title": "Training AMR Generator",
        "text": [
          "Fine-tune: init parameters from previous step and train on Original Dataset",
          "Original Dataset Parse S4 with P"
        ],
        "page_nums": [
          76,
          77,
          78
        ],
        "images": []
      },
      "16": {
        "title": "Final Results Generation",
        "text": [
          "TreeToStr: Flanigan et al, NAACL 2016 TSP: Song et al, EMNLP 2016 PBMT: Pourdamaghani and Knight, INLG 2016"
        ],
        "page_nums": [
          79,
          80,
          81,
          82,
          83,
          84,
          85
        ],
        "images": []
      },
      "17": {
        "title": "Final Results Parsing",
        "text": [
          "SBMT CharLSTM+CAMR Seq2Seq NeuralAMR-20M"
        ],
        "page_nums": [
          86,
          87,
          88,
          89,
          90
        ],
        "images": []
      },
      "18": {
        "title": "How did we do Generation",
        "text": [
          "US officials held an expert group meeting in",
          "January 2002 in New York .",
          "In January 2002 United States officials held a meeting of the group experts in New York .",
          "The report stated British government must help to stabilize weak states and push for international regulations that would stop terrorists using freely available information to create and unleash new forms of biological warfare such as a modified version of the influenza virus.",
          "The report stated that the Britain government must help stabilize the weak states and push international regulations to stop the use of freely available information to create a form of new biological warfare such as the modified version of the influenza ."
        ],
        "page_nums": [
          91,
          92
        ],
        "images": []
      },
      "19": {
        "title": "Summary",
        "text": [
          "Sequence-to-sequence models for Parsing and Generation",
          "Paired Training: scalable data augmentation algorithm",
          "Achieve state-of-the-art performance on generating from AMR",
          "Best-performing Neural AMR Parser",
          "Demo, Code and Pre-trained Models: http://ikonstas.net"
        ],
        "page_nums": [
          93,
          94
        ],
        "images": []
      },
      "20": {
        "title": "Bonus Slides",
        "text": [],
        "page_nums": [
          95
        ],
        "images": []
      },
      "21": {
        "title": "Encoding",
        "text": [
          "Linearize -> RNN encoding",
          "hold ARG0 person ARG0-of",
          "Recurrent Neural Network (RNN)"
        ],
        "page_nums": [
          96,
          97,
          98,
          99,
          100,
          101,
          102
        ],
        "images": []
      },
      "22": {
        "title": "Decoding",
        "text": [
          "US a the meeting",
          "US person expert meeting meetings meet",
          "w11: Holding w21: Hold a wk1: The US officials held",
          "w12: Helds w22: Hold the wk2: US officials held a",
          "w13: Hold w23: Held a wk3: US officials hold the",
          "US w14: w24: Held the wk4: US officials will hold a"
        ],
        "page_nums": [
          103,
          104,
          105,
          106,
          107,
          108
        ],
        "images": []
      },
      "23": {
        "title": "Attention",
        "text": [
          "hold ARG0 person role US official ) ARG1 ( meet expert group )",
          "ai = softmax X fi h(s), hi",
          "held an expert group meeting in January"
        ],
        "page_nums": [
          109,
          110,
          111,
          112,
          113,
          114,
          115
        ],
        "images": []
      }
    },
    "paper_title": "Neural AMR: Sequence-to-Sequence Models for Parsing and Generation"
  },
  "1113": {
    "slides": {
      "0": {
        "title": "KyotoEBMT Overview",
        "text": [
          "sJll a few language-specific rules",
          "Maybe the least commonly used variant of x-to-x",
          "SensiJve to parsing quality of both source and target languages",
          "Maximize the chances of preserving informaJon",
          "Less commonly used than ConsJtuent trees",
          "Most natural for Japanese",
          "Should contain all important semanJc informaJon"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "KyotoEBMT pipeline",
        "text": [
          "1- Preprocessing of the parallel corpus",
          "2- Processing of input sentence",
          "Tuning and reranking done with kbMira",
          "seems to work beVer than PRO for us"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1113-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Other specificities",
        "text": [
          "all translaJon rules computed on-the-fly for each input cons:",
          "possibly slower (but not so slow) compuJng significance/ sparse features more complicated",
          "full-context available for compuJng features no limit on the size of matched rules possibility to output perfect translaJon when input is very similar to an example",
          "OpJonal words AlternaJve inserJon posiJons Decoder can process flexible rules more efficiently than a long list of alternaJve rules some flexible rules may actually encode >millions of standard rules"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Flexible Rules Extracted on the fly",
        "text": [
          "the hydrogen is produced",
          "Input: natural example) gas",
          "(plasJc) and raw petroleum",
          "at present X(plasJc) is Y(for example) produced Y(for example) Flexible translaJon rule created on-the-fly: from",
          "X: Simple case (X has an equivalent in the source example)",
          "Y: ambiguous inserJon posiJon",
          "raw: null-aligned -> opJonal raw* petroleum (encode many translaJon opJons at once) Y(for example) opJonal word"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Other specifici3es",
        "text": [
          "all translaJon rules computed on-the-fly for each input cons:",
          "possibly slower (but not so slow) compuJng significance/ sparse features more complicated",
          "full-context available for compuJng features no limit on the size of matched rules possibility to output perfect translaJon when input is very similar to an example",
          "OpJonal words AlternaJve inserJon posiJons Decoder can process flexible rules more efficiently than a long list of alternaJve rules some flexible rules may actually encode >millions of standard rules"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Improvements since WAT2014",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "KyotoEBMT improvements",
        "text": [
          "Our system is very sensiJve to",
          "Forest Juman parses KNP",
          "Added support for parse forests",
          "System is also very sensiJve to alignment errors",
          "We used to correct alignments by",
          "Forest using dependency trees (Nakazawa parses and Kurohashi, 2012)",
          "Now we further improve them with",
          "BeVer handling of flexible rules",
          "Forest 10 new features parses alignment score",
          "context similarity score based on word2vec vectors",
          "Forest RNNLM language model parses",
          "Now also using a Neural MT based",
          "automaJc nightly tesJng for variaJons in BLEU/ asserJon errors/",
          "Forest memory leaks parses Overall improvements across all",
          "EsJmaJng the global contribuJon of each element is tough, but here are the final results,"
        ],
        "page_nums": [
          9,
          11,
          13,
          14,
          16
        ],
        "images": [
          "figure/image/1113-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Forest Input",
        "text": [
          "A parJal soluJon to the issues of Tree-to-Tree MT",
          "Can help with parsing errors",
          "Can help with syntacJc divergences",
          "we used 20-best input parses n-best list of all inputs merged and reranked",
          "an exponenJal number of input parses can be encoded the selecJon of parses is done during decoding"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Alignment Improvements",
        "text": [
          "Used Nile (Riesa et al., 2011) to improve the alignment",
          "As suggested by (Neubig and Duh, 2014)",
          "Require us to parse into consJtuent trees as well",
          "Ckylark parser for Japanese (Oda+, 2015)",
          "Berkeley Parser for Chinese/English",
          "Nile becomes the third element of an alignment pipeline",
          "with dependency trees with consJtuent trees",
          "Giza++ Kurohashi, (Nakazawa 2012) and Nile"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Bilingual Neural Network Language Model",
        "text": [
          "Combine Neural MT with EBMT",
          "We use the state-of-the-art model described by (Bahdanau et al., 2015)",
          "Model seen as a Language Model condiJonalized on the input",
          "Processing Japanese and Chinese as sequences of characters gave good results",
          "Avoid segmentaJon issues Faster training",
          "Reranked BLEU/ NeuralMT char-BLEU vs Epochs for J->C",
          "Neural MT models alone produced bad translaJons eg. Character BLEU for C->J almost half that of KyotoEBMT Reranking performances saturates before MT performances",
          "Neural MT cBLEU reranked BLEU KyotoEBMT cBLEU"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Results",
        "text": [],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Results for WAT2015",
        "text": [
          "The various improvements lead to good changes in BLEU.",
          "Almost +4 BLEU for the JC/CJ",
          "Only for J->C, we find that reranking decreased",
          "(While sJll improving BLEU/RIBES)"
        ],
        "page_nums": [
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "KyotoEBMT is a (Dependency) Tree-to-Tree MT system with state-of-",
          "Improvements across the whole pipeline lead us to close to +4 BLEU improvements",
          "Make more use of the target structure",
          "Use of deep learning features in the decoder"
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "KyotoEBMT System Description for the 2nd Workshop on Asian Translation"
  },
  "1115": {
    "slides": {
      "0": {
        "title": "Questions and answers",
        "text": [
          "0. Do current language models do equally well on all languages? No.",
          "1. Which one do they struggle more with: German or English? German.",
          "2. What about non-Indo-European languages, say Chinese? It depends.",
          "3. What makes a language harder to model? Actually, rather technical factors.",
          "4. Is Translationese easier? Its different, but not actually easier!"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "1": {
        "title": "How to measure difficulty",
        "text": [
          "Language models measure surprisal/information content (NLL; log p()):",
          "en I love Florence! 5 bits",
          "Ich grue meine Oma und die Familie dahein.",
          "Alle mensen worden vrij en gelijk in waardigheid en rechten geboren. 11 bits",
          "Issue 1: Different topics/styles/content Issue 2: Comparing scores",
          "en Resumption of the session. de Wiederaufnahme der Sitzung. nl Hervatting van de sessie.",
          "Solution: train and test on translations!",
          "Europarl: 21 languages share ~40M chars",
          "Bibles: 62 languages share ~4M chars",
          "and this one takes a big ILP to solve, which is really fun Gurobi Why?",
          "Bibles: 69 languages 62 languages share ~4M chars",
          "13 language fam ilies and this one takes",
          "Use total bits of an open-vocabulary model."
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "2": {
        "title": "How to compare your language models across languages",
        "text": [
          "We need to be open-vocabulary no UNKs.",
          "Every UNK is cheating morphologically rich languages have more UNKs, unfairly advantaging them.",
          "We cant normalize per word or even per character in languages individually.",
          "Example: if puccz and Putschde are equally likely, they should be equally difficult.",
          "just use overall bits (i.e., surprisal/NLL) of an aligned sentence",
          "[note: total easily obtainable from BPC or perplexity by multiplying with total chars/words]"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "3": {
        "title": "How to aggregate multiple intents surprisals into difficulties",
        "text": [
          "For fully parallel corpora... we can just sum everything up and compare that is fair.",
          "Wieder- aufnah- me der",
          "Although we were not al-",
          "Jetzt ist die Zeit y4,en y4,de y4,bg",
          "The peace that language",
          "aligned multi-text den dde dbg",
          "But what if theres missing data? Or we want robustness?",
          "LM surprisals/NLLs log-normal noise",
          "y2,en y2,de y2,bg n2 This is a probabilistic model language we can perform inference in!",
          "not qu ite, ou exp dde",
          "This is a probabilistic model E R O n2",
          "al m od el is",
          "we E can D A perform inference in!",
          "i j i n exl"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
        ],
        "images": [
          "figure/image/1115-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Good open vocabulary language models",
        "text": [
          "Formerly state-of-the-art-ish AWD-LSTM (Merity et al., 2018) language models:",
          "RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell",
          "char-RNNLM: t h e c a t c h a s e d"
        ],
        "page_nums": [
          41
        ],
        "images": []
      },
      "5": {
        "title": "Good open vocabulary language models Mielke and Eisner 2019",
        "text": [
          "Formerly state-of-the-art-ish AWD-LSTM (Merity et al., 2018) language models:",
          "RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell RNN cell",
          "char-RNNLM: t h e c a t c h a s e d",
          "RNN cell RNN cell R NN cell RNN cell RNN cell BPE-RNNLM, few merges: the ca@@ t cha@@ sed"
        ],
        "page_nums": [
          42,
          43
        ],
        "images": []
      },
      "6": {
        "title": "Choosing the number of BPE merges how many is best",
        "text": [
          "It depends on the language (total surprisal, given merges as a ratio of the vocabulary):",
          "hu ro nl p el hu de hu hu hu",
          "sv es pt cs",
          "f i hu de hu hu hu de de de de hu de de de cs p el cs pl pl pl nl pl pt pl cs pl pl cs cs pt cs el cs pl cs et et et ro nl ro cs et es it ro nl et nl et et it pt nl el el t el el el et ro el n el es es pt it pt f i nl en es pt pt fi ro fi nl ro pt fi nl sk es it i f es es pt fr fr it ro es es bg i f sl en lt ro lt ro lt lt f i it sk it lt sk lt sk lt lt it it sk sl fi sk sk sl lt i f en sk sk sl sl sl sl bg fr fr sl lv sl fr bg lv fr lv fr lv fr fr da sv lv lv bg lv bg bg bg en bg bg en lv en lv en en en",
          "da sv lv lv bg lv fr lv bg bg bg en bg bg en lv en lv en en en",
          "da sv sv sv sv sv da sv sv sv da da da da da da",
          "da sv lv lv bg lv bg bg bg en bg lv fr bg en lv en lv en en en",
          "is this one going to be fine?",
          "i f de de",
          "pt cs el cs pl et et et et ro es it nl ro cs ro nl et nl et nl el el el et it el t el et ro pt el n el es pt it pt i f nl fi ro fi nl ro pt fi nl",
          "en es es pt es pt sk fr fr it es it i f es pt es",
          "bg f i sl en lt ro lt ro lt ro es i f it sk it lt sk lt lt it sk lt it sk sl lt fi sk sk sl",
          "it doesnt matter that much.",
          "et es pt nl ro cs f i bg it el da lt sv sk en sl"
        ],
        "page_nums": [
          44,
          45,
          46,
          47
        ],
        "images": []
      },
      "7": {
        "title": "Difficulties for char BPE RNNLM 21 Europarl languages",
        "text": [
          "difficulty (100) using char-RNNLM",
          "difficulty (100) using BPE-RNNLM with 0.4|V| merges",
          "et es pt nl",
          "cs ro f i bg it el da lt sv sk en sl easier with chars"
        ],
        "page_nums": [
          48,
          49,
          50,
          51
        ],
        "images": [
          "figure/image/1115-Figure4-1.png"
        ]
      },
      "8": {
        "title": "Difficulties for char BPE RNNLM 21 Europarl languages and 106 Bibles",
        "text": [
          "difficulty (100) using char-RNNLM",
          "easier with BPE easier with BPE",
          "de de de de de",
          "et es de de de",
          "pt en nl en de",
          "i cs ro f bg it el en",
          "da en en lt sv sk en sl easier with chars easier with chars eng",
          "bba bqc arb lv cmn lit difficulty (100) using BPE-RNNLM with 0.4|V| merges difficulty (100) using BPE-RNNLM with 0.4|V| merges",
          "fr pt nl ro cs el it f i bg",
          "poh deu deu deu deu cak ceb ayr",
          "fr hu in f ita ceb kjb ceb ita fra tgl wbm deu som ces cac deu et cnh deu por ita ita vie deu deu es gur ukurkr pt eng vie bul f in hun ayr nl nld dan por ell bul fra ron",
          "afr ind ben por fra dan nld ell ita no fra fra ces hhurn v quy vie mya xho tpi eng deu cym mmamri fra ind ben zom fra ron fra fra por aln plt f in f in cs ro f i mah kek quh hat tlh rus bg hat eng qub it el fra lat bul wal quz da kek eng epo fra nor lt arz fra sv sk tpm en tbz lit sl easier with chars easier with chars eng"
        ],
        "page_nums": [
          52,
          53,
          54,
          55
        ],
        "images": [
          "figure/image/1115-Figure4-1.png"
        ]
      },
      "9": {
        "title": "How about morphological counting complexity Sagot 2013",
        "text": [
          "pl el ro pt es et de hu",
          "cs pl nl fr hu",
          "it nl es pt et",
          "fr en ro bg cs f i",
          "sk sl bg el it lt f i da",
          "en lt sv sk sl lv da sv lv",
          "en da nl fr sv de sk el it ro es",
          "bg sl et pl lt cs f i",
          "5 10 an 5 0 outlier 0 en da nl fr sv de sk",
          "es pt lv hu",
          "lt cs i f"
        ],
        "page_nums": [
          57,
          58
        ],
        "images": []
      },
      "10": {
        "title": "Other linguistically motivated regressors",
        "text": [
          "WALS: Prefixing vs. Suffixing Morphology (for languages where present)?",
          "WALS: Order of Subject, Object and Verb (for languages where present)?",
          "Head-POS Entropy (Dehouck and Denis, 2018)?",
          "...neither mean and skew show correlation.",
          "Average dependency length (computed using UDPipe (Straka et al., 2016))?",
          "...correlation! But not significant after correcting for multiple hypotheses."
        ],
        "page_nums": [
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67
        ],
        "images": []
      },
      "11": {
        "title": "Very simple heuristics are very predictive",
        "text": [
          "Raw sequence length # predictions char-RNNLM difficulty",
          "i.e., for the char-RNNLM puccz is easier than Putschde! i.e., the BPE-RNNLM still suffers if a language has high type-token-ratio!",
          "Significant on: not Europarl",
          "but Bibles at p",
          "Wow! What is happening here? We have many conjectures..."
        ],
        "page_nums": [
          68,
          69,
          70
        ],
        "images": []
      },
      "12": {
        "title": "Translationese translations as a separate language",
        "text": [
          "Common assumption: Translationese is somehow simpler than native text.",
          "We have partial parallel data that we can use to evaluate our models:",
          "enoriginal entranslated deoriginal detranslated nloriginal nltranslated",
          "The German... Der deutsche... De Duitse...",
          "Thank you... Vielen Dank... Hartelijk...",
          "...and indeed the original languages seem harder. But we missed something!"
        ],
        "page_nums": [
          72,
          73,
          74,
          75
        ],
        "images": []
      },
      "13": {
        "title": "We trained on mostly translationese",
        "text": [
          "en fr de es nl it pt sv el fi pl da ro hu sk cs sl lt bg et lv",
          "languages, sorted by absolute # native sentences",
          "Of course we will then find it easier..."
        ],
        "page_nums": [
          76
        ],
        "images": [
          "figure/image/1115-Figure9-1.png"
        ]
      },
      "14": {
        "title": "Repeat the experiment with fairly balancing training data",
        "text": [
          "Change the training sets!",
          "We can rebalance a single language, leaving the others merged, i.e.:",
          "enoriginal entranslated de nl",
          "The German... Der deutsche... De Duitse...",
          "Thank you... Vielen Dank... Hartelijk...",
          "And the result: the difficulties are now the same!",
          "(more precisely, native is 0.004 easier)"
        ],
        "page_nums": [
          77,
          78
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion cross linguistic comparisons are tricky hope we didnt mess up",
        "text": [
          "1. Make sure your training data is comparable and fair.",
          "2. Make sure your metrics are comparable and fair.",
          "3. Make sure your stats are fair (no p-hacking!).",
          "4. Work on more NLP resources for more languages!"
        ],
        "page_nums": [
          79,
          80,
          81,
          82,
          83
        ],
        "images": []
      }
    },
    "paper_title": "What Kind of Language Is Hard to Language-Model?"
  },
  "1116": {
    "slides": {
      "0": {
        "title": "NLU as Relationship Identification",
        "text": [
          "Natural language inference (entailment)",
          "Premise: A woman is running in the park with her dog",
          "Hypothesis: A woman is sleeping",
          "Relation: entailment, neutral, contradiction",
          "No, he replied, except that he seems in a great hurry. Thats just it, Jimmy returned promptly. Did you ever see him hurry unless he was frightened? Peter confessed that he never had.",
          "Q: Well, he isnt now, yet just look at him go A: Do, case, confessed , frightened, m ean, replied, returned, said, see, thought Q: Is the girl walking the bike?",
          "Reading comprehension Visual question answering",
          "Assumption: Identifying the relationship requires",
          "nguage Visual understanding question answering"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "One Sided Biases",
        "text": [
          "Hypothesis-only NLI (Poliak+ 18; Gururangan+ 18; Tsuchia 18)",
          "Hypothesis: A woman is sleeping",
          "Reading comprehension (Kaushik & Lipton 18)",
          "Visual question answering (Zhang+ 16; Kafle & Kanan 16; Goyal+ 17;",
          "Agarwal+ 17; inter alia)",
          "Story cloze completion (Schwartz+ 17, Cai+ 17)"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "2": {
        "title": "Problem",
        "text": [
          "One-sided biases mean that models may not learn the true relationship between premise and hypothesis"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "3": {
        "title": "Strategies for dealing with dataset bias",
        "text": [
          "o o Other bias",
          "Construct new datasets (Sharma+ 18)",
          "Filter easy examples (Gururangan+ 18)",
          "o Hard to scale o May still have biases (see SWAG BERT HellaSWAG)",
          "Forgo datasets with known biases",
          "o Not all bias is bad o Biased datasets may have other useful information"
        ],
        "page_nums": [
          15,
          16,
          17
        ],
        "images": []
      },
      "4": {
        "title": "Our approach",
        "text": [
          "Design models that facilitate learning less biased representations"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "5": {
        "title": "A Generative Perspective",
        "text": [
          "Typical NLI models maximize the discriminative likelihood",
          "Our key idea: If we generate the premise, it cannot be ignored",
          "We will maximize the likelihood of generating the premise",
          "Hypothesis: A woman is sleeping Premise: A woman is running in",
          "Relation: contradiction the park with her dog",
          "Unfortunately, text generation is hard!",
          "Premise: A woman is running in the park with her dog",
          "Premise: A woman sings a song while playing piano",
          "Premise: This woman is laughing at her baby",
          "Instead, rewrite as follows",
          "Assume p(P |H) is constant",
          "Need to estimate this"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28
        ],
        "images": []
      },
      "6": {
        "title": "Method 1 Auxiliary Hypothesis Classifier",
        "text": [
          "Learn a new estimator p\u0000,(y|H)",
          "Learn an additional classification layer"
        ],
        "page_nums": [
          29,
          30,
          31
        ],
        "images": []
      },
      "7": {
        "title": "Method 2 Negative Sampling",
        "text": [
          "Lower bound from Jensens inequality",
          "Approximate the expectation with uniform samples P"
        ],
        "page_nums": [
          32,
          33,
          34,
          35
        ],
        "images": []
      },
      "8": {
        "title": "What is this good for",
        "text": [
          "Are less biased models more transferable?"
        ],
        "page_nums": [
          36,
          37
        ],
        "images": []
      },
      "9": {
        "title": "A Toy Example",
        "text": [],
        "page_nums": [
          38,
          39,
          40
        ],
        "images": []
      },
      "10": {
        "title": "Models transfer well on synthetic data",
        "text": [],
        "page_nums": [
          41,
          42
        ],
        "images": []
      },
      "11": {
        "title": "Degradation in domain",
        "text": [
          "SNLI Test SNLI Hard",
          "Baseline Auxiliary Hyp. Classifier Negative Sampling"
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "12": {
        "title": "Transfer to other datasets",
        "text": [
          "When it works, it works well"
        ],
        "page_nums": [
          45,
          46
        ],
        "images": []
      },
      "13": {
        "title": "Analysis",
        "text": [
          "Q: Does it matter what kind of bias we have?",
          "A: Yes! Different biases than training data",
          "Usually, more improvement from our methods",
          "Q: Do stronger hyper-parameters help?",
          "A: More emphasis on the auxiliary objective",
          "More transferability, but worse in-domain performance",
          "Q: What if we get a bit of out-of-domain training data?",
          "A: Pre-training with our methods still helps",
          "Especially with datasets with different biases"
        ],
        "page_nums": [
          47,
          48,
          49,
          50
        ],
        "images": []
      },
      "14": {
        "title": "More Analysis",
        "text": [
          "Q: Are biases really removed from the hidden representations?",
          "A: Some, but not all",
          "See our recent work: On Adversarial Removal of Hypothesis-only Bias in NLI,",
          "Q: Does this approach work for other tasks?",
          "A: Seems to work for VQA (Ramakrishnan+ 18)",
          "A: But there are shortcomings",
          "See our recent work: Adversarial Regularization for VQA: Strengths,",
          "Shortcomings, and Side Effects, SiVL 2019"
        ],
        "page_nums": [
          51,
          52
        ],
        "images": []
      },
      "15": {
        "title": "Contributions",
        "text": [
          "Our approach may aid with one-sided biases in NLI and other tasks",
          "Reduces the amount of bias",
          "Our analysis shows that the methods should be handled with care",
          "Not all bias may be removed",
          "Some other information may also be removed",
          "The goal matters: bias may sometimes be helpful"
        ],
        "page_nums": [
          53,
          54
        ],
        "images": []
      }
    },
    "paper_title": "Don't Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference"
  },
  "1117": {
    "slides": {
      "0": {
        "title": "Task Description",
        "text": [
          "Given a sentence Sentiment",
          "Polarity More fine-grained classes",
          "The food is very delicious. Positive",
          "The movie is so boring. Negative"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Early Methods",
        "text": [
          "Linguistic knowledge based-----Sentiment lexicon [Turney, 2002; Taboada et",
          "Recursive Neural Network [Socher et al. 2011]",
          "Convolutional Neural Network [Kim, 2014]",
          "Recurrent Neural Network/LSTM [Hochreiter and Schmidhuber,",
          "Incorporating Linguistic Knowledge with Neural Networks",
          "Linguistically regularized LSTM [Qian et al., 2017]",
          "Lexicon integrated CNN models with attention [Bonggun et al., 2017]"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Motivation",
        "text": [
          "Sentiment linguistic knowledge (e.g. sentiment words, intensity words, negation words) play important roles in sentiment detection.",
          "By attention mechanism, we can integrate various sentiment resource information into neural networks to boost the performance."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Our Model",
        "text": [
          "The overall framework of our model"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Coupled word Embedding",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Multi sentiment resource attention module",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Context sentiment correlation modeling",
        "text": [
          "Note that in proceeding version, there are some typos in this part. The updated version can be obtained via arxiv.org: https://arxiv.org/abs/1807.04990"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Multi sentiment resource attention",
        "text": [
          "Intensity attention and Negation attention are computed via the similar methods with the sentiment word attention",
          "Finally, the multi-sentiment-resource enhanced sentence representation:"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Training",
        "text": [
          "The predicted sentiment polarity distribution can be obtained via a fully connected layer with softmax."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Experiments",
        "text": [
          "training/validation/test split is the same as (Qian et al., 2017) ;",
          "Sentiment words-----combined from (Hu and Liu, 2004) and",
          "Intensity words and Negation words manually collected due to the limited number."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Experiments Results",
        "text": [],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1117-Table1-1.png"
        ]
      },
      "11": {
        "title": "Summary and Future work",
        "text": [
          "Integrating sentiment resources into neural networks is effective to improve the performance of sentence-level sentiment classification.",
          "How to deign the more effective information-fusion methods is still challenging, such as regularization, attention, .",
          "In future work, we can consider employing position embedding to automatically detecting various sentiment resource words."
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification"
  },
  "1118": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "They have been married for three years.",
          "Event Trigger ismarried, which represents a marry event"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "... I knew it was time to leave.",
          "A single sentence may cause ambiguous",
          "Is not that a great argument for term limits?",
          "The contextual information of a individual sentence offers",
          "more confident for classifying",
          "Liao and Grishman, ACL, 2010",
          "Huang and Riloff, AAAI, 2012"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "DEEB RNN The Proposed Model",
        "text": [
          "I qi qi qL",
          "I I I I I I I I I I I I I I I I I I I I I I t a N SN",
          "fi a fit we fir",
          "rj document e embedding > eld \\e) word embedding entity type embedding",
          "Document-level Enhanced Event Detector"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1118-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Model ED Oriented Document Embedding Learning",
        "text": [
          "Indicatedis a event trigger and is setted as 1, other words are setted as 0.",
          "The square error as the general loss of the attention at sentence level to supervise the learning process.",
          "S1, S3 and SL are sentences with event triggers and is setted as 1, other sentences are setted as 0."
        ],
        "page_nums": [
          6,
          7,
          8,
          9
        ],
        "images": [
          "figure/image/1118-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Model Document level Enhanced Event Detector",
        "text": [
          "softmax output layer to get the predicted probability for each word"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Model Joint Training",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Experiments Configuration",
        "text": [
          "GRU w ,GRU s ,GRUe",
          "entity type embeddings 50 (randomly initialized)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Experiments Model analysis",
        "text": [
          "both gold attention signals"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1118-Table1-1.png"
        ]
      },
      "9": {
        "title": "Experiments Baselines",
        "text": [
          "* Feature-based methods without document-level information :",
          "* Representation-based methods without document-level information :",
          "* Feature-based methods using document level information :"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Experiments Main Results",
        "text": [],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1118-Table2-1.png"
        ]
      },
      "11": {
        "title": "Summary",
        "text": [
          "hierarchical and supervised attention",
          "gold word- and sentence-level attentions"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Document Embedding Enhanced Event Detection with Hierarchical and Supervised Attention"
  },
  "1119": {
    "slides": {
      "0": {
        "title": "Semantic Role Labeling SRL",
        "text": [
          "Find out who did what to whom in text",
          "I ate pizza with friends"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "SRL as BIO Tagging",
        "text": [
          "ARG0 V ARG1 AM-PRP",
          "Input1 Many tourists visit Disney to meet their favorite cartoon characters",
          "Needs target predicate as input!",
          "(Prior works typically used gold predicates)",
          "Ne eds to re-run the tag ger f or ea ch pre dicate"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "SRL as Predicting Word Span Relations",
        "text": [
          "Many tourists visit Disney to meet their favorite cartoon characters",
          "(similar to Punyakanok08, FitzGerald15, inter alia)",
          "* Too many possible edges (n2 argument spans x n predicates)"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "Our Model",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Our Model Overview",
        "text": [
          "Many tourists visit Disney to meet their favorite cartoon characters",
          "tourists visit Disney their favorite cartoon",
          "Many tourists Disney to meet their cartoon characters",
          "(1) Construct span representations for all n2 spans!",
          "(2) Local classifier over labels (including NULL) for all possible (predicate, argument) pairs",
          "(3) Greedy beam pruning for spans"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": [
          "figure/image/1119-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Results and Analysis",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "6": {
        "title": "End to End SRL Results",
        "text": [
          "He17 Ours He17 (Ensemble) Ours+ELMo",
          "BIO-based, pipelined predicate ID",
          "CoNL05 WSJ Test CoNL05 Brown Test CoNLL2012 (OntoNotes)",
          "With ELMo, over 3 points improvement over SotA ensemble!",
          "*ELMo: Deep Contextualized Word Representations, Peters et al., 2018"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "7": {
        "title": "Span based vs BIO",
        "text": [
          "Predicate Identification Pipelined Joint",
          "Predicate Identification Due to the strong independence Pipelined Joint",
          "Global Consistency By allowing direct interaction",
          "between predicates and arguments"
        ],
        "page_nums": [
          27,
          28,
          29
        ],
        "images": []
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "Joint prediction of predicates and arguments",
          "1. Contextualized span representations",
          "2. Local label classifiers",
          "3. Greedy span pruning",
          "Future work: Improve global consistency, use span representations for downstream tasks, etc."
        ],
        "page_nums": [
          30,
          31,
          32
        ],
        "images": [
          "figure/image/1119-Figure2-1.png"
        ]
      }
    },
    "paper_title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"
  },
  "1120": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Our target problem is the extraction of drug-drug interactions",
          "(DDIs) from biomedical texts",
          "Grepafloxacin inhibits the metabolism of Theophylline",
          "We investigate the use of external drug database (DrugBank) information in extracting DDIs from texts",
          "We especially focus on molecular structure information"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Method Overview",
        "text": [
          "We obtain the representations of textual drug pairs using convolutional neural networks (CNNs) and molecular drug pairs using graph convolutional networks (GCNs)",
          "We concatenate text-based and molecule-based vectors",
          "Grepafloxacin inhibits the metabolism of Theophylline"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Method",
        "text": [
          "DDI extraction from texts using molecular structures",
          "Molecular structure-based DDI representation",
          "word + position embeddings",
          "Grepafloxacin inhibits Textual vector",
          "Text Corpus the metabolism of",
          "Input sentence word vector"
        ],
        "page_nums": [
          4,
          5,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Method Text based DDI Representation",
        "text": [
          "word + position embeddings",
          "Grepafloxacin inhibits Textual vector",
          "Text Corpus the metabolism of",
          "Our model for representing textual DDIs is based on the CNN model by",
          "We use word and position embeddings as the input to the convolution layer",
          "We convert the output of the convolution layer into a fixed-size textual vector"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Method Molecular Structure based DDI Representation",
        "text": [
          "We represent drug pairs in molecular graph structures using",
          "We pre-train GCNs using interacting (positive) pairs mentioned in the DrugBank and not mentioned (pseudo negative) pairs in the DrugBank",
          "Theophylline interact not mentioned",
          "Graph Convolutional Network (GCN) [Li et al. 2016]",
          "We use GCNs to convert a drug molecule graph into a fixed size vector by aggregating node vectors",
          "graph structure molecular vector",
          "Node : neighbors of",
          "GRU : gated Recurrent Unit",
          ": element-wise product : concatenation : learned weight"
        ],
        "page_nums": [
          8,
          9,
          10
        ],
        "images": []
      },
      "5": {
        "title": "Method DDI Extraction from Texts Using Molecular Structures",
        "text": [
          "word + position embeddings",
          "Grepafloxacin inhibits the metabolism of",
          "Link mentions in text corpus to drug database entries by relaxed string matching",
          "Obtain molecular vectors via GCNs with fixed parameters",
          "Grepafloxacin GCN DrugBank Theophylline",
          "Predict DDIs from concatenated textual and molecular vectors",
          "Grepafloxacin GCN concat DrugBank Theophylline"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "6": {
        "title": "Task Settings",
        "text": [
          "The data set is composed of documents annotated with drug mentions and their 4 types of interactions (Mechanism, Effect, Advice and Interaction) or no interaction",
          "Statistics of the DDI SemEval2013 shared task"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "7": {
        "title": "Data for Pre training GCNs",
        "text": [
          "We extracted 255,229 interacting (positive) pairs from",
          "DrugBank and generated the same number of pseudo negative pairs by randomly pairing DrugBank drugs",
          "We deleted drug pairs mentioned in the test set of the text corpus"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "8": {
        "title": "Molecular Structure Features",
        "text": [
          "To obtain the graph of a drug molecule, we took as input the SMILES string encoding of the molecule from",
          "DrugBank and then converted it into the 2D graph structure using RDKit",
          "For the initial atom (node) vectors, we used randomly embedded vectors for atoms, i.e., C, O, N,",
          "We also used 4 bond (edge) types: single, double, triple, and aromatic"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Differences of Labels in Text and Database Tasks",
        "text": [
          "Interacting drug pairs in database may not appear as positive instances in the text task",
          "Text task define 4 detailed types, while database task has one positive type.",
          "Grepafloxacin inhibits the metabolism of Theophylline",
          "While the effect of Grepafloxacin on the metabolism of",
          "C.P.A substrates is not evaluated, in vitro data suggested similar effects of Grepafloxacin in Theophylline metabolism"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "10": {
        "title": "Training Settings",
        "text": [
          "Mini-batch training using the Adam optimizer with L2 regularization",
          "Word embeddings trained by the word2vec tool on the",
          "2014 MEDLINE/PubMed baseline distribution",
          "Hyper-parameters for text-based model Hyper-parameters for molecule-based"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation on Relaxed String Matching",
        "text": [
          "How much of drug mentions in texts are linked to",
          "DrugBank entries by relaxed string matching?",
          "We lowercased the mentions and the names in the entries and chose the entries with the most overlaps",
          "As a result, 92.15% and 93.09% of drug mentions in train and test",
          "SemEval2013 data set matched the DrugBank entries"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Evaluation on DDI Extraction from Texts SemEval2013 Shared Task",
        "text": [
          "We observe the increase of micro F-score by using molecular structures",
          "Text + Molecular Structure"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "13": {
        "title": "Analysis",
        "text": [
          "Can molecular structures alone represent DDIs in texts ?",
          "Grepafloxacin inhibits the metabolism of",
          "Grepafloxacin GCN concat interact not interact",
          "- This might be because the drug pairs that interact can appear in the textual context that does not describe their interactions"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "14": {
        "title": "Conclusions",
        "text": [
          "We proposed a novel neural method for DDI extraction using both textual and molecular information",
          "The molecular information has improved DDI extraction performance",
          "As future work, we will investigate the use of other information in DrugBank"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Enhancing Drug-Drug Interaction Extraction from Texts by Molecular Structure Information"
  },
  "1121": {
    "slides": {
      "0": {
        "title": "Again",
        "text": [
          "Heard on the campaign trail:",
          "Make the middle class mean something again, with rising incomes and broader horizons.",
          "Make America great again."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "What is presupposition",
        "text": [
          "Presuppositions: assumptions shared by discourse participants in an",
          "Presupposition triggers: expressions that indicate the presence of presuppositions.",
          "Oops! I did it again Trigger",
          "Presupposes Britney did it before"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Linguistic Analysis",
        "text": [
          "Presuppositions are preconditions for statements to be true or false",
          "Classes of construction that can trigger presupposition (Zare et al., 2012):",
          "Definite descriptions (Kabbara et al., 2016), e.g.: The queen of the United",
          "Stressed constituents (Krifka, 1998), e.g.: Yes, Peter did eat pasta.",
          "Factive verbs, e.g.: Michael regrets eating his mothers cookies.",
          "Implicative verbs, e.g.: She managed to make it to the airport on time."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Motivation and Applications",
        "text": [
          "Interesting testbed for pragmatic reasoning: investigating presupposition triggers requires understanding preceding context.",
          "Presupposition triggers influencing political discourse:",
          "The abundant use of presupposition triggers helps to better communicate political messages and consequently persuade the audience (Liang and Liu,",
          "To improve the readability and coherence in language generation applications (e.g., summarization, dialogue systems)."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Adverbial Presupposition Triggers",
        "text": [
          "Indicate the recurrence, continuation, or termination of an event in the discourse context, or the presence of a similar event.",
          "The most commonly occurring presupposition triggers (after existential triggers) (Khaleel, 2010).",
          "Little work has been done on these triggers in the computational literature from a statistical, corpus-driven perspective.",
          "All others (lexical and structural)"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "This Work",
        "text": [
          "Computational approach to detecting presupposition triggers.",
          "Create new datasets for the task of detecting adverbial presupposition triggers.",
          "Control for potential confounding factors such as class balance and syntactic governor of the triggering adverb.",
          "Present a new weighted pooling attention mechanism for the task."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Task",
        "text": [
          "Detect contexts in which adverbial presupposition triggers can be used.",
          "Requires detecting recurring or similar events in the discourse context.",
          "Five triggers of interest: too, again, also, still, yet.",
          "Frame the learning problem as a binary classification for predicting the presence of an adverbial presupposition (as opposed to the identity of the adverb)."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Sample Configuration",
        "text": [
          "3-tuple: label, list of tokens, list of POS tags.",
          "Back to our example:",
          "Make America great again. Trigger",
          "(aka governor of again)",
          "Special token: to identify the candidate context in the passage to the model.",
          "Make, America, great], Tokens",
          "VB, NNP, JJ ] POS tags"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Positive vs Negative Samples",
        "text": [
          "Same governors as in the positive cases but without triggering presupposition.",
          "Example of positive sample:",
          "Juan is coming to the event too.",
          "Example of negative sample:",
          "Whitney is coming tomorrow."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Extracting Positive Samples",
        "text": [
          "Scan through all the documents to search for target adverbs.",
          "For each occurrence of a target adverb:",
          "Store the location and the governor of the adverb.",
          "Extract 50 unlemmatized tokens preceding the governor, together with the tokens right after it up to the end of the sentence (where the adverb is)."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Extracting Negative Samples",
        "text": [
          "Extract sentences containing the same governors (as in the positive cases) but not any of the target adverbs.",
          "Number of samples in the positive and negative classes roughly balanced.",
          "Negative samples are extracted/constructed in the same manner as the positive examples."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Position Related Confounding Factors",
        "text": [
          "We try to control position-related confounding factors by two randomization approaches:",
          "Randomize the order of documents to be scanned.",
          "Within each document, start scanning from a random location in the document."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Learning Model",
        "text": [
          "Presupposition involves reasoning over multiple spans of text.",
          "At a high level, our model extends a bidirectional LSTM model by:",
          "Computing correlations between the hidden states at each timestep.",
          "Applying an attention mechanism over these correlations.",
          "No new parameters compared to standard bidirectional LSTM."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Learning Model Overview",
        "text": [],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "14": {
        "title": "Learning Model Input",
        "text": [
          "Optionally concatenate with POS tags."
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "15": {
        "title": "Learning Model RNN",
        "text": [
          "concatenates all hidden states.",
          "We continue to feel that the stock market biLSTM is the @@@@ place to be for long-term appreciation."
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "16": {
        "title": "Learning Model Matching Matrix",
        "text": [
          "Pair-wise matching matrix M"
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "17": {
        "title": "Learning Model Softmax",
        "text": [
          "Learn how to aggregate.",
          "Row-wise softmax: Attention distribution over words."
        ],
        "page_nums": [
          24,
          25
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "18": {
        "title": "Learning Model Attention Score",
        "text": [
          "School of Computer Science",
          "Column-wise softmax Row-wise softmax",
          "The columns of M\" are then '",
          "averaged, forming vector [.",
          "biLSTM: hidden states concatenated to",
          "embeddings concatenated [ word embedding lookup ] :",
          "t The Old Granary... @@@@_ included Bertrand Russell",
          "based on (Cui et al.,"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Learning Model Attend",
        "text": [],
        "page_nums": [
          28
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "20": {
        "title": "Learning Model Predict",
        "text": [],
        "page_nums": [
          29
        ],
        "images": [
          "figure/image/1121-Figure2-1.png"
        ]
      },
      "21": {
        "title": "Datasets",
        "text": [
          "New datasets extracted from:",
          "The English Gigaword corpus:",
          "Individual sub-datasets (i.e., presence of each adverb vs. absence).",
          "ALL (i.e., presence of one of the 5 adverbs vs. absence).",
          "The Penn Tree Bank (PTB) corpus:"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "22": {
        "title": "Results Overview",
        "text": [
          "Our model outperforms all other models in 10 out of 14 scenarios",
          "(combinations of datasets and whether or not POS tags are used).",
          "WP outperforms regular LSTM without introducing additional parameters.",
          "For all models, we find that including POS tags benefits the detection of adverbial presupposition triggers in Gigaword and PTB datasets."
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "23": {
        "title": "Results WSJ",
        "text": [
          "WP best on WSJ.",
          "WSJ - Accuracy MFC: Most Frequent Class",
          "baselines by large margin.",
          "Models Variants All adverbs",
          "Network based on (Kim",
          "+ POS LSTM - POS",
          "+ POS WP - POS"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "24": {
        "title": "Results Gigaword",
        "text": [
          "Models Variants All adverbs Again Still Too Yet Also",
          "+ POS CNN - POS",
          "+ POS LSTM - POS",
          "+ POS WP - POS",
          "in 10 out of cases.",
          "Better performance with POS."
        ],
        "page_nums": [
          33,
          34,
          35
        ],
        "images": []
      },
      "25": {
        "title": "Qualitative Analysis",
        "text": [
          "... We continue to feel that the stock market is the place to be for long-term appreciation.",
          "... Careers count most for the well-to-do. Many affluent people place personal success and money above family."
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "26": {
        "title": "Conclusion",
        "text": [
          "New task, detection of adverbial presupposition triggers",
          "New datasets for the task.",
          "New attention model tailored for the task.",
          "Our model outperforms other strong baselines without additional parameters over the standard LSTM model."
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "27": {
        "title": "Future Directions",
        "text": [
          "Incorporate such a system in an NLG pipeline (e.g., dialogue or summarization with text rewriting).",
          "Discourse analysis with presupposition (e.g., political speech).",
          "Investigate other types of presupposition."
        ],
        "page_nums": [
          38
        ],
        "images": []
      }
    },
    "paper_title": "Let's do it \"again\": A First Computational Approach to Detecting Adverbial Presupposition Triggers"
  },
  "1122": {
    "slides": {
      "0": {
        "title": "Discourse Dependency Structure and Treebanks",
        "text": [
          "Example text: [Syntactic parsing is useful in NLP.]e1 [We present a parsing algorithm,]e2",
          "[which improves classical transition-based approach.]e3",
          "Discourse dependency tree: background elaboration [Li. 2014; Yoshida. 2014]",
          "Advantage: flexible, simple, support non-projection (ROOT node)",
          "Conversion based dependency treebanks from RST or SDRT representations [Li. 2014; Stede. 2016]",
          "Limitations: conversion errors and not support non-projection",
          "Build a dependency treebank from scratch",
          "Scientific abstracts: short with strong logics"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Annotation Framework Discourse Segmentation",
        "text": [
          "Discourse segmentation: Segment abstracts into elementary discourse units (EDUs)",
          "Generally treats clauses as EDUs [Polanyi. 1988, Mann and Thompson. 1988]",
          "Subjective and some objective clauses are not segmented [Carlson and Marcu. 2001]",
          "Example 1: [The challenge of copying mechanism in Seq2Seq is that new machinery is needed]e1 [to decide when to perform the operation.]e2",
          "Strong discourse cues always starts a new EDU",
          "Example 2: [Despite bilingual embeddings success,]e1 [the contextual information]e2",
          "[which is important to translation quality,]e3 [was ignored in previous work.]e4"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Annotation Framework Obtain Tree Structure",
        "text": [
          "A tree is composed of relations",
          ": the EDU with essential information",
          ": the EDU with supportive content",
          ": relation type (17 coarse-grained and 26 fine-grained types)",
          "Each EDU has one and only one head",
          "One EDU is dominated by ROOT node",
          "Polynary relations joint process-step"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Annotation Example in SciDTB",
        "text": [],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1122-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Corpus Construction",
        "text": [
          "5 annotators were selected after test annotation",
          "Semi-automatic: pre-trained SPADE [Soricut. 2003] Manual proofreading",
          "The annotation lasted 6 months",
          "63% abstracts were annotated more than twice",
          "An online tool was developed for annotating and visualizing DT trees"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Online Annotation Tool",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Reliability Annotation Consistency",
        "text": [
          "The consistency of tree annotation is analyzed by 3 metrics:",
          "Unlabeled accuracy score: structural consistency",
          "Labeled accuracy score: overall consistency",
          "Cohens Kappa: consistency on relation label conditioned on same structure",
          "Annotators #Doc. UAS LAS Kappa score",
          "Annotator 1 & 2",
          "Annotator 3 & 4",
          "Annotator 4 & 5"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Annotation Scale",
        "text": [
          "comparable with PDTB and RST-DT considering size of units and relations",
          "much larger than existing domain-specific discourse treebanks",
          "Corpus #Doc. #Doc. (unique) #Text unit #Relation Source Annotation form",
          "SciDTB Scientific abstracts Dependency trees",
          "RST-DT Wall Street Journal RST trees",
          "PDTB v2.0 Wall Street Journal Relation pairs",
          "BioDRB Biomedical articles Relation pairs"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Structural Characteristics",
        "text": [
          "Most relations (61.6%) occur between neighboring EDUs",
          "The distance of 8.8% relations is greater than 5",
          "Non-projection: 3% of the whole corpus"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "SciDTB as Benchmark",
        "text": [
          "We make SciDTB as a benchmark for evaluating discourse dependency parsers",
          "3 baselines are implemented:",
          "Vanilla transition based parser",
          "Two-stage transition based parser a simpler version of [Wang, 2017]",
          "Dev set Test set Model UAS LAS UAS LAS"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Conclusions",
        "text": [
          "We propose a discourse dependency treebank with following features:",
          "comparable with existing treebanks in size",
          "We further make SciDTB as a benchmark",
          "Consider longer scientific articles",
          "Develop effective parsers on SciDTB"
        ],
        "page_nums": [
          12
        ],
        "images": []
      }
    },
    "paper_title": "SciDTB: Discourse Dependency TreeBank for Scientific Abstracts"
  },
  "1123": {
    "slides": {
      "0": {
        "title": "Extractive Summarization",
        "text": [
          "Select salient sentences from input document to create a summary",
          "INPUT Document with sentences S1, S2,.., Sn"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Our Contribution",
        "text": [
          "A Deep Learning Architecture for training an extractive summarizer: SWAP-NET",
          "Unlike previous methods, SWAP-NET uses keywords for sentence selection",
          "Predicts both important words and sentences in document",
          "Two-level Encoder-Decoder Attention model",
          "Outperform state of the art extractive summarisers.",
          "INPUT Document with sentences S1, S2,.., Sn"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Extractive Summarization Methods",
        "text": [
          "Pre-trained word embeddings Word Encodings wrt other words Sentence Encoding wrt words in it Sentence Encodings wrt other sentences Document Encoding wrt its sentences",
          "Sentence encodings wrt other sentences",
          "Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2017. Summarunner: A recurrent neural network based sequence model for extractive summarization of docments. In Association for the Advancement of Artificial Intelligence, pages 30753081. Jianpeng Cheng and Mirella Lapata. 2016. Neural summarization by extracting sentences and words. 54th Annual Meeting of the Association for Computational Linguistics.",
          "SummaRuNNer (Nallapati et al., 2017)",
          "Both assume saliency of sentence s depends on salient sentences appearing before s",
          "Word Label Prediction (with decoder)",
          "Sentence Label Prediction (with decoder)"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          44
        ],
        "images": []
      },
      "3": {
        "title": "Intuition Behind Approach",
        "text": [
          "Question: Which sentence should be considered salient (part of summary)?",
          "Our hypothesis: saliency of a sentence depends on both salient sentences and words appearing before that sentence in the document",
          "Similar to graph based models by Wan et al. (2007)",
          "Along with labelling sentences we also label words to determine their saliency",
          "Moreover, saliency of a word depends on previous salient words and sentences",
          "Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007. Towards an iterative reinforcement approach for simultaneous document summarization and keyword extraction. In Proceedings of the 45th annual meeting of the association of computational linguistics, pages 552559.",
          "Three types of Interactions:"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "4": {
        "title": "Intuition Interaction Between Sentences",
        "text": [
          "A sentence should be salient if it is heavily linked with other salient sentences"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Intuition Interaction Between Words",
        "text": [
          "A word should be salient if it is heavily linked with other salient words"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Intuition Words and Sentences Interaction",
        "text": [
          "A sentence should be salient if it contains many salient words",
          "A word should be salient if it appears in many salient sentences",
          "Generate extractive summary using both important words and sentences",
          "Word-Word Important Sentences: S3 Important Words: V2, V3"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Keyword Extraction and Sentence Extraction",
        "text": [
          "Sentence to Sentence Interaction as Sentence Extraction",
          "Word to Word Interaction as Word Extraction",
          "For discrete sequences, pointer networks have been successfully used to learn how to select positions from an input sequence",
          "We use two pointer networks one at word-level and another at sentence-level"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Pointer Network",
        "text": [
          "Encoder-Decoder architecture with Attention",
          "Attention mechanism is used to select one of the inputs at each decoding step",
          "Thus, effectively pointing to an input"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Three Interactions",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Three Interactions SWAP NET",
        "text": [
          "A Mechanism to Combine",
          "Word Level Attentions and"
        ],
        "page_nums": [
          16,
          18,
          21
        ],
        "images": []
      },
      "11": {
        "title": "Questions",
        "text": [
          "Q1 : How can the two attentions be combined?",
          "Q2 : How can the summaries be generated considering both the attentions?",
          "A Mechanism to Combine",
          "Word Level Attentions and"
        ],
        "page_nums": [
          17,
          41
        ],
        "images": []
      },
      "12": {
        "title": "SWAP NET Architecture Word Level Pointer Network",
        "text": [
          "Similar to Pointer Network,",
          "The word encoder is bi-directional LSTM",
          "Word-level decoder learns to point to important words",
          "E W E W E W E W E W D W D W D W",
          "Purple line: attention vector given as input to each decoding step",
          "Sum of word encodings weighted by attention probabilities generated in previous step",
          "Probability of word i, at decoding step j"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "13": {
        "title": "SWAP NET Architecture",
        "text": [
          "Sentence-Level Hierarchical Pointer Network",
          "Sentence is represented by encoding of last word of that sentence",
          "Word Encoder E W E W E W E W E W D W D W D W",
          "Attention vectors are sum of sentence encodings weighted by attention probabilities by previous decoding step",
          "Probability of sentence k, at decoding step j"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": []
      },
      "14": {
        "title": "Combining Sentence Attention and Word Attention",
        "text": [
          "Q1 : How can the two attentions be combined?",
          "A document with three sentences and corresponding words is shown"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "15": {
        "title": "Sentence and Word Interactions",
        "text": [
          "Step 1: Hold sentence processing. Then group all words and determine their saliency sequentially",
          "Step 2: Using output of step 1, i.e., using keywords, process sentences to determine salient sentences",
          "INCOMPLETE SOLUTION This methods processes sentence depending on words but does not use sentences for processing words.",
          "Group each sentence and its words separately and process them sequentially",
          "Hold sentence processing. Determine saliency of words in S1",
          "Using information about saliency of words in S2 and saliency of previous sentence S1",
          "Hold word processing and resume sentence processing.",
          "Using information about saliency of both S1 and its words",
          "Hold sentence processing and resume word processing.",
          "Determine saliency of words in next sentence S2",
          "Determine saliency of sentence S2",
          "This methods ensures that saliency of word and sentence is determined from previously predicted both salient sentences and words",
          "Using previously predicted salient word and sentences",
          "Synchronising Decoding Steps: Decide when to turn off and on word processing and sentence processing to synchronise word and sentence prediction",
          "Sharing Attention Vectors: Determine salient words and sentences"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "16": {
        "title": "Three Interaction SWAP NET",
        "text": [],
        "page_nums": [
          34
        ],
        "images": []
      },
      "17": {
        "title": "SWAP NET Switch Mechanism",
        "text": [
          "Sharing both attention vectors (purple and orange lines) between the two decoder",
          "Synchronising decoding steps of the two decoders by allowing only one decoder output at a step",
          "Feedforward Netw ork Switch Probability",
          "E W E W E W E W E W D W D W D W Word Decoder Hidden State",
          "Output is selected with maximum of final word and sentence probabilities",
          "Final Word Probabilities E W E W E W E W E W D W D W D W"
        ],
        "page_nums": [
          35,
          36
        ],
        "images": []
      },
      "18": {
        "title": "Prediction with SWAP NET Encoding",
        "text": [
          "E W E W E W E W E W",
          "Input Document w1 w2 w3 w4 w5"
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "19": {
        "title": "Prediction with SWAP NET Decoding Step",
        "text": [
          "Switch has two states,",
          "Q = 0 : word selection and",
          "Q = 1 : sentence selection",
          "Q=0 E W E W E W E W E W D W D W D W"
        ],
        "page_nums": [
          38,
          39,
          40
        ],
        "images": []
      },
      "20": {
        "title": "Summary Generation",
        "text": [
          "House prices across the UK will rise at a fraction of last years frenetic pace, forecasts show.",
          "prices rise fraction frenetic pace forecasts show",
          "Probability KeyWord P1 P2 P3 P4 P5 P6 P7",
          "Score of Given Sentence = (Sentence Probability) + (Sum of its keyword Probabilities)",
          "k = Ps + Pi where k is number of keywords in sentence S i=1",
          "Top 3 sentences with maximum scores are chosen as summary"
        ],
        "page_nums": [
          42,
          43
        ],
        "images": []
      },
      "21": {
        "title": "Dataset and Evaluation",
        "text": [
          "Large Benchmark Dataset CNN/DailyMail News Corpus",
          "News articles from CNN/DailyMail along with human generated summary (gold summary) for each article",
          "GroundTruth Binary Labels For Training",
          "Sentences: Anonymised version of dataset given by (Cheng and Lapata, 2016)",
          "Words: Extract keywords from each gold summary using RAKE",
          "Dataset Training Validation Test",
          "Standard Evaluation Metric: Three Variates of Rouge Score",
          "Comparing generated summaries and gold summaries for matching:",
          "ROUGE-L (RL): Longest Common Subsequences Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley. 2010. Automatic key word extraction from individual documents. Text Mining: Applications and Theory."
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "22": {
        "title": "Results",
        "text": [
          "Performance on DailyMail Dataset using limited length recall of Rouge",
          "Performance on CNN and Daily-Mail test set using the full length Rouge F score"
        ],
        "page_nums": [
          46,
          47
        ],
        "images": []
      },
      "23": {
        "title": "Example",
        "text": [
          "Meet the four immigrant students each accepted to ALL EIGHT Ivy League schools who want to pay back their parents who moved to the U.S. to give them a better",
          "Their parents came to the U.S. for opportunities and now these four teens have them in abundance .",
          "The high-achieving high schoolers have each been accepted to all eight Ivy League schools : Brown University , Columbia University ,",
          "Cornell University , Dartmouth College , Harvard University , University of Pennsylvania , Princeton University and Yale University .",
          "And as well as the Ivy League colleges , each of them has also been accepted to other top schools . While they all grew up in different cities , the students are the offspring of immigrant parents who moved to America - from Bulgaria , Somalia or Nigeria . Summary Generated",
          "Munira_Khalif from Minnesota , Stefan_Stoykov from Indiana , Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York got multiple offers All have immigrant parents - from Somalia , Bulgaria or Nigeria - and say they have their parents ' hard work to thank for their successes They hope to use the opportunities for good , from improving education across the world to becoming neurosurgeons"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "24": {
        "title": "SWAP NET Predicted Keywords",
        "text": [
          "Summary Generated by SWAP-NET",
          "While they all grew up in different cities , the students are the offspring of immigrant parents who moved to America - from Bulgaria , Somalia or Nigeria",
          "And all four - Munira_Khalif from Minnesota , Stefan_Stoykov from Indiana , Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York - say they have their parents ' hard work to thank .",
          "Now they hope to use the opportunities for good - whether its effecting positive social change , improving education across the world or becoming a neurosurgeon",
          "SWAP-NET predictions highlighted in green"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "25": {
        "title": "Keywords Ground truth vs SWAP NET predictions",
        "text": [
          "SWAP-NET key words (green) and Ground truth (blue)",
          "While they all grew up in different cities , the students are the offspring of immigrant parents who moved to America - from Bulgaria , Somalia or Nigeria",
          "And all four - Munira_Khalif from Minnesota Stefan_Stoykov from Indiana , Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York - say they have their parents hard work to thank . Now they hope to use the opportunities for good - whether its effecting positive social change , improving education across the world or becoming a neurosurgeon",
          "Now they hope to use the opportunities for good - whether its effecting positive social change , improving education across the world or becoming a neurosurgeon",
          "Munira_Khalif from Minnesota Stefan_Stoykov from Indiana Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York got multiple offers All have immigrant parents - from Somalia Bulgaria or Nigeria - and say they have their parents hard work to thank for their successes They hope to use the opportunities for good , from improving education across the world to becoming neurosurgeons"
        ],
        "page_nums": [
          50
        ],
        "images": []
      },
      "26": {
        "title": "Observations",
        "text": [
          "Almost no keyword is repeated across different sentence in the summary",
          "Summary Generated by SWAP-NET:",
          "Presence of key words in all the overlapping segments of text with the gold summary",
          "While they all grew up in different cities , the students are the offspring of immigrant parents who moved to America - from Bulgaria Somalia or Nigeria And all four - Munira_Khalif from Minnesota Stefan_Stoykov from Indiana , Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York - say they have their parents hard work to thank . Now they hope to use the opportunities for good - whether its effecting positive social change , improving education across the world or becoming a neurosurgeon",
          "Bulgaria , Somalia or Nigeria",
          "And all four - Munira_Khalif from Minnesota ,",
          "Munira_Khalif from Minnesota Stefan_Stoykov from Indiana Victor_Agbafe from North_Carolina , and Harold_Ekeh from New_York got multiple offers All have immigrant parents - from Somalia Bulgaria or Nigeria - and say they have their parents hard work to thank for their successes They hope to use the opportunities for good , from improving education across the world to becoming neurosurgeons",
          "North_Carolina , and Harold_Ekeh from New_York - say they have their parents ' hard work to thank .",
          "Now they hope to use the opportunities for good - whether its effecting positive social change , improving education across the world or becoming a neurosurgeon",
          "Most of the predicted keywords are actual keywords",
          "Most of the extracted summary sentences contain keywords",
          "Gold Summary: Large proportion of key words from the",
          "gold summary present in the generated summary"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "27": {
        "title": "Experiments",
        "text": [
          "Key word coverage measures the proportion of key words from those in the gold summary present in the generated summary",
          "Sentences with key words measures the proportion of sentences containing at least one key word",
          "Average pairwise cosine distance between paragraph vector representations of sentences in summaries to measure semantic redundancy in summaries",
          "SWAP-NET summaries are similar in redundancy to the Gold summary",
          "Highlights the importance of key words in finding salient sentences for extractive summaries"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "28": {
        "title": "Conclusion",
        "text": [
          "We develop SWAP-NET, a neural sequence-to- sequence model for extractive summarization",
          "By effective modelling of interactions between sentences and key words,",
          "SWAP- NET outperforms state-of-the-art extractive single-document summarizers",
          "SWAP-NET models these interactions using a new two-level pointer network based architecture with a switching mechanism",
          "Experiments suggest that modelling sentence-keyword interaction has the desirable property of less semantic redundancy in summaries generated by SWAP-NET",
          "An implementation of SWAP-NET and generated summaries from the test sets are available online: https://github.com/aishj10/swap-net"
        ],
        "page_nums": [
          53
        ],
        "images": []
      }
    },
    "paper_title": "Reinforced Extractive Summarization with Question-Focused Rewards"
  },
  "1126": {
    "slides": {
      "0": {
        "title": "What is Cross Language Plagiarism Detection",
        "text": [
          "Cross-Language Plagiarism is a plagiarism by translation, i.e. a text has been plagiarized while being translated (manually or automatically).",
          "From a text in a language L, we must find similar passage(s) in other text(s) from a set of candidate texts in language L (cross-language textual similarity)."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Why is it so important",
        "text": [
          "- McCabe, D. (2010). Students cheating takes a high-tech turn. In Rutgers Business School. - Josephson Institute. (2011). What would honest Abe Lincoln say?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Research Questions",
        "text": [
          "How do the state-of-the-art methods behave according to the characteristics of the compared texts?",
          "Are the methods depend on the characteristics of the compared texts? And if so, which characteristics?",
          "Are the state-of-the-art methods complementary?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "State of the Art Methods",
        "text": [
          "Length Model, CL-CnG [Potthast et al., 2011], Cognateness",
          "MT-Based Models Translation + Monolingual Analysis [Muhr et al., 2010]"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1126-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Evaluation Dataset Ferrero et al 2016",
        "text": [
          "French, English and Spanish;",
          "Parallel and comparable (mix of Wikipedia, conference papers, product reviews,",
          "Different granularities: document level, sentence level and chunk level;",
          "Human and machine translated texts;",
          "Obfuscated (to make the similarity detection more complicated) and without added noise;",
          "Written and translated by multiple types of authors;",
          "1A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity",
          "Detection. In Proceedings of LREC 2016."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "First experiment Evaluation Protocol",
        "text": [
          "We compared each textual unit to its corresponding unit in another language and to 999 other units randomly selected;",
          "We threshold the obtained distance matrix to find the threshold giving the best F1 score;",
          "We repeat these two steps 10 times, leading to a 10 folds validation;",
          "The final value are the average of the 10 F1 score."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Results Across Language Pairs",
        "text": [
          "Methods ENFR FREN ENES ESEN ESFR FRES",
          "Table 1: Overall F1 score over all sub-corpora of the state-of-the-art methods for each language pair (EN: English; FR: French; ES: Spanish).",
          "(a) Chunk granularity (b) Sentence granularity",
          "Table 2: Top 3 methods by source and target language.",
          "Strong correlation between languages!",
          "ENFR FREN ENES ESEN ESFR FRES Overall Lang. Pair ENFR FREN ENES ESEN ESFR FRES",
          "Table 3: Pearson correlations of the overall F1 score over all sub-corpora of all methods between the different language pairs (EN: English; FR: French; ES: Spanish).",
          "Strong correlation between granularities!",
          "Table 4: Pearson correlations of the results of all methods on all sub-corpora, between the chunk and the sentence granularity, by language pair (EN: English; FR: French; ES: Spanish)",
          "Table 5: Pearson correlations of the results on all sub-corpora on all language pairs, between the chunk and the sentence granularity, by methods (calculated from Table 1)."
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16
        ],
        "images": [
          "figure/image/1126-Table7-1.png",
          "figure/image/1126-Table3-1.png",
          "figure/image/1126-Table6-1.png"
        ]
      },
      "7": {
        "title": "Results Detailed Analysis for English French",
        "text": [
          "CL-CTS CL-ASA CL-ESA T+MA",
          "Table 6: Average F1 scores and confidence intervals of methods applied on ENFR sub-corpora at chunk and sentence level 10 folds validation."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "8": {
        "title": "Second Experiment Evaluation Protocol",
        "text": [
          "We compare 1000 English textual units to their corresponding unit in French, and to one other (not relevant) French unit;",
          "Each unit must strictly leads to one match and one mismatch",
          "We repeat these two steps 10 times, leading to a 10 folds validation."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Complementarity",
        "text": [
          "Figure 1: Distribution histograms of Random Baseline (left) and CL-C3G (right) for",
          "1000 positives (lightgreen) and 1000 negatives (darkred) (mis)matches.",
          "Figure 2: Distribution histograms of CL-ASA (left) and CL-C3G (right) for 1000 positives"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "Results show a common behavior of methods across different language pairs;",
          "Strong correlations across languages, sizes and types of texts;",
          "Methods behave differently in clustering, even if they seem similar in performance combination or fusion?",
          "I invit you to come see my poster this afternoon at SemEval workshop to verify"
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Deep Investigation of Cross-Language Plagiarism Detection Methods"
  },
  "1130": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Objective: classify between false friends or cognates for",
          "False friends: pair of words from different languages that are written or pronounced in a similar way, but have different meanings."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Example False Friends",
        "text": [
          "obligado obrigado no no aceite aceite borracha borracha cadera cadeira desenvolver desenvolver propina propina"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Motivation",
        "text": [
          "False friends make harder to learn a language or to communicate, especially when its similar to the mother tongue.",
          "Between Spanish and Portuguese, the amount of cognates reaches the 85% of the total vocabulary (Ulsh, 1971)."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Frunza, 2006: supervised machine learning using orthographic distances as features to classify between cognates, false friends or unrelated.",
          "Mitkov et al., 2007: used a combination of distributional and taxonomy-based approaches. Worked with English-French,",
          "They use WordNet taxonomy similarities to classify, and if a word is missing they fall back to a distributional method.",
          "For the distributional method they build vectors based on word windows, computing the co-occurrence probability.",
          "Then, they compared the N closest words of each word in the pair, translate one of them and count occurrences in the other one. They defined a threshold based on Dice coefficient.",
          "experiment with several ways to build the vector space (e.g. tf-idf) and measure vector distances (e.g. cosine distance).",
          "They also proposed to use PMI.",
          "They worked with closely related languages: Slovene and",
          "Sepulveda and Aluisio, 2011: false friends resolution for",
          "Spanish-Portuguese, highly based on (Frunza, 2006).",
          "They added an experiment with a new feature whose value is the likelihood of translation, from a probabilistic dictionary",
          "(generated taking a large sentence-aligned bilingual corpus)."
        ],
        "page_nums": [
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "4": {
        "title": "Word Vector Representations",
        "text": [
          "Related work crafted their own word vector representations.",
          "We propose to use the skip-gram-based word2vec model"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Transform between Vector Spaces",
        "text": [
          "Mikolov et al, 2013b: propose a method to correspond two word2vec vector spaces via a linear transformation.",
          "Used to build dictionaries and phrase tables."
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "6": {
        "title": "Our Method",
        "text": [
          "Build word2vec vector spaces, find a linear transformation and measure vector distances.",
          "Note that we dont cope with related/unrelated, we just focus on cognate/false friends",
          "We used the Wikipedias for the vector spaces.",
          "Open Multilingual WordNet (Bond and Paik, 2012) was used as a bilingual lexicon to fit the linear transformation: we iterate over synsets and took lexical units from each language. Then we employed Least Squares.",
          "We take one of the word vectors, transform it to the other space and compute:",
          "The cosine distance between T(source_vector) and target_vector.",
          "The number of word vectors in the target vector space closer to target_vector than T(source_vector).",
          "The sum of the distances between target_vector and",
          "T(source_vector_i) for the top 5 word vectors source_vector_i nearest to source_vector."
        ],
        "page_nums": [
          12,
          13,
          14,
          15
        ],
        "images": [
          "figure/image/1130-Figure2-1.png"
        ]
      },
      "7": {
        "title": "Experiments",
        "text": [
          "We used (Sepulveda and Aluisio, 2011) dataset, which is composed by 710 pairs (338 cognates and 372 false friends)."
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "8": {
        "title": "Experiments different configurations",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Experiments bilingual lexicon",
        "text": [],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1130-Figure3-1.png"
        ]
      },
      "10": {
        "title": "Conclusions",
        "text": [
          "We have provided a new approach to classify false friends with high accuracy and coverage.",
          "We studied it for Spanish-Portuguese and provided state-of-the-art results for the pair.",
          "The method doesnt require rich bilingual datasets.",
          "It could be easily applied to other language pairs."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "Future Work",
        "text": [
          "Experiment with other word vector representations and state-of-the-art vector space linear transformation.",
          "Work on fine-grained classifications.",
          "E.g., partial false friends."
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "A High Coverage Method for Automatic False Friends Detection for Spanish and Portuguese"
  },
  "1137": {
    "slides": {
      "0": {
        "title": "What are Polarity Shifters",
        "text": [
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Shifters vs Negation",
        "text": [
          "Marc Schulder Saarland University",
          "Word Type Closed Class Open Class",
          "Existing polarity classifiers can process negation, but fail to detect polarity shifters due to a lack of resources."
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Goal",
        "text": [
          "Marc Schulder Saarland University",
          "Main sentence predicate far reaching scope"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Input Resource WordNet WordNet",
          "Shifter Labels Lemma Word Sense",
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Word Sense Ambiguity",
        "text": [
          "50% of verbs are polysemous.",
          "12% of verbs are shifters in at least one word sense.",
          "Among polysemous verbal shifters, only 23% are shifters in all their word senses.",
          "Mark down: Reduce in price Shifter",
          "The agency [marked down [their assets]+]-.",
          "Mark down: Write down No Shifter",
          "She [marked down [his confession of guilt]-]-.",
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Shifter Scope",
        "text": [
          "When a phrase contains a polarity shifter, you need to know what part of the phrase it can affect.(Wiegand et al., 2017, GSCL)",
          "The villain]- defeated [the hero]+.",
          "The villain]- surrendered [to the hero]+. subj",
          "Marc Schulder Saarland University",
          "Scope annotated for dependency relations."
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "6": {
        "title": "Annotation Workflow",
        "text": [
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
        ],
        "images": [
          "figure/image/1137-Table2-1.png"
        ]
      },
      "7": {
        "title": "Annotators",
        "text": [
          "Experience in linguistics and annotation work",
          "2nd annotator labelled 400 word senses",
          "Both annotators are authors of this paper.",
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "8": {
        "title": "Lexicon Example",
        "text": [
          "Blow out Synset 00436247 SUBJ Shifter melt, break, or become otherwise unusable",
          "Blow out Synset 02767855 DOBJ Shifter put out, as of fires, flames, or lights",
          "erupt in an uncontrolled manner",
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "We introduced a lexicon of English verbal shifters:",
          "Covers all verbs in WordNet",
          "Annotations for each word sense",
          "Marc Schulder Saarland University"
        ],
        "page_nums": [
          36
        ],
        "images": []
      }
    },
    "paper_title": "Introducing a Lexicon of Verbal Polarity Shifters for English"
  },
  "1138": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "u Capture common-sense knowledge about the",
          "fine-grained events of everyday experience",
          "u opening a fridge enabling preparing food",
          "u getting out of bed being triggered by an alarm",
          "Contingency relation between events",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Much of the user generated content on social media is providing by ordinary people telling stories about their daily lives",
        "text": [
          "Learning Fine-Grained Knowledge about Contingent Relations between Everyday Events",
          "Elahe Rahimtoroghi, Ernesto Hernandez and Marilyn A Walker",
          "Natural Language and Dialogue Systems Lab",
          "Department of Computer Science, University",
          "We develop and test a novel method for learning fine-grained common-sense knowl- edge from these stories about contingent",
          "(causal and conditional) relationships be- tween everyday events. This type of knowl- edge is useful for text and story under- standing, information extraction, question answering, and text summarization. We test and compare different methods for learning contingency relation, and com- pare what is learned from topic-sorted story collections vs. general-domain stories. Our experiments show that using topic- specific datasets enables learning finer- grained knowledge about events and results in significant improvement over the base- lines. An evaluation on Amazon Mechani-",
          "We packed all our things on the night before Thu (24 Jul) except for frozen food. We brought a lot of things along. We woke up early on Thu and JS started packing the frozen marinatinated food inside the small cooler... In the end, we decided the best place to set up the tent was the squarish ground thats located on the right. Prior to setting up our tent, we placed a tarp on the ground. In this way, the underneaths of the tent would be kept clean. After that, we set the tent up.",
          "u Rich with common-sense knowledge about",
          "contingent relations between events",
          "u placing a tarp, setting up a tent",
          "the hurricane made landfall, the wind u Storm blew, a tree fell I dont know if I wouldve been as calm as I was without the radio, as the hurricane made landfall in Galveston at 2:10AM on Saturday. As the wind blew, branches thudded on the roof or trees snapped, it was helpful to pinpoint the place... A tree fell on the garage roof, but its minor dam- age compared to what couldve happened. We then started cleaning up, despite Sugar Land implementing a curfew un- til 2pm; I didnt see any policemen enforcing this. Luckily my dad has a gas saw (as opposed to electric), so we helped cut up three of our neighbors trees. I did a lot of raking, and theres so much debris in the garbage.",
          "started cleaning up, cut up the trees, u raking",
          "This fine-grained knowledge is simply not found in previous work on narrative Figure Natural Language 1: Excerpts and Dialougue of two Systems stories UC in Santa the Cruz blogs corpus on the topics of Camping Trip and Storm. event collections"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "A Brief Look at Previous Work",
        "text": [
          "u Much of the previous work is not",
          "focused on a particular relation between events (Chambers and Jurafsky,",
          "Balasubramanian et al., 2013; Pichotta and",
          "u Main focus is on newswire Personal stories",
          "u Evaluation criteria: narrative cloze test New evaluation method as well as previous Natural Language and Dialougue Systems UC Santa Cruz work"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Challenge Personal stories provide both advantages and disadvantages",
        "text": [
          "u Told in chronological order",
          "u Temporal order between events is a strong cue to contingency",
          "u Their structure is more similar to oral narrative (Labov and Waletzky, 1967; Labov, 1997)",
          "u Only about a third of the sentences in a personal narrative describe actions",
          "Novel methods are needed to find useful relationships between events u"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Event Representation and Extraction",
        "text": [
          "Event: Verb Lemma (subj:Subject Lemma, dobj:Direct Object Lemma, prt:Particle)",
          "In previous work different representations have been proposed for the event structure such as single verb and verb with two or more arguments. Verbs are used as a central indication of an event in a narra- tive. However, other entities related to the verb also play a strong role in conveying the meaning of the event. In (Pichotta and Mooney, 2014) it is shown that the multi-argument representation is richer than the previous ones and is capable of capturing inter- actions between multiple events. We use a repre- sentation that incorporates the Particle of the verb in the event structure in addition to the Subject and the Direct Object and define an event as a verb with its dependency relations as follows:",
          "Sentence Event Representation Multi-argument representation is richer, u but it wasnt at all frustrating putting up the tent and setting up the first night put (dobj:tent, prt:up)",
          "capable of capturing interactions between multiple events (Pichotta and",
          "The next day we had oatmeal for breakfast have (subj:PERSON, dobj:oatmeal) Mooney, 2014)",
          "by the time we reached the Lost River Valley Camp- ground, it was already past 1 pm reach (subj:PERSON, dobj:LOCATION) Event extraction u",
          "then JS set up a shelter above the picnic table set (subj:PERSON, dobj:shelter, prt:up) Stanford dependency parser u",
          "once the rain stopped, we built a campfire using the irewoods f build (subj:PERSON, dobj:campfire) Stanford NER u",
          "Table 3: Event representation examples from Camping Natural Language Trip and topic. Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1138-Table3-1.png"
        ]
      },
      "5": {
        "title": "Contributions",
        "text": [
          "u Generate topic-sorted personal stories using bootstrapping",
          "u Direct comparison of topic-specific data vs. general-domain stories",
          "u Learn more fine-grained and richer knowledge from topic-specific corpus",
          "u Even with less amount of data",
          "u Two sets of experiments",
          "u Directly compare to previous work",
          "u Introduce new evaluation methods",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Semi Supervised Algorithm for Generating Topic Specific Dataset",
        "text": [
          "Labeled 870 more Camping Trip stories AutoSlog-TS data 971 more Storm stories",
          "small set ( of stories on the topic",
          "Camping: 299 Storm: 361 Event-patterns NP-Prep-(NP):CAMPING-IN (subj)-ActVB-Dobj:WENT-CAMPING",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Causal Potential",
        "text": [
          "Event Representation In previous work different representations have been proposed for the event structure such as single verb and verb with two or more arguments. Verbs are used as a central indication of an event in a narra- tive. However, other entities related to the verb also play a strong role in conveying the meaning of the event. In (Pichotta and Mooney, 2014) it is shown that the multi-argument representation is richer than the previous ones and is capable of capturing inter-",
          "actions between multiple events. We use a repre- sentation that incorporates the Particle of the verb in the event structure in addition to the Subject and the Direct Object and define an event as a verb with its dependency relations as follows:",
          "Verb Lemma (subj:Subject Lemma, dobj:Direct Object Lemma, prt:Particle)",
          "Table 3 shows example sentences describing an event from the Camping topic along with their event structure. The examples show how including the ar- guments often change the meaning of an event. In",
          "Row 1 the direct object and particle are required to completely understand the event in this sentence.",
          "Row 2 shows another example where the verb have cannot implicate what event is happening and the direct object oatmeal is needed to understand what has occurred in the story.",
          "We parse each sentence and extract every verb lemma with its arguments using Stanford dependen-",
          "tract the nsubj, dobj, and prt dependency relations",
          "Sentence Event Representation but it wasnt at all frustrating putting up the tent and setting up the first night put (dobj:tent, prt:up) The next day we had oatmeal for breakfast have (subj:PERSON, dobj:oatmeal) by the time we reached the Lost River Valley Camp- ground, it was already past 1 pm reach (subj:PERSON, dobj:LOCATION) then JS set up a shelter above the picnic table set (subj:PERSON, dobj:shelter, prt:up)",
          "once the rain stopped, we built a campfire using the irewoods f build (subj:PERSON, dobj:campfire)",
          "Table 3: Event representation examples from",
          "of an event pair to encode a causal relation, where event pairs with high CP have a higher probability of occurring in a causal context. We calculate CP for every pair of adjacent events in each topic-specific dataset. We used a 2-skip bigram model which con- siders two events to be adjacent if the second event occurs within two or less events after the first one.",
          "We use skip-2 bigram in order to capture the fact that two related events may often be separated by a non-essential event, because of the oral-narrative nature of our data (Rahimtoroghi et al., 2014). In contrast to the verbs that describe an event (e.g., hike, climb, evacuate, drive), some verbs describe private states such as as belong, depend, feel, know.",
          "We filter out clauses that tend to be associated with private states (Wiebe, 1990). A pilot evaluation showed that this improves the results. if they exist, and use their lemma in the event rep- resentation. To generalize the event representations,",
          "(B1 esahomwes rt hae nfdor mGuila rjfu",
          "P denotes probability and",
          "is the probability of occurring after in the adjacency window which is equal to 3 due to the",
          "u Unsupervised distributional measure skip-2 bigram model.",
          "(e2|e1) is the conditional",
          "by its type LOCATION. We use abstract types for probability of given that has been seen in the named entities such as PERSON, ORGANIZATION, u Tendency of an event adjacency pair to encode window. a causal This is equivalent relation to the Event-",
          "TIME and DATE. We also represent each pronoun by Bigram model described in Sec. 3.3.",
          "the abstract type PERSON, e.g. u Row 5 in Table 3. Probability of occurring in a causal context",
          "We define a contingent event pair as a sequence of two events (e1, e2) such that e1 and e2 are likely to occur together in the given order and e2 is contin-",
          "To calculate CP, we need to compute event counts gent upon e1. We apply an unsupervised distribu- u Calculate CP for every pair of adjacent events from the corpus and thus we need to define when tional measure called Causal Potential to induce the two events are considered equal. The simplest ap- contingency relation between two u events. Skip-2 bigram model proach is to define two events to be equal when Causal Potential (CP) was introduced by Beamer Two related events may often be separated by a non-event sentences u their verb and arguments exactly match. However, and Girju (2009) as a way to measure the tendency with a close look at the data this approach does not",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Evaluations",
        "text": [
          "u Narrative cloze test",
          "u Sequence of narrative events in a document from which one event has been",
          "u Predict the missing event",
          "Unigram model results nearly as good as other complicated models (Pichotta u",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Automatic Two Choice Test",
        "text": [
          "u Automatically generated set of two-choice questions with the answers",
          "u Modeled after the COPA task (An Evaluation of Commonsense Causal Reasoning, Roemmele",
          "u From held-out test sets for each dataset",
          "u Each question consists of one event and two choices",
          "Question event: arrange (dobj:outdoor)",
          "Choice 1: help (dobj:trip)",
          "Choice 2: call (subj:PERSON)",
          "Predict which of the two choices is more likely to have a contingency relation u with the event in the question",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Comparison to Previous Work Rel gram Tuples",
        "text": [
          "seem adequate. For example, consider the following events:",
          "go (subj:PERSON, dobj:camp) go (subj:family, dobj:camp) go (dobj:camp)",
          "Label Contingent & Strongly Relevant Contingent & Somewhat Relevant Contingent & Not Relevant Total Contingent",
          "Table 4: Evaluation of Rel-gram tuple",
          "They encode the same action although their repre- sentations do not exactly match and differ in the sub- ject. Our intuition is that when we count the num- ber of events represented as go (subj:PERSON, dobj:camp) we should also include the count of",
          "go (dobj:camp). To be able to generalize over the event structure and take into account these nuances, we consider two events to be equal if they have the",
          "same verb lemma and share at least one argument other than the subject.",
          "Our previous work on modeling contingency re- lations in film scripts data compared Causal Po- tential to methods used in previous work: Bigram event models (Manshadi et al., 2008) and Pointwise",
          "Mutual Information (PMI) (Chambers and Jurafsky,",
          "2008) and the evaluations showed that CP obtains better results (Hu et al., 2013). In this work, we use CP for inducing contingency relation between events and apply three other models as baselines for comparison:",
          "Event-Unigram. This method will produce a distri- bution of normalized frequencies for events.",
          "Event-Bigram. We calculate the bigram probability of every pair of adjacent events using skip-2 bigram model using the Maximum Likelihood Estimation",
          "(MLE) from our datasets:",
          "We conducted three sets of experiment different aspects of our work. First, we content of our topic-specific event pai state of the art event collections to s f ine-grained knowledge we learned ab",
          "events does not exist in previous work the news genre. Second, we run an auto ation test, modeled after the COPA task",
          "event pair collections that we have ex both General-Domain and Topic-Speci in terms of contingency relations. We that the contingent event pairs can be sic elements for generating coherent and narrative schema. So, in the thir experiments, we extract topic-indicativ event pairs from our Topic-Specific dat an experiment on Amazon Mechanical to evaluate the top N pairs with respect tingency relation and topic-relevance.",
          "4.1 Comparison to Rel-gram Tuple",
          "We chose Rel-gram tuples (Balasubra",
          "2013) for comparison since it is the previous work to us: they generate p tional tuples of events, called Rel-gra occurrence statistics based on Symm tional Probability described in Sec 3.3",
          "ally, the Rel-grams are publicly availabl",
          "Event-SCP. We use the Symmetric Conditional online search interface3 and their evalu",
          "Probability between event tuples (Rel-grams) used in (Balasubramanian et al., 2013) as another base-",
          "u Rel-grams: Generate pairs of relational tuples of events line method. The Rel-gram model is the most rele-",
          "u Use co-occurrence vant statistics previous based work on to Symmetric our method Conditional and outperforms Probability",
          "that their method outperforms the prev the art on generating narrative event sc",
          "However, their work is focused on n and does not consider the causal relat the previous state of the art on generating narrative",
          "u Publicly available through an online search interface events for inducing event schema. We",
          "event schema. This metric combines bigram proba- content of what we learned from our t",
          "u Outperform the bility previous considering work both directions: corpus to the Rel-gram tuples to show t",
          "grained type of knowledge that we learn",
          "occurrence statistics that they used on",
          "u Two experiments: Like Event-Bigram, we used MLE for estimating",
          "u Content of the learned event knowledge Event-SCP from the corpus. 3http://relgrams.cs.washington.edu:10000/re",
          "u Method: one of the baselines on our data",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Baselines",
        "text": [
          "u Produce a distribution of normalized frequencies for events",
          "u Bigram probability of every pair of adjacent events using skip-2 bigram model",
          "Symmetric Conditional Probability between event tuples (Balasubramanian et al., u",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Datasets",
        "text": [
          "u Held-out test (200 stories)",
          "Topic Dataset # Docs Model Ac",
          "Camping Hand-labeled held-out test Event-Unigram Trip Hand-labeled train (Train-HL) Train-HL + Bootstrap (Train-HL-BS) Event-Bigram Event-SCP (Rel-gram)",
          "Storm Hand-labeled held-out test Hand-labeled train (Train-HL) Train-HL + Bootstrap (Train-HL-BS)",
          "Table 6: Automatic two-choice t",
          "General-Domain dataset. Table 5: Number of stories in the train and test sets",
          "Natural Language and Dialougue Systems UC Santa Cruz from topic-specific dataset. Topic Model Train Dat Camping Event-Unigram Train-HL- Trip Event-Bigram Train-HL-"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Results",
        "text": [
          "Topic Dataset # Docs",
          "Camping Hand-labeled held-out test",
          "Trip Hand-labeled train (Train-HL)",
          "Train-HL + Bootstrap (Train-HL-BS)",
          "Storm Hand-labeled held-out test Event-Bigram Train-HL-BS",
          "Train-HL Causal Potential Bootstrap (Train-HL-BS) Train-HL General-Domain Stories Table 6: Automatic two-choice test results for Causal Potential Train-HL-BS General-Domain dataset.",
          "Table Number of stories in the train and test sets from topic-specific dataset. Table 7: Automatic two-choice test results for",
          "Topic-Specific u CP results dataset. stronger than all the baselines Topic Model Train Dataset Accuracy",
          "baseline (Event-SCP) for comparison to our method and present the results in Sec. 4.2.",
          "In this experiment we compare the event pairs ex- tracted from our Camping Trip topic to the Rel-gram tuples. The Rel-gram tuples are not sorted by topic.",
          "To find tuples relevant to Camping Trip, we used our top 10 indicative events and extracted all the",
          "Rel-gram tuples that included at least one event cor- responding to one of the Camping Trip indicative events. For example, for go(dobj:camp), we pulled out all the tuples that included this event from the",
          "Rel-grams collection. The indicative events for each topic were automatically generated during the boot- strapping using AutoSlog-TS (Sec. 2). Then we applied the same sorting and filtering methods presented in the Rel-grams work and re- moved any tuple with frequency less than 25 and",
          "Topic Dataset Event-SCP Train-HL-BS # Docs Model Accuracy",
          "Camping HaCnda-ulasbael lPeod theenltdia-ol ut teTsrt ain-HL-BS",
          "Storm TraEinv-eHnL t-U+ nBiogoratsm trap (TTrraainin-H-HLL-B-BSS",
          "Hand-labeled Event-SCP train (Train-HL) Train-HL-BS",
          "and present u the results in Sec. 4.2. occurring More in training the test data set. The collected following by bootstrapping is an exam- improves the accuracy Causal Potential Train-HL Causal Potential Train-HL-BS ple In this of a experiment question from we compare the Camping the event Trip pairs test ex- set: Storm Event-Unigram Event-Bigram Event-SCP",
          "Train-HL-BS tracted from our Camping Trip topic to the Rel-gram tuples. Question The Rel-gram event: tuples arrange are not (dobj:outdoor) sorted by topic. Train-HL-BS Train-HL-BS Natural Language and Dialougue Systems UC Santa Cruz Causal Potential Train-HL To find Choice tuples relevant help (dobj:trip) to Camping Trip, we used Causal Potential Train-HL-BS our top Choice 10 indicative call (subj:PERSON) events and extracted all the Rel-gram tuples that included at least one event cor- Table 7: Automatic two-choice test results for"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1138-Table6-1.png"
        ]
      },
      "14": {
        "title": "Compare Camping Trip Event Pairs against the Rel gram tuples",
        "text": [
          "u Find tuples relevant to Camping Trip",
          "u Used our top 10 indicative event-patterns, generated and ranked during the bootstrapping",
          "u Apply filtering and ranking",
          "u Evaluate top N = 100",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "15": {
        "title": "Evaluation on Mechanical Turk",
        "text": [
          "u New method for evaluating topic-specific contingent event pairs",
          "u Rate each pair",
          "0: The events are not contingent",
          "1: The events are contingent but not relevant to the specified topic",
          "2: The events are contingent and somewhat relevant to the specified topic",
          "3: The events are contingent and strongly relevant to the specified topic",
          "u More readable representation for annotators:",
          "Subject - Verb Particle - Direct Object pack (subj:PERSON, dobj:car, prt: up) person pack up - car",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "16": {
        "title": "Rel gram Evaluation Results",
        "text": [
          "seem adequate. For example, consider the following events:",
          "Contingent & Strongly Relevant",
          "Contingent & Somewhat Relevant",
          "Contingent & Not Relevant",
          "go (subj:PERSON, dobj:camp) go (subj:family, dobj:camp) go (dobj:camp)",
          "Table 4: Evaluation of Rel-gram tuples on AMT.",
          "They encode the same action although their repre- sentations do not exactly match and differ in the sub- ject. Our intuition is that when we count the num- ber of events represented as go (subj:PERSON,",
          "dobj:camp) we should also include the count of",
          "go (dobj:camp). To be able to generalize over the event structure and take into account these nuances, we consider two events to be equal if they have the same verb lemma and share at least one argument other than the subject.",
          "Label >2: Contingent & strongly topic-relevant",
          "Label = 2: Contingent & somewhat topic-relevant",
          "Evaluation Label < 2: Contingent Experiments & not topic-relevant",
          "Label < 1: Not contingent We conducted three sets of experiments to evaluate",
          "different aspects of our work. First, we compare the content of our topic-specific event pairs to current state of the art event collections to show that the",
          "Natural Language and Dialougue Systems UC Santa Cruz f ine-grained knowledge we learned about everyday events does not exist in previous work focused on the news genre. Second, we run an automatic evalu-"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "17": {
        "title": "Topic Specific Contingent Event Pairs",
        "text": [
          "u Two filtering methods",
          "u Selected the frequent pairs for each topic and removed the ones that occur less than 5 times",
          "u Used the indicative event-patterns for each topic and extracted the pairs that at least included",
          "one of these patterns",
          "Rank by Causal Potential scores to identify the highly contingent ones u",
          "u Evaluated the top N = 100 pairs on Mechanical Turk task",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "18": {
        "title": "Topic Specific Pairs Evaluation Results",
        "text": [
          "go (nsubj:PERSON) go (dobj:trail , prt:down) find (nsubj:PERSON , dobj:fellow) go (prt:back) see (nsubj:PERSON , dobj:gun) see (dobj:police) go (nsubj:PERSON) go (nsubj:PERSON , dobj:rafting) come (nsubj:PERSON) go (nsubj:PERSON) go (prt:out) find (nsubj:PERSON , dobj:sconce) go (nsubj:PERSON) see (dobj:window, prt:out) go (nsubj:PERSON) walk (dobj:bit , prt:down)",
          "Contingent & Strongly Relevant",
          "Contingent & Somewhat Relevant",
          "Contingent & Not Relevant",
          "Figure 2: Examples of event pairs with high CP",
          "Table 8: Results of evaluating indicative contingent event pairs on AMT. scores extracted from General-Domain stories. u Inter-annotator reliability",
          "u average kappa = 0.73 (substantial agreement) that occur less than 5 times in the corpus. Second,",
          "learn contingent event pairs and tested the pair col- lections on the questions generated from held-out test set. We extracted about 418K contingent event we used the indicative event-patterns for each topic and extracted the pairs that at least included one of these patterns. Indicative event-patterns are auto-",
          "pairs from General-Domain train set, 437K Natural from Language and Dialougue Systems UC Santa Cruz matically generated during the bootstrapping using",
          "Storm Train-HL-BS and 630K pairs from Camping AutoSlog-TS and mapped to their corresponding event representation as described in Sec. 2. Then"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1138-Table8-1.png",
          "figure/image/1138-Table4-1.png"
        ]
      },
      "19": {
        "title": "Examples of Event Pairs",
        "text": [
          "Topic-Specific Dataset General-Domain Dataset",
          "climb person - find - rock person - go go down - trail",
          "person - pack up - car head out person - find - fellow go back",
          "wind - blow - transformer power - go out person - see - gun see - police",
          "tree - fall - eave crush person - go person - walk down",
          "hit - location evacuate - person",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [
          "u Learned new type of knowledge",
          "u Common-sense knowledge about everyday events focused on contingency relation",
          "u Semi-supervised bootstrapping approach create topic-sorted dataset",
          "u New evaluation methods",
          "u Two-choice test and Mechanical Turk task",
          "On topic-specific dataset is significantly stronger than general-domain u",
          "Method used on the news genre do not work as well on personal stories u",
          "Fine-grained relations we learn are not found in existing event collections u",
          "Natural Language and Dialougue Systems UC Santa Cruz"
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Learning Fine-Grained Knowledge about Contingent Relations between Everyday Events"
  },
  "1141": {
    "slides": {
      "0": {
        "title": "Main Clustering Aspects",
        "text": [
          "Text preprocessing and representation"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Text Representation Models",
        "text": [
          "Becker and Kuropka, 2003",
          "Polyvyanyy and Kuropka, 2007",
          "Hammouda and Kamel, 2004",
          "Suffix Tree Zamir and Etzioni, 1998",
          "N-Grams Schenker et al, 2007",
          "Parse Thickets Galitsky, 2013 matrix"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Parse Thickets basic characteristics",
        "text": [
          "Preserving a linguistic structure of a text paragraph",
          "Constructing of parse trees for each sentence within a paragraph",
          "Adding inter-sentence relations between parse tree nodes"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Parse Thickets types of discourse relations",
        "text": [
          "Rhetoric structure theory (RST) (Mann et al., 1992)",
          "Communicative Actions (Searle, 1969)"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Coreferences example",
        "text": [
          "io sonseeing et of oh on macy soaps ars LE Sot thats mee ree epee ese ES Se",
          "oa a 7 NUCLEAR | 4 RESEARCH | sso PRS S6.AIN.OFNNTP"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Relations based on Rhetoric Structure Theory",
        "text": [
          "RST characterizes structure of text in terms of relations that hold between parts of text",
          "RST describes relations between clauses in text which might not be syntactically linked",
          "RST helps to discover text patterns such as nucleus/satellite structure with relation such as evidence, justify, antithesis, concession and so on."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Parse Thickets an example",
        "text": [
          "Iran refuses to accept the UN proposal to end the dispute over work on nuclear weapons",
          "UN nuclear watchdog passes a resolution condemning Iran for developing a second uranium enrichment site in secret,",
          "A recent IAEA report presented diagrams that suggested Iran was secretly working on nuclear weapons,",
          "Iran envoy says its nuclear development is for peaceful purpose, and the material evidence against it has been fabricated by the US",
          "UN passes a resolution condemning the work of Iran on nuclear weapons, in spite of",
          "Iran claims that its nuclear research is for peaceful purpose,",
          "Envoy of Iran to IAEA proceeds with the dispute over its nuclear program and develops an enrichment site in secret, Iran confirms that the evidence of its nuclear weapons program is fabricated by the US and proceeds with the second uranium enrichment site"
        ],
        "page_nums": [
          8,
          11
        ],
        "images": []
      },
      "7": {
        "title": "Parse Thickets discourse relations",
        "text": [
          "Iran confirms that the evidence of its nuclear weapons program is fabricated by the US and proceeds with the second uranium enrichment site",
          "Iran envoy says its nuclear development is for peaceful purpose, and the material evidence against it has been fabricated by the US",
          "UN nuclear watchdog passes a resolution condemning Iran for developing a second Uranium enrichment site in secret,",
          "A recent IAEA report presented diagrams that suggested Iran was secretly working on nuclear weapons,",
          "UN passes a resolution condemning the work of Iran on nuclear weapons, in spite of Iran claims that its nuclear research is for peaceful purpose,",
          "Envoy of Iran to IAEA proceeds with the dispute over its nuclear program and develops an enrichment site in secret"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "8": {
        "title": "Clustering of Parse Thickets the main idea",
        "text": [
          "Similarity of parse thickets based on sub-trees matching",
          "nodes with part of speech and stem of a word"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Clustering of paragraphs generalisation of syntacic trees",
        "text": [
          "[NN-work IN-* IN-on JJ-nuclear NNS-weapons ],",
          "[DT-the NN-dispute IN-over JJ-nuclear NNS-* ],",
          "[VBZ-passes DT-a - NN-resolution],",
          "[VBG-developing DT-* NN-enrichment NN-site IN-in NNsecret],",
          "[DT-* JJ-second NN-uranium NN-enrichment NN-site],",
          "[VBZ-is IN-for JJ-peaceful NN-purpose],",
          "[VBN-* VBN-fabricated - IN-by DT-the NNP-us]"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Clustering of paragraphs generatisation of parse trees",
        "text": [
          "[NN-Iran VBG-developing DT-* NN-enrichment NN-site IN-in",
          "[NN-generalization-<UN/nuclear watchdog> * VB-pass NN-resolution",
          "[NN-generalization- <Iran/envoy of Iran> Communicative action",
          "DT-the NN-dispute IN-over JJ-nuclear NNS-*]",
          "[Communicative action NN-work IN-of NN-Iran IN-on JJ-nuclear",
          "[NN-generalization <Iran/envoy to UN> Communicative action",
          "NN-Iran NN-nuclear NN-* VBZ-is IN-for JJ-peaceful NN-purpose ]",
          "[Communicative action NN-generalization <work/develop> IN-of",
          "NN-Iran IN-on JJ-nuclear NNS-weapons]",
          "NN-evidence IN-against NN-Iran NN-nuclear VBN-fabricated IN-by",
          "[NN-Iran JJ-nuclear NN-weapon NN-* RST-evidence VBN-fabricated IN-by DT-the NNP-US condemnproceed [enrichment site] <leads to> suggestcondemn [ work Iran nuclear weapon ]"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Clustering of Parse Thickets what do we want",
        "text": [
          "Adequately represent groups of texts with overlapping content",
          "Get text clusters with different refinement",
          "Goal: (multi-level) hierarchical structure",
          "Solution: Construction of pattern structures on parse thickets"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Clustering of Parse Thickets the mathematical foundation",
        "text": [
          "A triple (G (D,u) , ), where G is a set of objects, (D,u) is a complete meet-semilattice of descriptions and G D is a mapping an object to a description.",
          "A pair (A, d) for which A\u0003 d and d\u0003 A, where A\u0003 and d\u0003 are the Galois connections, defined as follows:",
          "A\u0003 ugA (g) for A G"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Pattern Structures on Parse Thickets",
        "text": [
          "an original paragraph of text an object a A",
          "parse thickets constructed a set of its maximal",
          "from paragraphs generalized sub-trees d",
          "a pattern concept a cluster",
          "Drawback: the exponential growth of the number of clusters by increasing the number of texts (objects)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "14": {
        "title": "Reduced pattern structuress meaningfullness estimates of a pattern concept",
        "text": [
          "Maximum score among all sub-trees in the cluster",
          "Scoremax A, d := max Score (chunk)",
          "Average score of sub-trees in the cluster",
          "Scoreavg A, d Score (chunk) |d chunkd",
          "where Score (chunk) = nodechunk wnode"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "15": {
        "title": "Reduced pattern Structures loss estimates of a cluster with respect to original texts",
        "text": [
          "Estimates minimal lost meaning of cluster content w.r.t. original texts in the cluster",
          "Score max A, d",
          "mingA Scoremax g dg",
          "Estimates lost meaning of cluster content on average",
          "ScoreLossavg A, d Score avg A, d",
          "|d gA Score max g dg"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "16": {
        "title": "Reduced pattern structures generalization",
        "text": [
          "Controlling the loss of meaning w.r.t. the original texts",
          "ScoreLoss A1 A2 d1 d2"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "17": {
        "title": "Reduced pattern structures clusters distinguishability",
        "text": [
          "Controlling the loss of meaning w.r.t. the nearest more meaningfulness neighbors in the cluster hierarchy",
          "Controlling the distinguishability w.r.t. the nearest neighbors in the hierarchy of clusters"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "18": {
        "title": "Reduced pattern structures constraints",
        "text": [
          "ScoreLoss A1 A2 d1 d2",
          "pattern structure reduced pattern structure without reduction with 1 and"
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1141-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Implementation",
        "text": [
          "The Apache OpenNLP library (the most common NLP tasks)",
          "Bing search API (to obtain news snippets)",
          "Pattern structure builder: modified by authors version of",
          "AddIntent algorithm (van der Merwe et al., 2004)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "20": {
        "title": "News Clustering motivation",
        "text": [
          "A long list of search results",
          "Many groups of pages with a similar content"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "21": {
        "title": "User Study non overlapping partition",
        "text": [
          "web snippets on worlds most pressing news: F1 winners, fighting Ebola with nanoparticles, 2015 ACM awards winners, read facial expressions through webcam, turning brown eyes blue",
          "inconsistency of human-labeled partitions: low values of a pairwise Adjusted Mutual Information score of human-labeled partitions 0, MIadj"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "22": {
        "title": "Example The Ebola News Set",
        "text": [
          "Text ID words symbols sentences quoted speech reported speech"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "23": {
        "title": "Accuracy of non overlapping clustering met",
        "text": [
          "Accuracy of conventional clustering methods in the case of overlapping texts groups",
          "low (in most cases)",
          "greatly depends on taken as ground truth a human-labeled partition",
          "A human-labeled partition Method Linkage Distance",
          "average cityblock complete cityblock euclidean average cosine euclidean complete cosine euclidean"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "24": {
        "title": "Accuracy of non overlapping clustering methods",
        "text": [
          "Accuracy of conventional clustering methods for 4 human-labeled partitions"
        ],
        "page_nums": [
          28
        ],
        "images": [
          "figure/image/1141-Figure1-1.png"
        ]
      },
      "25": {
        "title": "An example of pattern structures clustering clusters with maximal score",
        "text": [
          "reduced pattern structure with 1 and",
          "INNP-* NNP-sierra NNP-leone J,"
        ],
        "page_nums": [
          29,
          30
        ],
        "images": []
      },
      "26": {
        "title": "Conclusion",
        "text": [
          "Short text clustering problem",
          "A failure of the traditional clustering methods",
          "Parse Thickets as a text model",
          "Texts similarity based on pattern structures",
          "Reduced pattern structures with constraints",
          "Score and ScoreLoss to improve efficiency and to remove redundant clusters",
          "Improvement of browsing and navigation through texts set for users"
        ],
        "page_nums": [
          31
        ],
        "images": []
      }
    },
    "paper_title": "News clustering approach based on discourse text structure"
  },
  "1142": {
    "slides": {
      "0": {
        "title": "Summary",
        "text": [
          "With the explosive growth of informal electronic communications such as soci al media, web comments, text messaging, etc., historically u nwritten languages are being written for the first time.",
          "For these languages, there ar e extremely limited resources such as translation lexicons a vailable.",
          "We present a method for ind ucing portions of translation lexicons through the use of e xpert knowledge for these settings and quantify its effec tiveness in experiments attempting to induce a Moro ccan Darija-English translation lexicon via French loanwords."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Translation lexicons are a cor e resource used for multilingual processing of languages.",
          "Manual creation of translatio n lexicons by lexicographers is time-consuming and expensiv e.",
          "There are more than seven th ousand languages in the world, many of which are historically unwritten (Lewis et al.,",
          "Many historically unwritten la nguages are being written for the first time with the explos ive growth of informal electronic communications."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Past work",
        "text": [
          "There has been a lot of work on automating translation lexicon induction, including ( Bloodgood and Strauss, ACL,",
          "The best methods for automa tic translation lexicon induction involve using many sources o f information such as word",
          "information, temporal inform ation (Klementiev and Roth,",
          "The methods for automatic t ranslation lexicon induction have various data requirements suc h as bilingual seed dictionaries and monolingual text coming from the same time period for each of the languages."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Challenges",
        "text": [
          "For historically unwritten lang uages that are just being written for the first time, there are of ten extremely limited resources of any type available, not eve n large amounts of monolingual text.",
          "The written data that can be obtained often has non-standard spellings and code-switching.",
          "The code-switching is someti mes within words whereby the base is borrowed and the affi xes are not borrowed, analogous to the multi-language catego ries V and N from (Mericli and"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Potential Solution",
        "text": [
          "Many historically unwritten la nguages borrow parts of their lexicons from more highly res ourced written languages.",
          "It is often possible to find a l anguage informant that can provide guidance for how sou nds would be rendered in a written script if words were t o be written.",
          "Our proposed method makes use of these facts to acquire parts of a translation lexicon quickly."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Loanword Candidate Generation Method high level summary",
        "text": [
          "Take word pronunciations from the donor language and convert them to how they would be borrowed in the borrowing language if they were to be borrowed.",
          "These are our candidate loanwords."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Loanword Candidate Possibilities",
        "text": [
          "There are three possible case s for a given generated candidate loanword:",
          "true match string occurs in borrowing language and is a loanword from t he donor language; false match string occurs in borrowing language by coincidence, bu t its not a loanword from the donor language no match string does not occur in the borrowing language."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Use Case Moroccan Darija English translation lexicon via French",
        "text": [
          "Our use case is inducing a Moroccan Darija-English translation lexicon via French.",
          "We start with a French-English bilingual dictionary and take all the French pronunciations in IPA (International Phonetic",
          "Alphabet) and convert them to how they would be rendered in",
          "Arabic script via a multiple step transliteration process."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Multiple step Transliteration Process",
        "text": [
          "Step 1 Break pronunciation into syllables.",
          "Step 2 Convert each IPA sy llable to a string in modified",
          "Buckwalter translite ration, which is a commonly used transliteration schem e that supports a one-to-one mapping to Arabic s cript.",
          "Step 3 Convert each syllabl es string in modified Buckwalter transliteration to Ar abic script.",
          "Step 4 Merge the resulting syllable to generate",
          "Arabic script strings for each a candidate loanword string."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Step 2",
        "text": [
          "Buckwalter characte rs such as aa,kk, y:iy, etc. that w ere supplied by a language expert."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Experimental Data Sources",
        "text": [
          "We extracted a French-Englis h bilingual dictionary using the freely available English Wikti onary dump 20131101 downloaded from",
          "The data used for testing con sists of a million lines of user comments crawled from the M oroccan news website"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Initial Statistics of our Data",
        "text": [
          "Converting each of the Frenc h pronunciations from our dictionary into Arabic script y ielded 8277 unique loanword candidates.",
          "The total number of tokens i n our Hespress corpus is",
          "We found that 1150 of our 8 277 loanword candidates appear in our Hespress corpus.",
          "More than a million (1169087 ) loanword candidate instances appear in the corpus."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Filtering out short words",
        "text": [
          "False matches are particularly likely to occur for very short words.",
          "So we filter out candidates th at are of length less than four characters.",
          "This leaves us with 838 cand idates appearing in the corpus and 217616 candidate instanc es in the corpus."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Percentage of True Matches versus False Matches",
        "text": [
          "We conducted an annotation exercise with two native",
          "Moroccan Darija speakers wh o also knew at least intermediate",
          "We pulled a random sample o f 1185 candidate instances from our corpus and asked each an notator to mark each instance as either:",
          "A if the instance i s originally from Arabic,",
          "F if the instance i s originally from French, or",
          "U if they were not sure."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Annotation Results",
        "text": [
          "Annotator Arabic Un known French Total",
          "Table: Number of word instances annotated."
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1142-Table1-1.png"
        ]
      },
      "15": {
        "title": "Examples of Translations Found",
        "text": [
          "omelette I\u0010 JE @; and"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Machine Translation Experiment",
        "text": [
          "We selected a random set of sentences from the Hespress corpus that each contained a t least one candidate instance.",
          "A Modern Standard Arabic/M oroccan Darija/English trilingual translator translated 273 of t he sentences into English.",
          "These manually translated se ntences served as our test set.",
          "We trained a baseline MT sys tem using all GALE MSA-English parallel corpora available from the Linguistic Data Consortium from 2007 to 2013 using Mos es 3.0 with default parameters.",
          "The baseline system achieves BLEU score of 7.48 on our difficult test set of code-switc hed Moroccan Darija and",
          "We trained a second system lexicon appended to the end with our induced translation of the training data.",
          "The BLEU score increased to 8.11, a gain of 0.63 BLEU points."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "17": {
        "title": "Conclusions",
        "text": [
          "With the explosive growth of informal textual electronic communications such as soci al media, web comments, etc., many colloquial everyday lang uages that were historically unwritten are now being writ ten for the first time.",
          "The new written versions of t hese languages pose significant challenges for multilingual pr ocessing technology due to",
          "Out-Of-Vocabulary (OOV) ch allenges.",
          "Often these historically unwri tten languages borrow significant amounts of vocabulary from languages. relatively well resourced written",
          "We presented a method for t ranslation lexicon induction via loanwords.",
          "This paper demonstrates indu ction of a Moroccan",
          "Darija-English translation lex icon via bridging French loanwords using the approach"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "18": {
        "title": "Future Work",
        "text": [
          "Explore using the method for other languages.",
          "Examine whether adaptations can be made to increase the yield of the method."
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "Acquisition of Translation Lexicons for Historically Unwritten Languages via Bridging Loanwords"
  },
  "1143": {
    "slides": {
      "0": {
        "title": "Relative Merits Demerits",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Inner workings well understood",
          "Better at translating low-frequency words",
          "Produce more fluent output",
          "Probabilistic model can score output of other systems!"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Reranking with Neural MT Models",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Input N-best w/MT Features Neural Features",
          "he has a cold"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "What Do We Know About Reranking",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Reranking greatly improves BLEU score, even over strong baseline systems:"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "What Dont We Know About Reranking",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Does reranking improve subjective impressions of results?",
          "What are the qualitative differences before/after reranking with neural MT models?"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Experimental Setup",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Data: ASPEC Scientific Abstracts",
          "Baseline: NAIST WAT2014 Tree-to-String System",
          "Strong baseline achieving high scores",
          "Implemented using Travatar (http://phontron.com/travatar)",
          "Neural MT Model: Attentional model",
          "Trained ~500k sent., 256 hidden nodes, 2 model ensemble",
          "Trained w/ lamtram (http://github.com/neubig/lamtram)",
          "Automatic Evaluation: BLEU, RIBES",
          "Manual Evaluation: WAT 2015 HUMAN Score"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Results",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "en-ja ja-en zh-ja ja-zh en-ja ja-en zh-ja ja-zh",
          "Confirm what we know: Neural reranking helps automatic evaluation",
          "Show what we didn't know: Also help manual evaluation."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "What is Getting Better",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "Perform detailed categorization of the changes in",
          "1. Is the sentence better/worse after ranking?",
          "2. What is the main error corrected: insertion, deletion, substitution, reordering, or conjugation?",
          "3. What is the detailed subcategory?"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "What Do We Know Now",
        "text": [
          "Neural reranking improves subjective quality of machine translation output.",
          "Main gains are from grammatical factors, and not lexical selection."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "8": {
        "title": "What Do We Still Not Know Yet",
        "text": [
          "Neural Reranking Improves Subjective Quality of Machine Translation",
          "How do neural translation models compare with neural language models?",
          "How does reranking compare with pure neural MT?"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Neural Reranking Improves Subjective Quality of Machine Translation: NAIST at WAT2015"
  },
  "1147": {
    "slides": {
      "0": {
        "title": "ML as an engineering discipline",
        "text": [
          "A mature engineering discipline should be able to predict the cost of a project before it starts",
          "Collecting/producing training data is typically the most expensive part of an ML or NLP project",
          "We usually have only the vaguest idea of how accuracy is related to training data size and quality",
          "I More data produces better accuracy",
          "I Higher quality data (closer domain, less noise) produces",
          "I But we usually have no idea how much data or what quality of",
          "data is required to achieve a given performance goal",
          "Imagine if engineers designed bridges the way we build systems!",
          "See statistical power analysis for experimental design, e.g., Cohen (1992)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Goals of this research project",
        "text": [
          "Given desiderata (accuracy, speed, computational and data resource pricing, etc.) for an ML/NLP system, design for a system that meets these.",
          "Example: design a semantic parser for a target application domain that achieves 95% accuracy across a given range of queries.",
          "I What hardware/software should I use?",
          "I How many labelled training examples do I need?",
          "Idea: Extrapolate performance from small pilot data to predict performance on much larger data"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "What this paper contributes",
        "text": [
          "Studies di\u001berent methods for predicting accuracy on a full dataset from results on a small pilot dataset",
          "We propose new accuracy extrapolation task, provide results for the 9 extrapolation methods on 8 text corpora",
          "I Uses the fastText document classi er and corpora (Joulin",
          "Investigates three extrapolation models and three item weighting functions for predicting accuracy as a function of training data size",
          "I Easily inverted to estimate training size required to achieve a",
          "Highlights the importance of hyperparameter tuning and item weighting in extrapolation"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Accuracy extrapolation task",
        "text": [
          "Corpus Labels Train (K) Test (K)",
          "FastText document classi er",
          "Development ag_news dbpedia amazon_review_full yelp_review_polarity",
          "Evaluation amazon_review_polarity sogou_news yahoo_answers yelp_review_full",
          "I 4 development corpora",
          "I 4 evaluation corpora",
          "Goal: use pilot data to predict test accuracy when trained on full train data"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Extrapolation on agnews corpus",
        "text": [
          "Extrapolation with biased power-law model",
          "Pilot data binomial weights (n/e(1 e))",
          "Extrapolation from training data is generally good",
          "Extrapolation from training data is poor unless hyperparameters are optimised at each subset of pilot data"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1147-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Relative residuals on dev corpora",
        "text": [
          "ag_news amazon_review_full dbpedia yelp_review_polarity"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1147-Figure2-1.png"
        ]
      },
      "6": {
        "title": "RMS relative residuals on test corpora",
        "text": [
          "Pilot data amazon review polarity sogou news yahoo answers yelp review full",
          "Based on dev corpora results, use:",
          "I biased power law model (e(n) a bnc)",
          "I binomial item weights (n/e(1 e))",
          "Evaluate extrapolations with RMS of relative residuals",
          "Larger pilot data smaller extrapolation error",
          "Optimise hyperparameters at each pilot subset smaller extrapolation error"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Conclusions and future work",
        "text": [
          "The eld need methods for predicting how much training data a system needs to achieve a target performance",
          "We introduced an extrapolation task for predicting a classi ers accuracy on a large dataset from a small pilot dataset",
          "Highlight the importance of hyperparameter tuning and item weighting",
          "Future work: extrapolation methods that dont require expensive hyperparameter optimisation"
        ],
        "page_nums": [
          13
        ],
        "images": []
      }
    },
    "paper_title": "Predicting accuracy on large datasets from smaller pilot data"
  },
  "1148": {
    "slides": {
      "0": {
        "title": "Multiword Expressions",
        "text": [
          "Expressions of mul0ple words that can exhibit an idioma0c meaning"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Idiomatic vs Literal",
        "text": [
          "(I) They pulled the plug on the Department of",
          "(L) Unfortunately someone pulled the sink plug",
          "(I) It caught him on the head and he went down seeing liAle sparkling stars",
          "(L) Its sDll dark enough to see the brightest stars"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Idiom Token Classifica0on",
        "text": [
          "Determine if an MWE instance is idioma0c",
          "They pulled the plug on the project [IdiomaDc/Literal]",
          "Kick the bucket [mourir/frapper avec le pied]",
          "Keegan is ready to pull the plug on [a deal the tv]"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Overview of Approach",
        "text": [
          "VNC token instances are represented via use of an embedding model"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Lexico Syntactic Fixedness",
        "text": [
          "The idioma0c meaning of an expression is typically restricted to a small number of lexico-syntac0c paVerns",
          "Ac0ve voice, no determiner, plural noun",
          "Ac0ve voice, determiner, singular noun",
          "Passive voice, plural noun"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Patterns",
        "text": [
          "Afsaneh Fazly et al. 2009"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Canonical Form",
        "text": [
          "Lexico-syntac0c paVerns that idioma0c usages tend to occur in",
          "Afsaneh Fazly et al. 2009"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Integrating Canonical Forms",
        "text": [
          "Unsupervised method used in Fazly et al. to iden0fy canonical forms",
          "One-dimensional binary vector represen0ng if the expression is in the canonical form"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "VNC Tokens Dataset",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Accuracy",
        "text": [],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1148-Table2-1.png"
        ]
      },
      "10": {
        "title": "Results per class",
        "text": [],
        "page_nums": [
          11,
          14
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Averaging word2vec embeddings outperforms all other models used",
          "Canonical form feature improves results"
        ],
        "page_nums": [
          12
        ],
        "images": []
      }
    },
    "paper_title": "Leveraging distributed representations and lexico-syntactic fixedness for token-level prediction of the idiomaticity of English verb-noun combinations"
  },
  "1150": {
    "slides": {
      "0": {
        "title": "Story",
        "text": [
          "3. Conclusions and Future Work",
          "Representations as Multimodal Embeddings. AAAI",
          "Learn mapping f text vision.",
          "Finding 1: Imagined vectors, f (text), outperform original visual vectors in 7/7 word similarity tasks.",
          "So, why are mapped vectors multimodal? We conjecture:",
          "Continuity. Output vector is nothing but the input vector transformed by a continuous map: f (x x",
          "Finding 2 (not in AAAI paper): Vectors imagined with an untrained network do even better."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "3. Conclusions and Future Work",
          "Applications (e.g., zero-shot image tagging, zero-shot translation or cross-modal retrieval):",
          "Use linear or NN maps to bridge modalities / spaces.",
          "Then, they tag / translate based on neighborhood structure of mapped vectors f (X",
          "Research question: Is the neighborhood structure of f (X similar to that of Y? Or rather to X?",
          "How to measure similarity of 2 sets of vectors from different spaces? Idea: mean nearest neighbor overlap"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "General Setting",
        "text": [
          "3. Conclusions and Future Work",
          "Mappings f X Y to bridge modalities X and Y:"
        ],
        "page_nums": [
          3
        ],
        "images": [
          "figure/image/1150-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Experiment 1",
        "text": [
          "1. Motivation and Setting",
          "3. Conclusions and Future Work",
          "Nearest Neighbor Overlap (NNOK (vi zi)) = number of K nearest neighbors that two paired data points vi zi share in their respective spaces.",
          "The mean NNO is:",
          "mNNOK (V ,Z KN NNOK (vi zi)",
          "NN3(vcat) = {vdog vtiger vlion}",
          "NN3(zcat) = {zmouse, ztiger zlion} NNO3(vcat zcat) =",
          "Goal: Learn map f X Y and calculate mNNO(Y f (X )). Compare it with mNNO(X f (X",
          "Datasets: (i) ImageNet ; (ii) IAPR TC-12; (iii) Wikipedia",
          "Visual features: VGG-128 and ResNet.",
          "Text features: ImageNet (GloVe and word2vec); IAPR",
          "Loss: MSE 12f (x) y2. We also tried max-margin and cosine."
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "Experiment 1 Results",
        "text": [
          "1. Motivation and Setting",
          "3. Conclusions and Future Work",
          "X f (X Y f (X X f (X Y f (X",
          "I T T I lin nn",
          "Table: X f (X and Y f (X denote mNNO10(X f (X and"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Experiment 2",
        "text": [
          "1. Motivation and Setting",
          "3. Conclusions and Future Work",
          "Goal: Map X with an untrained net f and compare performance of X with that of f (X",
          "(i) Semantic similarity: SemSim, Simlex-999 and",
          "(ii) Relatedness: MEN and WordSim-353.",
          "(iii) Visual similarity: VisSim."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Experiment 2 Results",
        "text": [
          "1. Motivation and Setting",
          "3. Conclusions and Future Work",
          "Cos Eucl Cos Eucl Cos Eucl",
          "Table: Spearman correlations between human ratings and similarities (cosine or Euclidean) predicted from embeddings."
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1150-Table2-1.png"
        ]
      },
      "7": {
        "title": "Conclusions and Future Work",
        "text": [
          "1. Motivation and Setting",
          "Neighborhood structure of f (X more similar to X than Y",
          "Neighborhood structure of embeddings not significantly disrupted by mapping them with an untrained net.",
          "Future Work: How to mitigate the problem?",
          "Discriminator (adversarial) trying to guess whether the sample is from Y or f (X",
          "Incorporate pairwise similarities into loss function."
        ],
        "page_nums": [
          9
        ],
        "images": []
      }
    },
    "paper_title": "Do Neural Network Cross-Modal Mappings Really Bridge Modalities?"
  },
  "1151": {
    "slides": {
      "0": {
        "title": "Hypernymy",
        "text": [
          "Hierarchical relations play a central role in",
          "animals such as cats and dogs",
          "knowledge representation (Miller, 1995)",
          "animals including cats and dogs",
          "cat is a feline is a mammal is an animal",
          "cats, dogs, and other animals",
          "All animals are living things -> cats are living things",
          "Automatic hypernymy detection approaches:",
          "Pattern based: high-precision lexico-syntactic patterns",
          "Distributional Inclusion: unconstrained word co-occurrences",
          "(Zhitomirsky-Geffet and Dagan, 2005)"
        ],
        "page_nums": [
          1
        ],
        "images": [
          "figure/image/1151-Figure1-1.png"
        ]
      },
      "1": {
        "title": "Objectives",
        "text": [
          "Are Hearst patterns more valuable than distributional information?",
          "Do we learn more from using general semantic contexts, or exploiting highly targeted ones?",
          "Are differences robust across multiple evaluation settings?",
          "Can we remedy some of Hearst patterns' weaknesses?",
          "Scaling up data and extraction is cheaper and easier today",
          "Do embedding methods help alleviate sparsity?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Tasks",
        "text": [
          "Distinguish hypernymy pairs from other relations",
          "Average Precision (AP) across 5 datasets (Shwartz et al., LEDS (Baroni et al., 2012)",
          "Direction WBLESS (Weeds et al., 2014)",
          "Identify the direction of entailment (XY or YX?)",
          "Accuracy across 3 datasets (Kiela et al., BLESS (Baroni and Lenci, 2011)",
          "Graded Entailment Graded Entailment Predict the degree of entailment Hyperlex (Vulic et al., 2017)",
          "Spearman's rho on 1 dataset (Vulic et al.,"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Hearst Pattern Extraction",
        "text": [
          "Matches were aggregated and filtered:",
          "Pair must match 2 distinct patterns",
          "431K distinct pairs covering 243K unique types"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1151-Table1-1.png"
        ]
      },
      "4": {
        "title": "Hearst Pattern Models",
        "text": [
          "PPMI(x, y): transform counts using",
          "Positive Pointwise Mutual Information Frequency (log scale)",
          "Simple embedding (Truncated SVD)",
          "SPMI(x, y): apply truncated SVD to PPMI counts",
          "Select k using validation set",
          "Related to Cederberg and Widdows (2003)"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1151-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Distributional Methods",
        "text": [
          "Selected 3 high performing, unsupervised methods based on Shwartz et al. (2017)",
          "Use strong distributional space from Shwartz et al. (2017)",
          "POS tagged and lemmatized",
          "Dependency contexts (Pado and Lapata, 2007; Levy and Goldberg, 2014)",
          "Tune hyperparameters on validation"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Detection",
        "text": [
          "Cosine Best Distributional PPMI SPMI",
          "trouble with global calibration (AP)",
          "Pattern has mixed performance",
          "SPMI model best on",
          "Embedding Hearst patterns helps overcome sparsity",
          "Downweights outliers BLESS Shwartz EVAL LEDS WBLESS"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Direction",
        "text": [
          "Cosine Best Distributional PPMI SPMI",
          "Patterns outperform distr. methods on",
          "Accuracy BLESS pathologically difficult",
          "for cosine and PPMI",
          "Embedding patterns overcomes sparsity"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Graded Entailment",
        "text": [
          "Cosine Best Distributional PPMI SPMI",
          "Pattern based methods outperform distr.",
          "Spearman's rho Spearman's rho",
          "Spearman's rho doesn't punish ties (many 0s)",
          "PPMI model to break ties randomly",
          "SPMI best after adjustment"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Conclusions",
        "text": [
          "Pattern-based approaches outperform distributional methods",
          "Targeted Hearst contexts are more valuable than semantic similarity gains",
          "Embedding Hearst patterns works well",
          "Helps substantially with sparsity issues",
          "We open source our experiments and evaluation framework:"
        ],
        "page_nums": [
          10
        ],
        "images": []
      }
    },
    "paper_title": "Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora"
  },
  "1152": {
    "slides": {
      "0": {
        "title": "Complaints",
        "text": [
          "| wish | had more time to tell you about complaining, but the organizers only allocated 15 minutes for this talk.",
          "2019 Bloomberg Finance L.P. All rights reserved. . : Engineering"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "Complaints Applications",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "2": {
        "title": "Data Annotation",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "Data Sampling",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          11,
          12,
          13
        ],
        "images": []
      },
      "4": {
        "title": "Data Statistics",
        "text": [
          "Not complaints, random tweets",
          "Not complaints, sent to other handles",
          "Not complaints, sent to customer support",
          "2019 Bloomberg Finance L.P. All rights reserved.",
          "weets matched to a domain based on the customer support handle",
          "Food Apparel Retail Cars Services Software Transport Electronics Other Complaint Not Complaint"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "5": {
        "title": "Features",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "Analysis Complaints",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "7": {
        "title": "Analysis Not Complaints",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          25,
          26,
          27
        ],
        "images": []
      },
      "8": {
        "title": "Prediction",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved.",
          "Most Freq Class Complaint Specific Sentiment Emotions POS Tags LIWC Word2Vec Clusters Unigrams Combined MLP BiLSTM"
        ],
        "page_nums": [
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
        ],
        "images": []
      },
      "9": {
        "title": "Prediction Other Experiments",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "10": {
        "title": "Takeaways",
        "text": [
          "2019 Bloomberg Finance L.P. All rights reserved."
        ],
        "page_nums": [
          37
        ],
        "images": []
      }
    },
    "paper_title": "Automatically Identifying Complaints in Social Media"
  },
  "1153": {
    "slides": {
      "0": {
        "title": "Agenda",
        "text": [
          "Issue of false-alarm self-labeled data",
          "Disambiguation of hashtag usages"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Self Labeled Data",
        "text": [
          "Large amount of self-labeled data available on the Internet are popular research materials in many NLP areas.",
          "Metadata such as tags and emoticons given by users are considered as labels for training and testing learning-based models.",
          "The tweets with a certain types of hashtags are collected as self-label data in a variety of research works."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Irony Detection with Hashtag Information",
        "text": [
          "It is impractical to manually annotate the ironic sentences from randomly sampled data due to the relatively low occurrences of irony.",
          "Alternatively, collecting the tweets with the hashtags like",
          "#sarcasm, #irony, and #not becomes the mainstream approach.",
          "@Anonymous doing a great job... #not What do I pay my extortionate council taxes for? #Disgrace #OngoingProblem http://t.co/FQZUUwKSoN"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "False alarm Issue",
        "text": [
          "The reliability of issue. the self-labeled data is an important",
          "Not all tweet writers know the definition of irony",
          "BestProAdvice @Anonymous More clean OR cleaner, never more cleaner. #irony"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Hashtags Functioning as Content Words",
        "text": [
          "A hashtag in a tweet may also function as a content word in its word form.",
          "The removal of the hashtag can change the meaning of the tweet, or even make the tweet grammatically incomplete.",
          "The #irony of taking a break from reading about #socialmedia to check my social media."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Research Goal",
        "text": [
          "Two kinds of unreliable data are our targets to remove from the training data for irony detection.",
          "The tweets with a misused hashtag",
          "The tweets in which the hashtag serves as a content word,",
          "Compared to general training data cleaning approaches, our work leverages the characteristics of hashtag usages in tweets.",
          "With small amount of golden labeled data, we propose a neural network classifier for pruning the self-labeled tweets, and train an ironic detector on the less but cleaner instances."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Dataset",
        "text": [
          "The ground-truth is based on the dataset released for",
          "The hashtag itself has been removed in the SemEval dataset.",
          "The hashtag information, the position and the word form of the hashtag (i.e., not, irony, or sarcasm), is missing.",
          "We recover the original tweets by using Twitter search.",
          "Hashtag False-Alarm Irony Total"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Disambiguation of Hashtags",
        "text": [
          "Word sequences of the context preceding and following the targeting hashtag are separately encoded by neural network sentence encoders.",
          "Lengths of the tweet in words and in characters.",
          "Type of the target hashtag",
          "Number of all hashtags tweet. in the",
          "If the targeting hashtag is the irst/last f token in the tweet.",
          "If the targeting hashtag is f irst/last hashtag in the tweet the",
          "Position of the targeting hashtag",
          "A tweet will be more grammatical complete with only the hash symbol removed if the hashtag is also a content word.",
          "On the other hand, the tweet will be more grammatical complete with the whole hashtag removed since the hashtag is a metadata.",
          "GRU-based language model on the level of POS tagging is used to measure the grammatical completeness of the tweet with and without the hashtag.",
          "Remove the whole hashtag removed.",
          "Remove the hash symbol # only."
        ],
        "page_nums": [
          8,
          9,
          10
        ],
        "images": [
          "figure/image/1153-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Results of Hashtag Disambiguation",
        "text": [
          "By integrating various kinds of information, our method outperforms all baseline models no matter which encoder is used. The best model is the one integrating the attentive GRU encoder, which is significantly superior",
          "The addition of language model significantly improves the performance",
          "Model Encoder Precision Recall F-score",
          "Our Model GRU Our Model Att.GRU Without LM Att.GRU"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Training Data Pruning for Irony Detection",
        "text": [
          "We employ our model to prune self-labeled data for irony detection.",
          "A set of tweets that contain indication hashtags as (pseudo) positive instances",
          "A set of tweets that do not contain indication hashtags as negative instances.",
          "Our model is performed to predict whether it is a real ironic tweet or false-alarm ones, and the false-alarm ones are discarded."
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1153-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Results on Irony Detection",
        "text": [
          "We implement a state-of-the-art irony detector, which is based on attentive-RNN classifier, and train it on the prior- and the post- pruned training data.",
          "The irony detection model trained on the less, but cleaner instances significantly outperforms the model that is trained on all data (p <",
          "The irony detector trained on the small genuine data does not compete with the models that are trained on larger amount of self- labeled data.",
          "Data Size Precision Recall F-score",
          "Prior-Pruning Post-Pruning Human Verified"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Different Threshold Values for Data Pruning",
        "text": [
          "We can sort all self-labeled data by their calibrated confidence and control the size of training set by adjusting the threshold.",
          "The higher the threshold value is set, the less the training instances remain.",
          "The best result achieved by the detector trained on the 9,234 irony data f iltered by our model with the default",
          "This confirms that our model is able to select useful training instances in a strict manner",
          "The bullet symbol () indicates the size of training data, and the bar indicates the F-score achieved by the irony detector trained on those data."
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1153-Figure3-1.png"
        ]
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "We make an empirically study on an issue that is potentially inherited in a number of research topics based on self-labeled data.",
          "We propose a model for hashtag disambiguation. For this task, the human-verified ground-truth is quite limited. To address the issue of sparsity, a novel neural network model for hashtag disambiguation is proposed.",
          "The data pruning method is capable of improving the performance of irony detection, and can be applied to other work relied on self-labeled data."
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Disambiguating False-Alarm Hashtag Usages in Tweets for Irony Detection"
  },
  "1155": {
    "slides": {
      "0": {
        "title": "Objective",
        "text": [
          "What geometric properties of an embedding space are important for performance on a given task?",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019",
          "Understand utility of embeddings as input features.",
          "Provide direction for future work in training and tuning embeddings."
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Embedding space",
        "text": [
          "In NLP, the term embedding is often used to denote both a map and (an element of) its image.",
          "We define an embedding space as a set of word vectors in Rd.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Geometric properties",
        "text": [
          "We consider the following attributes of word embedding geometry: position relative to the origin; distribution of feature values in Rd; global pairwise distances; local pairwise distances.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Our approach",
        "text": [
          "We transform the embedding space such that we expose only a subset of the stated properties to downstream models.",
          "position relative to the origin; distribution of feature values in Rd; global pairwise distances; local pairwise distances.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Affine",
        "text": [
          "pos. relative to the origin distribution of features global distances local distances",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Cosine distance embedding CDE",
        "text": [
          "d embedding dimension (300);",
          "|V distance vector dimension (104 most",
          "pos. relative to the origin distribution of features global distances local distances",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Nearest neighbor embedding NNE",
        "text": [
          "pos. relative to the origin distribution of features global distances local distances",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Hierarchy of transformations",
        "text": [
          "Ordering is with respect to number of properties ablated.",
          "We include a random baseline of meaningless vectors.",
          "Arrow length does not mean anything.",
          "Transformations are applied independently to the original embeddings.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Embeddings and Tasks",
        "text": [
          "Word2Vec on Google news;",
          "GloVe on common crawl;",
          "10 standard intrinsic tasks.",
          "5 extrinsic tasks (embeddings plugged into a downstream machine learning model).",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Tasks",
        "text": [
          "Word Similarity and Relatedness via cosine distance",
          "Sentence-level sentiment polarity classif. on MR movie reviews",
          "Sentiment classif. on IMDB reviews",
          "Subj./Obj. classif. on Rotten",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Results intrinsic tasks",
        "text": [
          "We see the lowest performance on thresholded-NNE.",
          "Largest drop in performance at",
          "CDE (written as distAE on the",
          "Rotations, dilations, and reflections are innocuous.",
          "Displacing the origin has a nontrivial effect.",
          "NNE causes a significant drop in performance as well.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Results extrinsic tasks",
        "text": [
          "CDE is still the largest drop.",
          "NNE recover most of the losses, and are on par with affines.",
          "Extrinsic tasks are more robust to translations, but not homotheties.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Discussion",
        "text": [
          "Drop due to CDE likely associated with the importance of locality in embedding learning.",
          "With thresholded-NNE, high out-degree words are rare words, introducing noise during node2vecs random walk.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Takeaways",
        "text": [
          "We find that in general, both intrinsic and extrinsic models rely heavily on local similarity, as opposed to global distance information.",
          "We also find that intrinsic models are more sensitive to absolute position than extrinsic ones.",
          "Methods for tuning and training should focus on local geometric structure in Rd.",
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Questions",
        "text": [
          "Whitaker, Newman-Griffis, Haldar, et al. Characterizing Embedding Geometry June 4, 2019"
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "Characterizing the Impact of Geometric Properties of Word Embeddings on Task Performance"
  },
  "1160": {
    "slides": {
      "0": {
        "title": "What is StackLSTM",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "A Partial Tree",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Good Edge",
        "text": [],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Lstm",
        "text": [],
        "page_nums": [
          6,
          24,
          25
        ],
        "images": []
      },
      "4": {
        "title": "StackLSTM",
        "text": [
          "An LSTM whose states are stored in a stack",
          "Computation is conditioned on the stack operation"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Parallelization Problem",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "6": {
        "title": "Batched LSTM",
        "text": [],
        "page_nums": [
          26
        ],
        "images": []
      },
      "7": {
        "title": "Benchmark",
        "text": [
          "Transition-based dependency parsing on Stanford Dependency Treebank",
          "PyTorch, Single K80 GPU"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "8": {
        "title": "Hyperparameters",
        "text": [
          "Largely following Dyer et al. (2015); Ballesteros et",
          "Adam w/ ReduceLROnPlateau and warmup",
          "Arc-Hybrid w/o composition function",
          "action embedding) perform better"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "9": {
        "title": "Speed",
        "text": [],
        "page_nums": [
          53,
          54
        ],
        "images": []
      },
      "10": {
        "title": "Performance",
        "text": [],
        "page_nums": [
          55
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "We propose a parallelization scheme for StackLSTM architecture.",
          "Together with a different optimizer, we are able to train parsers of comparable performance within 1 hour."
        ],
        "page_nums": [
          56,
          57
        ],
        "images": []
      }
    },
    "paper_title": "Parallelizable Stack Long Short-Term Memory"
  },
  "1161": {
    "slides": {
      "0": {
        "title": "Twitter for Public health",
        "text": [
          "Many users tweet when they caught a disease",
          "# of tweets is in proportion to # of flu patients",
          "# of flu related tweets"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Noise included in tweets",
        "text": [
          "For more information about bird flu link",
          "I got a flu I couldnt do anymore Only counts this type of tweets",
          "Ive never caught a flu",
          "I got a flu shot yesterday"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Our lab runs flu surveillance system",
        "text": [
          "ae 47S A ~ NLP Flu Warning ~",
          "BIvILY FOr a-ARAMHSRORVRERN TS.",
          "() (CELA(5) RE MROKIAAORS MR, TLIL-mROMBAIC https://t.co/CsRvdgSL4v #RB HAR #Xvb A/09-7 IDR HAY DID",
          "e>) AVINLYEOANW ADT, MMA CEAN?HHBAY FIDL BN EY +",
          "Av FAI tiweett MRE AREY YAN",
          "Aramaki, Eiji, Sachiko Maskawa, and Mizuki Morita. \"Twitter catches the flu: detecting influenza epidemics using Twitter.\" In Proc of EMNLP 2011. http://mednlp.jp/influ_map/"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Similarity between Tweets and Patients",
        "text": [
          "ME X2ieys(fh):Ad Tweets about flu",
          "is slightly earlier than reports of flu in patients"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Each word has a specific time lag",
        "text": [
          "Counts of flu related tweets of flu patients",
          "The word Fever The word Injection days time lag days time lag",
          "# of the word fever # of the word Injection",
          "Time shifted Time shifted"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "What is Forecasting Words",
        "text": [
          "Twitter tends to be an early indicator of actual condition",
          "We observed that each word has a specific time lag with actual condition",
          "Our objective: more flexible modeling",
          "Extend future forecasting model"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1161-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Training data Twitter Corpus",
        "text": [
          "Query: The word flu in Japanese"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Gold standard IDSC reports",
        "text": [
          "Infectious Disease Surveillance Center (IDSC) reports",
          "# of flu patients once a week",
          "They gather the number of flu patients during the period of epidemic",
          "We split IDSC reports into three seasons as follows:"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Time lag measure Cross Correlation",
        "text": [
          "Cross Correlation is used to search for the most suitable time shift width for each word frequency as between # of tweets days before and # of actual patients",
          "The cross correlation is exactly the same as the Pearsons correlation when"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Motivating examples",
        "text": [
          "When = 16, r is 0.95 B/T tweet and IDSC reports",
          "# of the word fever",
          "# of flu patients",
          "When increases, word counts moves to right side:"
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": [
          "figure/image/1161-Figure1-1.png"
        ]
      },
      "10": {
        "title": "Estimate optimal time lag",
        "text": [
          "We define optimal time-lag by maximizing the cross correlation"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Heatmap representation of Matrix",
        "text": [
          "R a w w o rd c o un t s # of patients",
          "Apply t i m e s hift",
          "X y X y"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1161-Figure2-1.png"
        ]
      },
      "12": {
        "title": "Effectiveness of time shift",
        "text": [
          "Regression for nowcasting with applying time-shift or not:",
          "The searching range of time shift is in [0, , 60]",
          "Train Season 2 Season 3 Season 1 Season 3 Season 1 Season 2 Avg. Test Season 1 Season 2 Season 3"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Limitation",
        "text": [
          "To estimate specific day of the epidemic through",
          "Twitter, we need to gather same days tweet",
          "How to predict future disease outbreaking?",
          "# of flu related tweets",
          "# of flu patients"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Restrict time shift estimation",
        "text": [
          "In order to forecast t days future epidemics,",
          "we restrict searching interval of time shift at least t days"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Motivating example",
        "text": [
          "Nowcasting case: [0, max]",
          "# of the word fever (10 days shifted) # of the word # of flu fe patients ver (10 d ays shifted)",
          "# of the word fever (16 days shifted) # of flu patients",
          "# of the word # of th fever word fever",
          "of the # of word the word fever fever of the # of wo fl u rd patients fever 30 days shifted) of flu patients",
          "# of the word Injection (30 days shifted) # of the word # of flu In patients jection (3 0 days shifted)",
          "# of the word # of the Injection word Injection",
          "# of the word Injection (55 days shifted) # of flu patients"
        ],
        "page_nums": [
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "16": {
        "title": "Forecasting Modeling",
        "text": [
          "In each t, we search optimal time shift for all words.",
          "Estimate model by Lasso & ENet using these features."
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "17": {
        "title": "Our model beyonds baseline",
        "text": [
          "Correlation b/w model and IDSC Correlation b/w model and IDSC Correlation b/w model and IDSC",
          "Minimum Time-Lag Tnin Minimum Time-Lag Tinin Minimum Time-Lag Tinin",
          "g Lasso 3 B06 Lasso c Elastic-Net Elastic-Net 5 BaseLine 5 5 0.44 BaseLine c c Lasso c % Elastic-Net 0.2 o o BaseLi 3 5 aseLine 5 oO oO oO 0.0",
          "Base Line: Yrest (t) = Ytrain(t) * Higher is better"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "18": {
        "title": "Summary",
        "text": [
          "We discovered the time difference between twitter and actual phenomena.",
          "We proposed but handling such difference to improve the nowcasting performance and extend for forecasting model.",
          "Our method is widely applicable for other time series data which has time-lag between response and predictors.",
          "Code and Data available at http://sociocom.jp/~iso/forecastword"
        ],
        "page_nums": [
          29
        ],
        "images": []
      }
    },
    "paper_title": "Forecasting Word Model: Twitter-based Influenza Surveillance and Prediction"
  },
  "1162": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Context Free Graph Grammars and Parsing",
        "text": [
          "Brief facts about context-free graph grammars:",
          "emerged in the 1980s",
          "generalization of context-free string grammars to graphs",
          "can easily generate NP-complete graph languages even non-uniform parsing is impractical",
          "early polynomial solutions were merely of theoretical interest:",
          "strong restrictions restrictions difficult to check degree of polynomial usually depends on grammar",
          "renewed interest nowadays due to Abstract Meaning Representation and similar notions of semantic graphs in computational linguistics."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Different Strategies",
        "text": [
          "Recent attempts use different strategies to deal with NP-completeness:",
          "Do your best, but be prepared to pay the price in the worst case.",
          "Generate deterministic parsers based on LL- or LR-like restrictions.",
          "Make sure that the generated graphs have a unique decomposition which determine the structure of derivation trees.",
          "This talk will summarize those approaches."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Context Free Graph Grammars",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Hypergraphs",
        "text": [
          "Graphs contain labelled hyperedges instead of edges:",
          "The number k is the rank of A and of the hyperedge.",
          "Rank yields an ordinary edge: is",
          "Some nodes may be marked 2, . . . , p and are called ports.",
          "The number p is the rank of the hypergraph.",
          "From now on: edge means hyperedge"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Hyperedge Replacement HR",
        "text": [
          "A rule A H consists of a label A and a graph H of equal rank.",
          "remove a hyperedge e with label A, insert H by fusing its ports with the incident nodes of e."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Why is Parsing Difficult",
        "text": [
          "Cocke-Kasami-Younger for HR works, but is inefficient because a graph has exponentially many subgraphs.",
          "Even when this is not the problem, we still have too many ways to order the attached nodes of nonterminal hyperedges. . ."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Reducing SAT",
        "text": [
          "ConHs. idBejor rka lunpd, roF. pDorsewiteiso, annad l P. foErrimcsoun la K1",
          "K i Polynomial Unifor",
          "S K K K K i m)",
          "Ki Kij if xj Ki Ki Kij if xj Ki n time",
          "Kij Kij for [n] \\ {j} Kij c",
          "Fig. 4. Input graph in the proof of Theor",
          "Fig. 3. Reduction of SAT to the uniform membership problem 1H. Bjorklund et al., LNCS 9618, 2016 copies of the original input, both sha with an outgoing -hyperedge targetin"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Early Approaches to HR Grammar Parsing",
        "text": [
          "Conditions for polynomial running time3",
          "Cubic parsing of languages of strongly connected graphs5 6",
          "After that, the area fell more or less silent for almost 2 decades.",
          "Then came Abstract Meaning Representation7, and with it a renewed interest in the question."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Recent General Approaches",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Choosing Generality over Guaranteed Efficiency",
        "text": [
          "Approaches that avoid restrictions (exponential worst-case behaviour):",
          "Lautemanns algorithm refined by efficient matching8, implemented in Bolinas",
          "S-graph grammar parsing9, using interpreted regular tree grammars as implemented in Alto",
          "Generalized predictive shift-reduce parsing10, implemented in Grappa"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "The Approach by Chiang et al",
        "text": [
          "Use dynamic programming to determine, for every subgraph G of the input G, the set of nonterminals A that can derive G.",
          "Every: Consider G that can be cut out along rank(A) nodes.",
          "For efficient matching of rules, use tree decompositions of right-hand sides.",
          "The algorithm runs in time O((3dn)k+1) where",
          "d is the node degree of G,",
          "n is the number of nodes, and",
          "k is the width of tree decompositions of right-hand sides.",
          "Important: G is assumed to be connected!"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "The S Graph Grammar Approach",
        "text": [
          "Instead of HR, use the more primitive graph construction operations by Engelfriet and Courcelle with interpreted regular tree grammars11.",
          "Strategy (parsing by intersection):",
          "Compute regular tree language LG of all trees denoting G.",
          "Intersect with the language of the grammars derivation trees.",
          "Trick: use a lazy approach to avoid building LG explicitly.",
          "The algorithm runs in time O(ns3sep(s)) where",
          "s is the number of source names number of ports)",
          "sep(s) is Lautemanns s-separability ( n)",
          "Alto is reported to be 6722 times faster than Bolinas on a set of AMRs from the Little Prince AMR-bank.",
          "11Koller & Kuhlmann, Proc. Intl. Conf. on Parsing Technologies 2011"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Generalized Predictive Shift Reduce Parsing",
        "text": [
          "A compiler generator approach.",
          "Use LR parsing from compiler construction, but allow conflicts.",
          "Parser uses characteristic finite automaton to select actions.",
          "In case of conflicts, use breadth-first search implemented with graph structured stack.",
          "In addition, use memoization.",
          "Grappa measurements for a grammar generating Sierpin- ski graphs (by M. Minas):"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "LL and LR like Restrictions to",
        "text": [],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Predictive Parsing",
        "text": [
          "Two versions of predictive parsing:",
          "deterministic recursive descent, generalizing SLL string parsing predictive top-down12",
          "deterministic bottom-up, generalizing SLR string parsing predictive shift-reduce13",
          "View right-hand side as a list of edges to be matched step by step.",
          "Terminal edges are consumed from the input graph.",
          "Nonterminal edges are handled by recursive call (top-down) or reduction (bottom-up)."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "16": {
        "title": "Predictive Top Down Parsing PTD",
        "text": [
          "In PTD parsing, each nonterminal A becomes a parsing procedure:",
          "parser generator determines lookahead for every A-rule: rest graphs (lookahead sets) for alternative A-rules must be disjoint the current rest graph determines which rule to apply;",
          "in doing so, we have to distinguish between different profiles of A;",
          "alternative terminal edges require free edge choice.",
          "Lookahead and free edge choice are approximated by",
          "Parikh sets to obtain efficiently testable conditions.",
          "Running time of generated parser is O(n2)."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "17": {
        "title": "Predictive Shift Reduce Parsing PSR",
        "text": [
          "PSR parsing reduces the input graph back to the initial nonterminal:",
          "parser maintains a stack representing the graph to which the input read so far has been reduced",
          "shift steps read the next terminal edge from the input graph (free edge choice needed here as well)",
          "reduce steps replace rhs on top of stack with lhs",
          "parser generator determines characteristic finite automaton (CFA) that guides the choice of shift and reduce steps",
          "CFA must be conflict free",
          "string parsing only faces shift-reduce and reduce-reduce conflicts; now there may also be shift-shift conflicts.",
          "Running time of generated parser is O(n)."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "18": {
        "title": "Unique Decomposability",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "19": {
        "title": "Reentrancies",
        "text": [
          "PTD and PSR grammar analysis can be expensive for large grammars.",
          "In NLP, grammars may be volatile and very large uniformly polynomial parsing may be preferable.",
          "Original strong assumptions14 were later relaxed15 and extended to weighted HR grammars16.",
          "This type of HR grammar can also be learned a la Angluin17.",
          "Requirements on right-hand sides:",
          "targets of every nonterminal hyperedge e are reentrant w.r.t. e",
          "all nodes reachable from the root",
          "Yields a unique hierarchical decomposition revealing the structure of derivation trees.",
          "However, there is one problem left. . ."
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "20": {
        "title": "Recall Reducing SAT",
        "text": [
          "H. Bjorklund, F. Drewes, and P. Ericson",
          "K i Polynomial Unifor",
          "S K K K K i m)",
          "Ki Kij if xj Ki Ki Kij if xj Ki n time",
          "Kij Kij for [n] \\ {j} Kij c",
          "Fig. 4. Input graph in the proof of Theor",
          "Fig. 3. Reduction of SAT to the uniform membership problem copies of the original input, both sha with an outgoing -hyperedge targetin",
          "We first give a construction that violates conditions 4 and 5. It uses nonter- If we also disregard restriction 2, t minals S, K, Ki, Kij with i [m], j [n]. The terminal labels are c, all j [m],"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "21": {
        "title": "Order Preservation",
        "text": [
          "Conclusion: we also need order preservation!",
          "We must provide a binary relation on nodes that",
          "coincides with the order of targets of nonterminal edges, and",
          "is compatible with hyperedge replacement.",
          "For a reentrancy and order preserving HRG G and a graph",
          "G as input, G L(G) can be decided in time",
          "This holds also for computing the weight of G if the rules of G have weights from a commutative semiring."
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "22": {
        "title": "Systems and Tools",
        "text": [],
        "page_nums": [
          32
        ],
        "images": []
      },
      "23": {
        "title": "Bolinas",
        "text": [
          "translation via synchronous HR grammars",
          "EM training from corpora"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "24": {
        "title": "Alto",
        "text": [
          "One instantiation is the HR parser of (Koller & Kuhlmann, 2011).",
          "Main features correspond to those of Bolinas:",
          "translation via synchronous HR grammars",
          "EM training from corpora"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "25": {
        "title": "Grappa",
        "text": [
          "generators for predictive top-down (PTD), predictive shift-reduce",
          "(PSR), generalized PSR parsers",
          "can generate PTD and PSR parsers for contextual HR grammars21",
          "is constantly being improved and extended",
          "has a tasty logo"
        ],
        "page_nums": [
          35,
          36
        ],
        "images": []
      },
      "26": {
        "title": "Future Work",
        "text": [],
        "page_nums": [
          37
        ],
        "images": []
      },
      "27": {
        "title": "Some Questions for Future Work",
        "text": [
          "How to make HR grammars efficiently parsable by design?",
          "Can HR grammars be learned from data so that they are (1) small and (2) efficiently parsable?",
          "What are useful and benign extensions that can be handled efficiently (like contextual HR)?",
          "How to handle node labels in a good way (e.g., enabling relabelling)?",
          "Efficient transductions that turn strings/trees into graphs?"
        ],
        "page_nums": [
          38
        ],
        "images": []
      }
    },
    "paper_title": "A Survey of Recent Advances in Efficient Parsing for Graph Grammars Invited Talk"
  },
  "1163": {
    "slides": {
      "0": {
        "title": "2 min summary",
        "text": [
          "Probabilistic FastText FastText + Gaussian Mixture Embeddings"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Probabilistic fasttext",
        "text": [
          "L[cool] = COOL f(cool) COOL",
          "~rock,0 music L[coolzz] = f(coolzz) COOLZZ",
          "dictionary-based embeddings character-based probabilistic embeddings",
          "w2gm FastText PFT ~rock,1 Spearman Correlation",
          "Word Component Nearest neighbors (cosine similarity) rock rocks:0, rocky:0, mudrock:0, rockscape:0 rock punk:0, punk-rock:0, indie:0, pop-rock:0",
          "Word Component Nearest neighbors (cosine similarity) Word Component / Meaning Nearest neighbors (English Translation) rock rocks:0, rocky:0, mudrock:0, rockscape:0 secondo 0 / 2nd Secondo (2nd), terzo (3rd) , quinto (5th), primo (first) rock punk:0, punk-rock:0, indie:0, pop-rock:0",
          "secondo 1 / according to conformit (compliance), attenendosi (following), cui (which)"
        ],
        "page_nums": [
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Vector embeddings",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "3": {
        "title": "Word embeddings",
        "text": [
          "one-hot vector dense representation",
          "size of vocabulary dimension"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Dense representation of words",
        "text": [
          "vindicates vindicate exculpate absolve exonerate",
          "Country and Gap tal Vectors Projected by PCA",
          "China - Beijing ~ Japan - Tokyo"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Fasttext with word2gm",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "6": {
        "title": "Similarity score energy between",
        "text": [
          "vector space function space"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "7": {
        "title": "Energy of two gaussian mixtures",
        "text": [
          "total energy = weighted sum of pairwise partial energies"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "8": {
        "title": "Word sampling",
        "text": [
          "I like that rock band"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Loss function",
        "text": [
          "word: w context word: c",
          "rock band high E(w,c)",
          "word: w negative context: c",
          "rock dog low E(w,c)"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "10": {
        "title": "Training illustration",
        "text": [],
        "page_nums": [
          20,
          21,
          22
        ],
        "images": []
      },
      "11": {
        "title": "Evaluation",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "Spearman correlations",
        "text": [
          "W O R D S I M D ATA S E T S FA S T T E X T W 2 G M P F T- G M"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "13": {
        "title": "Comparison with other multi prototype embeddings",
        "text": [
          "TIAN MAXSIM 63.6 - PFT performs better",
          "W2GM MAXSIM : 62.7 than other multi-",
          "NEELAKANTAN AVGSIM | 64.2 prototype",
          "PFT-GM MAXSIM 63. embeddings on ee Pe SCWS, a benchmark CHEN-M AVGSIM 200 66.2 ar for word similarity W2GM MAXSIM 200 65.5 with multiple",
          "NEELAKANTAN AVGSIM | 300 67. meanings.",
          "Table 3: Spearmans Correlation p x 100 on word similarity dataset SCWS."
        ],
        "page_nums": [
          29
        ],
        "images": [
          "figure/image/1163-Table3-1.png"
        ]
      },
      "14": {
        "title": "Foreign language embeddings",
        "text": [
          "Word Meaning Nearest Neighbors",
          "(IT) secondo according to conformit (compliance), attenendosi (following), cui (which), conformemente (accordance with)",
          "(IT) porta lead, bring portano (lead), conduce (leads), portano, porter, portando (bring), costringe (forces)",
          "(IT) porta door porte (doors), finestrella (window), finestra (window), portone (doorway), serratura (door lock)",
          "(FR) voile veil voiles (veil), voiler (veil), voilent (veil), voilement, foulard (scarf), voils (veils), voilant (veiling)",
          "(FR) voile sail catamaran (catamaran), driveur (driver), nautiques (water), Voile (sail), driveurs (drivers)",
          "(FR) temps weather brouillard (fog), orageuses (stormy), nuageux (cloudy)",
          "(FR) femps time mi-temps (half-time), partiel (partial), Temps (time), annualis (annualized), horaires (schedule)",
          "(FR) voler steal envoler (fly), voleuse (thief), cambrioler (burgle), voleur (thief), violer (violate), picoler (tipple)",
          "(FR) voler fly airs (air), vol (flight), volent (fly), envoler (flying), atterrir (land)",
          "Table 5: Nearest neighbors of polysemies based on our foreign language PFT-GM models.",
          "Table 4: Word similarity evaluation on foreign languages."
        ],
        "page_nums": [
          30
        ],
        "images": [
          "figure/image/1163-Table4-1.png",
          "figure/image/1163-Table5-1.png"
        ]
      },
      "15": {
        "title": "Future work multi lingual embeddings",
        "text": [
          "Literature: align embeddings of many languages after training",
          "Use disentangled embeddings to disambiguate alignment"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "Elegant representation of semantics using multimodal distributions",
          "Suitable modeling words with multiple meanings",
          "Model words as character levels",
          "Better semantics for rare words",
          "Able to estimate semantics of unseen words"
        ],
        "page_nums": [
          32
        ],
        "images": []
      }
    },
    "paper_title": "Probabilistic FastText for Multi-Sense Word Embeddings"
  },
  "1164": {
    "slides": {
      "0": {
        "title": "Cutoff",
        "text": [
          "Removing low-frequency words from a corpus",
          "Common practice to save computational costs in learning",
          "Needed even in a distributed environment, since the feature",
          "space of k-grams is quite large [Brants+ 2007]",
          "Enough for roughly analyzing topics, since low-frequency words",
          "have a small impact on the statistics [Steyvers&Griffiths 2007]",
          "f(remaining word) f(removed word) holds"
        ],
        "page_nums": [
          1,
          8
        ],
        "images": []
      },
      "1": {
        "title": "Question",
        "text": [
          "How many low-frequency words can we remove while",
          "More generally, how much can we reduce a corpus/model using",
          "Many experimental studies addressing the question",
          "Discussing trade-off relationships between the size of reduced",
          "corpus/model and its performance"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "This work",
        "text": [
          "First address the question from a theoretical standpoint",
          "Derive the trade-off formulae of the cutoff strategy for k-",
          "gram models and topic models",
          "Perplexity vs. reduced vocabulary size",
          "Verify the correctness of our theory on synthetic corpora",
          "and examine the gap between theory and practice on"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Approach",
        "text": [
          "Assume a corpus follows Zipfs law (power law)",
          "Empirical rule representing a long-tail property in a corpus",
          "Essentially the same approach as in physics",
          "Constructing a theory while believing experimentally observed",
          "results (e.g., gravity acceleration g)",
          "We can derive the landing point of a ball by believing g.",
          "Similarly, we try to clarify the trade-off relationships by"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Zipfs law",
        "text": [
          "Empirical rule discovered on real corpora [Zipf, 1935]",
          "Word frequency f(w) is inversely proportional to its frequency",
          "C f w r w",
          "Frequency f(w) Frequency ranking Zipf random",
          "(Linear on a log-log graph) Log-log graph"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Perplexity PP",
        "text": [
          "Widely used evaluation measure of statistical models",
          "Geometric mean of the inverse of the per-word likelihood on",
          "the held-out test corpus",
          "PP means how many possibilities one has for estimating the",
          "Lower perplexity means better generalization performance"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Constant restoring",
        "text": [
          "Infer the prob. of the removed words as a constant",
          "Approximate the result learned from the original corpus"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Perplexity of unigram models",
        "text": [
          "Predictive distribution of unigram models",
          "f w p w",
          "N Reduced corpus size",
          "Obtained by minimizing PP w.r.t. a constant , after substituting",
          "the restored probability p (w) into PP",
          "Vocab. size Reduced vocab. size"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Theorem PP of unigram models",
        "text": [
          "For any reduced vocabulary size W, the perplexity PP1 of",
          "the optimal restored distribution of a unigram model is",
          "Bertrand series (special form)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Approximation of PP of unigrams",
        "text": [
          "H(X) and B(X) can be approximated by definite integrals",
          "Approximate formula o is obtained as",
          "is quasi polynomial (quadratic)",
          "Behaves as a quadratic function on a log-log graph"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "PP of unigrams vs reduced vocab size",
        "text": [
          "same size as Reuters",
          "Log-log graph Real (Reuters)",
          "Our theory is suited for inferring the growth rate of perplexity",
          "rather than the perplexity value itself"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Perplexity of k gram models",
        "text": [
          "Simple model where k-grams are calculated from a",
          "random word sequence based on Zipfs law",
          "The model is stupid",
          "Bigram is is is quite frequent",
          "Two bigrams is a and a is have the same frequency",
          "Later experiment will uncover the fact that the model can",
          "roughly capture the behavior of real corpora"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Frequency of a k gram",
        "text": [
          "Frequency fk of a k-gram wk is defined by",
          "Decay function g2 of bigrams is as follows",
          "Decay function gk of k-grams is defined through its",
          "Piltz divisor function that",
          "represents # of divisors of n"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Exponent of k gram distributions",
        "text": [
          "Assume k-gram frequencies follow a power law",
          "[Ha+ 2006] found k-gram frequencies roughly follow a power",
          "law, whose exponent k is smaller than 1 (k>1)",
          "Optimal exponent in our model based on the assumption",
          "By minimizing the sum of squared errors between the inverse",
          "gradients gk -1(r) and r1/k on a log-log graph"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Exponent of k grams vs gram size",
        "text": [],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Corollary PP of k gram models",
        "text": [
          "For any reduced vocabulary size W, the perplexity of the",
          "optimal restored distribution of a k-gram model is",
          "X H X a x x a",
          "Hyper harmonic series X a ln x B X a x x a Bertrand series (another special form)"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "PP of k grams vs reduced vocab size",
        "text": [
          "We need to make assumptions that include",
          "backoff and smoothing for higher order k-grams"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "17": {
        "title": "Additional properties by power law",
        "text": [
          "Treat as a variant of the coupon collectors problem",
          "How many trials are needed for collecting all coupons whose",
          "occurrence probabilities follow some stable distribution",
          "There exists several works about power law distributions",
          "Corpus size for collecting all of the k-grams, according to",
          "When k W ln , otherwise, k",
          "Lower and upper bound of the number of k-grams from",
          "the corpus size N and vocab. size W, according to"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "18": {
        "title": "Perplexity of topic models",
        "text": [
          "Latent Dirichlet Allocation (LDA) [Blei+ 2003]",
          "[Griffiths&Steyvers 2004] Learning with Gibbs sampling",
          "Obtain a good topic assignment zi for each word wi",
          "Posterior distributions of two hidden parameters",
          "z n d d z",
          "w nw z z",
          "Mixture rate of topic z in document d",
          "Occurrence rate of word w in topic z"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "19": {
        "title": "Rough assumptions of",
        "text": [
          "Word distribution z of each topic z follows Zipfs law",
          "It is natural, regarding each topic as a corpus",
          "Assumptions of (two extreme cases)",
          "Case All: Each document evenly has all topics",
          "Case One: Each document only has one topic (uniform dist.)",
          "The curve of actual perplexity is expected to be between their values",
          "Case All: PP of a topic model PP of a unigram",
          "Marginal predictive distribution is independent of d"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "20": {
        "title": "TheoremPP of LDA models Case One",
        "text": [
          "For any reduced vocabulary size W, the perplexity of the",
          "optimal restored distribution of a topic model in the Case",
          "One is calculated as",
          "T : # of topics in LDA"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "21": {
        "title": "PP of LDA models vs reduced vocab size",
        "text": [],
        "page_nums": [
          27
        ],
        "images": []
      },
      "22": {
        "title": "Time memory and PP of LDA learning",
        "text": [
          "Results of Reuters corpus",
          "Memory usage of the (1/10)-corpus is only 60% of that of",
          "Helps in-memory computing for a larger corpus,",
          "although the computational time decreased a little"
        ],
        "page_nums": [
          28
        ],
        "images": [
          "figure/image/1164-Table2-1.png"
        ]
      },
      "23": {
        "title": "Conclusion",
        "text": [
          "Trade-off formulae of the cutoff strategy for k-gram",
          "models and topic models based on Zipflaw",
          "Perplexity vs. reduced vocabulary size",
          "Experiments on real corpora showed that the estimation",
          "of the perplexity growth rate is reasonable",
          "We can get the best cutoff parameter by maximizing the",
          "reduction rate ensuring an acceptable (relative) perplexity",
          "Possibility that we can theoretically derive empirical",
          "parameters, or rules of thumb, for different NLP",
          "Can we derive other rules of thumb based on Zipfs law?"
        ],
        "page_nums": [
          30
        ],
        "images": []
      }
    },
    "paper_title": "Perplexity on Reduced Corpora"
  },
  "1167": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Modeling coherence in linguistics theory into computational task (Barzilay & Lapata,",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Coherence",
        "text": [
          "Coherent text is integrated as a whole, rather than a series",
          "Every sentence in a coherent text has relation(s) to each other (Halliday and Hasan, 1976; Mann and Thompson,",
          "Evaluate coherence through cohesion",
          "Lexical and semantic (meaning) continuity are indispensable",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "RelatedWork Entity Graph",
        "text": [
          "Entity graph was introduced by Guinaudeau &",
          "Text -> Bipartite Graph -> Projection Graphs",
          "Coherence is achieved by cohesion: considers repeated mention of entities and their syntactical role (weight)",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017",
          "Graph data structure can represent the structure of text and relations among sentences",
          "Coherence is achieved through lexical cohesion: repeated mention of entities.",
          "Disadvantage: cannot capture the relation between related-yet-not identical entities (Li and Hovy,",
          "Solution: use distributed representation of words/sentences",
          "Relation between vertices in projection graph has to satisfy surface sequential ordering",
          "Proposal: allows two directions (omit the constraint)"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": [
          "figure/image/1167-Figure2-1.png"
        ]
      },
      "3": {
        "title": "Proposed Method",
        "text": [
          "Formally, text is a graph , where",
          "is a set of vertices, represents i-th sentence. is a set of edges, represents relation (cohesion) from i-th to j-th sentence (weighted & directed).",
          "Evaluate the coherence through cohesion",
          "Sentences are encoded into their meaning form",
          "Average of summation of word vectors (distributed representation of words)",
          "An edge represents cohesion among sentences",
          "Establishment of edge is decided as the operation of vectors representation of sentences",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017",
          "An edge is established from the sentence vertex in question to the other vertex with the weight calculated by",
          "Text coherence measure (higher is better) is calculated by averaging the averaged weight of outgoing edges from every vertex in the graph as",
          "# vertices # outgoing edges of vertex vi"
        ],
        "page_nums": [
          5,
          7
        ],
        "images": []
      },
      "4": {
        "title": "Propose Method",
        "text": [
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation",
        "text": [
          "Task 1: Discrimination (Barzilay and Lapata, 2008)",
          "Task 2: Insertion (Eisner and Charniak, 2011)",
          "Both tasks evaluate how well the methods in comparing coherence between texts",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Evaluation Discrimination Task",
        "text": [
          "The goal is to compare original vs. permutated text S4",
          "Program is considered successful when giving greater score to the more coherent (original) text",
          "Dataset: 683 WSJ (LDC) texts, permutations (avg. 24 sentences, 521 tokens)",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Result Discrimination Task",
        "text": [
          "Difference of performance is statistically significant at",
          "PAV > MSV > Entity Graph",
          "Cohesion is not only about repeating mention of entities",
          "PAV MSV pair shares 88.3% same judgement",
          "Local (adjacent) cohesion is possibly more important than long-distance cohesion",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Evaluation Insertion Task",
        "text": [
          "Insertion task is more important than discrimination task",
          "It was proposed by Eisner and Charniak (2011):",
          "Given a text, take out a sentence (randomly), then place it into other positions",
          "Program is considered successful if it prefers to insert take-out-sentence at its original position rather than arbitrary (distorted) positions",
          "Our Proposal: useTOEFL iBT insertion-type questions",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "TOEFL iBT Insertion type Question",
        "text": [
          "A text is coherent even without the insertion sentence",
          "Preservation of coherence is achieved when the question-sentence is inserted",
          "(A) The raising of livestock is a major economic activity in semiarid lands, where grasses are generally the dominant type of natural vegetation.",
          "(B) The consequences of an excessive number of livestock grazing in an area are the reduction of the vegetation cover and trampling and pulverization of the soil. (C) This is usually followed by the drying of the soil and accelerated erosion. (D)",
          "in the correct place coherence otherwise but disrupt",
          "Question: Insert the following sentence into one of",
          "question sentence = \"This economic reliance on livestock in certain regions makes large tracts of land susceptible to overgrazing.",
          "correct answer = B",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Result Insertion Task",
        "text": [
          "Difference in every pair of methods is not statistically significant at p < 0.05",
          "14 questions are answered incorrectly by PAV, but correctly by SSV.",
          "In these questions, SSV tends to establish the relationship between distance sentences (dist = 2.8). For example, exemplification text",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion and FutureWork",
        "text": [
          "Coherence can be achieved through cohesion (lexical and semantic continuity)",
          "Local cohesion is more important than long-distance cohesion coherence, but long-distance cohesion can also contribute as well in evaluating",
          "We need to introduce a more refined mechanism for incorporating distant sentence relations.",
          "The representation of sentences and method to establish edges would be direct targets of the refinement",
          "Semantic Similarity Graph | wiragotama.github.io TextGraph-11, ACL 2017"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Evaluating text coherence based on semantic similarity graph"
  },
  "1170": {
    "slides": {
      "0": {
        "title": "What we are aiming at",
        "text": [
          "Finding novel topics in news streams",
          "So far not much success in the literature"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Problem",
        "text": [
          "Frequencies of (manually assigned) topic descriptors that appeared in the New York Times from June to December, 2013.",
          "Rank of Topic Descriptor"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Statistics",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "SVM cannot handle a huge taxonomy Liu 2005",
        "text": [
          "The number of unique topics in NYT over 6 months"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Approach",
        "text": [
          "Memory Based Topic Label"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "How it works Overview",
        "text": [
          "Look up Wikipedia to find pages most relevant to a news story",
          "Generate label candidates from page titles",
          "Pick those that are deemed most fit to represent the content"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "WikiLabel Concept Generation with Wikipedia",
        "text": [],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": []
      },
      "7": {
        "title": "Example",
        "text": [
          "2009 detention of A merican hikers by Iran",
          "detention of hikers by Iran",
          "Making it shorter makes it more general"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Dependency pruning",
        "text": [
          "C3 C2 detentio n"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Use every NP in the title as a resource",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "What you get with extension",
        "text": [
          "Original approach 2009 dentetion of A merican hikers by Iran you start here",
          "2009 dentetion o f hikers by Iran",
          "2009 dente tion by Iran"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Testing it out in the field",
        "text": [
          "country media outlets #outlets #stories",
          "us/uk the new york times, yahoo, cnn,",
          "msnbc, fox, washington post, abc,",
          "south-korea joongang ilbo (English edition),",
          "chosun ilbo (English edition)",
          "japan asahi, jcast, jiji.com, mainichi,",
          "nhk, nikkei, sankei, tbs, tokyo, tv-"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "North Korean Agenda",
        "text": [
          "North-Korea nuclear program! North-Korea relations! North-Korea Russia relations! North-Korea United-States relations! North-Korean test! North-Korean missile test! North-Korea weapons! North-Korean defectors! North-Korea South-Korea relations! North-Korean nuclear test! North-Korean famine! North-Korea program! North-Korean abductions! North-Korea weapons of mass destruction! North-Korean floods! North-Korean abductions of Japanese citizens! North-Korea women's team! Japan North-Korea relations! People's Republic North-Korea relations!",
          "North-Korean famine! rocket North-Korea! province North-Korea!",
          "North-Koreans! North-Korean abductions of Japanese citizens!",
          "First Secretary of the Workers' Party of Korea!",
          "Human rights in North-Korea!",
          "North-Korea sponsored schools in Japan!",
          "Prisons in North-Korea! North-South Summit! North Korean abductions of Japanese citizens>>Victims! Mount Kumgang>>Tourist Region! Korean Language! North-Korean Intelligence Agencies!",
          "Topic Popularity (South Korea)!",
          "Kim Jong-il's visit to China! Culture in North-Korea! North-South relations! Japan! South-Korea!",
          "News Coverage Ratio! Topic Popularity (US)!"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1170-Figure2-1.png"
        ]
      },
      "13": {
        "title": "Human Evaluation",
        "text": [
          "Title is one of major topics in Article. Article gives a particular",
          "Part of Article deals with Title. Article makes a clear reference",
          "Part of Title has some relevance to a dominant theme of Article.",
          "Example: Title European Tax System is partially relevant to",
          "an article discussing US Tax System.",
          "Article makes a reference to part of Title.",
          "Title has no relevance to Article, in whatever way.",
          "language rating #instances english japanese"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1170-Table2-1.png"
        ]
      },
      "14": {
        "title": "Evaluation Metric ROUGE W",
        "text": [
          "The United States of The United States of America"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "15": {
        "title": "Results",
        "text": [
          "Text Rank vs. WikiLabel",
          "trank rm0 rm1 rm1/x"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "16": {
        "title": "Summary",
        "text": [
          "Talked about topic detection using WikiLabel",
          "Generalizing concept with sentence compression",
          "Use of sentence compression led to a huge improvement, producing performance twice as good as that of TextRank",
          "Online topic learning seems promising"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "17": {
        "title": "Solution to Problem",
        "text": [
          "Frequencies of (manually assigned) topic descriptors that appeared in the New York Times from June to December, 2013.",
          "Rank of Topic Descriptor"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "MediaMeter: A Global Monitor for Online News Coverage"
  },
  "1171": {
    "slides": {
      "0": {
        "title": "Parallel Speech Corpora",
        "text": [
          "Spoken parallel corpora are useful in building speech-to-speech applications.",
          "Costly: Laborious with respect to translation and interpretation",
          "Contain unexpressive speech (e.g. interpreted)",
          "Do not capture spontaneous spoken language traits",
          "Lack one-to-one alignment between words/sentences"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Dubbed movies as a resource",
        "text": [
          "Popular movies, documentaries, TV shows are dubbed in many countries*.",
          "A good resource for obtaining bilingual data:",
          "(1) Available parallel audio data in dubbed movies.",
          "Transcripts available with time information in subtitles. Speech!",
          "Movie still from The Man Who Knew Too Much (1956) Universal Pictures"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Example Dubbing in European Countries",
        "text": [
          "Image source: Wikipedia - Dubbing (filmmaking)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Proposed Method",
        "text": [
          "Automatic extraction of segmented parallel sentences with prosodic parameters",
          "Input: Bilingual audio and subtitles pair",
          "Output: Aligned bilingual sentences annotated with prosodic features",
          "Supports any language pair",
          "Aligned at sentence level"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Methodology Overview",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Stage 1 Sentence Segmentation",
        "text": [
          "Use subtitle time-information to find script location in audio"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "6": {
        "title": "Stage 2 Prosodic Parameter Extraction",
        "text": [
          "ProsodyPro1 library used for prosodic feature extraction"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Stage 3 Parallel Sentence Alignment",
        "text": [
          "Goal: Given sentence s1 in lang. 1 find corresponding sentence s2 in lang.2",
          "Yandex Translate Meteor library (Denkowski and Lavie, 2014)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Applying the Methodology",
        "text": [
          "The Man Who Knew Too Much (1956)",
          "Films originally in English, dubbed to Spanish.",
          "Audio extracted from DVD using Libav1",
          "English and Spanish subtitles obtained from opensubtitles2."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Currently obtained corpus",
        "text": [],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1171-Table3-1.png"
        ]
      },
      "10": {
        "title": "Shortcomings",
        "text": [
          "Copyright restrictions for distributing the corpus.",
          "Main bottlenecks in capturing data:",
          "15% sentences lost in original language.",
          "49% sentences lost in dubbed language. Processing The Man Who Knew Too Much",
          "Translation difference in dubbed audio and subtitles"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1171-Table4-1.png"
        ]
      },
      "11": {
        "title": "Sub dub differences",
        "text": [
          "Extra cted English (Sub + audio) Spanish Sub Spanish Dub",
          "Daddy , you're sure I've never been to Africa before ?",
          "Papa , estas seguro de que nunca estuve antes Papa, estas seguro que no habiamos estado ya yes en Africa ? en Africa?",
          "no It looks familiar. Me parece conocido. Todo esto ya lo conozco.",
          "You saw the same scenery last summer driving to Las Vegas .",
          "Viste el mismo panorama el verano pasado Vimos un paisaje muy parecido cuando fuimos a yes cuando manejamos a Las Vegas . Las Vegas",
          "Where Daddy lost all that money at the crap Claro , donde papa perdio todo ese dinero en la Ah claro, donde papa perdio toda el dinero en la yes mesa mesa de juego?",
          "no Hey, look! Miren! Hey mirad!",
          "no A Camel. Un camello! Un camello!",
          "yes Of course this isn't really Africa, honey. Y esto no es realmente Africa . Realmente esto no es Africa, carino.",
          "yes It's the French Morocco . Es el Marruecos frances . Es el Marruecos Frances.",
          "yes Well , it's northern Africa . Es Africa del Norte. Bueno, es Africa del Norte.",
          "yes Still seems like Las Vegas . Aun se parece a Las Vegas . Pues, sigue pareciendose a Las Vegas."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "Automatic building of multimodal bilingual corpora from dubbed media",
          "Conversational speech Useful for speech-to-speech translation applications",
          "Works on any language pair (with trained acoustic model)",
          "No further training needed",
          "Code available at http://www.github.com/TalnUPF/movie2parallelDB"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Future Work",
        "text": [
          "Switch from proprietary audio-text aligner software to open source",
          "E.g. p2fa (based on CMU Sphinx ASR system)",
          "XML based structure as corpus metadata",
          "Instead of directory structure only",
          "Identifying the speaker of each sentence",
          "Extend and publish the corpus",
          "Depending on agreement with Copyright holders"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Appendix A State of the Art Corpora",
        "text": [],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1171-Table1-1.png"
        ]
      },
      "15": {
        "title": "Appendix B ProsodyPro Files",
        "text": [
          "Some of the files generated by ProsodyPro"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1171-Table2-1.png"
        ]
      }
    },
    "paper_title": "Automatic Extraction of Parallel Speech Corpora from Dubbed Movies"
  },
  "1173": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Opinions towards products, restaurants, events, etc.",
          "Feelings towards self or others.",
          "Models of product sentiment and emotion should be different",
          "Discrete Emotions Dimensional Models",
          "Most popular in NLP are Ekmans six emotions: anger, disgust, fear, joy sadness, surprise",
          "Each affective state is a combination of real-valued components",
          "Most popular is the circumplex",
          "-s sJi aopnasn oef",
          "Two independent neurophysiological systems: valence (or sentiment) and arousal",
          "Some emotions driven by similar words (hell, bad sadness, fear, anger)"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Emotion Circumplex",
        "text": [
          "Source: Jonker & Van der Merwe - Emotion episodes of Afrikaans-speaking employees in the workplace"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Applications",
        "text": [
          "Goal: Automated large-scale psychological studies",
          "measuring time-of-day and day-of-week mood swings",
          "and what causes them",
          "bipolar, schizophrenic breaks ...",
          "analysing movies and books",
          "and how they vary in emotion content",
          "correlating with external effects",
          "e.g. weather, sports game outcomes, ..."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Measuring Valence and Arousal",
        "text": [
          "Valence (or sentiment or polarity)",
          "1 (very negative) 5 (neutral/objective) 9 (very positive)",
          "1 (neutral/objective post) 9 (very high intensity)"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Examples",
        "text": [
          "Is the one whoz GOing to Light Up your",
          "Blessed with a baby boy today ... the boring life is back :( ...",
          "IS SUPER STRESSED AND ITS JUST THE SEC-",
          "OND MONTH OF SCHOOL ..D:",
          "Example of posts annotated with average valence (V) and arousal (A) ratings."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Data Source",
        "text": [
          "Each message from a distinct user",
          "All messages from the same time interval"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Annotation",
        "text": [
          "psychology students received training in annotating these traits, including anchoring no distractions that may affect they mood (music, etc.)",
          "Messages are un-ratable if they are not in English or contain no cues"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Annotation Results",
        "text": [
          "Histograms of average rating scores.",
          "ValenceArousal r 0.085 (ignoring neutral posts)"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1173-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Gender and Age Differences",
        "text": [
          "Variation in valence and arousal with age in our data set using a LOESS fit. Data is split by gender: Male and Female."
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1173-Figure2-1.png"
        ]
      },
      "9": {
        "title": "Predicting Valence and Arousal",
        "text": [
          "Train a classifier for predicting valence and arousal separately",
          "Features: Bag-of-words (only unigrams)",
          "Model: Linear regression with elastic net regularization",
          "Test: 10 fold cross-validation"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Baseline Models",
        "text": [
          "valence and arousal ratings for 1400 words (Bradley and",
          "valence and arousal ratings for 14000 words (Warriner et",
          "7629 words rated for positive or negative sentiment (Wilson",
          "Hashtag Sentiment Lexicon adapted to Social Media"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Results",
        "text": [
          "ANEW AffNorms MPQA NRC BOW Model",
          "Message rating prediction accuracy (in Pearson r)."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Valence",
        "text": [
          "birthday happy thank great love thanks wishes wonderful hate",
          "Words most positively and negatively correlated with valence",
          "correlation strength relative frequency"
        ],
        "page_nums": [
          14,
          19
        ],
        "images": []
      },
      "13": {
        "title": "Arousal",
        "text": [
          "birthday happy its wishes soooo thanks christmas sunday yay status life people bored",
          "Words most positively and negatively correlated with arousal",
          "correlation strength relative frequency"
        ],
        "page_nums": [
          15,
          20
        ],
        "images": []
      },
      "14": {
        "title": "Quantitative Analysis Circumplex",
        "text": [
          "bored soooo excited yay"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Take Aways",
        "text": [
          "Annotated Facebook data set and bag-of-words model available"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "16": {
        "title": "Agreement",
        "text": [
          "Dimension R1 R2 IA Corr.",
          "Individual rater mean and standard deviation and inter-annotator correlation (IA Corr)"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1173-Table2-1.png"
        ]
      }
    },
    "paper_title": "Modelling Valence and Arousal in Facebook posts"
  },
  "1174": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Neural question answering (QA) systems are end-to-end trainable machine learning models which achieve top performance in domains with large training datasets",
          "We apply an extractive neural QA system (FastQA [1]) to BioASQ 5B",
          "Phase B (list & factoid questions)",
          "Extractive QA: Answer is given as start and end pointers in the context (snippets)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Network Architecture",
        "text": [
          "Original FastQA [1] Our Architecture",
          "Change start probab ility activation from softma x to sig moid",
          "Multiple s tarts ca n be selected for list questions",
          "For each sele cted st art, select the correspondin g end p ointer via softmax"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": [
          "figure/image/1174-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Training Procedure",
        "text": [
          "Problem: Neural QA typically requires ~105 questions to train",
          "Datasets of such scale exist in the open domain, e.g. SQuAD [2] with factoid questions on Wikipedia articles",
          "We train in two steps:",
          "Pre-training on a large (~105 questions) open-domain dataset (SQuAD)",
          "Fine-tuning on BioASQ (~103 questions)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "3": {
        "title": "Systems",
        "text": [
          "We trained five models using 5-fold cross validation on all available training data",
          "We submitted two systems:",
          "Single: Best single model according to its respective development set",
          "Ensemble: Ensemble of all five models (averaging scores before sigmoid/softmax activation)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Results",
        "text": [
          "Our system won 3/5 batches",
          "Averaged over the five batches, our system",
          "percentage points above the best competitor",
          "On average, the best competitor performed 3.4 percentage points better than our ensemble model"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Discussion",
        "text": [
          "Strengths: Competitive performance, despite:",
          "Less feature engineering than traditional QA systems",
          "A less domain-dependent architecture, because we dont rely on domain-specific structured resources",
          "Extractive QA cannot generate answer which are not explicitly mentioned in the snippets",
          "No yes/no & summary questions"
        ],
        "page_nums": [
          10
        ],
        "images": []
      }
    },
    "paper_title": "Neural Question Answering at BioASQ 5B"
  },
  "1175": {
    "slides": {
      "0": {
        "title": "Stance Classification in Tweets",
        "text": [
          "Automatically identify users positions on a pre-chosen target of interest (e.g., public issues) from text",
          "Target (given): Climate Change is Real Concern",
          "Tweet (given): We need to protect our islands and stop the destruction of coral reef.",
          "(Output) Stance label (to be predicted): Favour"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Cross Target Stance Classification",
        "text": [
          "Generalise user stance on unseen targets",
          "Target: A mining project in Australia (Destination)",
          "Tweet: Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef.",
          "Apply classifiers trained on a source target to the destination target",
          "Target: Climate Change is Real Concern (Source)",
          "Tweet: We need to protect our islands and stop the destruction of coral reef."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Our Approach Basic Idea",
        "text": [
          "For targets both related to a common domain, stance generalisation is possible via domain-specific information that reflects users major concerns",
          "Tweet: Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef.",
          "Tweet: We need to protect our islands and stop the destruction of coral reef.",
          "Target: A mining project in Australia",
          "Target: Climate Change is Real Concern",
          "Destination target Source target",
          "Domain aspects: e.g., reef, destruction/damage"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Extraction of Domain Aspects",
        "text": [
          "Key properties of domain aspects",
          "They tend to be mentioned by multiple users in a corpus",
          "They tend to carry the core meaning of a stance-bearing tweet",
          "In our project dataset, 3776 our of 41805 tweets mentioned the aspect reef",
          "why fund Adani #Coal Mine and destroy our Reef when theres so much sun in Queensland?",
          "And your massive polluting Carmichael mine will do its bit to kill Australia's great barrier reef?",
          "And thousands of jobs will be lost in reef tourism when Adani goes ahead.",
          "The coral reef crisis is actually a crisis of governance."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "A Self Attention Neural Model Overview",
        "text": [
          "Aspect-aware & target-dependent sentence encoding",
          "The simplest case: source- side-only model"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": [
          "figure/image/1175-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Context Encoding Layer",
        "text": [
          "Conditional sentence encoding [Augenstein et al., 2016]: Learn a target-dependent representation for the sentence"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1175-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Aspect Attention Layer",
        "text": [
          "Extract domain aspect words using self-attention weighting",
          "Attention weights on word positions : the importance in carrying the sentence meaning",
          "sentence We need to protect destruction of coral reef",
          "Compatibility function semantic similarity",
          "word position We need to of coral reef"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1175-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Experiments",
        "text": [
          "SemEval 2016 Task 6: Twitter stance detection",
          "Climate Change is Concern",
          "1. Womens Rights: Feminist Movement Legalisation of Abortion",
          "2. American Politics: Hillary Clinton Donald Trump"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1175-Table2-1.png"
        ]
      },
      "8": {
        "title": "Classification performance",
        "text": [
          "Extracted domain aspects benefit cross-target task more",
          "Better performance on both tasks across almost all targets",
          "LA: Legalization of Abortion HC: Hillary Clinton DT: Donald Trump CC: Climate Change is Concern"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1175-Table3-1.png"
        ]
      },
      "9": {
        "title": "Visualisation of attention",
        "text": [
          "The heatmap of the attention weights assigned to some tweet examples",
          "FM: Feminist Movement A: Against",
          "LA: Legalization of Abortion F: Favour",
          "HC: Hillary Clinton Words central to expressing stances",
          "DT: Donald Trump CC: Climate Change is Concern AMP: Australian mining project",
          "are highlighted by our model!"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": [
          "figure/image/1175-Table4-1.png"
        ]
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "A self-attention model which can attend high-level information about the domain for stance generalisation",
          "Domain aspect words are useful to determine the user stance",
          "Incorporation of target divergence into our modelling.",
          "Learning aspects from multiple sources (e.g., environment, community, and economics aspects for mining projects)"
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Cross-Target Stance Classification with Self-Attention Networks"
  },
  "1177": {
    "slides": {
      "0": {
        "title": "Context and objectives",
        "text": [
          "semantic specialization of word embeddings",
          "most approaches following Retrofitting [Faruqui et al., 2015]",
          "a priori set of lexical semantic relations",
          "bring word vectors closer if they are part of similarity relations (synonymy, lexical",
          "move them away from each other if they are part of dissimilarity relations",
          "improving word embeddings for semantic similarity without a priori lexical"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Principles general perspective",
        "text": [
          "equal split of C in 2 parts: C1 and C2",
          "distributional representation of a word w from a corpus C = distrepC(w)",
          "differences between distrepC1(w) and distrepC2(w) are contingent",
          "bringing distrepC1(w) and distrepC2(w) closer more general (and better)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Principles implementation",
        "text": [
          "dense representations: Skip-Gram [Mikolov et al., 2013]",
          "2 sub-corpora 2 representation spaces",
          "require projection in a shared space source of disturbances",
          "instead, 1 corpus but 2 pseudo-senses for each word",
          "arbitrarily split the occurrences of a word into two or more subsets",
          "generation of distributional contexts for pseudo-senses",
          "turning pseudo-sense contexts into dense representations",
          "convergence of pseudo-word representations more general word representation"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Representations of pseudo words",
        "text": [
          "2 successive occurrences of a word 2 different pseudo-senses",
          "3 representations / word",
          "2 pseudo-senses + word itself for each occurrence, generation of contexts for",
          "the current pseudo-sense + word",
          "frequency trick : adding the representation of the word avoiding the impact",
          "of having half the occurrences for each pseudo-sense",
          "A policeman1 was arrested by another policeman2.",
          "Building of dense representations"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Convergence of pseudo word representations",
        "text": [
          "3 representations / word w: v (word); v1, v2 (pseudo-senses)",
          "v, v1 and v2: supposed to be semantically equivalent",
          "application of a semantic specialization method for word embeddings to v,",
          "v1 and v2 with the similarity relations between them",
          "final representation for w: v after its specialization",
          "specialization method: PARAGRAM [Wieting et al., 2015]",
          "comparable to Retrofitting but includes an automatically generated repelling component",
          "for each target word to specialize, selection of a repelling word, either randomly or according to their dissimilarity"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Intrinsic evaluation",
        "text": [
          "1 billion lemmatized words randomly selected from the Annotated English",
          "Gigaword corpus [Napoles et al., 2012] at the level of sentences",
          "word embeddings built with the best parameters from [Baroni et al., 2014]",
          "Spearmans rank correlation between human judgments and similarity",
          "between vectors for 3 representative datasets of word pairs"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Synonym extraction",
        "text": [
          "Gold Standard: WordNets synonyms",
          "for each evaluated noun, retrieval of its 100 nearest neighbors",
          "neighbors ranked from most similar (Cosine) to less similar",
          "Information Retrieval (IR) paradigm",
          "evaluated word query; neighbors docs"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Sentence similarity",
        "text": [
          "Semantic Textual Similarity: STS Benchmark dataset [Cer et al., 2017]",
          "Pearson rank correlation between human judgments and similarity between",
          "sentences for a set of reference sentence pairs",
          "Computation of sentence similarity",
          "strong baseline approach based on word embeddings",
          "sentence representation: elementwise addition of the embeddings of the",
          "plain words of the sentence",
          "use of Pseudofit[max,fus-max-pooling] embeddings, defined for nouns, verbs and",
          "sentence similarity: Cosine between sentence representations"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Conclusions and perspectives",
        "text": [
          "Pseudofit: method for improving word embeddings towards semantic",
          "similarity without external semantic relations",
          "method based on the convergence of several representations built from the",
          "same corpus more general representation",
          "successful intrinsic and extrinsic evaluations for word similarity, synonym",
          "extraction and sentence similarity",
          "transposition of Pseudofit with several corpora link with researches",
          "about meta-embeddings and ensembles of word embeddings"
        ],
        "page_nums": [
          9
        ],
        "images": []
      }
    },
    "paper_title": "Using pseudo-senses for improving the extraction of synonyms from word embeddings"
  },
  "1178": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I Sentence acceptability: the extent to which a sentence is natural to native",
          "I It encompasses semantic, syntactic and pragmatic plausibility and other",
          "non-linguistic factors such as memory limitation.",
          "I Grammaticality, by contrast, is a theoretical concept that measures the syntactic",
          "well-formedness of a sentence.",
          "I Here we are interested in predicting acceptability judgements."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "I We previously explored using unsupervised probabilistic methods to predict",
          "sentence acceptability, and found some success.",
          "I It provides evidence that linguistic knowledge can be represented as a probabilistic",
          "system, addressing foundational questions concerning the categorical nature of grammatical knowledge."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Acceptability in Context",
        "text": [
          "I In previous experiments sentence acceptability was judged (by humans) or",
          "predicted (by models) independently of context.",
          "I Here we extend the research to investigate the impact of context on acceptability.",
          "I Context is defined as the full document environment surrounding a sentence.",
          "I Specifically, we want to understand the influence of context on:",
          "I Human acceptability ratings",
          "I Model prediction of acceptability"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Human Acceptability Ratings in Context",
        "text": [
          "I We perform round-trip translation of sentences (e.g. ENFREN) from English",
          "Wikipedia to generate a set of sentences with varying degrees of acceptability.",
          "I We use MTurk to collect acceptability judgements (rated on a 4-point scale).",
          "I Annotation task was run twice: first without context, and second within the",
          "I We collect multiple ratings for a sentence and take the mean.",
          "I Human acceptability ratings:",
          "I without context = h;",
          "I with context = h+"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "With context h Against Without context h Ratings",
        "text": [
          "mean h per sentence"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1178-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Observations",
        "text": [
          "I Pearsons r = 0.80 between h+ and h.",
          "I Context boosts acceptability ratings most for ill-formed sentences.",
          "I Surprisingly, context reduces acceptability for the most acceptable sentences.",
          "I Context compresses distribution of ratings.",
          "I One-vs-rest correlation, performance of a single annotator against the rest: 0.628",
          "I Low correlation is explained by the compression effect of context - good and bad",
          "sentences are now less separable."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Modelling Acceptability with Unsupervised Models",
        "text": [
          "I lstm: standard LSTM language model",
          "I tdlm: a topically driven language model; language model is driven by a topic",
          "vector automatically learnt on the document context.",
          "I 4 variants at test time:",
          "I Use only the sentence as input: lstm and tdlm;",
          "I Use both sentence and context as input: lstm+ and tdlm+.",
          "I lstm+ incorporates context by feeding it to the LSTM network and taking the",
          "f inal state as the initial state for the current sentence.",
          "I Models trained on 100K English Wikipedia articles (40M tokens)."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Acceptability Measures",
        "text": [
          "I P = probability of the sentence given by a model;",
          "I U = unigram probability of the sentence;",
          "I L = sentence length"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [
          "lstm lstm+ tdlm tdlm+",
          "I Across all models (lstm or tdlm) and human ratings (h or h+), using context at",
          "test time improves performance.",
          "I tdlm consistently outperforms lstm (even tdlm lstm+).",
          "I Lower correlation when predicting sentence acceptability judged with context.",
          "I It suggests h+ ratings are more difficult to predict than h, which corresponds to",
          "the low one-vs-rest human performance."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Summary",
        "text": [
          "I Context positively influences acceptability, particularly for ill-formed sentences.",
          "I But it also has the reverse effect for well-formed sentences.",
          "I Incorporating context (during training or testing) helps modelling acceptability.",
          "I Prediction performance declines when tested on acceptability ratings judged with",
          "context, due to the compression effect of ratings.",
          "I Future work: investigate why context reduces acceptability for highly acceptable"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "The Influence of Context on Sentence Acceptability Judgements"
  },
  "1179": {
    "slides": {
      "0": {
        "title": "Text Simplification",
        "text": [
          "If the trend continues, the researchers say, some of the rarer amphibians could disappear in as few as six years from roughly half the sites where they're now found, while the more common species could see similar declines in 26 years.",
          "If the trend continues, some of the rarer amphibians could be gone from roughly half the sites where they are now found in as few as six years.",
          "I For a specific target audience, e.g. non-native speakers",
          "I For improving NLP tasks, e.g. MT"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Newsela Corpus",
        "text": [
          "I Wikipedia Simple Wikipedia (WSW)",
          "I not professionally simplified",
          "I no defined target audience",
          "I simplified versions target different grade levels in the US",
          "I Automatic sentence-level alignments"
        ],
        "page_nums": [
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Sequence to Sequence TS",
        "text": [
          "I Previous work disregards specificities of different audiences",
          "I Googles multilingual NMT approach [Johnson et al., 2017]:",
          "artificial token to guide the encoder",
          "<2es> How are you? Como estas?",
          "I Our approach: artificial token representing the grade level",
          "of the target sentence"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "3": {
        "title": "TS for Different Grade Levels",
        "text": [
          "dusty handprints stood out against the rust of the fence near Sasabe.",
          "dusty handprints could be seen on the fence near Sasabe.",
          "I More adequate simplifications for audiences with different",
          "I Real world scenario grade level is given by the end-user",
          "I Robust for repetitions of source sentences"
        ],
        "page_nums": [
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "4": {
        "title": "Simplification Operations Information",
        "text": [
          "I Sentence-level alignments coarse-grained operations",
          "I Identical, Elaborate, Split, Merge",
          "< elaboration > dusty handprints stood out against the rust of the fence near Sasabe.",
          "dusty handprints could be seen on the fence near Sasabe.",
          "I Problem: not available at test time",
          "I Simplification operations classification",
          "I four-class classifier Naive Bayes with nine features"
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": []
      },
      "5": {
        "title": "Experiment and results",
        "text": [
          "I NMT approach default OpenNMT"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1179-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Experiments and Results",
        "text": [
          "I NTS (w2v): no artificial tokens",
          "I s2s (baseline): no artificial tokens",
          "I s2s+operation (pred/gold) <elaboration>",
          "I s2s+to-grade+operation (pred/gold) <2-elaboration>",
          "s2s+to-grade s2s+operation (pred) s2s+to-grade+operation (pred)",
          "s2s+operation (gold) s2s+to-grade+operation (gold)"
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "7": {
        "title": "Example",
        "text": [
          "We want to reassure you that we take fire safety very seriously. Grades 6-5 We are doing everything we can to make sure our residents are safe.",
          "Grade 4 We want to make sure we take fire safety very seriously.",
          "We want to make sure people take fire safety very seriously. Grade 3 We are doing everything we can to make sure our people are safe ."
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "8": {
        "title": "Zero shot TS",
        "text": [
          "I Example: from grade level 12 to grade level 4",
          "I No instances of 12-to-4 in the training set"
        ],
        "page_nums": [
          31,
          32,
          33
        ],
        "images": []
      },
      "9": {
        "title": "Conclusions",
        "text": [
          "I TS without target audience results not ideal",
          "I Using a simple artificial token with grade level to guide the",
          "I can improve the quality of TS",
          "I enables target-audience-oriented simplifications",
          "I enables zero-shot TS",
          "I Simplification operation information can help",
          "I improve classifier for the task",
          "I explore multi-task learning"
        ],
        "page_nums": [
          34,
          35,
          36
        ],
        "images": []
      }
    },
    "paper_title": "Learning Simplifications for Specific Target Audiences"
  },
  "1187": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I overall: build a computational model detecting semantic",
          "I in this paper: distinguish metaphoric change from semantic",
          "I How we do it:",
          "I exploit the idea of semantic generality from hypernym",
          "I apply entropy to distributional semantic model",
          "I sample language German",
          "I introduce the first resource for evaluation of models of"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Shortcomings of Related Work",
        "text": [
          "I Previous work includes mainly:",
          "(i) spatial displacement models",
          "(ii) word sense induction models",
          "I quantify the degree of overall change rather than being able",
          "to qualify different types",
          "I do not examine metaphoric change"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Metaphoric Change",
        "text": [
          "I frequent and important type of semantic change",
          "I source and target concept are related by similarity or a",
          "earlier: ... mu ich mich vmbweltzen / vnd kan keinen schlaff in meine augen bringen",
          "... I have to turn around and cannot bring sleep into my eyes.",
          "later: Kinadon wollte den Staat umwalzen ...",
          "Kinadon wanted to revolutionize the state ...",
          "(ii) often results in more abstract or general meanings",
          "assumption: (i) and (ii) imply extension and dispersion in the range of linguistic contexts"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Corpus",
        "text": [
          "I Deutsches Textarchiv (erweitert) (DTA)",
          "I large: provides more than 2447 lemmatized and POS-tagged",
          "texts (with more than 140M tokens)",
          "I covers long time period: late 15th to the early 20th century",
          "I balanced: includes literary and scientific texts as well as"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Word Entropy",
        "text": [
          "I corresponds to entropy of word vector",
          "I is assumed to reflect semantic generality in hypernym",
          "I is given by",
          "where P(ci w) is the occurrence probability of context word ci given target word w",
          "I measures the unpredictability of w s co-occurrences"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation",
        "text": [
          "I no standard test set of semantic or metaphoric change",
          "I we create a small but first test set via annotation (28 items)",
          "I annotators judged 560 context pairs for a metaphorical",
          "(i) preselect 14 changing words",
          "(ii) add 14 stable distractors",
          "(iii) identify a date of change",
          "(iv) extract 20 contexts for each target from before and after date of change",
          "(v) for each word combine contexts between time periods randomly",
          "(vi) annotation of context pairs"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Annotation",
        "text": [
          "I steps to identify metaphoric relation of C1 to C2:",
          "Does any of these hold?:",
          "I C1 is less concrete than C2",
          "I C1 is less human-oriented than C2",
          "I C1 is not related to bodily action in contrast to C2",
          "I C1 is less precise than C2",
          "if yes: does C1 contrast with C2 but can be understood in comparison with it?",
          "I agreement: (Fleiss Kappa) between .40 and",
          "I result is gold ranking of targets for strength of metaphoric"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Annotation Results",
        "text": [
          "target POS type date meaning score",
          "N met thunderstorm thunderstorm, blowup",
          "Table 1 : Sample of test set items ordered by their annotated degree of metaphoric change."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [
          "Table 2 : Correlation () between predicted and gold ranks. Significance is determined with a t-test."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Result Analysis",
        "text": [
          "Von einem Bawren / welcher einem Kalbskopff die Augen austach.",
          "About a Farmer / who cut out the eyes of a calfs head.",
          "Sie wollen ihre Aufgabe nicht nur losen, sondern auch elegant, d. h. rasch losen, um Nebenbuhler auszustechen.",
          "They not only wanted to solve their task, but also elegantly, i.e., solve it fast, in order to excel rivals.",
          "Die Lufft ist hei / vnd gibt viel Blitzen vnd Donnerwetter ...",
          "The air is hot / and there are many lightnings and thunderstorms ..."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Conclusions",
        "text": [
          "I you can annotate semantic change in a corpus (so do it)",
          "I entropy correlates strongly and significantly with degree of",
          "I frequency correlates moderately, but non-significantly on small",
          "I annotation and model are generalizable to different types of"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "German in Flux: Detecting Metaphoric Change via Word Entropy"
  },
  "1188": {
    "slides": {
      "0": {
        "title": "Self disclosure SD",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Self disclosure",
        "text": [],
        "page_nums": [
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "2": {
        "title": "Self disclosure Definition",
        "text": [
          "The verbal expressions by which a person reveals aspects of self to others [Jourard1971b]",
          "Process of making the self known to others [Jourard&Lasakow1958]"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Self disclosure Level",
        "text": [
          "General level (No disclosure)",
          "Medium level (Medium disclosure)",
          "High level (High disclosure)"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Self disclosure G level",
        "text": [
          "General information and ideas",
          "No information about self or someone close to him"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Self disclosure M level",
        "text": [
          "General information about self or someone close to him",
          "Personal events, age, occupation and family members"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Self disclosure H level",
        "text": [
          "Sensitive information about self or someone close to him",
          "Problematic behaviors of self and family members",
          "Physical appearance, health, death, sexual topics"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Self disclosure Relations",
        "text": [
          "Degree of self-disclosure in a relationship depends on the strength of the relationship [Duck2007]",
          "Strategic self-disclosure can strengthen the relationship",
          "Can get social support from others [Derlega et al.1993]",
          "Can cope with stress [Derlega et al.1993,Tamir and Mitchell2012]"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "8": {
        "title": "Limitations in Previous Works",
        "text": [
          "Asking questions to participants",
          "Cons) Biased by participants memory",
          "Analyzing dataset by human",
          "Cons) Cannot apply to large dataset",
          "Experiments held in lab or artificial environment",
          "Cons) Not real/naturally occurring dataset"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "9": {
        "title": "Research Questions",
        "text": [
          "How can we find self-disclosure in large & naturally occurring corpus automatically?",
          "What are relations between self-disclosure and social dynamics in large & naturally occurring corpus?",
          "Q1) Does high self-disclosure lead to longer conversations?",
          "Q2) Is there difference in conversation length patterns over time depending on overall self-disclosure level?",
          "Low SD level dyad"
        ],
        "page_nums": [
          16,
          17,
          58,
          59
        ],
        "images": []
      },
      "10": {
        "title": "Twitter Conversations",
        "text": [
          "5 or more tweets",
          "At least one reply by each user"
        ],
        "page_nums": [
          18,
          22,
          23
        ],
        "images": []
      },
      "11": {
        "title": "Conversation in Twitter",
        "text": [],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "Conversation Topics",
        "text": [
          "Users discuss several topics with others"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "13": {
        "title": "Self disclosure Topic Model",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "14": {
        "title": "Challenges for SD research",
        "text": [
          "Lack of ground-truth dataset of SD level",
          "No tagged dataset for Twitter conversation",
          "No accessible self-disclosure datasets",
          "Lack of study about SD in computational linguistics",
          "Definitions and examples in social psychology",
          "Related word categories in LIWC [Houghton2012]"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "15": {
        "title": "Ground truth Dataset",
        "text": [
          "Ask it to three judges",
          "Work on a web-based platform",
          "Screenshot of annotation web-based platform"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": []
      },
      "16": {
        "title": "Assumptions First person pronouns",
        "text": [
          "First person pronouns are good indicators for self-disclosure",
          "Used in previous research [Joinson et al.2001, Barak et al.2007]",
          "Observed as highly discriminative features between G and M/H in annotated dataset",
          "my I love I have a",
          "I I was is going to",
          "Im I have to go to",
          "but my dad want to go",
          "was go to and I was",
          "Ive my mom going to miss"
        ],
        "page_nums": [
          29,
          30
        ],
        "images": []
      },
      "17": {
        "title": "Assumptions Topics",
        "text": [
          "M and H level have different topics",
          "[General vs Sensitive] information about self or intimate",
          "Self-disclosure related topics by LDA [Bak2012]",
          "Location Time Adult Health Family Profanity",
          "san tonight pants teeth family nigga",
          "live time wear doctor brother lmao",
          "state tomorrow boobs dr sister shit",
          "texas good naked dentist uncle ass",
          "south ill wearing tooth cousin bitch",
          "Can be formalized as topics",
          "General information about self",
          "Ex) name, location, email address, job,",
          "Ex) physical appearance, health, sexuality, death,"
        ],
        "page_nums": [
          31,
          32,
          33
        ],
        "images": []
      },
      "18": {
        "title": "Self Disclosure Topic Model SDTM",
        "text": [
          "Graphical model of Self-Disclosure Topic Model",
          "Classifying G and M/H level",
          "Classifying M and H level",
          "Seed words for each level",
          "Rough figure of how to infer self-disclosure in SDTM"
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42
        ],
        "images": [
          "figure/image/1188-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Maximum Entropy Classifier",
        "text": [
          "Learned from annotated dataset",
          "Works better than others",
          "(C4.5, Naive Bayes, SVM with linear kernel, polynomial kernel and radial basis)",
          "Used to identify aspect and opinions in topic model [Zhao2010]"
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "20": {
        "title": "Seed Words",
        "text": [
          "Seed words are prior knowledge for each level",
          "No seed words (symmetric prior)",
          "Data-driven approach in Twitter conversation",
          "Data-driven approach from external dataset",
          "Use Twitter conversation dataset",
          "Get frequently occurred trigram that begin with I and my",
          "Name Birthday Location Occupation",
          "My name is My birthday is I live in My job is",
          "My last name My birthday party I lived in My new job",
          "My real name My bday is I live on My high school",
          "Use external dataset (Six Billion Secrets)",
          "Users write and share his/her secrets",
          "Extract high ranked word features",
          "Example seed words Example of secret posts in Six Billion Secrets",
          "Physical appearance Health condition Death",
          "chubby addicted dead fat surgery died scar syndrome suicide acne disorder funeral"
        ],
        "page_nums": [
          44,
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "21": {
        "title": "Classifying Performance",
        "text": [
          "Bag of Words + Bigrams + Trigrams features",
          "Seed words and trigrams features",
          "FirstP and SEED feature"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56
        ],
        "images": [
          "figure/image/1188-Figure6-1.png",
          "figure/image/1188-Table5-1.png"
        ]
      },
      "22": {
        "title": "Self disclosure and Social dynamics",
        "text": [],
        "page_nums": [
          57
        ],
        "images": []
      },
      "23": {
        "title": "Results",
        "text": [
          "High ranked topics in each level (G, M, H levels)",
          "Shown by high probability words in each topic",
          "obama league send going better ass",
          "hes win email party sick bitch",
          "romney game ill weekend feel fuck",
          "vote season sent day throat yo",
          "right team dm night cold shit",
          "president cup address dinner hope fucking",
          "Q1) Does high self-disclosure lead to longer conversations?",
          "Ans) Positive relations between initial SD level and changes CL",
          "Q2) Is there difference in CL patterns over time by overall SD level?",
          "Ans) high and mid groups increase CL over time, not low",
          "high groups talk more in a conversation than mid & low groups"
        ],
        "page_nums": [
          60,
          61,
          62
        ],
        "images": [
          "figure/image/1188-Figure6-1.png",
          "figure/image/1188-Figure7-1.png"
        ]
      },
      "24": {
        "title": "Contributions",
        "text": [
          "Made ground-truth Twitter conversation dataset for SD level",
          "Made first annotated Twitter conversations for SD level",
          "Share it with researchers",
          "Suggested novel method for identifying SD level (SDTM)",
          "Our assumptions are reasonable and verified by experiments",
          "SDTM performs better than others",
          "Showed relations between SD & social dynamics",
          "Strategic self-disclosure can strengthen the relationship supported by Twitter conversation dataset and SDTM"
        ],
        "page_nums": [
          63
        ],
        "images": []
      },
      "25": {
        "title": "Future Work",
        "text": [
          "Self-disclosure for a user general messages",
          "Self-disclosure is related with",
          "Online social network usage [Trepte2013]",
          "We can predict users",
          "Loneliness and give a social support",
          "Usage patterns and give a feedback"
        ],
        "page_nums": [
          64
        ],
        "images": []
      }
    },
    "paper_title": "Self-disclosure topic model for classifying and analyzing Twitter conversations"
  },
  "1189": {
    "slides": {
      "0": {
        "title": "Emojis are Ubiquitous",
        "text": [
          "A study found that half of social media text contains emojis",
          "The same parts of the brain are activated as when we look at a real human face",
          "Oxford Dictionaries named Face",
          "With Tears of Joy",
          "Word of the year",
          "http://instagram-engineering.tumblr.com/post/117889701472/emojineering-part-1-machine-learning-for-emoji Emoticons in mind: An event-related potential study by Churches O, Nicholls M, Thiessen M, Kohler M, Keage H (2014)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Goal Emoji based Lexical Resources",
        "text": [
          "Standard word embeddings are not interpretable",
          "Capture relationships among words only",
          "No relationships between emotion and words",
          "Interpretable Word Vectors based on",
          "No lexicon for emoji-emotions yet",
          "Use emoji to derive features/emotions for arbitrary words Emotion Text"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "EmoTag",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Data Acquisition and Lexicons",
        "text": [
          "Collected ~20M tweets over a period of 1 year",
          "100 tweets per day for each of 620 most frequently used emoji",
          "Every single tweet contains at least one emoji",
          "No more than 5 tweets from an individual user",
          "Each tweet contains tweet-id, text, username, date, retweets, favorites, geo-location, emoji, hashtags"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Vector Induction",
        "text": [
          "Word2Vec on Tweets corpus",
          "word word2 .. w ord",
          "em oji em oji em oji3 e moji620",
          "Cosine_Similarity( word2 , emoji3"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Emoji Vector Induction",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Task WASSA Shared Task",
        "text": [
          "EmoInt WASSA Shared Task",
          "Task: given a tweet and an emotion X, determine the intensity or degree of emotion",
          "X felt by the speaker",
          "Predicts the intensity of emotions in Tweets",
          "Intensities are real valued scores in [0,1]",
          "Emotions: classified as anger, fear, joy, sadness",
          "Approach: Supervised Learning Method",
          "Random Forest regressor with 800 trees",
          "Combines many features including the output of a CNN-LSTM network that uses our Emoji Vectors as the word embedding"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "EmoInt Results Including Other Baselines",
        "text": [
          "Methods Anger Fear Joy Sadness Average Dim",
          "Pearson Correlations between Gold Score and Predicted Emotion Score for Tweets"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Evaluating Sentiment",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Sentiment Score Generation",
        "text": [
          "Evaluating Sentiment of Emojis",
          "NRC EmoLex is used to capture sentiment words from EmoTag",
          "Find top K words (based on EmoTag Similarity Scores) for a given emoji",
          "Aggregated similarity scores (K=3) are the final sentiment score for that emoji",
          "Evaluation we use Sentiment of Emojis by Novak et al. as ground truth"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Sentiment Score Evaluation",
        "text": [
          "Comparison of Emoji Sentiment Score",
          "Pearson Correlations of Our Sentiment",
          "Score and Novaks Score"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1189-Table5-1.png",
          "figure/image/1189-Table4-1.png"
        ]
      },
      "11": {
        "title": "Emotion Score Generation",
        "text": [
          "Evaluating Emotion of Emojis",
          "NRC EmoLex is used to capture emotion words from EmoTag",
          "Rank top K words (based on EmoTag SImilarity Scores) for a given emoji",
          "Weighted average scores (K=3) are the final emotion score for a given emoji",
          "Affect Intensity Lexicon from NRC is used to reproduce their score using EmoTag",
          "Rank top K emojis (based on EmoTag SImilarity Scores) for a given word",
          "Arithmetic mean (K=10) is the final emotion scores for that word",
          "Emoji2Emotion is used to predict Emotion Label for Emojis"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Emotion Score Evaluation 1",
        "text": [
          "Snapshot of Proposed Emotion Score for Emojis",
          "Pearson Correlations of Our Score & Gold Score for Affect Intensity Lexicon"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1189-Table7-1.png"
        ]
      },
      "13": {
        "title": "Emotion Score Evaluation 2",
        "text": [
          "A comparison between Emoji2EMotion (E2E) and EmoTag"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion EmoTag",
        "text": [
          "Its a huge and meaningful collection of Emoji centric Tweets",
          "It shows how emojis and words co-occur in social media, including their connection to emotions",
          "It provides a unique way to create interpretable word embedding with the help of emoji",
          "Contact - abu.shoeb@rutgers.edu All resources can be found at http://emoji.nlproc.org"
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "EmoTag -Towards an Emotion-Based Analysis of Emojis"
  },
  "1191": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Attention over multiple source sequences relatively unexplored.",
          "This work proposes two techniques:",
          "Applied to tasks of multimodal translation and automatic post-editing.",
          "No universal method that models explicitly the importance of each input."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Multi Source Sequence to Sequence Learning",
        "text": [
          "Any number of input sequences with possibly different modalities.",
          "Figure 1: Multimodal translation example.",
          "Multimodal translation, automatic post-editing, multi-source machine translation, ..."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Attentive Sequence Learning",
        "text": [
          "In each decoder step i compute distribution over encoder states given the decoder state the decoder gets a context vector to decide about its output eij va tanh(Wasi Uahj)",
          "What about multiple inputs?"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Context Vector Concatenation",
        "text": [
          "Attention over input sequences computed independently.",
          "Combination resolved later on in the network"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Flat Attention Combination",
        "text": [
          "Importance of different inputs reflected in the joint attention distribution.",
          "one source N sources eij va tanh(Wasi Uahj) e(k) tanh(Wasi Ua(k)hj)",
          "ci ijhj ci ij",
          "U(k)a U(k)c project states to a common space",
          "Question: Should U(k)a U(k)c ? (i.e. should the projection parameters be shared?)"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "5": {
        "title": "Hierarchical Attention Combination",
        "text": [
          "Attention distribution is factored by input.",
          "Compute the context vector:",
          "j=1 ij j ij",
          "h , where using the vanilla attention",
          "Compute another attention distribution over the intermediate context vectors c(k)i and get the resulting context vector ci. e(k)i vb tanh(Wbsi U (k)",
          "As in the flat scenario, the context vectors have to be projected to a shared space.",
          "Same question arises should U(k)b U (k) c"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "6": {
        "title": "Experiments and Results",
        "text": [
          "Experiments conducted on multimodal translation (MMT) and automatic post-editing (APE)",
          "In both flat and hierarchical scenarios, we tried both sharing and not sharing the projection matrices.",
          "Additionally, we tried using the sentinel gate [Lu et al., 2016], which enables the decoder to decide whether or not to attend to any encoder.",
          "Experiments conducted using Neural Monkey, code available here:",
          "BLEU METEOR BLEU HTER concat.",
          "Results on the Multi30k dataset and the APE dataset. The column share denotes whether the projection matrix is shared for energies and context vector computation, sent. indicates whether the sentinel vector has been used or not."
        ],
        "page_nums": [
          10,
          11
        ],
        "images": [
          "figure/image/1191-Table1-1.png"
        ]
      },
      "7": {
        "title": "Example",
        "text": [
          "Source: Output with attention:",
          "ein Mannschlaft auf einemgrunenSofain einemgrunenRaum.",
          "A man sleeping in a green room on a couch.",
          "Reference: ein Mann schlaft in einem grunen",
          "Raum auf einem Sofa ."
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1191-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Conclusions",
        "text": [
          "The results show both methods achieve comparable results to the existing approach (concatenation of the context vectors).",
          "Hierarchical attention combination achieved best results on MMT, and is faster to train.",
          "Both methods provide a trivial way to inspect the attention distribution w.r.t. the individual inputs.",
          "Thank you for your attention!"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      }
    },
    "paper_title": "Attention Strategies for Multi-Source Sequence-to-Sequence Learning"
  },
  "1192": {
    "slides": {
      "0": {
        "title": "NMT is all the rage",
        "text": [
          "Driving the current state-of-the-art (Sennrich et al., 2016)",
          "Widely adopted by the industry"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "seq2seq with Attention",
        "text": [],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "2": {
        "title": "syntax was all the rage",
        "text": [
          "The previous state-of-the- art was syntax-based SMT",
          "Can we bring the benefits of syntax into the recent neural systems? From Rico Sennrich, NMT: Breaking the Performance Plateau, 2016",
          "i.e. systems that used linguistic information (usually represented as parse trees)",
          "From Williams, Sennrich, Post & Koehn (2016), Syntax-based Statistical Machine Translation",
          "Beaten by NMT in 2016"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "3": {
        "title": "syntax Constituency Structure",
        "text": [
          "A Constituency (a.k.a Phrase-Structure) grammar defines a set of rewrite rules which describe the structure of the language.",
          "Groups words into larger units (constituents)",
          "Defines a hierarchy between constituents",
          "Draws relations between different constituents (words, phrases, clauses)"
        ],
        "page_nums": [
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "4": {
        "title": "Why Syntax Can Help MT",
        "text": [
          "Hints as to which word sequences belong together",
          "Helps in producing well structured sentences",
          "Allows informed reordering decisions according to the syntactic structure",
          "Encourages long-distance dependencies when selecting translations"
        ],
        "page_nums": [
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "5": {
        "title": "String to Tree Translation",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "6": {
        "title": "Our Approach String to Tree NMT",
        "text": [
          "Main idea: translate a source sentence into a linearized tree of the target sentence",
          "Inspired by works on RNN-based syntactic parsing (Vinyals et. al, 2015, Choe & Charniak, 2016)",
          "Allows using the seq2seq framework as-is"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28
        ],
        "images": []
      },
      "7": {
        "title": "Experimental Details",
        "text": [
          "We used the Nematus toolkit (Sennrich et al. 2017)",
          "Joint BPE segmentation (Sennrich et al. 2016)",
          "For training, we parse the target side using the BLLIP parser",
          "(McClosky, Charniak and Johnson, 2006)",
          "Requires some care about making BPE, Tokenization and Parser work together"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "8": {
        "title": "Experiments Large Scale",
        "text": [
          "German to English, 4.5 million parallel training sentences from WMT16",
          "Train two NMT models using the same setup (same settings as the SOTA neural system in WMT16)",
          "The syntax-aware model performs better in terms of BLEU"
        ],
        "page_nums": [
          31,
          32,
          33,
          34,
          35
        ],
        "images": [
          "figure/image/1192-Table1-1.png"
        ]
      },
      "9": {
        "title": "Experiments Low Resource",
        "text": [
          "The syntax-aware model performs better in terms of",
          "BLEU in all cases (12 comparisons)",
          "Up to 2+ BLEU improvement"
        ],
        "page_nums": [
          36
        ],
        "images": [
          "figure/image/1192-Table1-1.png",
          "figure/image/1192-Table2-1.png"
        ]
      },
      "10": {
        "title": "Accurate Trees",
        "text": [
          "99% of the predicted trees in the development set had valid bracketing",
          "Eye-balling the predicted trees found them well-formed and following"
        ],
        "page_nums": [
          38
        ],
        "images": []
      },
      "11": {
        "title": "Where Syntax Helps Alignments",
        "text": [
          "The attention based model induces soft alignments between the source and the target",
          "The syntax-aware model produced more sensible alignments"
        ],
        "page_nums": [
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47
        ],
        "images": []
      },
      "12": {
        "title": "Attending to Source syntax",
        "text": [
          "We inspected the attention weights during the production of the trees opening brackets",
          "The model consistently attends to the main verb (hatte\") or to structural markers (question marks, hyphens) in the source sentence",
          "Indicates the system implicitly learns source syntax to some",
          "and possibly plans the decoding accordingly"
        ],
        "page_nums": [
          49,
          50,
          51
        ],
        "images": [
          "figure/image/1192-Figure6-1.png"
        ]
      },
      "13": {
        "title": "Where Syntax Helps Structure",
        "text": [],
        "page_nums": [
          52,
          53,
          54
        ],
        "images": [
          "figure/image/1192-Figure1-1.png"
        ]
      },
      "14": {
        "title": "Structure 1 Reordering",
        "text": [
          "German to English translation requires a significant amount of reordering during translation",
          "Quantifying reordering shows that the syntax-aware system performs more reordering during the training process",
          "We would like to interpret the increased reordering from a syntactic perspective",
          "We extract GHKM rules (Galley et al., 2004) from the dev set using the predicted trees and attention-induced alignments",
          "The most common rules reveal linguistically sensible transformations, like moving the verb from the end of a German constituent to the beginning of the matching English one",
          "More examples in the paper"
        ],
        "page_nums": [
          56,
          57,
          58,
          59,
          60,
          61,
          62
        ],
        "images": [
          "figure/image/1192-Figure1-1.png",
          "figure/image/1192-Figure4-1.png"
        ]
      },
      "15": {
        "title": "Structure II Relative Constructions",
        "text": [
          "A common linguistic structure is relative constructions, i.e. The XXX which",
          "YYY, A XXX whose YYY",
          "The words that connect the clauses in such constructions are called relative pronouns, i.e. who, which, whom",
          "The syntax-aware system produced more relative pronouns due to the syntactic context",
          "Guangzhou, das in Deutschland auch Kanton genannt wird",
          "Guangzhou, which is also known as Canton in Germany",
          "Guangzhou, also known in Germany, is one of",
          "Guangzhou, which is also known as the canton in Germany,",
          "Zugleich droht der stark von internationalen Firmen abhangigen",
          "At the same time, the image of the region, which is heavily reliant on international companies",
          "At the same time, the region's heavily dependent region",
          "At the same time, the region, which is heavily dependent on international firms"
        ],
        "page_nums": [
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75
        ],
        "images": [
          "figure/image/1192-Figure5-1.png"
        ]
      },
      "16": {
        "title": "Human Evaluation",
        "text": [
          "We performed a small-scale human-evaluation using mechanical turk on the first 500 sentences in newstest 2015",
          "Two turkers per sentence",
          "The syntax-aware translations had an advantage over the baseline",
          "2bpe better neutral 2tree better"
        ],
        "page_nums": [
          77,
          78,
          79
        ],
        "images": []
      },
      "17": {
        "title": "Conclusions",
        "text": [
          "Neural machine translation can clearly benefit from target-side syntax",
          "Other recent work include:",
          "A general approach - can be easily incorporated into other neural language generation tasks like summarization, image caption generation",
          "Larger picture: dont throw away your linguistics! Neural systems can also leverage symbolic linguistic information"
        ],
        "page_nums": [
          81,
          82,
          83,
          84,
          85
        ],
        "images": []
      }
    },
    "paper_title": "Towards String-to-Tree Neural Machine Translation"
  },
  "1193": {
    "slides": {
      "0": {
        "title": "STARTING FROM THE END spoiler",
        "text": [
          "the Indo-European phylogenetic tree",
          "(the ground truth) phylogenetic tree reconstructed from monolingual English texts translated from",
          "French Italian Spanish Portuguese Latvian Lithuanian Polish Slovak Czech Slovenian Bulgarian",
          "Swedish Danish Romanian Lithuanian Portuguese Czech Slovak Bulgarian Latvian Polish Slovenian"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Background the features of translationese",
        "text": [
          "Translators (almost) always tried to remain invisible",
          "Translations have unique characteristics that set them apart from originals",
          "Universals (simplification, standardization, explicitation)",
          "Interference (the fingerprints of a source language on the translation product)",
          "Languages closer to each other are likely to share more",
          "features in the target language of translation",
          "The distance between languages is retained and can be recovered when assessed through these features in"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Dataset",
        "text": [
          "Europarl (the proceedings of the European Parliament)",
          "Members are allowed to speak in any of the EU languages",
          "All parliament speeches were translated from the original language into other EU languages using English as a pivot",
          "Direct translations into English, indirect translations into all other languages",
          "We explore indirect translations into French in this work",
          "We focus on 17 source languages, grouped into 3 language families",
          "Germanic, Romance, and Balto-Slavic"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Reconstruction of language trees",
        "text": [
          "POS-trigrams, reflecting shallow syntactic structures",
          "(strongly associated with interference)",
          "Function words, reflecting grammar (associated with interference)",
          "Cohesive markers (associated with a translation universals)",
          "AGGLOMERATIVE (HIERARCHICAL) CLUSTERING OF FEATURE VECTORS",
          "Using the variance minimization algorithm (Ward, 1963)",
          "Phylogenetic language trees generated with translated text",
          "Romanian Lithuanian Portuguese Czech Slovak Bulgarian Latvian Polish Slovenian",
          "Slovak Lithuanian Latvian Bulgarian Romanian Slovenian Portuguese Polish Czech",
          "ENGLISH translations FRENCH translations"
        ],
        "page_nums": [
          4,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Identification of translationese and its source language",
        "text": [
          "MATRIX source-language classification (POS-trigrams)"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1193-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Evaluation methodology",
        "text": [
          "MEASURE SIMILARITY TO THE GOLD STANDARD",
          "(topological) similarity assessing similarity based on both structure and branching length",
          "Adaptation of the L2-norm to leaf-pair distance",
          "Suitable for both weighted and unweighted evaluation",
          "g t the gold tree a tree subject to evaluation",
          "C Dt(li, lj) distance between two leaves in a tree D"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "6": {
        "title": "Evaluation results",
        "text": [
          "DISTANCE OF A RECONSTRUCTED TREE FROM THE GOLD STANDARD",
          "(using various feature sets)",
          "HTD VA ON D E",
          "feature AVG STD AVG STD feature AVG STD AVG STD",
          "POS-trigrams + FW POS-trigrams + FW",
          "Function words Function words",
          "Cohesive markers Cohesive markers",
          "trees built from English translations are systematically closer to the gold standard than trees built from translations into French (done via a third language) the quality of trees increases for feature sets associated with interference the worst tree is generated using cohesive markers",
          "FOUD IN RAN N: R RUCTNG P NSLAT"
        ],
        "page_nums": [
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Analysis",
        "text": [
          "Indefinite (a, an) and definite (the)",
          "With clitic s (the guests room)",
          "With a prepositional phrase containing of (the room of the guest)",
          "With noun compounds (guest room)",
          "Verbs that combine with a particle to create a new meaning (MWEs), e.g., turn down, get over",
          "With the auxiliary verbs have (present) or be (progressive), e.g., have done, was going",
          "FREQUENCIES reflecting various linguistic phenomena in English translations",
          "define articles (per 10 tokens) of' constructions (per 25 tokens) verb-particle (per 250 tokens) perfect (per 100 tokens) progressive (per 500 tokens)"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Summary",
        "text": [
          "Translation does not distorts the original text randomly",
          "A phylogenetic language tree can be reconstructed from monolingual texts translated from various languages",
          "Features associated with interference (POS-ngrams, FWs) yield more accurate phylogenetic language trees",
          "Translations impact the evolution of languages",
          "It is estimated that for certain languages up to 30% of published texts are mediated through translations (Pym and Chrupaa, 2005)",
          "Are translations likely to play a role in language change?"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Starting from the end",
        "text": [
          "phylogenetic tree reconstructed from monolingual English texts translated from",
          "17 IE languages phylogenetic tree reconstructed from monolingual French texts translated indirectly from 17 IE languages via English pivot",
          "Danish Romanian Lithuanian Portuguese Czech Slovak Bulgarian Latvian Polish Slovenian",
          "English Slovak Lithuanian Latvian Bulgarian Romanian Slovenian Portuguese Polish Czech"
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "Found in Translation: Reconstructing Phylogenetic Language Trees from Translations"
  },
  "1195": {
    "slides": {
      "0": {
        "title": "Motivation Model senses instead of only words",
        "text": [
          "He withdrew money from the bank."
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Related Work",
        "text": [
          "Learn sense embeddings exploiting text corpora only (Huang et al.",
          "and Jurafsky, EMNLP 2015...). Easily adaptable to new domains.",
          "Senses not interpretable (+change from model to model)",
          "Knowledge from resources cannot be easily exploited",
          "Senses (esp. not frequent ones) not easy to discriminate",
          "Model senses as defined on a sense inventory.",
          "Usually obtained as a postprocessing of word embeddings",
          "Infrequent senses not accurately captured",
          "Knowledge-based sense embeddings (Our approach)"
        ],
        "page_nums": [
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "Idea",
        "text": [
          "A word is the surface form of a sense: we can exploit this intrinsic relationship for jointly training word and sense embeddings.",
          "Updating the representation of associated senses interchangeably. the word and its"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "Methodology",
        "text": [
          "Given as input a corpus and a semantic network:",
          "1. Use a semantic network to link to each word its associated senses in context.",
          "He withdrew money from the bank.",
          "2. Use a neural network where the update of word and sense embeddings is linked, exploiting virtual connections.",
          "He withdrew from the bank",
          "In this way it is possible to learn word and sense/synset embeddings jointly on a single training."
        ],
        "page_nums": [
          11,
          12,
          16,
          17,
          18,
          19,
          20,
          21,
          22
        ],
        "images": []
      },
      "4": {
        "title": "Methodology Linking words and senses in context",
        "text": [
          "He withdrew money from the bank",
          "take out financial institution",
          "Graph-based representation of the sentence using semantic networks"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": []
      },
      "5": {
        "title": "Methodology Joint training of words and sense embeddings",
        "text": [
          "Once each word is connected to its set of senses in context, it is possible to modify standard word embedding architectures to take into account this information.",
          "In this work we explore the CBOW architecture of Word2Vec",
          "Other neural network architectures could be explored as well",
          "(Skip-gram also included in the code)."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "6": {
        "title": "Full architecture of W2V Mikolov et al 2013",
        "text": [
          "Words and associated senses used both as input and output."
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Full architecture of SW2V this work",
        "text": [
          "Words and associated senses used both as input and output."
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Output layer alternatives only words",
        "text": [
          "The architecture does not try to predict senses. No loss contribution from them."
        ],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Output layer alternatives only senses",
        "text": [
          "The architecture does not try to predict words. No loss contribution from them."
        ],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "10": {
        "title": "Input layer alternatives only words",
        "text": [
          "Senses are not included in the input layer. Only words contribute to the hidden state.",
          "This way, during backpropagation sense embeddings do not receive any gradient.",
          "During backpropagation, sense embeddings will receive the same gradient of the word they are associated with."
        ],
        "page_nums": [
          28,
          29
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "11": {
        "title": "Input layer alternatives only senses",
        "text": [
          "Words are not included in the input layer. Only senses contribute to the hidden state.",
          "This way, during backpropagation word embeddings do not receive any gradient.",
          "During backpropagation, their embeddings will receive the same gradient of their associated senses."
        ],
        "page_nums": [
          30,
          31
        ],
        "images": [
          "figure/image/1195-Figure1-1.png"
        ]
      },
      "12": {
        "title": "Analysis Model configurations",
        "text": [
          "We used word similarity for analyzing the performance of sense embeddings on each of the nine configurations.",
          "- Best configuration -",
          "Input layer: Only senses",
          "Output layer: Both words and senses",
          "Why? (Intuition) Co-occurrence information gets duplicated if both words and senses are included in the input layer."
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "13": {
        "title": "Evaluation Experimental setting",
        "text": [
          "Best configuration used in all experiments",
          "Semantic networks used: WordNet and BabelNet",
          "Corpora used: UMBC and Wikipedia",
          "Word and sense interconnectivity (qualitative)"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "14": {
        "title": "Evaluation Comparison systems",
        "text": [
          "AutoExtend (Rothe and Schutze, 2015)",
          "SensEmbed (Iacobacci et al. 2015)",
          "NASARI (Camacho-Collados et al. 2016)",
          "Retrofitting (Faruqui et al. 2015)"
        ],
        "page_nums": [
          34,
          35,
          36,
          37
        ],
        "images": []
      },
      "15": {
        "title": "Evaluation Word and sense interconnectivity",
        "text": [
          "How coherent is the shared vector space of word and sense embeddings?",
          "Intuition: the Most Frequent Sense (MFS) should be close to the word embedding -> Reasonably strong MFS baseline for WSD",
          "Evaluation on two WSD datasets using the embeddings as a",
          "MFS baseline (closest sense embedding to its associated word embedding is selected)."
        ],
        "page_nums": [
          38,
          39
        ],
        "images": []
      },
      "16": {
        "title": "Word and sense interconnectivity Example I",
        "text": [
          "Ten closest word and sense embeddings to the sense company (military unit)"
        ],
        "page_nums": [
          40
        ],
        "images": [
          "figure/image/1195-Table6-1.png"
        ]
      },
      "17": {
        "title": "Word and sense interconnectivity Example II",
        "text": [
          "Ten closest word and sense embeddings to the sense school (group of fish)"
        ],
        "page_nums": [
          41
        ],
        "images": [
          "figure/image/1195-Table6-1.png"
        ]
      },
      "18": {
        "title": "Evaluation Word similarity",
        "text": [
          "All models using Wikipedia corpus (Pearson correlation)",
          "All models using UMBC corpus (Pearson correlation)"
        ],
        "page_nums": [
          42,
          43,
          44
        ],
        "images": []
      },
      "19": {
        "title": "Evaluation Sense clustering",
        "text": [
          "Some sense inventories make a fine-grained distinction between senses, which can be harmful on downstream applications (Hovy",
          "Evaluation datasets (Dandala et al. 2013): Highly ambiguous words from past SemEval competitions.",
          "Embedding Words and Senses Together via Joint Knowledge-Enhanced training Massimiliano Mancini, Jose Camacho-Collados, Ignacio lacobacci and Roberto Navigli"
        ],
        "page_nums": [
          45,
          46
        ],
        "images": []
      },
      "20": {
        "title": "Conclusion",
        "text": [
          "W e presented SW2V: a neural architecture for jointly learning word and sense embeddings in the same vector space using text corpora and knowled ge obtained from semantic networks.",
          "Fu ture wor k:",
          "Exploitin g our model for other linked representations such as multilingual or Image-to-Text embeddings.",
          "Word Sense Disambiguation and Entity Linking.",
          "- Integrating our embeddings into downstream NLP applications, following the lines of Pilehvar et al. (ACL 2017)."
        ],
        "page_nums": [
          47,
          48,
          49
        ],
        "images": []
      }
    },
    "paper_title": "Embedding Words and Senses Together via Joint Knowledge-Enhanced Training"
  },
  "1200": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Theres always a bone to pick on MT evaluation metrics (Babych and Hartley, 2004; Callison-",
          "Appeared calm when he was taken to the American plane , which will to",
          "Reference: Orejuela appeared calm as he was led to the American plane which will take him to Miami , Florida .",
          "which will he was , when taken Appeared calm to the American plane to",
          "lower BLEU not necessarily worse translation",
          "But is higher BLEU = better translation true?",
          "Callison-Burch et al. (2006) meta-evaluation on 2005 NIST MT Eval"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Bleu",
        "text": [
          "Penalize if the length of the Count the proportion of n-grams that hypothesis is too long appears in hypothesis and reference"
        ],
        "page_nums": [
          5,
          7
        ],
        "images": []
      },
      "2": {
        "title": "BLEU in practice",
        "text": [
          "Penalize if the length of the Count the proportion of n-grams that hypothesis is too long appears in hypothesis and reference"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "3": {
        "title": "Ribes",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "System Level HUMAN",
        "text": [],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "5": {
        "title": "Segment Level HUMAN",
        "text": [
          "Baseline: #Hyp 7 #Base",
          "Source/Reference English Gloss: Tmelt (DSC) = 8 9. 9 C; Teryst (DSC) = 7 C (measured using DSC at 5 C / min) re"
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "6": {
        "title": "Experiment Setup",
        "text": [],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1200-Table1-1.png"
        ]
      },
      "7": {
        "title": "Results",
        "text": [
          "higher BLEU = better translation is not always true."
        ],
        "page_nums": [
          16,
          17
        ],
        "images": [
          "figure/image/1200-Table2-1.png"
        ]
      },
      "8": {
        "title": "Segment level Meta Evaluation",
        "text": [
          "Difference in Segment level RIBES (Hypothesis - Baseline RIBES)",
          "An interactive graph can be found here: https://plot.ly/171/~alvations/ (Hint: click on the bubbles here on the interactive graph",
          "Generally, -BLEU or RIBES from baseline means worse translations",
          "Note that the grey bubbles are the same as the previous graph",
          "Its more prominent here since there are many more instances of +BLEU with 0 HUMAN score than negative HUMAN score",
          "With regards to positive HUMAN scores, it fits the conventional wisdom that",
          "lower BLEU/RIBES = worse translation",
          "Higher BLEU/RIBES = better translation",
          "When it comes to negative HUMAN scores, it is inconsistent with the conventional wisdom"
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
        ],
        "images": [
          "figure/image/1200-Figure2-1.png",
          "figure/image/1200-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "Higher BLEU and RIBES doesnt necessary mean better translations",
          "At segment level, >+30 BLEU might not be reliable",
          "Possible reasons for BLEU/RIBES to not correlate with human judgments includes:",
          "Minor lexical differences -> huge difference in n-gram precision",
          "Minor MT evaluation metric differences not reflecting major translation inadequacy"
        ],
        "page_nums": [
          31
        ],
        "images": []
      }
    },
    "paper_title": "An Awkward Disparity between BLEU / RIBES Scores and Human Judgements in Machine Translation"
  },
  "1201": {
    "slides": {
      "0": {
        "title": "Introduction What is BioASQ",
        "text": [
          "I BioASQ is a series of challenges on biomedical semantic",
          "indexing and question answering (QA).",
          "I Participants are required to semantically index content from",
          "large-scale biomedical resources (e.g. MEDLINE) and/or",
          "I to assemble data from multiple heterogeneous sources (e.g.",
          "scientific articles, knowledge bases, databases)",
          "I to compose informative answers to biomedical natural",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Presentation of the challenge Tasks",
        "text": [
          "Task A: Hierarchical text classification",
          "I Organizers distribute new unclassified MEDLINE articles.",
          "I Participants have 21 hours to assign MeSH terms to the articles.",
          "I Evaluation based on annotations of MEDLINE curators.",
          "1st batch 2nd batch 3rd batch End of Task5a",
          "ry ry ry rch rch rch rch rch ril ril br br br Ma Ma Ma Ma ua ua ua Ma y 0 Ma y 0 Ma Ap y 1 Ma Ap Ap ril y 2 Ma Fe Fe Fe",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017",
          "Task B: IR, QA, summarization",
          "I Organizers distribute English biomedical questions.",
          "I Participants have 24 hours to provide: relevant articles,",
          "snippets, concepts, triples, exact answers, ideal answers.",
          "I Evaluation: both automatic (GMAP, MRR, Rouge etc.) and",
          "manual (by biomedical experts).",
          "1st batch 2nd batch 3rd batch 4th batch 5th batch",
          "rch rch Ma Ma rch Ma Ma Ap Ap ril ril Ap Ap ril ril rch y 3 Ma y 4 Ma",
          "Phase A Phase B"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Presentation of the challenge New task",
        "text": [
          "Task C: Funding Information Extraction",
          "I Organizers distribute PMC full-text articles.",
          "I Participants have 48 hours to extract: grant-IDs, funding",
          "agencies, full grants (i.e. the combination of a grant-ID and the corresponding funding agency).",
          "I Evaluation based on annotations of MEDLINE curators.",
          "Dry Run Test Batch",
          "ril Ap ril Ap",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Presentation of the challenge BioASQ ecosystem",
        "text": [
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Presentation of the challenge Per task",
        "text": [
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Task 5A Hierarchiacal text classification",
        "text": [
          "Week Batch 1 Batch 2 Batch 3",
          "The numbers in parentheses are the annotated articles for each test dataset.",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Task 5A System approaches",
        "text": [
          "I Feature Extraction: Representing each abstract",
          "I tf-idf of words and bi-words",
          "I doc2vec embeddings of paragraphs",
          "I Concept Matching: Finding relevant MeSH labels",
          "I k-NN between article-vector representations",
          "I Linear SVM binary classifiers for each MESH label",
          "I Recurrent Neural Networks for sequence-to-sequence prediction",
          "I UIMA-ConceptMapper and MeSHLabeler tools for boosting NER",
          "I Latend Dirichlet Allocation and Labeled LDA utilizing topics found",
          "I Ensemble methodologies and stacking",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Task 5A Evaluation Measures",
        "text": [
          "Flat measures Hierarchical measures",
          "I Example Based Precision (EBP)",
          "I Example Based Recall (EBR)",
          "I Example Based F-Measure (EBF)",
          "I Micro Precision/Recall/F-Measure (MiP,MIR,MiF)",
          "I Hierarchical Precision (HiP)",
          "I Hierarchical Recall (HiR)",
          "I Hierarchical F-Measure (HiF)",
          "I Lowest Common Ancestor Precision",
          "I Lowest Common Ancestor Recall (LCA-R)",
          "I Lowest Common Ancestor F-measure (LCA-F)",
          "A. Kosmopoulos, I. Partalas, E. Gaussier, G. Paliouras and I. Androutsopoulos: Evaluation Measures for Hierarchical Classification: a unified view and novel approaches. Data Mining and Knowledge Discovery, 29:820-865, 2015.",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Task 5A results Evaluation",
        "text": [
          "I Systems ranked using MiF (flat) and LCA-F (hierarchical).",
          "I Results, in all batches and for both measures :",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Task 5A results",
        "text": [
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Task 5B Statistics on datasets",
        "text": [
          "Batch Size of documents # of snippets",
          "The numbers for the documents and snippets refer to averages",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Task 5B Training Dataset Insights",
        "text": [
          "Average of items per question",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017",
          "I Broad terms (e.g. proteins, syndromes)",
          "I More specific terms (e.g. cancer, heart, thyroid)",
          "I Number of questions related to cancer vs thyroid per year",
          "I The numbers on top of the bars denote the contributing experts"
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": []
      },
      "12": {
        "title": "Task 5B Evaluation measures",
        "text": [
          "I Evaluating Phase A (IR)",
          "Retrieved items Unordered retrieval measures Ordered retrieval measures",
          "Mean Precision, Recall, F-Measure MAP, GMAP snippets",
          "I Evaluating the exact answers for Phase B (Traditional QA)",
          "Question type Participant response Evaluation measures",
          "yes/no yes or no Accuracy",
          "factoid up to 5 entity names strict and lenient accuracy, MRR",
          "list a list of entity names Mean Precision, Recall, F-measure",
          "I Evaluating the ideal answers for Phase B (Query-focused Summarization)",
          "any paragraph-sized text ROUGE-2, ROUGE-SU4, manual scores*",
          "(Readability, Recall, Precision, Repetition)",
          "*with the help of BioASQ Assessment tool.",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Task 5B System approaches",
        "text": [
          "I Question analysis: Rule-based, regular expressions, ClearNLP,",
          "Semantic role labeling (SRL), Stanford Parser, tf-idf, SVD, word embeddings.",
          "I Query expansion: MetaMap, UMLS, sequential dependence",
          "I Document retrieval: BM25, UMLS, SAP HANA database, Bag",
          "of Concepts (BoC), statistical language model.",
          "I Snippet selection: Agglomerative Clustering, Maximum",
          "Marginal Relevance, tf-idf, word embeddings.",
          "I Exact answer generation: Standford POS, PubTator, FastQA,",
          "SQuAD, Semantic role labeling (SRL), word frequencies, word embeddings, dictionaries, UMLS.",
          "I Ideal answer generation: Deep learning (LSTM, CNN, RNN),",
          "neural nets, Support Vector Regression.",
          "I Answer ranking: Word frequencies.",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Task 5B Results",
        "text": [
          "I Our experts are currently assessing systems responses",
          "I The results will be announced in autumn",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Task 5C Statistics on datasets",
        "text": [
          "I unique grant IDs",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017",
          "Number of articles per agency in training dataset"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "16": {
        "title": "Task 5C Evaluation measures",
        "text": [
          "I A subset of the Grant IDs and Agencies mentioned in full text",
          "are available in ground truth data Micro-Recall",
          "I Each Grant ID (or lone Agency) must exist verbatim in the text",
          "I Different scores for each subtask:",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "Task 5C System approaches",
        "text": [
          "I Grant Support Sentences: Identifying sentences containing",
          "I Features: tf-idf of n-grams",
          "I Techniques: SVM and Naive Bayes for scoring, specific XML fields",
          "I Grant Information Extraction: Detecing Grant-IDs and",
          "I Manually crafted Regular Expressions",
          "I Sequential Learning Models, such as Conditional Random Fields,",
          "Hidden Markov Models, Max Entropy Models",
          "I Ensemble of classifiers for pairing Grant-IDs to Agencies",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "18": {
        "title": "Task 5C Results",
        "text": [
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "19": {
        "title": "Challenge Participation Overall",
        "text": [
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions and Prespectives",
        "text": [
          "I BioASQ will run in 2018.",
          "I Continuous development of benchmark datasets.",
          "G. Paliouras. Results of the fifth edition of the BioASQ Challenge, 4th of August 2017",
          "Oracle for continuous testing"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": []
      }
    },
    "paper_title": "Results of the fifth edition of the BioASQ Challenge"
  },
  "1202": {
    "slides": {
      "0": {
        "title": "Simultaneous Interpretation SI",
        "text": [
          "Translation of the spoken word in real time"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Computer Assisted Interpretation CAI",
        "text": [
          "How do we ensure",
          "maximum utility with minimum distraction?"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Estimating Interpreter Performance",
        "text": [
          "Dont offer help when they dont need it!",
          "Estimate how well the interpreter is doing"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Quality Estimation",
        "text": [
          "We already do this in Machine Translation!",
          "Can we apply it to Simultaneous Interpretation?",
          "QuEst++ is an existing framework for QE (Specia et al., 2015)"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "4": {
        "title": "Method",
        "text": [
          "QuEst++ baseline features Apply",
          "Features tailored to interpretation (METEOR)",
          "Test using 10-fold cross-validation"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "5": {
        "title": "Baseline Features",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "6": {
        "title": "Features of interpretation",
        "text": [
          "SOURCE: Will the Parliament grant President Dilma Rousseff, on the very first occasion after her groundbaking groundbreaking election and for no sound formal reason, the kind of debate that we usually reserve for people like Mugabe? So, I ask you to remove Brazil from the agenda of the urgencies. (48 words)",
          "INTERP: Ehm il Parlamento... dopo le elezioni... darem- dar spazio a un dibattito sul ehm sul caso per esempio del presidente Mugabe invece di mettere il Brasile allordine del giorno? (27 words)",
          "GLOSS: Ehm the Parliament... after the elections... well gi- will give way to a",
          "debate on the ehm on the case for example of President Mugabe instead of putting Brazil on the agenda?"
        ],
        "page_nums": [
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "7": {
        "title": "SI Model Features",
        "text": [
          "Non-specific words - is the interpreter avoiding specific terminology?",
          "Cognates/loan words - if a word is almost identical in both languages an interpreter shouldnt struggle with it (unless its a false friend!)"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [],
        "page_nums": [
          29,
          30
        ],
        "images": []
      },
      "9": {
        "title": "Analysis",
        "text": [
          "SOURCE: Will the Parliament grant President Dilma Rousseff, on the very first occasion after her groundbaking groundbreaking election and for no sound formal reason, the kind of debate that we usually reserve for people like Mugabe? So, I ask you to remove Brazil from the agenda of the urgencies. (48 words)",
          "INTERP: Ehm il Parlamento... dopo le elezioni... darem- dar spazio a un dibattito sul ehm sul caso per esempio del presidente Mugabe invece di mettere il Brasile allordine del giorno? (27 words)"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "10": {
        "title": "Future Work",
        "text": [
          "Evaluation Metric - finding a metric better aligned with the uniqueness of strategies in SI",
          "Live system integration - streamlining the system to provide instantaneous feedback",
          "ASR - evaluate the model on ASR output",
          "Speech model - enhance the model using prosodic speech features"
        ],
        "page_nums": [
          32
        ],
        "images": []
      }
    },
    "paper_title": "Automatic Estimation of Simultaneous Interpreter Performance"
  },
  "1203": {
    "slides": {
      "0": {
        "title": "Reviews in recommender system",
        "text": [
          "Wr We We W Great purchase. Works fast and has all the applications ...",
          "Wok We We Great unit! By Thinking Independently on April 12, 2018 Style: Tablet Verified Purchase This is a great tablet! Setup was super easy, | had it going in short order. I've been using it a lot with no issues. Battery life is great, lasts a few hours with constant use. | don't know how long the battery would last in standby mode because | haven't left it unused for more than a few hours.",
          "So much more reliable so far than my laptop which was more expensive. Great purchase. Works fast and has all the applications | might need for general work, school and play.",
          "The Samsung Galaxy Tab E 16 GB WiFi works fine for me, it does everything | want it to do. I'm happy with my purchase and would buy it again. 5 people found this helpful Helpful | | Not Helpful | > Comment Report abuse",
          "| Helpful | | Not Helpfut > Comment Report abuse",
          "The screen is nice and bright for reading. I've watched a number of videos, they look fine both visually, and audio. | don't know the frame rate and the other technical specs off the top of my head, but | am well pleased with the display and the audio performance.",
          "| have run some apps from the App Store and it runs fine for those. I'm not a big app person, | primarily use it for email, web browsing, and to stream video and music and I've been very happy with it, and have had no issues. I've paired it with a small Bluetooth speaker and it worked fine with no issues also."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Help user write reviews in an easier way",
        "text": [
          "Expand and rewrite phrases",
          "Estimate reactions and provide suggestions"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Incorporate information and knowledge",
        "text": [
          "User and item attribute",
          "Dong et al. EACL 2017. Learning to Generate Product Reviews from",
          "Tang et al. Arxiv 2016. Context-aware Natural Language Generation with Recurrent Neural Networks.",
          "Short phrases (user input)",
          "Service vendor seller supplier reply refund",
          "Price price value overall dependable reliable",
          "Screen screen touchscreen browse display scrolling",
          "Interaction Case case cover briefcase portfolio",
          "A1 AK A1 AK Drive drive disk copying copied fat32",
          "U1 I1 Table 1 Representative words of aspects"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Proposed method",
        "text": [
          "Sequence attention Attribute attention Aspect attention",
          "Attribute latent factor Aspect-aware factor",
          "Aspect preference score Embedding layers easy to use",
          "Sequence Encoder Attribute Encoder Aspect Encoder",
          "A1 A2 Ak <str> the display is beautiful and easy to",
          "Pv(display) + Pdisplay in Ak(Ak) Pw(display)",
          "Projection layer Aspect bias"
        ],
        "page_nums": [
          5,
          6,
          7
        ],
        "images": [
          "figure/image/1203-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Experiment setting",
        "text": [
          "Vocabulary of 30,000 tokens",
          "Much sparser than previous work",
          "Use teacher-forcing and masked cross-entropy loss"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Automatic evluation metrics",
        "text": [
          "Table 2 Comparison of different algorithms"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Examples of generated review",
        "text": [
          "Summary easy to use and nice standard apps",
          "Real review the display is beautiful and the tablet i s very easy to use. it comes with some really nice standard apps .",
          "Attr2Seq i bought this for my wife s new ipad air . it fits perfectly and looks great . the only thing i do nt like is that the cover is a little too small for the ipad air .",
          "ExpansionNet i love this tablet . it is fast and easy to use . i have no complaints . i would recommend this tablet to anyone .",
          "+title i love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it .",
          "+attribute & aspect i love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has a micro sd slot . i have not tried the tablet app yet b ut i do nt have any problems with it . i am very happy with this tablet ."
        ],
        "page_nums": [
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "7": {
        "title": "Broader aspect coverage in generation",
        "text": [
          "# aspect plus one, if the review covers the representative words from that aspect",
          "Our model covers more real reviews aspects",
          "# aspects in generated review also covered in real review"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Conclusion and future work",
        "text": [
          "Build ExpansionNet to incorporate short phrases, product title and aspect preference in review generation",
          "Show aspect embedding and aspect extraction can be used in personalized text generation",
          "Combine text expansion task with text rewriting techniques",
          "Generate longer text such as product recommendation articles"
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations"
  },
  "1204": {
    "slides": {
      "0": {
        "title": "SNLI Bowman et al 2015",
        "text": [
          "A large scale dataset for NLI (Natural Language Inference;",
          "Recognizing Textual Entailment [Dagan et al., 2013])",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 2 / 13",
          "Premises are image captions, hypotheses generated by crowdsourcing workers:",
          "Street performer is doing his act for kids",
          "A person performing for children on the street ENTAILMENT",
          "A juggler entertaining a group of children on the street NEUTRAL",
          "A magician performing for an audience in a nightclub CONTRADICTION"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "1": {
        "title": "Neural NLI Models",
        "text": [
          "End-to-end, either sentence-encoding or attention-based",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 3 / 13",
          "Premise Hypothesis Premise Hypothesis",
          "Lexical knowledge: only from pre-trained word embeddings",
          "As opposed to using resources like WordNet",
          "SOTA exceeds human performance..."
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "2": {
        "title": "New Test Set",
        "text": [
          "We constructed a new test set to answer this question",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 5 / 13",
          "Premise: sentences from the SNLI training set",
          "Replacing a single term w in the premise with a related term w w is in the SNLI vocabulary and in pre-trained embeddings",
          "Crowdsourcing labels (mostly contradictions!)",
          "The man is holding a saxophone The man is holding an electric guitar",
          "A little girl is very sad A little girl is very unhappy",
          "A couple drinking wine A couple drinking champagne"
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "3": {
        "title": "Evaluation Setting",
        "text": [
          "Residual-Stacked-Encoder [Nie and Bansal, 2017]",
          "ESIM (Enhanced Sequential Inference Model) [Chen et al., 2017]",
          "Decomposable Attention [Parikh et al., 2016]",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 6 / 13",
          "Train on SNLI training set, test on the original & new test set",
          "In the paper: enhancing with additional existing datasets"
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "4": {
        "title": "Results Can neural NLI models recognize lexical inferences",
        "text": [
          "Decomposable Attention ESIM Residual-Stacked-Encoder",
          "Dramatic drop in performance across models.",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 7 / 13"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "5": {
        "title": "Sanity Check Performance of WordNet informed Models",
        "text": [
          "The test set is solvable using WordNet.",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 8 / 13"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "6": {
        "title": "Analysis 1 Word Similarity",
        "text": [
          "Models err on contradicting word-pairs with similar embeddings",
          "A man starts his day in India A man starts his day in Malaysia",
          "Cosine Similarity of (word, replacement) Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 10 / 13",
          "Especially for fixed word embeddings"
        ],
        "page_nums": [
          29,
          30
        ],
        "images": []
      },
      "7": {
        "title": "Analysis 2 Frequency in Training",
        "text": [
          "Tuning embeddings may associate specific (word, replacement) pairs to a label, e.g. (man, woman) contradiction",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 11 / 13",
          "Accuracy increases with frequency in training set",
          "Frequency of (word, replacement) pairs in contradiction training examples"
        ],
        "page_nums": [
          31,
          32
        ],
        "images": []
      },
      "8": {
        "title": "Recap",
        "text": [
          "New NLI test set that evaluates systems ability to make inferences that require very simple lexical knowledge",
          "Max Glockner, Vered Shwartz and Yoav Goldberg Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 12 / 13",
          "SOTA systems perform poorly on the test set",
          "Systems are limited in their generalization ability",
          "May be used as a complementary test set to assess the lexical inference abilities of NLI systems"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37
        ],
        "images": []
      }
    },
    "paper_title": "Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
  },
  "1205": {
    "slides": {
      "0": {
        "title": "Why is my classifier getting worse",
        "text": [
          "The data distribution has changed",
          "Is there anything systematic about how it changes?",
          "Is there anything we can do to adapt to temporal changes?",
          "Subtle shifts in topic distribution"
        ],
        "page_nums": [
          2,
          5,
          11
        ],
        "images": []
      },
      "1": {
        "title": "Experiments",
        "text": [
          "Two types of time periods:",
          "Logistic regression, n-gram features",
          "Six datasets, each grouped into 4-6 time periods"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": [
          "figure/image/1205-Table1-1.png",
          "figure/image/1205-Table3-1.png",
          "figure/image/1205-Table2-1.png"
        ]
      },
      "2": {
        "title": "RQ1 How does performance vary",
        "text": [
          "Train and test on each time period",
          "Measure how performance drops when the test period is different",
          "Balanced so each time period has same # of documents",
          "Yelp reviews are getting more informative over time?",
          "This type of analysis can reveal characteristics of corpus",
          "Unanswered: why does performance vary?"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "RQ2 Can we adapt to temporal variations",
        "text": [
          "Address this as a domain adaptation problem",
          "Treat explicitly-defined time periods as domains",
          "Feature augmentation method from Daume III (2007)",
          "Domain-specific copies of the feature set:",
          "General Jan-Mar Apr-Jun Jul-Sep Oct-Dec",
          "Straightforward to apply to seasonal features:",
          "How to use in non-seasonal settings?",
          "Separately weigh domain-specific features",
          "During training: weigh domain-specific features differently",
          "Can also combine with seasonal domains",
          "3 copies of each feature (general, year-specific, season-specific)",
          "Simulating performance on future data:",
          "Train in initial time periods",
          "Tune on second-to-last period",
          "Test on final time period",
          "Simple-to-implement adaptation can make classifiers more",
          "Suggestion: tune hyperparameters on heldout data from",
          "the chronological end of your corpus (cf. cross-validation)",
          "Can lead to better performance on future data"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22
        ],
        "images": [
          "figure/image/1205-Table3-1.png",
          "figure/image/1205-Table2-1.png"
        ]
      }
    },
    "paper_title": "Examining Temporality in Document Classification"
  },
  "1206": {
    "slides": {
      "0": {
        "title": "Parsing by Local Decisions",
        "text": [
          "The cat took a nap",
          "(S (NP The cat (VP"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Non local Consequences",
        "text": [
          "NP NP VP NP",
          "The cat took a nap . The cat took a nap .",
          "(S (NP The cat",
          "Prediction (S (NP (VP"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Dynamic Oracle Training",
        "text": [
          "Explore at training time. Supervise each state with an expert policy.",
          "True Parse (S (NP The cat",
          "Prediction (S (NP (VP The",
          "Oracle (NP The The cat",
          "choose log to maximize achievable F1 (typically)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Dynamic Oracles Help",
        "text": [
          "Expert Policies / Dynamic Oracles",
          "PTB Constituency Parsing F1",
          "Coavoux and Crabbe, 2016"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Reinforcement Learning Helps in other tasks",
        "text": [
          "CCG several, machine parsing including translation dependency parsing"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Policy Gradient Training",
        "text": [
          "Minimize expected sequence-level cost:",
          "NP NP NP NP NP NP NP NP",
          "The man had an idea. The man had an idea.",
          "(compute by sampling) addresses loss mismatch compute in the same way as for the",
          "Input, The cat took a nap.",
          "S S-INV S S",
          "k candidates, NP VP VP ADJP VP",
          "The cat took a nap . The cat took a nap . The cat took a nap . The cat took a nap ."
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "6": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Setup",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "English PTB F1",
        "text": [
          "Static oracle Policy gradient Dynamic oracle"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Training Efficiency",
        "text": [
          "PTB learning curves for the Top-Down parser",
          "Development F1 static oracle dynamic oracle policy gradient"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "French Treebank F1",
        "text": [
          "Static oracle Policy gradient Dynamic oracle"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Chinese Penn Treebank v51 F1",
        "text": [
          "Static oracle Policy gradient Dynamic oracle"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "Local decisions can have non-local consequences",
          "How to deal with the issues caused by local decisions?",
          "Dynamic oracles: efficient, model specific",
          "Policy gradient: slower to train, but general purpose"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "For Comparison A Novel Oracle for RNNG",
        "text": [
          "(S (NP The man (VP had",
          "1. Close current constituent if its a true constituent",
          "or it could never be a true constituent.",
          "(S (VP (NP The man",
          "2. Otherwise, open the outermost unopened true constituent at this position.",
          "3. Otherwise, shift the next word."
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Policy Gradient as a Proxy for Dynamic Oracles in Constituency Parsing"
  },
  "1211": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "I Phrase-based decoding without further constraints is NP-hard",
          "I Proof: reduction from the travelling salesman problem",
          "I Hard distortion limit is commonly imposed in PBMT systems",
          "I Is phrase-based decoding with a fixed distortion limit NP-hard",
          "A related problem: bandwidth-limited TSP",
          "This work: a new decoding algorithm",
          "I Process the source word from left-to-right",
          "I Maintain multiple tapes in the target side",
          "I Run time: O(nd!lhd+1) n: source sentence length",
          "d : distortion limit"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Overview of the proposed decoding algorithm",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "I Process the source word from left-to-right",
          "I Maintain multiple tapes in the target side"
        ],
        "page_nums": [
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Phrase based decoding problem",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "I Segment the German sentence into non-overlapping phrases",
          "this must our concern also be",
          "I Find an English translation for each German phrase",
          "this must also be our concern",
          "I Reorder the English phrases to get a better English sentence",
          "Derivation: complete translation with phrase mappings"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "3": {
        "title": "Score a derivation",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "score(<s> this must also be our concern </s>)",
          "I Phrase translation score: score(das muss, this must) +",
          "I Language model score:"
        ],
        "page_nums": [
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "4": {
        "title": "Fixed distortion limit distortion distance",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "this must also be our concern"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "5": {
        "title": "Target side left to right the usual decoding algorithm",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "unsere sorge das muss gleichermaen sein",
          "this must also be our concern"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "6": {
        "title": "Target side left to right dynamic programming algorithm",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "unsere sorge das muss gleichermaen sein",
          "this must also be our concern"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28
        ],
        "images": []
      },
      "7": {
        "title": "Source side left to right the proposed algorithm",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "this must our concern",
          "this must also our concern",
          "this must also be our concern"
        ],
        "page_nums": [
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "8": {
        "title": "Source side left to right dynamic programming state",
        "text": [
          "das muss unsere sorge gleichermaen sein",
          "this must our concern",
          "this must also our concern",
          "this must also be our concern"
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "9": {
        "title": "The number of DP states fixed distortion limit d",
        "text": [
          "State: j . . . r} r : number of tapes",
          "I j n} n: source sentence length O(n)",
          "I s, t: source word indices",
          "I ws ,wt : translated target words",
          "j d j j",
          "Next phrase starts at Translated source words",
          "s, t can only occurs here",
          "I r is bounded by d"
        ],
        "page_nums": [
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
        ],
        "images": []
      },
      "10": {
        "title": "Extend a sub derivation by four operations",
        "text": [
          "Consider a new phrase starting at source position j O(l)",
          "I New segment r+1 p",
          "I Append i i p",
          "I Prepend i p, i",
          "I Concatenate i i p, i",
          "das muss unsere sorge gleichermaen sein",
          "Sub-derivation: this must) our concern)(5, also",
          "this must our concern also",
          "this must also our concern",
          "Sub-derivation: this must)(5, also)(3, our concern)"
        ],
        "page_nums": [
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "11": {
        "title": "Bound on running time Ond lhd1",
        "text": [
          "I n: source sentence length",
          "I d : distortion limit",
          "I l : bound on the number of phrases starting at any position",
          "I h: bound on the maximum number of target translations for"
        ],
        "page_nums": [
          65
        ],
        "images": []
      },
      "12": {
        "title": "Summary",
        "text": [
          "Problem: Phrase-based decoding with a fixed distortion limit",
          "I A new decoding algorithm with O(nd!lhd+1) time",
          "I Operate from left to right on the source side",
          "I Maintain multiple tapes on the target side"
        ],
        "page_nums": [
          66
        ],
        "images": []
      },
      "13": {
        "title": "Follow up paper in EMNLP discussing experimental results",
        "text": [
          "To appear in EMNLP 2017:",
          "Source-side left-to-right or target-side left-to-right?",
          "An empirical comparison of two phrase-based decoding algorithms",
          "I Beam search with a trigram language model",
          "I Constraints on the number of tapes",
          "I Achieve similar efficiency and accuracy as Moses"
        ],
        "page_nums": [
          67
        ],
        "images": []
      },
      "14": {
        "title": "Future work",
        "text": [
          "Finite state transducer (FST) formulation",
          "I An NMT system using this kind of approach?",
          "I Replace the attention model by absolving source words strictly"
        ],
        "page_nums": [
          68
        ],
        "images": []
      }
    },
    "paper_title": "A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit"
  },
  "1212": {
    "slides": {
      "0": {
        "title": "A Realistic Language Learning Scenario",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Speech Model",
        "text": [
          "Project to the joint semantic space",
          "Attention: weighted sum of last RHN layer units",
          "RHN RHN: Recurrent Highway",
          "Grounded speech perception MFCC"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "2": {
        "title": "Chrupala et al ACL2017",
        "text": [
          "Representation of language in a model of visually grounded speech signal",
          "Using hidden layer activations in a set of auxiliary tasks",
          "Predicting utterance length and content, measuring representational similarity and disambiguation of homonyms",
          "Encodings of form and meaning emerge and evolve in hidden layers of stacked RNNs processing grounded speech"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Current Study",
        "text": [
          "Questions: how is phonology encoded in",
          "MFCC features extracted from speech signal?",
          "activations of the layers of the model?",
          "Data: Synthetically Spoken COCO dataset",
          "Phoneme decoding and clustering"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Phoneme Decoding",
        "text": [
          "Identifying phonemes from speech signal/activation patterns: supervised classification of aligned phonemes",
          "Speech signal was aligned with phonemic transcription using Gentle toolkit (based on Kaldi, Povey et al., 2011)",
          "CoNLL 2017 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.",
          "MFCC features and activations) are stored in a",
          "are the num- ered from the activations at recurrent layers 1 and",
          "2, and the accuracy decreases thereafter. This sug- ber of times steps and the dimensionality, respec- tively, for each representation",
          "r. Given the align-",
          "ment of each phoneme token to the underlying au- dio, we then infer the slice of the representation gests that the bottom recurrent layers of the model specialize in recognizing this type of low-level phonological",
          "It is notable however that even the last recurrent layer encodes phoneme identity to a substantial degree. matrix corresponding to it.",
          "In this section we report on four experiments which we designed to elucidate to what extent in- formation about phonology is represented in the activations of the layers of the COCO Speech model. In Section we quantify how easy it is to decode phoneme identity from activations. In",
          "Section we determine phoneme discriminabil- ity in a controlled task with minimal pair stimuli.",
          "Section shows how the phoneme inventory is organized in the activation space of the model. Fi- nally, in Section we tackle the general issue of the representation of phonological form versus",
          "MFCC Conv Rec1 Rec2 Rec3 Rec4 Rec5 Representation",
          "meaning with the controlled task of synonym dis- crimination."
        ],
        "page_nums": [
          9,
          10
        ],
        "images": [
          "figure/image/1212-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Phoneme Discrimination",
        "text": [
          "ABX task (Schatz et al., 2013): discriminate minimal pairs; is",
          "X closer to A or to B?",
          "A, B and X are CV syllables",
          "(A,B) and (B,X) are minimum pairs, but (A,X) are not",
          "CoNLL 2017 Submission ***. Confidential Review Cop",
          "Table 3: Accuracy of choosing the correct target in an ABX task using different representations."
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Phoneme Discrimination by Class",
        "text": [
          "The task is most challenging when the target (B) and distractor (A) belong to the same phoneme class",
          "CoNLL 2017 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.",
          "The first layer Convs,d,z is a one-dimensional con- volution of size s which subsamples the input with stride z, and projects it to d dimensions. It is fol- lowed by RHNk,L which consists of k residual- ized recurrent layers. Specifically these are Recur- rent Highway Network layers (Zilly et al., which are closely related to GRU networks, with the crucial difference that they increase the depth of the transform between timesteps; this is the re- currence depth L. The output of the final recurrent layer is passed through an attention-like lookback operator Attn which takes a weighted average of the activations across time steps. Finally, both ut- terance and image projections are L2-normalized.",
          "See Section for details of the model configura- tion.",
          "Table 2: CO tecture.",
          "Experimental data and setup",
          "The phoneme activations in each layer are calcu- are as follows size 64, strid layers with 5 attention Mul den units, A",
          "trained on Im and are avera of each imag lated as the activations averaged over the duration of the phoneme token in the input. The average in- parameters is architecture o",
          "put vectors are similarly",
          "model. vectors averaged over the time course of the ar- ticulation of the phoneme token. When we need Synthet",
          "The task is most challenging when the target (B) and to represent a phoneme type we do so by averag- distractor (A) belong to the same phoneme class ing the vectors of all its instances in the valida- tion set. Table shows the phoneme inventory we",
          "Vowels i I U u",
          "e E @ A OI O o",
          "The Speech C thetically Spo",
          "dataset (Lin e thesized for th high-quality s",
          "aI 2 A aU",
          "j o l w Forced m n N p b t d k g f v T D s z S Z h",
          "Table Phonemes of General American English.",
          "We aligned th phonemic tra which in tur",
          "glish to transc f inds the opti work with; this is also the inventory used by Gen-",
          "Table 3: Accuracy of choosing the correct target in an ABX task using different representations.",
          "context invariance in phoneme discrimination by evaluating how often the model recognises X as mfcc conv rec1 rec2 rec3 rec4 rec5 Representation the syllable closer to B than to A. Class affricate approximant fricative nasal plosive vowel We used a list of all attested consonant-vowel"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": [
          "figure/image/1212-Figure2-1.png",
          "figure/image/1212-Table1-1.png"
        ]
      },
      "7": {
        "title": "Organization of Phonemes",
        "text": [
          "CoNLL 2017 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.",
          "Agglomerative hierarchical clustering of phoneme activation vectors from the first hidden layer:"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1212-Figure5-1.png"
        ]
      },
      "8": {
        "title": "Synonym Discrimination",
        "text": [
          "Distinguishing between synonym pairs in the same context:",
          "A girl looking at a photo",
          "A girl looking at a picture",
          "Synonyms were selected using WordNet synsets:",
          "The pair have the same POS tag and are interchangeable",
          "The pair clearly differ in form (not donut/doughnut)",
          "The more frequent token in a pair constitutes less than 95% of the occurrences.",
          "CoNLL Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.",
          "Figure 4: Hierarchical clustering of phoneme activation vectors on the first hidden layer",
          "in a multilayer recurrent neural network tr grounded speech signal. We believe it i tant to carry out multiple analyses usin",
          "mfcc conv rec1 rec2 rec3 rec4 rec5 emb methodology: Representation any single experiment ma",
          "Pair leading as it depends on analytical choice",
          "the type of supervised model used for d cut.slice sidewalk.pavement make.prepare rock.stone the algorithm used for clustering, or the s someone.person store.shop photo.picture purse.bag metric for representational similarity ana picture.image assortment.variety kid.child spot.place photograph.picture pier.dock the extent that more than one experiment slice.piece direction.way the same conclusion our confidence in the bicycle.bike carpet.rug photograph.photo ity of the insights gained will be increase bun.roll couch.sofa large.big tv.television vegetable.veggie The main high-level result of our st small.little",
          "mfcc conv rec1 rec2 rec3 rec4 rec5 emb Representation Pair cut.slice make.prepare someone.person photo.picture picture.image kid.child photograph.picture slice.piece",
          "f irms earlier work: encoding of sema comes stronger in higher layer, while enc rock.stone store.shop Figure Synonym form discrimination becomes weaker. This error general rates patt purse.bag assortment.variety be expected as the objective of the utter spot.place representation and synonym pair. pier.dock direction.way coder is to transform the input acoustic"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "Phoneme representations are most salient in lower layers",
          "Large amount of phonological information persists up to the top recurrent layer",
          "The attention layer filters out and significantly attenuates encoding of phonology and makes utterance embeddings more invariant to synonymy"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Encoding of phonology in a recurrent neural model of grounded speech"
  },
  "1214": {
    "slides": {
      "0": {
        "title": "Introduction Keyphrase",
        "text": [
          "o Short texts highly summarize the",
          "significant content of a document",
          "o Knowledge mining (concept)",
          "o Information retrieval (indexing term)",
          "o Provided by authors/editors",
          "This work aims to",
          "o obtain keyphrases from scientific papers"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Background Previous Approaches",
        "text": [
          "Recommender systems play an important role in reducing the negative impact of information overload on those websites where u sers have the possibility of voting for their preferences on items",
          "Candidates must be acquired from the",
          "1. Find candidates (noun phrase etc.) source text.",
          "recommender systems, important role, negative impact, information overload, websites, users, possibility of voting, preferences, items",
          "Only able to predict phrases appear in text",
          "2. Scoring Highly rely on manual fea ture design Dataset % Present % Absent",
          "simple featur es can hard ly represen t Inspec",
          "Krapivin deep semant ics NUS 3. Rank and return Top K neither flexib le nor scala ble SemEval recommender systems (0.733) information overload (0.524) preferences (0.197) websites (0.132), negative impact (0.057)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Motivation Revisit Keyphrase Generation",
        "text": [
          "How do humans assign keyphrases?",
          "Understand and get contextual information",
          "Summarize and write down the most",
          "Get hints from text, copy certain phrases",
          "Can machine simulate this process? topic tracking",
          "Memory Recurrent Neural Networks [Step 1-3] multilingual",
          "Copy Mechanism [Step 4] Write Keyphrase text mining"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Methodology Recurrent Neural Networks",
        "text": [
          "Memory Context tracking Prob=0.027",
          "Encoder-decoder model (Seq2seq) latent Prob=0.101 dirichlet allocation Prob=0.01",
          "o One and one mining text Prob=0.014 Prob=0.093 o Gated recurrent units (GRU) cell analysis Prob=0.003",
          "o Decoder generates multiple short sequences by beam search",
          "Memory Context topic tracking Prob=0.027",
          "Encoder-decoder model (Seq2seq) latent dirichlet allocatioPnrob=",
          "o One and one text mining Prob=0.014",
          "o Rank them and return the top K results",
          "unk unk unk topic tracking",
          "Problem of RNN model RNN Dictionary",
          "Keep everything in memory 0k words",
          "Only train vectors for top 50k high-frequency words topic",
          "Long-tail words are replaced with an unknown symbol <unk> text o Unable to predict long-tail words",
          "o Many keyphrases contain long-tail words (2%) multiple",
          "language multilingual 50k short-tail words 250k long-tail words"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Methodology Copy Mechanism",
        "text": [
          "unk unk unk topic tracking",
          "native language hypothesis CopyRNN Model RNN Dictionary",
          "o Copy words from input text 0k words",
          "o Locate the words of interest by contextual topic",
          "o Copy corresponding part to output text multiple",
          "o Enhance the RNN with extractive ability language multilingual 50k short-tail words 250k long-tail words"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Experiment Dataset",
        "text": [
          "All data are scientific papers in Computer Science domain",
          "Collected from Elsevier, ACM Digital Library, Web of Science etc.",
          "o # (Unique word)",
          "Four commonly used datasets, only use abstract text",
          "Overlapping papers are removed from training dataset",
          "Dataset # Paper # All (Avg) # Present # Absent % Absent"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "6": {
        "title": "Experiment Experiment Setup",
        "text": [
          "Process ground-truth and predicted phrases with Porter stemmer",
          "Macro-average of precision, recall and F-measure @5,@10",
          "o Compare to previous studies: Tf-Idf, TextRank, SingleRank, ExpandRank, KEA, Maui",
          "o No baseline comparison",
          "Transfer to news dataset"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Result Task 1 Predict Present Keyphrase",
        "text": [
          "Dataset Inspec Krapivin NUS SemEval KP20k",
          "Naive RNN model fails to compete with baseline models",
          "CopyRNN models outperform baseline models and RNN significantly. Copy mechanism can capture key",
          "information in source text."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Result Task 3 Transfer to News Articles",
        "text": [
          "So far training and testing are only about scientific papers",
          "What if transfer it to a completely unseen domain",
          "o Does model learn any universal feature?",
          "Test the CopyRNN on DUC-2001",
          "o 308 news articles and 2,488 keyphrases",
          "o CopyRNN recalls 766 keyphrases. 14.3% contain out-of-vocabulary words",
          "o Many names of persons and places are correctly predicted."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion Future Work",
        "text": [
          "Keyphrase generation study based on deep learning methods",
          "o First work concerns absent keyphrase prediction",
          "o RNN + Copy mechanism",
          "o Able to learn cross-domain features",
          "Better model on capturing contextual information",
          "Long documents, length & diversity penalties on output sequences"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Deep Keyphrase Generation"
  },
  "1217": {
    "slides": {
      "0": {
        "title": "The Word Embedding Pipeline",
        "text": [
          "U nlabeled corpus c or pus Unlabeled c orpus corpus",
          "W2V GloVe Polyglot FastText",
          "Unlabeled Supervised task corpus",
          "U nlabeled corpus c or pus c orpus",
          "Penn TreeBank SemEval OntoNotes Univ. Dependencies",
          "Tagging Parsing Sentiment NER"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Assumed Pattern",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "2": {
        "title": "Actual Pattern",
        "text": [
          "Affects supervised tas ks",
          "Our method - compositional"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "3": {
        "title": "Sources of OOVs",
        "text": [
          "Names Chalabi has increasingly marginalized within Iraq, ...",
          "Domain-specific jargon Important species (...) include shrimp, (...) and some varieties of flatfish.",
          "Foreign words This term was first used in German (Hochrenaissance),",
          "Without George Martin the Beatles would have been just another",
          "untalented band as Oasis.",
          "What if Google morphed into GoogleOS?",
          "Well have four bands, and Big D is cookin. lots of fun and great prizes.",
          "Typos and other errors",
          "I dislike this urban society and I want to leave this whole enviroment."
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "Common OOV handling techniques",
        "text": [
          "task corpus U nlabeled c o rpus Unlabeled c orpus corpus",
          "One UNK to rule them all",
          "Trained with embeddings (stochastic unking)",
          "Add subword model during WE training",
          "What if we dont have access to the original corpus? (e.g. FastText) OOV"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "5": {
        "title": "Char2Tag",
        "text": [
          "Unlabeled U nlabeled corpus Supervised task corpus U nlabeled c o rpus Unlabeled c orpus corpus",
          "Add subword layer to supervised task",
          "OOVs benefit from co-trained character model",
          "Requires large supervised training set for efficient transfer to test set OOVs"
        ],
        "page_nums": [
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "6": {
        "title": "Enter MIMICK",
        "text": [
          "(No context) Unlabeled U nlabeled corpus Supervised task corpus U nlabeled c o rpus Unlabeled c orpus Subword units as inputs corpus",
          "What data do we have, post-unlabeled corpus?",
          "Orthography (the way words are spelled)",
          "Use the former as training objective, latter as input",
          "Pre-trained vectors as target",
          "No need to access original unlabeled corpus"
        ],
        "page_nums": [
          32,
          33,
          34,
          35,
          36,
          37
        ],
        "images": []
      },
      "7": {
        "title": "MIMICK Training",
        "text": [
          "m a k e"
        ],
        "page_nums": [
          38,
          39,
          40,
          41,
          42,
          43
        ],
        "images": [
          "figure/image/1217-Figure1-1.png"
        ]
      },
      "8": {
        "title": "MIMICK Inference",
        "text": [
          "b l a h"
        ],
        "page_nums": [
          44
        ],
        "images": [
          "figure/image/1217-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Observation Nearest Neighbors",
        "text": [
          "English (OOV Nearest in-vocab words)",
          "MCT AWS, OTA, APT, PDM",
          "pesky euphoric, disagreeable, horrid, ghastly",
          "lawnmower tradesman, bookmaker, postman, hairdresser",
          "geometric (m.pl., nontrad. spelling) geometric (m.pl.)",
          "Surface form Syntactic properties Semantics"
        ],
        "page_nums": [
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
        ],
        "images": []
      },
      "10": {
        "title": "Intrinsic Evaluation RareWords",
        "text": [
          "RareWords similarity task: morphologically-complex, mostly unseen words",
          "Foreign words Rare(-ish) morphological derivations Nonce words Nonstandard orthography Typos and other errors"
        ],
        "page_nums": [
          56,
          57,
          58,
          59
        ],
        "images": []
      },
      "11": {
        "title": "Extrinsic Evaluation POS Attribute Tagging",
        "text": [
          "UD is annotated for POS and morphosyntactic attributes",
          "Cze: his stated goals",
          "osoby v pokrocilem veku",
          "people of advanced age",
          "Rare(-ish) morphological derivations Nonce words Nonstandard orthography Typos and other errors",
          "DT NN VBZ VBG POS",
          "the cat is sitting",
          "Attributes - same as POS layer",
          "Negative effect on POS",
          "Backward LSTM Micro F1"
        ],
        "page_nums": [
          60,
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "12": {
        "title": "Language Selection",
        "text": [
          "13 Indo-European (7 different branches)",
          "10 from 8 non-IE branches",
          "MRLs (e.g. Slavic languages)",
          "Relatively free word order"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78
        ],
        "images": []
      },
      "13": {
        "title": "Language Selection contd",
        "text": [
          "7 in non-alphabetic scripts",
          "Ideographic (Chinese) - ~12K characters",
          "Hebrew, Arabic - no casing, no vowels, syntactic fusion",
          "Vietnamese - tokens are non-compositional syllables",
          "OOV rate (UD against Polyglot vocabulary)"
        ],
        "page_nums": [
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
        ],
        "images": []
      },
      "14": {
        "title": "Evaluated Systems",
        "text": [
          "NONE: Polyglots default UNK embedding",
          "the flatf ish is sitt ing",
          "CHAR2TAG - additional RNN layer",
          "Char- LSTM Char- LSTM Char- LSTM Char- LSTM",
          "BOTH: MIMICK + CHAR2TAG"
        ],
        "page_nums": [
          90,
          91,
          92,
          93,
          94
        ],
        "images": []
      },
      "15": {
        "title": "Results Full Data",
        "text": [
          "POS tags (accuracy) Morpho. Attributes (micro F1)"
        ],
        "page_nums": [
          95
        ],
        "images": []
      },
      "16": {
        "title": "Results 5000 training tokens",
        "text": [
          "POS tags (accuracy) Morpho. Attributes (micro F1)"
        ],
        "page_nums": [
          96
        ],
        "images": []
      },
      "17": {
        "title": "Results Language Types 5000 tokens",
        "text": [
          "Slavic languages POS Agglutinative languages morpho. attribute F1"
        ],
        "page_nums": [
          97,
          98
        ],
        "images": []
      },
      "18": {
        "title": "Results Chinese",
        "text": [
          "POS tags (accuracy) Morpho. Attributes (micro F1)"
        ],
        "page_nums": [
          99
        ],
        "images": []
      },
      "19": {
        "title": "A Word Model from our Sponsor",
        "text": [
          "Our extrinsic results are on tagging",
          "Please consider us for all your WE use cases!",
          "IE! Code & models:",
          "Code compatible with w2v, Polyglot, FastText",
          "Models for Polyglot also on github",
          "<1MB each, dynet format",
          "Learn all OOVs in advance and add to param table, or",
          "Load into memory and infer on-line"
        ],
        "page_nums": [
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [
          "MIMICK: an OOV-extension embedding processing step for downstream tasks",
          "Compositional model complementing distributional artifact",
          "Powerful technique for low-resource scenarios",
          "Sore spots and Future Work",
          "Vietnamese - syllabic vocabulary",
          "Hebrew and Arabic - nontrivial tokenization, no case",
          "Try other subword levels (morphemes, phonemes, bytes)",
          "Improve morphosyntactic attribute tagging scheme"
        ],
        "page_nums": [
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124
        ],
        "images": []
      }
    },
    "paper_title": "Mimicking Word Embeddings using Subword RNNs"
  },
  "1219": {
    "slides": {
      "0": {
        "title": "Emotion Models Plutchiks Wheel",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "1": {
        "title": "Previous Work and State of the Art",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Name Data Size Domain",
          "Sentiment Strength tweets tweets tweets tweets tweets tweets tweets tweets",
          "Electoral Tweets descriptions sentences blogs headlines tweets tweets",
          "No manually annotated multi-label emotion corpus of Tweets available.",
          "(References are in the paper)",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "2": {
        "title": "Task Description and Research Question",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "(Additional annotation layers available)",
          "Whats the inter-annotator agreement?",
          "Which annotation layers interact?",
          "How well is it possible to computationally estimate such annotations?",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Annotation Process",
        "text": [
          "Annotation of SemEval 2016 Twitter Corpus",
          "Stance and sentiment annotations exist",
          "Six annotators finished their annotations",
          "Minimum number of annotations per Tweet is three",
          "2776 Tweets annotated by four annotators",
          "Undergraduate students of media-informatics",
          "German native speakers, college-level knowledge of English",
          "Training of annotators based on another set of Tweets",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Label Counts",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Seldom that all annotators agree",
          "Some classes are more difficult (Anticipation, Disgust, Fear,",
          "Sadness, Surprise) than others (Anger, Joy, Trust)",
          "Low number of majority vote annotations",
          "Low quality of annotation combination?",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Inter annotator Agreement",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Range of pairwise agreement between all annotation pairs",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "6": {
        "title": "Difficult Examples 1",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Anger Anticipation Disgust Fear Joy Sadness Surprise Trust",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Difficult Examples 2",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "2 pretty sisters are dancing with cancered kid",
          "Anger Anticipation Disgust Fear Joy Sadness Surprise Trust",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Cooccurrences of Labels t0",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Anger Anticipation Disgust Fear Joy Sadness Surprise Trust Positive Negative Neutral In Favor Against None",
          "Many cooccurrences as expected (pos w/ pos, neg w/ neg)Positive Anger Negative Joy Positive Disgust",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Examples",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Lets take back our country! Whos with me? No more",
          "Why criticise religions? If a path is not your own. Dont be pretentious. And get down from your throne.",
          "Global Warming! Global Warming! Global Warming! Oh wait, its summer.",
          "I love the smell of Hillary in the morning. It smells like",
          "#WeNeedFeminism because #NoMeansNo it doesnt mean yes, it doesnt mean try harder!",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Models Experimental Setting",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "175 dimensional LSTM layer, 0.5 dropout rate",
          "50 dimensional dense layer",
          "Convolution of window size 2,3,4",
          "Pooling of length 2",
          "(Twitter specific embeddings are used.) University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "11": {
        "title": "Models for t00",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "Annotation Aggregation Methods BiLSTM",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th, 2017"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Performance vs Frequency",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion and Summary",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Multi-label emotion annotation is a challenging task",
          "We publish all annotations",
          "Aggregation by disjunction leads to annotation which can better be modeled computationally",
          "Linear and neural models perform similarly well",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Future Work",
        "text": [
          "Motivation Annotation Process and Analysis Baseline Models",
          "Develop models which take into account label interactions explicitly",
          "Deeper linguistic analysis of annotation properties",
          "University of Stuttgart Schuff, Barnes, Mohme, Pado, Klinger September 8th"
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus"
  },
  "1220": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Traditional SMT and Neural MT",
        "text": [
          "Traditional SMT Traditional SMT + Neural Network Neural MT",
          "Target Sentence Target Sentence Target Sentence Target Sentence",
          "a few year ago recently more recently"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Neural Machine Translation",
        "text": [
          "Proposed by Google and Montreal University in 2014",
          "Input sentence is encoded into fix-length vector, and from the vector translated sentence is produced. Thats all",
          "Various extensions is emerged",
          "LSTM, GRU, Bidirectional Encoding, Attention Mechanism,",
          "RNN using attention mechanism [Bahdanau, 2015]",
          "Size of recurrent unit",
          "Optimization Stochastic gradient descent(SGD)",
          "Time of training 10 days (4 epoch)"
        ],
        "page_nums": [
          4,
          20
        ],
        "images": []
      },
      "3": {
        "title": "Pros and Cons of NMT",
        "text": [
          "no need domain knowledge no need to store explicit TM and LM",
          "Can jointly train multiple features",
          "Can implement decoder easily",
          "Is time consuming to train NMT model",
          "Is slow in decoding, if target vocab. is large",
          "Is weak to OOV problem",
          "Is difficult to debug"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Tree to String Syntax based MT",
        "text": [
          "1 million sentence pairs (train-1.txt)",
          "3 million Japanese sentences (train-1.txt, train-2.txt)",
          "Japanese: In-house tokenizer and POS tagger",
          "Assign linguistic syntax label to X hole of HPB model"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Tree to String Syntax based MT 2 2",
        "text": [
          "Proposed by CMUs venugopal and Zollmann in 2006",
          "Extract more rules by modifying parse trees",
          "Use relax-parser in Moses toolkit (option: SAMT 2)",
          "Baseline nodes Additional nodes"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Handling OOV",
        "text": [
          "1) Hyphen word split",
          "Ex.) nano-laminate -> nano laminate",
          "2) English spell correction",
          "Use open source spell checker, Aspell",
          "Detection Phrase Based on skip rules",
          "Skip the word containing capital, number or symbol",
          "Based on edit distance",
          "Because large gap causes wrong correction",
          "Select one with shortest distance among top-3 suggestion",
          "detection correction remrakable remarkable",
          "1. remarkable 2. remakable 3. reamarkable"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Neural Machine Translation 1 2",
        "text": [
          "RNN with an attention mechanism [Bahdanau, 2015]",
          "Size of recurrent unit",
          "Optimization Stochastic gradient descent(SGD)",
          "Time of training 10 days (4 epoch)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Neural Machine Translation 2 2",
        "text": [
          "Prob. of the next target word",
          "[ Modified RNN ]"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Experimental Results T2S Syntax based MT",
        "text": [
          "+ Rule augmentation 1950M",
          "+ Parameter modification 1950M",
          "Rule augmentation increases both BLEU and #Rules",
          "OOV handling improves the performance"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Experimental Results Neural MT",
        "text": [
          "Modified RNN (target char-level with BI)",
          "Char-level of target language is better than word-level",
          "BI representation is helpful",
          "Modified RNN is better than original RNN"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Experimental Results w Human evaluation",
        "text": [
          "T2S SB MT* only",
          "T2S SB MT* + NMT** re-ranking",
          "NMT only outperform T2S SB MT",
          "NMT re-ranking gives the best",
          "T2S SB MT* : Rule augmentation + Parameter modification + OOV handling NMT** : Modified NMT using target char. seg. with B/I"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Korean to Japanese",
        "text": [],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Outline of KOR JPN MT Task",
        "text": [
          "Korean N-best Re-ranking Decoding NMT sentence"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Phrase based MT system",
        "text": [
          "Translation model & Language model",
          "1 million sentence pairs (JPO corpus)",
          "use Mecab-ko and Juman for tokenization",
          "tokenize Korean and Japanese into char-level",
          "Max-phrase length : 10"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Combination of PBMT NMT",
        "text": [
          "Choose the result of char-based PB if there is OOV in word-level",
          "Choose the result of word-based PB, otherwise",
          "Re-rank simply by NMT score"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "16": {
        "title": "Experimental Results",
        "text": [
          "Word PB + Character PB",
          "Character-level PB is comparable to Word-level PB",
          "Combined system has the best result"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "Experimental Results w human evaluation",
        "text": [
          "Word PB + Character PB",
          "NMT only doesnt outperform PBMT",
          "NMT re-ranking gives the best"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "18": {
        "title": "Summary",
        "text": [
          "We apply different MT models for each task",
          "T2S/PB SMT + NMT Re-ranking is best in both tasks",
          "Char-level tokenization of target language is useful for NMT",
          "Speed up the time of training",
          "Give the better BLEU score",
          "BI representation of char-level tokenization is helpful also for NMT",
          "In the future, we will apply our method to other language-pair;"
        ],
        "page_nums": [
          24
        ],
        "images": []
      }
    },
    "paper_title": "NAVER Machine Translation System for WAT 2015"
  },
  "1223": {
    "slides": {
      "0": {
        "title": "Challenge understand the topics and structure of a document",
        "text": [
          "How can we represent a document with respect to the authors emphasis? Sy mptoms",
          "(e.g. semantic class labels) structural information [Ag09, Gla16]",
          "(e.g. coherent passages) in latent vector space [Le14, Bha16]",
          "(i.e. distributional embedding) required for TDT, QA IR"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Task split a document into coherent sections with topic labels",
        "text": [
          "We aim to detect topics in a document that are expressed by the author as a coherent sequence of sentences (e.g., a passage or book chapter)."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "WikiSection Wiki authors provide topics as section headings",
        "text": [
          "en_disease de_disease en_city de_city",
          "headings headings headings headings",
          "27 topics 25 topics 30 topics 27 topics"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "SECTOR sequential prediction approach",
        "text": [
          "Transform a document of N sentences s1...N into N topic distributions y1...N",
          "Predict M sections T1...M based on coherence of the networks weights",
          "Assign section-level topic labels y1...M",
          "of sections is unknown!"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Network architecture 0 4 Overview",
        "text": [
          "Objective: maximize the log likelihood of model parameters per document on sentence-level",
          "Requires the entire document as input",
          "Focus on sharp distinction at topic shifts"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Network architecture 1 4 Sentence encoding",
        "text": [
          "Input: Vector representation of a full document",
          "Split text into sequence of sentences s1...N",
          "Encode sentence vectors x1...N using",
          "Bag-of-words (~56k english words)",
          "Use sentences as time-steps"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Network architecture 2 4 Topic embedding",
        "text": [
          "Encoder: Bidirectional Long Short-Term Memory",
          "independent fw and bw parameters helps to sharpen left/right context embedding layer captures latent topics",
          "2x256 LSTM cells, 128 dim embedding layer,",
          "16 docs per batch, 0.5 dropout, ADAM opt. Sebastian Arnold"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Network architecture 3 4 Topic classification",
        "text": [
          "Human-readable topic labels for 2 Tasks:"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Network architecture 4 4 Segmentation",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Coherent segmentation using edge detection",
        "text": [
          "We use the topic embedding deviation (emd) dk to start new segments on peaks.",
          "Idea adapted from image processing: we apply Laplacian-of-Gaussian",
          "edge detection [Zi98] to find local maxima on the emd curve",
          "Steps: dimensionality reduction (PCA), Gaussian smoothing, local maxima",
          "Bidirectional deviation (bemd) on fw and bw layers allows for sharper separatio n"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1223-Figure4-1.png"
        ]
      },
      "10": {
        "title": "Experiments with 20 different models on 8 datasets",
        "text": [
          "dataset articles article type headings topics segments",
          "German/English diseases and cities",
          "Wiki-50 [Kosh18] 50 test English generic X X",
          "Cities/Elements 130 test English cities and",
          "Clinical Textbook 227 test English clinical X X",
          "Sentence Classification Baselines: ParVec [Le14], CNN [Kim14]"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Experiment 1 segmentation and single label classification",
        "text": [
          "Segment on sentence-level and assign one of 25-30 supervised topic labels (F1)",
          "ParVec* ParVec* CNN* SECTOR SECTOR SECTOR SECTOR SECTOR* [Le14] +emd [Kim14] +bow +bloom +bloom+emd +bloom+bemd +word2vect+bemd 13"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "Experiment 2 segmentation and multi label classification",
        "text": [
          "Segment on sentence-level and rank 1.0k-2.8k noisy topic words per section (MAP)",
          "CNN* SECTOR SECTOR SECTOR* SECTOR* SECTOR @fullwiki* [Kim14] +bloom +bloom+rank +word2vec +word2vectrank +word2vec 14"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Experiment 3 segmentation without topic prediction cross dataset",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "14": {
        "title": "Insights SECTOR captures topic distributions coherently",
        "text": [
          "Topic predictions on sentence level top: ParVec [Le14] bottom: SECTOR",
          "Segmentation left: newlines in text (\\n) right: embedding deviation (emd)"
        ],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1223-Figure5-1.png"
        ]
      },
      "15": {
        "title": "SECTOR prediction on par with Wiki authors for dermatitis",
        "text": [],
        "page_nums": [
          16
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion and future work",
        "text": [
          "SECTOR is designed as a building block for document-level knowledge representation",
          "Reading sentences in document context is an important step to capture both topical and structural information",
          "Training the topic embedding with distant-supervised complementary labels improves performance over self-supervised word embeddings",
          "In future work, we aim to apply the topic embedding for unsupervised passage retrieval and QA tasks",
          "q = ther apy"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "SECTOR: A Neural Model for Coherent Topic Segmentation and Classification"
  },
  "1224": {
    "slides": {
      "0": {
        "title": "Span Parsing is SOTA in Constituency Parsing",
        "text": [
          "Cross+Huang 2016 introduced Span Parsing",
          "But with greedy decoding.",
          "Stern et al. 2017 had Span Parsing with Exact Search and Global Training",
          "But was too slow: O(n3)",
          "Can we get the best of both worlds? Cross Huang",
          "Something that is both fast and accurate?",
          "Speed New at ACL 2018! Also Span Parsing!"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Both Fast and Accurate",
        "text": [
          "Baseline Chart Parser (Stern et al. 2017a)",
          "Our Linear Time Parser"
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/1224-Figure2-1.png"
        ]
      },
      "2": {
        "title": "In this talk we will discuss",
        "text": [
          "Linear Time Constituency Parsing using dynamic programming",
          "Going slower in order to go faster: O(n3) O(n4) O(n)",
          "Cube Pruning to speed up Incremental Parsing with Dynamic Programming",
          "From O(n b2) to O(n b log b)",
          "An improved loss function for Loss-Augmented Decoding",
          "2nd highest accuracy among single systems trained on PTB only"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Span Parsing",
        "text": [
          "Span differences are taken from an encoder",
          "(in our case: a bi-LSTM)",
          "A span is scored and labeled by a feed-forward network. s",
          "The score of a tree is the sum of all the labeled span scores",
          "(i,j,X)2t s You should eat ice cream /s"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Incremental Span Parsing Example",
        "text": [
          "Eat ice cream after lunch VB NN NN IN NN Cross + Huang 2016",
          "Eat NN NN IN NN",
          "S-VP ice cream after NN",
          "NP PP Shift NP",
          "S Action Label Stack",
          "Eat ice cream after lunch Reduce S-VP VB NN NN IN NN Cross + Huang"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "5": {
        "title": "How Many Possible Parsing Paths",
        "text": [
          "2 actions per state."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "6": {
        "title": "Equivalent Stacks",
        "text": [
          "Observe that all stacks that end with (i, j) will be treated the same!",
          "Until (i, j) is popped off.",
          "So we can treat these as temporarily equivalent, and merge.",
          "This is our new stack representation. Left Pointers",
          "Graph-Structured Stack (Tomita Huang Sagae 2010)"
        ],
        "page_nums": [
          16,
          17,
          18
        ],
        "images": []
      },
      "7": {
        "title": "Dynamic Programming Merging Stacks",
        "text": [
          "Temporarily merging stacks will make our state space polynomial."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "8": {
        "title": "Becoming Action Synchronous",
        "text": [
          "Shift-Reduce Parsers are traditionally action synchronous.",
          "This makes beam-search straight forward.",
          "We will also do the same",
          "But will show that this will slow down our DP (befo re applying beam -search)"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "9": {
        "title": "Action Synchronous Parsing Example",
        "text": [
          "Gold: (0,1) Shift Shift Shift Reduce Reduce Shift Shift Reduce Reduce",
          "sh sh sh sh sh r r r r",
          "r r sh r r r",
          "r r r r r r",
          "sh r r r sh sh sh",
          "r r r sh r sh r r r r"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "10": {
        "title": "Runtime Analysis",
        "text": [
          "sh sh sh sh sh r r r r",
          "r r r r r r",
          "sh r r r sh sh sh",
          "r r r sh r sh r r r r",
          "#left pointers per state: O(n)",
          "Check out the paper for our new theorem: r sh sh",
          "Thanks to Dezhong Deng!"
        ],
        "page_nums": [
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "11": {
        "title": "Going slower to go faster",
        "text": [
          "Our Action-Synchronous algorithm has a slower runtime than CKY!",
          "However, it also becomes straightforward to prune using beam search.",
          "So we can achieve a linear runtime in the end.",
          "sh sh sh sh sh sh sh sh sh sh r r r r r r r r O(n4) O(n4) r r r r r r r r r r r r sh sh r r r r r r sh sh sh sh sh sh r r r r r r sh sh r r sh sh r r r r r r r r r r",
          "sh sh sh sh sh sh sh sh sh sh r r r r r r r r O(n) O(n) r r r r r r r sh r sh sh r sh r r (approx. (approx. DP) DP) sh r sh r sh r sh"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "12": {
        "title": "Now our runtime is On",
        "text": [
          "sh sh sh sh sh r r r r",
          "r r r r r",
          "r sh r sh"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "13": {
        "title": "But this On is hiding a constant",
        "text": [
          "b states per action step",
          "O(b) left pointers per state"
        ],
        "page_nums": [
          35,
          36
        ],
        "images": []
      },
      "14": {
        "title": "Cube Pruning",
        "text": [
          "We can apply cube pruning to make O(nb log b)",
          "sh sh sh sh sh r r r r",
          "r r r r r",
          "r sh r sh",
          "By pushing all states and their left pointers into a heap",
          "And popping the top b unique subsequent states"
        ],
        "page_nums": [
          37,
          38,
          39,
          40
        ],
        "images": []
      },
      "15": {
        "title": "Runtime on PTB and Discourse Treebank",
        "text": [],
        "page_nums": [
          41
        ],
        "images": []
      },
      "16": {
        "title": "Training",
        "text": [
          "Goal: Score the gold tree higher than all others by a margin:"
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "17": {
        "title": "Loss Function",
        "text": [
          "Counts the incorrectly labeled spans in the tree (Stern et al. 2017)",
          "Happens to be decomposable, so can even be used to compare partial trees."
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "18": {
        "title": "Novel Cross Span Loss",
        "text": [
          "We observe that the null label is used in two different ways:",
          "To facilitate ternary and n-ary branching trees.",
          "As a default label for incorrect spans that violate other gold spans.",
          "i j i j",
          "We modify the loss to account for incorrect spans in the tree.",
          "Indicates whether (i, j) is crossing a span in the gold tree",
          "Still decomposable over spans, so can be used to compare partial trees."
        ],
        "page_nums": [
          44,
          45,
          46
        ],
        "images": []
      },
      "19": {
        "title": "Max Violation Updates",
        "text": [
          "Take the largest augmented loss value across all time steps.",
          "This is the Max-Violation, that we use to train.",
          "best in the beam full",
          "correct sequence early max- violation latest",
          "worst in the beam last valid falls off the beam update invalid update! biggest violation"
        ],
        "page_nums": [
          47
        ],
        "images": []
      },
      "20": {
        "title": "Comparison with Baseline Chart Parser",
        "text": [
          "Model Note F1 (PTB test)",
          "Stern et al. (2017a) Baseline Chart Parser"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "21": {
        "title": "Comparison to Other Parsers",
        "text": [
          "PTB only, Single Model, End-to-End Reranking, Ensemble, Extra Data",
          "Model Note F1 Model Note F1",
          "Durett + Klein 2015 Vinyals et al. 2015 Ensemble",
          "Cross + Huang 2016 Original Span Parser Dyer et al. 2016 Generative Reranking",
          "Dyer et al. 2016 Discriminative Fried et al. Reranking Ensemble",
          "Stern et al. 2017a Chart Baseline Parser",
          "Stern et al. 2017c Separate Decoding",
          "Our Work Beam 20"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "22": {
        "title": "Conclusions",
        "text": [
          "Linear-Time, Span-Based Constituency Parsing with Dynamic Programming",
          "Cube-Pruning to speedup Incremental Parsing with Dynamic Programming",
          "Cross-Span Loss extension for improving Loss-Augmented Decoding",
          "Result: Faster and more accurate than cubic-time Chart Parsing",
          "2nd highest accuracy for single-model end-to-end systems trained on PTB only",
          "Stern et al. 2017c is more accurate, but with separate decoding, and is much slower",
          "After this ACL, definitely no longer true. (e.g. Joshi et al. 2018, Kitaev+Klein 2018)",
          "But both are Span-Based Parsers and can be linearized in the same way!"
        ],
        "page_nums": [
          50
        ],
        "images": []
      }
    },
    "paper_title": "Linear-Time Constituency Parsing with RNNs and Dynamic Programming"
  },
  "1225": {
    "slides": {
      "0": {
        "title": "Query Auto Completion",
        "text": [
          "Search engine suggests queries as the user types",
          "an LSTM to generate completions",
          "Memory savings over most popular completion",
          "Handles previously unseen prefixes",
          "Can we do better by adapting the LM to provide personalized suggestions?"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "RNN Language Model Adaptation",
        "text": [
          "Learn an embedding, c, for each user and use it to adapt the predictions",
          "word embedding user embedding",
          "Method #1: Concatenate the user embedding with the input at each step*",
          "Same as applying a constant linear shift to the bias vector (in recurrent & output layers)",
          "Leaves most of the recurrent model parameters unchanged",
          "Method #2: Low-rank adaptation of recurrent weight matrix (FactorCell model)",
          "Concatenating the user embedding is the same as shifting the bias.",
          "Adjust b and W! * Referred to here as ConcatCell (Mikolov& Zweig, 2012)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "FactorCell Model",
        "text": [
          "Adapted weights Generic weights Low-rank adaptation",
          "The adaptation matrix is formed from a product of the context embedding with left and right bases.",
          "The two bases tensors (L and R) hold k different rank r matrices, each the same size as W. Context vectors give a weighted combination."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Learning",
        "text": [
          "User embeddings, recurrent layer weights and {L, R} tensor learned jointly",
          "Need online learning to adapt to users that were not previously seen",
          "In joint training, learn a cold-start embedding for set of infrequent users",
          "Initialize each users embedding with learned cold-start vector",
          "After user selects a query, back-propagate and only update the user embedding"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Data and Experiments",
        "text": [
          "users and 12 million queries for training",
          "User embedding size = 32, LSTM size = 600",
          "Evaluate on 500K queries with disjoint user population",
          "Mean reciprocal rank (MRR) as a metric"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Experimental Results",
        "text": [
          "Benefit improves over time!",
          "Performance for users with > 50 queries"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1225-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Qualitative Comparison",
        "text": [
          "What queries are boosted the most after searching for high school",
          "softball and math homework help?",
          "high school musical horoscope",
          "chris brown high school musical",
          "funnyjunk.com homes for sale",
          "chat room hair styles",
          "Queries that most decrease in likelihood with the",
          "FactorCell include travel agencies and plane tickets."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Recent Related Work Florini and Lu NAACL 2018",
        "text": [
          "Also personalized LSTM for query prediction",
          "User embedding learned separately",
          "Assessed on two datasets, but different split of AOL data",
          "Confirms benefit of adapted LM"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Conclusions",
        "text": [
          "Personalization helps and the benefit increases as more queries are seen",
          "Stronger adaptation of the recurrent layer (FactorCell) gives better results than concatenating a user vector",
          "No extra latency/computation due to caching of adapted weight matrix",
          "Try out the FactorCell on your data"
        ],
        "page_nums": [
          9
        ],
        "images": []
      }
    },
    "paper_title": "Personalized Language Model for Query Auto-Completion"
  },
  "1226": {
    "slides": {
      "0": {
        "title": "Improving NMT in low Resource scenarios",
        "text": [
          "Bilingually low-resource scenario: large amounts of bilingual training data is not available",
          "IDEA: Use existing resources from other tasks and train one model for all tasks using multi-task learning",
          "This effectively injects inductive biases to help improving the generalisation of",
          "Auxiliary tasks: Semantic Parsing, Syntactic Parsing, Named Entity Recognition"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Encoders Decoders for Individual Tasks",
        "text": [
          "I went home Encoder Decoder",
          "Obama was elected and his voter celebrated",
          "The burglar robbed the apartment",
          "NP Encoder Decoder VP apartment the",
          "Named-Entity Recognition NP N",
          "DT burglar the Jim bought 300 shares of Acme Corp. in 2006 Encoder Decoder B-PER 0 0 0 0 B-ORG I-ORG 0 B-MISC",
          "Noun Phrases (NP): the burglar, the apartment"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Sharing Scenario",
        "text": [
          "task tag Parse tree",
          "Machine Translation Encoder Decoder",
          "Semantic Parsing Encoder Decoder",
          "Syntactic Parsing Encoder Decoder",
          "Named-Entity Recognition Encoder Decoder"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Partial Parameter Sharing",
        "text": [
          "<translation> I went home Decoder Encoder",
          "I went home <EOS> <translation>",
          "Zaremoodi & Haffari, NAACL, 2018"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Adaptive Knowledge Sharing in MTL",
        "text": [
          "!Sharing the parameters of the recurrent units among all tasks",
          "Task interference sharing the knowledge for",
          "Inability to leverage commonalities among subsets of tasks controlling the information",
          "flow in the hidden states",
          "Multiple experts in handling different kinds of information",
          "Adaptively share experts among the tasks",
          "Extend the recurrent units with multiple blocks",
          "each block has its own information flow through the time",
          "Routing mechanism: to softly direct the input to these blocks"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": [
          "figure/image/1226-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Adaptive Knowledge Sharing",
        "text": [
          "We use the proposed recurrent unit inside encoder and decoder.",
          "<translation> I went home <EOS>",
          "Task Block Task Block"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": [
          "figure/image/1226-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Experiments",
        "text": [
          "Language Pairs: English to Farsi/Vietnamese",
          "English to Farsi: TED corpus & LDC2016E93",
          "English to Vietnamese: IWSLT 2015 (TED and TEDX talks)",
          "Semantic parsing: AMR corpus(newswire, weblogs, web discussion forums and broadcast conversations)",
          "Syntactic parsing: Penn Treebank",
          "NER: CONLL NER Corpus (newswire articles from the Reuters Corpus)",
          "NMT Architecture: GRU for blocks, 400 RNN hidden states and word embedding",
          "NMT best practice: Optimisation: Adam Byte Pair Encoding (BPE) on both source/target Evaluation metrics: PPL, TER and BLEU",
          "= MTL (Routing) BNMT =&MTL(Full) m MTL (Partial) = MTL (Routing)",
          "English > Farsi English > Vietnamese"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "7": {
        "title": "Experiments English to Farsi",
        "text": [
          "Block 1 Block 2 Block 3",
          "MT Semantic Syntactic NER",
          "Blocks specialisation: Block 1: MT, Semantic Parsing, Block 2: Syntactic/Semantic Parsing, Block 3: NER"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "Address the task interference issue in MTL"
        ],
        "page_nums": [
          15
        ],
        "images": []
      }
    },
    "paper_title": "Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation"
  },
  "1227": {
    "slides": {
      "0": {
        "title": "Problem Statement",
        "text": [
          "Judiciously select labeled data from assisting language to improve the NER performance in the primary language for multilingual learning"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Why need to judiciously select data from assisting language",
        "text": [
          "Many language have less named entity annotated data",
          "Several approaches have explored use of data from one or more languages (assisting languages) [Gillick et al. [2016], Yang et al.",
          "However, annotated data from assisting languages might negatively influence the performance on the primary language",
          "Word Per Loc Org Misc Word Per Loc Org Misc",
          "Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish",
          "I am going to Washington",
          "mein me washington washington jaa raha going to"
        ],
        "page_nums": [
          5,
          8,
          36
        ],
        "images": []
      },
      "2": {
        "title": "What can go wrong in multilingual learning for NER",
        "text": [
          "Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Select sentences from general domain data most similar to in-domain data",
          "Used language model to measure similarity of general domain data with the in-domain training data",
          "Ruder and Plank [2017] Learn to weigh various data selection measures using",
          "Zhao et al. [2018] Select assisting data for multi-task domain adaptation",
          "Assisting language sentences with highest log likelihood value were selected",
          "Ponti et al. [2018] Measure cross-lingual syntactic variation considering both morphological and structural properties",
          "Selecting a assisting language with a lower degree of anisomorphism is crucial for knowledge transfer",
          "Table 1: Literature most relevant to our work"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Proposed Approach",
        "text": [
          "Select sentences based on the agreement in tag distribution of common entities",
          "Goal: Improve Spanish NER performance by adding English NER annotated data",
          "Word Per Loc Org Misc Word Per Loc Org Misc",
          "Select English sentences containing entities with similar tag distribution",
          "Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish",
          "Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL",
          "for every sentence X, in assisting language do",
          "Score(X) for every word xi, in sentence X do if word xi appears in primary language then",
          "Pa(xi) are tag distributions of xi in primary and assisting lan- guages}",
          "end if end for end for",
          "Add assisting language sentences with sentence score Score(X) less than a threshold to the primary language data"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "5": {
        "title": "Dataset Statistics",
        "text": [
          "(#Tokens) Train (#Tokens) Test",
          "English Tjong Kim Sang and"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "6": {
        "title": "Network Details",
        "text": [
          "Parameter sharing configurations considered",
          "Sub-word feature extractors shared across languages",
          "Neural network trained in language independent way",
          "Figure 1: Architecture of the Neural",
          "Network (Murthy and Bhattacharyya"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "7": {
        "title": "Results",
        "text": [
          "Primary Assisting Layers Data Selection Primary Assisting Layers Data Selection",
          "Language Language Shared All SKL Language Language Shared All SKL",
          "Monolingual None Monolingual None",
          "Spanish All Spanish All 76.92Sub-word Sub-word",
          "Dutch All 77.29Sub-word Dutch All Sub-word",
          "Table 3: F-Score for German and Italian Test data using Monolingual and Multilingual learning strategies. indicates that the SKL results are statistically significant compared to adding all assisting language data with p-value 0.05 using two-sided Welch t-test.",
          "Hindi Marathi Bengali Malayalam Tamil",
          "ALL SKL ALL SKL ALL SKL ALL SKL ALL SKL",
          "Table 4: Test set F-Score from monolingual and multilingual learning on Indian languages.",
          "Result from monolingual training on the primary language is underlined. indicates SKL results statistically significant compared to adding all assisting language data with p-value 0.05 using two-sided Welch t-test."
        ],
        "page_nums": [
          22,
          25
        ],
        "images": []
      },
      "8": {
        "title": "Analysis",
        "text": [
          "Histogram of assisting language sentences ranked by their sentence scores",
          "Figure 2: English-Italian: Histogram of Figure 3: Spanish-Italian: Histogram",
          "English Sentences of Spanish Sentences",
          "Influence of SKL Threshold",
          "Figure 4: Spanish-Italian Multilingual Learning: Influence of Sentence score",
          "(SKL) on Italian NER"
        ],
        "page_nums": [
          23,
          27
        ],
        "images": [
          "figure/image/1227-Figure1-1.png",
          "figure/image/1227-Figure2-1.png"
        ]
      },
      "9": {
        "title": "Analysis European Languages",
        "text": [
          "Adding all Spanish/Dutch sentences to Italian data, leads to drop in Italian NER performance",
          "Label drift from overlapping entities is one of the reasons for the poor results",
          "We compare the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning",
          "Similar pattern is observed in the case of Dutch sentences"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "10": {
        "title": "Analysis Indian Languages",
        "text": [
          "Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy",
          "Hindi and Marathi NER performance improves when the other is used as assisting language",
          "Hindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam and Tamil"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "11": {
        "title": "Analysis Influence of SKL Threshold",
        "text": [
          "Train for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages",
          "We vary the threshold value from 0.0 to 9.0 in steps of 1",
          "Italian test F-Score increases initially as we add more and more",
          "Spanish sentences and then drops due to influence of drift becoming significant"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion And Future Work",
        "text": [
          "We address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER",
          "We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy",
          "A more principled approach for data selection would be exploring the",
          "We plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, neural machine translation",
          "We also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages"
        ],
        "page_nums": [
          29
        ],
        "images": []
      }
    },
    "paper_title": "Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER"
  },
  "1228": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Encode a variable-length input sentence into a constant size vector",
          "Based on Word Embeddings:",
          "(II) Concatenated P-Mean Embeddings (Ruckle et al. 2018)",
          "(I) SkipThought Vectors (Kiros et al. 2015)",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Goal",
        "text": [
          "Exploring what specific semantic properties are directly reflected by such embeddings.",
          "Focusing on a few select aspects of sentence semantics.",
          "Concurrent related work: Conneau et al. ACL 2018",
          "(i) Their work studies what you can learn to predict using 100,000 training instances",
          "(ii) Our goal: Directly study the embeddings (via cosine similarity)",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Approach Contrastive Sentences",
        "text": [
          "Minor alterations of a sentence may lead to notable shifts in meaning.",
          "(i) A rabbit is jumping over the fence ( S",
          "(ii) A rabbit is hopping over the fence ( S=",
          "(iii) A rabbit is not jumping over the fence S*",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Sentence Modification Schemes",
        "text": [
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Negation Detection",
        "text": [
          "A person is slicing an onion.",
          "A person is cutting an onion.",
          "A person is not slicing an onion.",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings",
          "Average of Word Embeddings is more easier misled by negation.",
          "Both InferSent and SkipThought succeed in distinguishing unnegated sentences from negated ones.",
          "Glove Avg P Means Sent2Vec SkipThought InferSent"
        ],
        "page_nums": [
          5,
          11
        ],
        "images": []
      },
      "5": {
        "title": "Negation Variant",
        "text": [
          "A man is not standing on his head under water.",
          "There is no man standing on his head under water.",
          "A man is standing on his head under water.",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings",
          "Both averaging of word embeddings and SkipThought are dismal in terms of the accuracy.",
          "InferSent appears to have acquired a better understanding of negation quantifiers, as these are commonplace in many NLI datasets.",
          "Glove Avg P Means Sent2Vec SkipThought InferSent"
        ],
        "page_nums": [
          6,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Clause Relatedness",
        "text": [
          "Octel said the purchase was expected.",
          "Octel said the purchase was not expected",
          "Glove Avg P Means Sent2Vec SkipThought InferSent Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings",
          "Both SkipThought vectors and InferSent works poorly when sub clause is much shorter than original one.",
          "Sent2vec best in distinguishing the embedded clause of a sentence from a negation of that sentence."
        ],
        "page_nums": [
          7,
          13
        ],
        "images": []
      },
      "7": {
        "title": "Argument Sensitivity",
        "text": [
          "Francesca teaches Adam to adjust the microphone on his stage",
          "Adam is taught to adjust the microphone on his stage",
          "Adam teaches Francesca to adjust the microphone on his stage",
          "Glove Avg P Means Sent2Vec SkipThought InferSent Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings",
          "None of the analyzed approaches prove adept at distinguishing the semantic information from structural information in this case."
        ],
        "page_nums": [
          8,
          14
        ],
        "images": []
      },
      "8": {
        "title": "Fixed Point Reordering",
        "text": [
          "A black dog in the snow is jumping off the ground and catching a stick.",
          "Fixed Point Inversion(Corrupted Sentence):",
          "In the snow is jumping off the ground and catching a stick a black dog.",
          "Glove Avg P Means Sent2Vec SkipThought InferSent Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings",
          "Methods based on word embeddings do not encode sufficient word order information into the sentence embeddings.",
          "SkipThought and InferSent did well when the original sentence and its semantically equivalence share similar structure"
        ],
        "page_nums": [
          9,
          15
        ],
        "images": []
      },
      "9": {
        "title": "Models and Dataset",
        "text": [
          "Dataset Embedding Dim of Sentences From",
          "Glove Avg Common Crawl Negation Detection SICK, SNLI",
          "P Means Common Crawl Negation Variant SICK, SNLI",
          "Sent2Vec English Wiki Clause Relatedness TreebankMSR Penn Paraphrase",
          "SkipThought Book Corpus Argument Sensitivity SICK, MS Paraphrase",
          "InferSent SNLI Fixed Point Reordering SICK",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "RNN based sentence embeddings better at identifying negation compared with word embedding based models",
          "Both SkipThought and InferSent distinguish negation of a sentence from synonymy.",
          "InferSent better at identifying semantic equivalence regardless of the order of words and copes better with quantifiers.",
          "SkipThoughts is more suitable for tasks in which the semantics of the sentence corresponds to its structure",
          "Zhu, Li & de Melo. Exploring Semantic Properties of Sentence Embeddings"
        ],
        "page_nums": [
          16
        ],
        "images": []
      }
    },
    "paper_title": "Exploring Semantic Properties of Sentence Embeddings"
  },
  "1229": {
    "slides": {
      "0": {
        "title": "Current State",
        "text": [
          "We dont know too much about the differences between them:",
          "Gated RNNs are shown to train better, beyond that:",
          "RNNs are Turing Complete?"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Turing Complete",
        "text": [
          "Uses stack(s), maintained in certain dimension(s)",
          "Zeros are pushed using division (using g = g/4 + 1/4)",
          "In 32 bits, this reaches the limit after pushes",
          "Allows processing steps beyond reading input",
          "(Not the standard use case!)"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "What happens on",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Real Use",
        "text": [
          "Gated architectures have the best performance",
          "LSTM and GRU are most popular",
          "Of these, the choice between them is unclear"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Main Result",
        "text": [
          "We accept all RNN types can simulate DFAs",
          "We show that LSTMs and IRNNs can also count",
          "And that the GRU and SRNN cannot"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Power of Counting",
        "text": [
          "LSTM better at capturing target length",
          "Finite State Machines vs Counter Machines"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "6": {
        "title": "K Counter Machines SKCMs",
        "text": [
          "Fischer, Meyer, Rosenberg - 1968",
          "Similar to finite automata, but also maintain k counters",
          "A counter has 4 operations: inc/dec by one, do nothing, reset",
          "Counters are observed by comparison to zero"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Counting Machines",
        "text": [
          "Context Free Languages (CFL)",
          "Context Sensitive Languages (CSL)",
          "Recursively Enumerable Languages (RE)"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Chomsky Hierarchy and SKCMs",
        "text": [
          "Context Free Languages (CFL)",
          "Context Sensitive Languages (CSL)",
          "Recursively Enumerable Languages (RE)",
          "SKCMs cross the Chomsky Hierarchy!"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "9": {
        "title": "Summary so Far",
        "text": [
          "Counters give additional formal power",
          "We claimed that LSTM can count and GRU cannot"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "10": {
        "title": "Popular Architectures",
        "text": [
          "zt (Wzxt Uzht1 bz) rt (Wrxt Urht1 br)",
          "ht zt ht1 zt) ht ct tanh(Wcxt Ucht1 bc)",
          "ft (Wf xt Uf ht1 bf it (Wixt Uiht1 bi) ot (Woxt Uoht1 bo) ct = tanh(Wcxt Ucht1 bc) ct ft ct1 it ct ht ot g(ct)",
          "ht tanh(Whxt Uh(rt ht1) bh)",
          "candidate ct ft ct1 it ct vectors ht ot g(ct)",
          "ht ot ht zt ht1 zt) ht ct",
          "ct ct1 ct ht ot g(ct)",
          "Interpolation Increase by 1",
          "ot Can Cou it"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "11": {
        "title": "Other Architectures",
        "text": [
          "ht h(Whxt Uhht1 bh) ht = max(0,Whxt Uhht1 bh)",
          "(subtraction in parallel, also increasing,",
          "Bounded ! Can Cou nt!"
        ],
        "page_nums": [
          34,
          35,
          36,
          37
        ],
        "images": []
      },
      "12": {
        "title": "So",
        "text": [
          "Counting gives greater computational power"
        ],
        "page_nums": [
          38
        ],
        "images": []
      },
      "13": {
        "title": "Empirically",
        "text": [
          "Activations on a b ACL 2018 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.",
          "(on positive examples up to length 100)",
          "Figure 1: Activations for LSTM and GRU networks fo to use an explicit counting mechanism, in contrast wit",
          "Did not generalise even within training domain begin ftao iliunsge aatn n=ex3p9l (ivcsit 2c5o7u fnotri nLg STmMe)c hanism, in contrast wit Figure 1: Activations for LSTM and GRU networks fo",
          "Figure 1: Activations for LSTM and GRU networks for anbn and anbncn. The LSTM has clearly lear Did not generalise well to use an explicit counting mechanism, in contrast with the GRU. begin failing at n=9 (vs 101 for LSTM) Did not learn any discernible counting mechanism",
          "ACL 2018 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE. Activations on a100b100c100",
          "Figure 1: Activations for LSTM and GRU networks for anbn and anbncn. The LSTM has clearly lear to use an explicit counting mechanism, in contrast with the GRU."
        ],
        "page_nums": [
          39,
          40,
          41,
          42,
          43,
          44
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion",
        "text": [],
        "page_nums": [
          45,
          46
        ],
        "images": []
      },
      "15": {
        "title": "Take Home Message",
        "text": [
          "and result in actual differences in expressive power",
          "Dont fall in the Turing Tarpit!"
        ],
        "page_nums": [
          47
        ],
        "images": []
      }
    },
    "paper_title": "On the Practical Computational Power of Finite Precision RNNs for Language Recognition"
  },
  "1230": {
    "slides": {
      "0": {
        "title": "News Context",
        "text": [
          "Identify the news category by URL pattern\u0000\b",
          "7 categories: Entertainment, World, Finance, Sports, Fashion,",
          "Classify words based on category document frequency",
          "E.g., superstar belongs to Entertainment",
          "For both English and Chinese news and words"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "1": {
        "title": "Word Sense Disambiguation",
        "text": [
          "Expanded College English Test 4 Dictionary",
          "English, Chinese (relative frequency), part-of-speech",
          "33,664 English-Chinese pairs and",
          "~4k unique English words",
          "Baseline: always choose the most frequent relative",
          "of coverage as it always has a translation",
          "Low accuracy as it lacks context modeling",
          "Approach 1: News Category",
          "Pick the Chinese translation with the same category as the news article",
          "E.g., =>interest in Finance news",
          "Approach 2: Part-of-Speech (POS)",
          "Pick up the Chinese translation with the same POS as the target English word"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "WSD Bing Translator Based Methods",
        "text": [
          "Approach 3: Substring Match",
          "2. Look up dictionary state department spokeswomen said",
          "into the worlds top 40 clubs",
          "(Bing) is a substring of",
          "Limited by dictionary coverage!",
          "into the worlds top clubs",
          "3. No output using substring match",
          "Approach 4: Relaxed Match",
          "Chinese Segmentation 3. Relaxed Match:",
          "(Bing) is superset of",
          "Chinese Segmentation 3. Two relaxed matches, both wrong",
          "Approach 5: Bing Alignment",
          "Better - No output if the alignment is phrase to phrase"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "3": {
        "title": "WSD Evaluation",
        "text": [
          "Baseline 1. News 2. POS 3. Bing - 4. Bing - Relaxed 5. Bing - Align Category Substring"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "4": {
        "title": "What is a set of suitable distractors",
        "text": [
          "Have the same form as the target word",
          "Fit the sentence context",
          "Have proper difficulty level according to users level of mastery",
          "Difficult distractors are more semantically similar to the target words"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "5": {
        "title": "Generating proper distractors",
        "text": [
          "The difficulty level is measured by Lin distance between the target word and candidate distractor in WordNet",
          "Lowest common subsumer synset",
          "A distractor is deemed hard when its similarity to target word is above threshold (e.g., 0.1)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "6": {
        "title": "Distractor Generation",
        "text": [
          "1. WordNews Hard: Same word form + \u0000\b",
          "2. Random News: Same word form + \u0000\b",
          "Vary the number of hard distractors based on users knowledge level",
          "Beginner: two random + one hard"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "7": {
        "title": "Human Evaluation",
        "text": [
          "WordGap System (Knoop and Wilske, 2013)",
          "Distractor: targets synonyms of synonyms in WordNet",
          "Evaluation 1: WordGap vs. Random News",
          "Evaluation 2: WordGap vs. WordNews Hard",
          "22. Most sex workers that Hail-Jares encounters through street-based outreach",
          "are not in it fora , or because they lack the drive to succeed, she says. *",
          "One is the target word, three are from i WordGap, and the other three are from @",
          "WordNews Hard or Random News ; es) @ i) w @ &) SS a =",
          "# of wins Avg. Score",
          "Lower scores are better"
        ],
        "page_nums": [
          19,
          20,
          21
        ],
        "images": [
          "figure/image/1230-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "WordNews: a Chrome extension enabling interactive vocabulary learning when reading online news",
          "Word Sense Disambiguation \u0000\b based on Machine Translation",
          "Distractor Generation based on news context and semantic similarity",
          "Mobile client and \u0000\b longitudinal user study"
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "Interactive Second Language Learning from News Websites"
  },
  "1231": {
    "slides": {
      "0": {
        "title": "Overview of pre reordering systems",
        "text": [
          "Reorder input text before translation",
          "John hits a ball",
          "John va_nsubj a ball va_obj hits"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Approaches of pre reordering",
        "text": [
          "Syntactic pre-reordering without parse tree",
          "Head-finalization (Isozaki et al., 2010)",
          "Supervised learning with word alignments",
          "Automatically learning Rewrite Patterns (Xia and"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Overview of our pre reordering system",
        "text": [
          "Head-restructured CFG Parse Tree"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Head restructured CFG Parse Tree",
        "text": [
          "Problem of CFG parse tree",
          "Hard to capture long-distance reordering patterns",
          "Problem of Dependency parse tree",
          "Fully lexicalized parse tree leads to a sparse reordering model",
          "Restructure a CFG parse tree to inject head information into it",
          "Head word is always lexicalized"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Learning reordering model based on LM",
        "text": [
          "Extract tag sequences in golden order",
          "Head-restructured CFG parse tree",
          "nsubj prep_by calculated auxpass aux",
          "Alignments Train a language model on"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Finding golden order with word alignments",
        "text": [
          "Given a bilingual sentence pair, source-side parse tree and word alignments, the golden order of a node layer is defined as",
          "Average position (Ranked) a1 a3 a2"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Reordering a input parse tree",
        "text": [
          "1.List all possible orders for a treelet 3. Select the best order to adjust the treelet",
          "nsubj dobj hits dobj nsubj hits hits nsubj dobj hits dobj nsubj dobj hits nsubj nsubj hits dobj nsubj dobj hits",
          "2.Score them with language model"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "N best reordering",
        "text": [
          "Reordered treelets with LM scores",
          "All 12 possible combinations here",
          "Selected N-best results by accumulated scores (Cube Pruning is applied in the practice)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "In house experiments",
        "text": [
          "N-best parse + N- best reorder",
          "For N-best reorder, 10 candidate reordering results are considered.",
          "For N-best parse, 30 candidate parse trees are considered.",
          "We select the final translation by the sum of translation score (given by decoder) and the score of pre-reordering."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "N best reordering and N best parse tree inputs",
        "text": [
          "Incorporating multiple reordering results and parse trees benefits automatic scores."
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1231-Figure3-1.png",
          "figure/image/1231-Figure4-1.png"
        ]
      },
      "10": {
        "title": "Official evaluation results",
        "text": [
          "N-best reorder + N-best parse"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "11": {
        "title": "Effect of pre ordering",
        "text": [
          "Identical ordered sentences increases to 15%"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1231-Figure5-1.png"
        ]
      },
      "12": {
        "title": "Example of pre reordering",
        "text": [
          "the improvement of the life is a large problem of the practical application.",
          "Reordered input the life of the improvement va_nsubjpass the practical application of a large problem is ."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Review",
        "text": [
          "Language model is just a quick solution to the reordering problem, sometimes it fails in simple cases.",
          "To gain more from forest input, its necessary to integrate it inside the pre-reordering model."
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Weblio Pre-reordering Statistical Machine Translation System"
  },
  "1232": {
    "slides": {
      "0": {
        "title": "Intro",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "* Typical difficulties in searching digital libraries (DL)",
          "Vagueness between search and indexing terms",
          "Weak rankings based on term frequency (tf*idf), also others ...",
          "Assumption I: a user's search (experience) should improve by using recommendation services (Mutschke et al., 2011), esp. in:",
          "Assumption II: scholarly user's search with keywords, author names and journal names and use search tactics (Carevic & Mayr, 2016 to appear)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Recommender Services",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "You type a query and",
          "IRM project at GESIS (Liike et al., 2013) __get specific recommendations has developed core journals v",
          "e Soziale Systeme (105)",
          "Search term recommender - STR + Zeitschrift fur",
          "(co-word analysis/Jaccard index) es",
          "Journal name recommender - JNR + Zeitschrift fur",
          "(core journals/bradfordizing) Rechtssoziologie (25)",
          "e Author name recommender - ANR central authors v",
          "(co-authorship analysis/betweenness * Luhmann, Niklas tra | it ) e Luhmann, Hans-Jochen cen y Schimank, Uwe",
          "e Tyrell, Hartmann e Hartmann, Jutta e Fischedick, Manfred"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Case Study",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "* 19 social sciences researchers (seniors, research staff and",
          "PhD candidates) assessed topical relevance for STR, JNR and",
          "ANR for their research topics/familiar field",
          "23 topics have been assessed",
          "[e.g. urban sociology, interviewer error, theory of action, atypical employment, ...]",
          "They assessed 4-5 recommendations for each recommender",
          "All recommendations were derived from the social sciences database SOLIS"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Results I",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "* >70% of the recommendations are relevant",
          "Precision of ANR is slightly better than STR and JNR",
          "* Top 1 recommendation of JNR is more often not relevant"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Results II",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "Practitioners tend to assess author names more relevant",
          "* Postdocs tend to assess journal names more relevant"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Conclusion Further Questions",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "Precision values of recommendations from STR, JNR and",
          "ANR are close together on a high level",
          "Q: Would the result be similar in a real retrieval scenario?",
          "Practitioners are favoring author name recommendations while postdocs are favoring journal name recommendations",
          "Q: Are author names typically more distinctive features than journal names?"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Outlook",
        "text": [
          "Leibniz Institute for the Social Sciences",
          "Integrate different recommender systems In real retrieval tasks (search sessions)",
          "Measure task completion rates or goal satisfaction",
          "Use and evaluate recommenders for query expansion and as dynamic features in IR",
          "Develop new measures of utility of recommender"
        ],
        "page_nums": [
          7
        ],
        "images": []
      }
    },
    "paper_title": "How do practitioners, PhD students and postdocs in the social sciences assess topic-specific recommendations?"
  },
  "1235": {
    "slides": {
      "0": {
        "title": "What is Cross Language Plagiarism Detection",
        "text": [
          "Cross-Language Plagiarism is a plagiarism by translation, i.e. a text has been plagiarized while being translated (manually or automatically).",
          "From a text in a language L, we must find similar passage(s) in other text(s) from among a set of candidate texts in language L (cross-language textual similarity)."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Why is it so important",
        "text": [
          "- McCabe, D. (2010). Students cheating takes a high-tech turn. In Rutgers Business School. - Josephson Institute. (2011). What would honest Abe Lincoln say?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Research Questions",
        "text": [
          "Are Word Embeddings useful for cross-language plagiarism detection?",
          "Is syntax weighting in distributed representations of sentences useful for the text entailment?",
          "Are cross-language plagiarism detection methods complementary?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "State of the Art Methods",
        "text": [
          "Length Model, CL-CnG [Mcnamee and Mayfield, 2004, Potthast et al., 2011], Cognateness",
          "MT-Based Models Translation + Monolingual Analysis [Muhr et al., 2010, Barron-Cedeno, 2012]"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Augmented CL CTS",
        "text": [
          "We use DBNary [Serasset, 2015] as linked lexical resource.",
          "< ) Le chat boit du lait Sp the cat drinks milk",
          "CL-CTS-WE uses the top 10 closest words in the embeddings model to build the",
          "BOW of a word;",
          "A BOW of a sentence is a merge of the BOW of its words;",
          "Jaccard distance between the two BOW."
        ],
        "page_nums": [
          5,
          6,
          7,
          23
        ],
        "images": []
      },
      "5": {
        "title": "CL WES Cross Language Word Embedding based Similarity",
        "text": [
          "This feature is available in MultiVec [Berard et al., 2016] (https://github.com/eske/multivec)",
          "The similarity between two sentences S and S is calculated by Cosine Distance between the two vectors V and V , built such as:",
          "ui is the ith word of S; vector is the function which gives the word embedding vector of a word."
        ],
        "page_nums": [
          8,
          9,
          10,
          24
        ],
        "images": []
      },
      "6": {
        "title": "CL WESS Cross Language Word Embedding based Syntax Similarity",
        "text": [
          "This feature is available in MultiVec [Berard et al., 2016] (https://github.com/eske/multivec)",
          "ui is the ith word of S; pos is the function which gives the universal part-of-speech tag of a word; weight is the function which gives the weight of a part-of-speech; vector is the function which gives the word embedding vector of a word; is the scalar product."
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          25
        ],
        "images": []
      },
      "7": {
        "title": "Evaluation Dataset",
        "text": [
          "French, English and Spanish;",
          "Parallel and comparable (mix of Wikipedia, conference papers, product reviews,",
          "Different granularities: document level, sentence level and chunk level;",
          "Human and machine translated texts;",
          "Obfuscated (to make the similarity detection more complicated) and without added noise;",
          "Written and translated by multiple types of authors;",
          "1A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity",
          "Detection. In Proceedings of LREC 2016."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "8": {
        "title": "Evaluation Protocol",
        "text": [
          "We compared each English textual unit to its corresponding",
          "French unit and to 999 other units randomly selected;",
          "We threshold the obtained distance matrix to find the threshold giving the best F1 score;",
          "We repeat these two steps 10 times, leading to a 10 folds:",
          "- 2 folds for tuning (CL-WESS) and fusion (Decision Tree)",
          "- 8 folds for validation"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "9": {
        "title": "Results",
        "text": [
          "Decision Tree fusion significantly improves the results.",
          "CL-CTS-WE: Cross-Language Conceptual Thesaurus-based Similarity with Word-Embedding Table: Average F1 scores of methods applied",
          "Table: Average F1 scores of methods applied on ENFR sub-corpora.",
          "CL-WES: Cross-Language Word Embedding-based Similarity",
          "CL-WESS: Cross-Language Word Embedding-based Syntax Similarity",
          "CL-C3G: Cross-Language Character 3-Gram"
        ],
        "page_nums": [
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "Augmentation of several baseline approaches using word embeddings instead of lexical resources;",
          "CL-WESS beats in overall the precedent best state-of-the-art methods;",
          "Methods are complementary and their fusion significantly helps cross-language textual similarity detection performance;",
          "Winning method at SemEval-2017 Task 1 track 4a, i.e. the task on",
          "Spanish-English Cross-lingual Semantic Textual Similarity detection."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "11": {
        "title": "Complementarity",
        "text": [
          "Figure: Distribution histograms of CL-CNG (left) and CL-ASA (right) for 1000 positives and"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "12": {
        "title": "Fusions",
        "text": [
          "Weighted Average Fusion Decision Tree Fusion C4.5 [Quinlan, 1993]"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "13": {
        "title": "Weighted Fusion",
        "text": [
          "M is the set of the scores of the methods for one match; mj and wj are the score and the weight of the jth method respectively."
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "14": {
        "title": "Results at Chunk Level",
        "text": [
          "Methods Wikipedia TALN (%) JRC (%) APR (%) Europarl Overall (%)",
          "Table: Average F1 scores of cross-language similarity detection methods applied on chunk-level",
          "ENFR sub-corpora 8 folds validation."
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "15": {
        "title": "Results at Sentence Level",
        "text": [
          "Methods Wikipedia TALN (%) JRC (%) APR (%) Europarl Overall (%)",
          "Table: Average F1 scores of cross-language similarity detection methods applied on sentence-level ENFR sub-corpora 8 folds validation."
        ],
        "page_nums": [
          30
        ],
        "images": []
      }
    },
    "paper_title": "Using Word Embedding for Cross-Language Plagiarism Detection"
  },
  "1236": {
    "slides": {
      "0": {
        "title": "In Short",
        "text": [
          "I good results with classical pipeline",
          "I explicit connectives and arguments: adapted approach from detection",
          "of speculation and negation (Velldal et al. 2012, Read et al. 2012)",
          "I cross-validation on training set",
          "I sense disambiguation: ensemble classifier",
          "I F1 27.77 on English blind test set"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Architecture",
        "text": [
          "Non-Explicit Relation Detection Non-Explicit Argument Ranking Non-Explicit Sense Classification",
          "Figure : OPT system overview."
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/1236-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Explicit Connective Detection",
        "text": [
          "I extends the work by Velldal et al. (2012) for identifying expressions of",
          "I disambiguate closed class list of connectives (heads only)",
          "I binary SVMlight classifier"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Classifier Features",
        "text": [
          "I token and POS n-grams around the candidate (up to",
          "I parent, sibling, path, etc. features over PTB-style parse trees",
          "I feature tuning by ten-fold cross-validation on training set",
          "I final model selection (among some thousand runs):",
          "I prefer smaller models with less variation across folds",
          "I test twelve candidate models against development set",
          "I surface features up to 3 tokens before/after candidate",
          "I full feature conjunction for self and parent categories",
          "I limited conjunctions for siblings",
          "I no connected context"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Explicit Connective Identification Results",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Arguments",
        "text": [
          "I based on work on the scope of speculation and negation (Read et al.,",
          "I assumption: arguments basically correspond to phrases",
          "I extract clausal constituents: S, SBAR, SQ",
          "I SVMlight classifiers; ten-fold cross-validation on training set"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Argument Position",
        "text": [
          "Table : Position of Arg2 relative to Arg1.",
          "I non-explicit relations: Arg1 is in previous sentence (PS) from Arg2",
          "I explicit relations: classifier for PS or same sentence (SS)",
          "I path from connective to root",
          "I connective position in sentence (tertiles)",
          "I POS bigram of connective and following token"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "7": {
        "title": "Argument Candidate Ranking",
        "text": [
          "I ordinal ranking of clausal constituents",
          "I iteratively build a pool of feature types",
          "Exp. PS Exp. SS Non-Exp.",
          "Arg1 Arg2 Arg1 Arg2 Arg1 Arg2",
          "Path to Initial Token",
          "Table : Feature types used to describe candidate constituents for argument ranking."
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1236-Table2-1.png"
        ]
      },
      "8": {
        "title": "Post Editing Heuristics",
        "text": [
          "Arg1 Arg2 Arg1 Arg2",
          "Table : Alignment of constituent yield with arguments (in SS or PS).",
          "I initial alignment of full constituent yield with arguments is low",
          "add conjunction (CC) preceding constituent (Arg1) cut clause headed by connective (Arg1, explicit, SS) cut constituent-final CC (Arg1) cut constituent-final wh-determiner (Arg1) cut constituent-initial CC (Arg2, explicit) cut relative clause, i.e. SBAR initiated by WHNP/WHADVP cut connective cut initial and final punctuation"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Argument Extraction Results",
        "text": [
          "WSJ Test Set Blind Set",
          "Arg1 Arg2 Both Arg1 Arg2 Both",
          "Table : Argument extraction results, no error propagation."
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1236-Table4-1.png"
        ]
      },
      "10": {
        "title": "Sense Classification",
        "text": [
          "I separate ensemble classifiers for explicit and non-explicit relations:",
          "Wang & Lan (2015)LSVC LIBLINEAR SVM classifier",
          "Wang & Lan (2015)XGBoost : decision trees with gradient boosting, same features",
          "I final prediction label picked from sum of individual classifier"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Sense Classification Results",
        "text": [
          "WSJ Test Set Blind Set",
          "System Exp Non-Exp All Exp Non-Exp All",
          "Table : Isolated results for sense classification (the bottom model was not part of the submission)."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Overall Results",
        "text": [
          "I WSJ test set and blind test set",
          "I compared to challenge in 2015 and 2016",
          "I error propagation, automatic parses"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "WSJ Test Set Blind Test Set",
        "text": [
          "Table : Per-component breakdown of system performance."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Take Home Messages",
        "text": [
          "I overall, the end-to-end problem is anything but solved",
          "I adaptation of constituent ranking good fit for argument identification",
          "I cross-validation has helped reduce over-fitting to WSJ data",
          "I classifier ensemble improves sense prediction (post-submission results)"
        ],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "15": {
        "title": "Non Explicit Relation Detection",
        "text": [
          "I non-explicit relation between sentences A and B, iff (PDTB):",
          "(i) A and B are adjacent,",
          "(ii) A and B are in the same paragraph,",
          "(iii) A and B are not linked by an explicit connective, and",
          "(iv) a coherence relation or an entity-based relation holds between them.",
          "I traverse sentence bigrams (i), (ii)",
          "I check for explicit connectives with Arg1 in PS (iii)",
          "I NoRel (0.6% in PDTB) and AltLex (1.5%) are currently ignored (iv)"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Non Explicit Relation Detection Results",
        "text": [
          "I module evaluation on gold standard explicit connectives"
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "OPT: Oslo-Potsdam-Teesside Pipelining Rules, Rankers, and Classifier Ensembles for Shallow Discourse Parsing"
  },
  "1238": {
    "slides": {
      "0": {
        "title": "Relations between ideas",
        "text": [
          "undocumented immigrants rivals illegal alien",
          "small government friends free market",
          "word alignment friends machine translation",
          "We have shown a framework to quantitatively",
          "describe relations between ideas.",
          "Anti-correlated Can we use them to effectively explore relations Correlated"
        ],
        "page_nums": [
          1,
          8,
          9,
          11,
          12,
          14,
          15,
          17
        ],
        "images": []
      },
      "1": {
        "title": "Main contributions",
        "text": [
          "First quantitative framework to systematically describe relations between ideas",
          "Demonstrate effective explorations with this framework on a wide range of datasets",
          "undocumented immigrants rivals illegal alien",
          "small government friends free market"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Using text to trace ideas",
        "text": [
          "Our focus is on relations between ideas.",
          "We will use standard approaches",
          "Topics from latent Dirichlet Hall et al. 2008 allocation Keywords (Blei et as al. ideas",
          "Keywords (Monroe et al.",
          "Culturomics, Michel et al. 2011"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Quantitatively describe relations between ideas",
        "text": [
          "Given a corpus of documents over time, each document consists of a set of ideas",
          "undocumented immigrants rivals illegal alien",
          "Cooccurrence does not capture which is winning or losing undocumented immigrants"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "Head to head",
        "text": [
          "immigrant, undocumented illegal, alien"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Friendship",
        "text": [
          "immigrant, undocumented obama, president"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1238-Figure4-1.png"
        ]
      },
      "6": {
        "title": "Arms race",
        "text": [
          "immigration, deportation republican, party"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Tryst",
        "text": [
          "immigration, deportation detainee, detention"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "8": {
        "title": "A wide range of datasets",
        "text": [
          "Newspapers and research articles as datasets"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "9": {
        "title": "Joint distributions",
        "text": [
          "Correlated, but many pairs in all four quadrants!"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "The strength of relations",
        "text": [
          "Strength = |PMI| |correlati o n",
          "Extreme pairs are the interesting ones!"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "Effectively explore relations between ideas",
        "text": [],
        "page_nums": [
          21,
          22,
          24
        ],
        "images": []
      },
      "12": {
        "title": "2 in trysts",
        "text": [],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1238-Figure4-1.png",
          "figure/image/1238-Figure6-1.png"
        ]
      },
      "13": {
        "title": "Top relations between ideas",
        "text": [
          "The relations between these topics are consistent with structural balance theory: the enemy of an enemy is a friend"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "14": {
        "title": "Effective explorations",
        "text": [
          "Rank among all relations",
          "federal, state afghanistan, taliban",
          "federal, state iran, lybia",
          "The interesting pair is ranked much higher according to our framework."
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "15": {
        "title": "Acl teaser",
        "text": [
          "machine translation rule,forest methods machine translation word alignment",
          "machine translation discourse (coherence) machine translation sentiment analysis"
        ],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1238-Figure9-1.png"
        ]
      },
      "16": {
        "title": "Visualization tool",
        "text": [],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "Friendships, Rivalries, and Trysts: Characterizing Relations between Ideas in Texts"
  },
  "1239": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "User attribute prediction from text is successful:",
          "I Gender (Burger et al. 2011 EMNLP)",
          "I Location (Eisenstein et al. 2010 EMNLP)",
          "I Personality (Schwartz et al. 2013 PLoS One)",
          "I Impact (Lampos et al. 2014 EACL)",
          "I Political Orientation (Volkova et al. 2014 ACL)",
          "I Mental Illness (Coppersmith et al. 2014 ACL)",
          "I Occupation (Preotiuc-Pietro et al. 2015 ACL)",
          "I Income (Preotiuc-Pietro et al. 2015 PLoS One)",
          "... and useful in many applications."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Political Ideology and Text",
        "text": [
          "Political ideology of a user is disclosed through language use",
          "I partisan political mentions or issues",
          "Previous CS/NLP research used data sets with user labels identified through:",
          "H1 Users are far more likely to be politically engaged",
          "H2 The prediction problem was so far over-simplified",
          "3. Lists of Conservative/Liberal users",
          "4. Followers of partisan accounts",
          "H4 Differences in language use exist between moderate and extreme users"
        ],
        "page_nums": [
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "2": {
        "title": "Data",
        "text": [
          "I specific of country and culture",
          "I our use case is US politics (similar to all previous work)",
          "I the major US ideology spectrum is Conservative Liberal",
          "I seven point scale",
          "We collect a new data set:",
          "I public Twitter handle with >100 posts",
          "Political ideology is reported through an online survey",
          "I only way to obtain unbiased ground truth labels (Flekova et al.",
          "I additionally reported age, gender and other demographics",
          "I full data for research purposes",
          "I aggregate for replicability",
          "I Twitter Developer Agreement & Policy VII.A4",
          "Twitter Content, and information derived from Twitter Content, may not be",
          "used by, or knowingly displayed, distributed, or otherwise made available to",
          "any entity to target, segment, or profile individuals based on [...] political",
          "I Study approved by the Internal Review Board (IRB) of the",
          "For comparison to previous work, we collect a data set:",
          "I follow liberal/conservative politicians on Twitter"
        ],
        "page_nums": [
          7,
          8,
          9,
          11
        ],
        "images": []
      },
      "3": {
        "title": "Class Distribution",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Hypotheses",
        "text": [
          "H1 Previous studies used users far more likely to be politically engaged",
          "H2 The prediction problem was so far over-simplified",
          "H3 Neutral users can be identified",
          "H4 Differences in language use exist between moderate and extreme users"
        ],
        "page_nums": [
          12,
          18,
          25,
          28
        ],
        "images": []
      },
      "5": {
        "title": "Engagement",
        "text": [
          "H1 Previous studies used users far more likely to be politically engaged",
          "I Political words (234)",
          "I Political NEs: mentions of politician proper names (39)",
          "I Media NEs: mentions of political media sources and",
          "Data set obtained using previous methods",
          "Political word usage across user groups",
          "Average percentage of political word usage",
          "I 3x more political terms for automatically identified users",
          "compared to the highest survey-based scores",
          "I almost perfectly symmetrical U-shape across all three",
          "types of political terms"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "Over simplification",
        "text": [
          "H2 The prediction problem was so far over-simplified",
          "Topics Political Terms Domain Adaptation",
          "ROC AUC, Logistic Regression, 10-fold cross-validation",
          "Predicting continuous political leaning (1 7)",
          "Unigrams LIWC Topics Emotions Political All",
          "Pearson R between predictions and true labels, Linear Regression,",
          "GR Logistic regression with Group Lasso regularisation"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "7": {
        "title": "Neutral Users",
        "text": [
          "Words associated with either Words associated with neutral extreme conservative or liberal users",
          "Correlations are age and gender controlled. Extreme groups are combined using matched age and gender distributions."
        ],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1239-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Political Engagement",
        "text": [
          "H3a There is a separate dimension of political engagement",
          "Unigrams LIWC Topics Emotions Political All",
          "Pearson R between predictions and true labels, Linear Regression, 10 fold-cross validation"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "9": {
        "title": "Moderate Users",
        "text": [
          "H4 Differences between moderate and extreme users",
          "Words associated with moderate",
          "Words associated with extreme",
          "correlation strength relative frequency",
          "Correlations are age and gender controlled"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "10": {
        "title": "Take Aways",
        "text": [
          "I User-level trait acquisition methodologies can generate",
          "I Goes beyond binary classes",
          "I The problem was to date over-simplified",
          "I New data set available for research",
          "I New model to identify political leaning and engagement"
        ],
        "page_nums": [
          30
        ],
        "images": []
      }
    },
    "paper_title": "Beyond Binary Labels: Political Ideology Prediction of Twitter Users"
  },
  "1241": {
    "slides": {
      "0": {
        "title": "Background Personalized Machine Translation",
        "text": [
          "The language we produce reflects our personality",
          "Demographics: gender, age, geography etc.",
          "Personality: extraversion, agreeableness, openness, conscientiousness, neuroticism (the Big Five)",
          "Authorial traits affect our perception of the content we face",
          "We may have a preference to a specific authorial style",
          "Preserving authorial traits in manual and machine translation (Mirkin et al., 2015)",
          "Predicting users translation preference (Mirkin and Meunier, 2015)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Background Authorial Gender",
        "text": [
          "Male and female speech differs, to an extent distinguishable by automatic",
          "Male speakers use nouns and numerals more frequently",
          "associated with the alleged information emphasis",
          "Female prominent signals include verbs and pronouns",
          "e.g., we as a marker of group identity"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Research Questions",
        "text": [
          "Are the prominent authorial signals preserved through translation?",
          "Human (a translator involved) and machine translation",
          "Can machine-translation models be adapted to better preserve authorial traits?",
          "Are authorial traits in translated text retained from the source?",
          "Do they differ from those of the target language?",
          "We focus on SMT adaptation to better preserve authorial gender markers through automatic translation",
          "ERS ANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Datasets",
        "text": [
          "Europarl - proceedings of the European Parliament",
          "Automatically annotated1 for speaker gender and age using:",
          "Wikidata (manually curated dataset)",
          "Michael Cramer instance of: human",
          "(Germany) sex or gender: male position held: member of the European parliament",
          "Genderize.io (based on persons first name and country)",
          "Alchemy vision (image classification for gender)",
          "Estimated accuracy of gender annotation in the dataset is 99.8%",
          "Based on an evaluation against the Wikidata ground truth"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Datasets cont",
        "text": [
          "English-French corpus of IWSLT 2014 Evaluation Campaigns MT track",
          "Annotated for speaker gender (Mirkin et al., 2015)",
          "additional (not annotated) data 1.7M 1.5M",
          "# of sentences by M speakers 140K",
          "* the numbers refer to sentences originally uttered in the source language"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Personalized MT Approach",
        "text": [
          "Personalization as a domain-adaptation task",
          "Gender-specific model components (TM and LM)",
          "Baseline model disregarding the gender information",
          "A single TM and LM is built using male, female and unlabeled data",
          "Tuning is done using a random sample of sentences"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Personalized MT Models",
        "text": [
          "MT-PERS1: a single system with 3 TMs and 3 LMs trained on male (M), female (F) and additional unlabeled data",
          "The model was tuned using the gender-specific tuning set",
          "Resulting in 2 sub-models that differ in their tuning",
          "ERS G ORIGINAL AUTHOR TRAITS"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Personalized MT Models cont",
        "text": [
          "MT-PERS2: two separate systems, each one comprising gender-specific",
          "(M or F), as well as unlabeled TM and LM",
          "Both models were tuned using the gender-specific tuning set"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "MT Evaluation Results BLEU",
        "text": [
          "Phrase-based SMT Moses (Koehn et al., 2007)",
          "Language modeling done using KenLM (Heafield, 2011)",
          "5-gram LMs with Kneser-Ney smoothing",
          "Personalized models do not harm MT quality"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Preserving Gender Traits Evaluation",
        "text": [
          "Binary (M vs F) classification of each model output",
          "Features: frequencies of function words and POS-trigrams",
          "Classification units: random chunks of 1K tokens",
          "Inline with Schler et al., 2006 (classified blog posts)",
          "Gender classification at small units, e.g., sentence, is practically impossible",
          "Linear SVM classifier, 10-fold cross-validation evaluation"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Preserving Gender Traits Results",
        "text": [
          "Binary classification using function words and top-1000 POS-trigrams",
          "en O en O",
          "fr O en-fr HT",
          "fr-en MT-baseline en-fr MT-PERS1",
          "fr-en MT-PERS1 en-fr MT-PERS2",
          "ERS RESERVIG ORIGNAL AUHOR TRITS",
          "* similar results obtained for en-de and de-en translations"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16
        ],
        "images": []
      },
      "11": {
        "title": "Analysis Gender Markers",
        "text": [
          "Are gender markers of the original language preserved in translation?",
          "Distribution of individual gender markers varies between languages",
          "English: must is a male marker",
          "French: doit and doivent are more frequent in female speech",
          "English: we exhibits nearly equal frequencies in male and female texts",
          "German: wir is a prominent female marker",
          "Translations tend to embrace gender tendencies of the original language",
          "Resulting in a hybrid outcome where M and F traits are affected both by markers of the source and (to a much lesser extent) the target language"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Analysis cont",
        "text": [],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Summary",
        "text": [
          "Author gender is strongly marked in original texts",
          "This signal is obfuscated in human and machine translation",
          "Simple personalized SMT models using standard domain adaptation techniques offer a good approach for preserving gender traits in automatic translation",
          "State-of-the-art NMT models for personalization in translation",
          "Additional domains, datasets and language-pairs",
          "Additional authorial traits, e.g., age"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Personalized Machine Translation: Preserving Original Author Traits"
  },
  "1246": {
    "slides": {
      "0": {
        "title": "Objectives",
        "text": [
          "Study the practices of the NLP (Spoken,",
          "Written and Sign Language) community regarding reuse and plagiarism",
          "Check whether there is a meaningful difference in taking the verbatim raw word strings compared with applying natural language processing methods to detect possible cases of reuse and plagiarism?"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "NLP4NLP Corpus",
        "text": [
          "Presently conduct large scholar analysis of NLP domain",
          "Production, Collaboration, Citation, Innovation",
          "Major conferences (ACL, IEEE-ICASSP, ISCA-Interspeech,",
          "ELRA-LREC, etc.) and Journals (IEEE-TASLP, CL,",
          "SpeechCom, CSAL, LRE, etc.)",
          "558 Venues (conferences) / Issues (journals)",
          "short name # docs format long name language access to content period # venues",
          "acl conference Association for Computational Linguistics Conference English open access *",
          "acmtslp journal ACM Transaction on Speech and Language Processing English private access",
          "alta conference Australasian Language Technology Association English open access *",
          "anlp conference Applied Natural Language Processing English open access *",
          "cath journal Computers and the Humanities English private access",
          "cl journal American Journal of Computational Linguistics English open access *",
          "coling conference Conference on Computational Linguistics English open access *",
          "conll conference Computational Natural Language Learning English open access *",
          "csal journal Computer Speech and Language English private access eacl conference European Chapter of the ACL English open access * emnlp conference Empirical methods in natural language processing English open access * hlt conference Human Language Technology English open access *",
          "icassps conference IEEE International Conference on Acoustics, Speech and Signal Processing - Speech Track English private access ijcnlp conference International Joint Conference on NLP English open access * inlg conference International Conference on Natural Language Generation English open access * isca conference International Speech Communication Association English open access jep conference Journees d'Etudes sur la Parole French open access * lre journal Language Resources and Evaluation English private access lrec conference Language Resources and Evaluation Conference English open access * ltc conference Language and Technology Conference English private access modulad journal Le Monde des Utilisateurs de L'Analyse des Donnees French open access mts conference Machine Translation Summit English open access muc conference Message Understanding Conference English open access * naacl conference North American Chapter of ACL English open access *",
          "paclic conference Pacific Asia Conference on Language, Information and Computation English open access * ranlp conference Recent Advances in Natural Language Processing English open access * sem conference Lexical and Computational Semantics / Semantic Evaluation English open access * speechc journal Speech Communication English private access tacl journal Transactions of the Association for Computational Linguistics English open access * tal journal Revue Traitement Automatique du Langage French open access taln conference Traitement Automatique du Langage Naturel French open access * taslp journal IEEE/ACM Transactions on Audio, Speech and Language Processing English private access tipster conference Tipster DARPA text program English open access * trec conference Text Retrieval Conference English open access Total incl. duplicates Total excl. duplicates"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Definitions",
        "text": [
          "Self-plagiarism: copy & paste when the source of the copy has at least one author who belongs to the group of authors of the text of the paste, but when the source is not cited.",
          "Reuse: copy & paste when the source of the copy has no author in the group of authors of the paste and when the source is cited.",
          "Plagiarism: copy & paste when the source of the copy has no author in the group of the paste and when the source is not cited.",
          "Source paper is quoted Source paper is not quoted",
          "At least one author in common",
          "No author in common Reuse Plagiarism"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Each year Papers of the focus borrowing papers of the search",
        "text": [
          "Focus NLP4NLP (Same year or previous years)",
          "Self-Reusing Self-Plagiarizing Reusing Plagiarizing"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Each year Papers of the focus being borrowed by papers of",
        "text": [
          "Focus NLP4NLP (Same year or following years)",
          "Self-Reused Self-Plagiarized Reused Plagiarized"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Algorithm",
        "text": [
          "Based on comparison of word sequences, had to be optimized:",
          "For each pair of documents D1 of the focus (LREC) and D2 of the search space",
          "either raw text or text after LP (Tagparser [Francopoulo 2007] with Global Atlas + LRE Map)",
          "Orthographic variations (British English versus American English)",
          "Spelling errors Abbreviations (BNC versus British National Corpus)",
          "Compare 2 texts D1 / D2 using sliding windows of (5-7) lemmas (excluding punctuations)",
          "Compute a similarity overlapping score [Lyon et al 2001] between documents D1 and D2, with (a variant of) the Jaccard similarity coefficient Score (D1,D2) = #shared windows / #union (D1 windows, D2 windows) Filter the pairs of documents D1 / D2 according to a threshold of (0.03-0.04) coverage) to retain only significantly similar pairs"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Raw text versus LP",
        "text": [
          "Strategy Backward study Forward study document pairs# after document pairs# document pairs# duplicate pruning",
          "2. Linguistic processing (LP)"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Tuning Parameters",
        "text": [
          "+ Number of shared windows > 50"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Example of IEEE ICASSP 2001",
        "text": [],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "9": {
        "title": "Example of similarities between 2 papers couple 18",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Self Reuse Plagiarism",
        "text": [
          "In 61% of the cases, authors do not quote the source paper",
          "130 papers have both the same title and the same list of authors",
          "205 papers have the same title",
          "Some specific cases (largest similarities)",
          "Republishing the corrigendum of a previously published paper",
          "Republishing a paper with a small difference in the title and one missing author in the authors list",
          "Same research center described by the same author in two different conferences, with an overlapping of 90%",
          "2 papers presented by the same author in 2 successive conferences, the difference being primarily in the name of the 2 systems being presented, that have been funded by the same project agency in 2 different contracts, with an overlapping of 45%",
          "Used Using acl acmtslp alta anlp cath cl coling conll csal eacl emnlp hlt icassps ijcnlp inlg isca jep lre lrec ltc modulad mts muc naacl paclic ranlp sem speechc tacl tal taln taslp tipster trec",
          "Total used Total using Difference",
          "anlp anlp cath cath cl cl coling coling conll conll csal csal eacl eacl emnlp emnlp hlt hlt icassps icassps ijcnlp ijcnlp inlg inlg isca isca jep jep lre lre lrec lrec ltc ltc modulad modulad mts mts muc muc naacl naacl paclic paclic ranlp ranlp sem sem speechc speechc tacl tacl tal tal taln taln taslp taslp tipster tipster trec trec Total using"
        ],
        "page_nums": [
          14,
          16
        ],
        "images": []
      },
      "11": {
        "title": "Similarity Scores Self Reuse Plagiarism",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Reuse and Plagiarism",
        "text": [
          "261 cases : manual checking",
          "25 have a least one author in common, but with a somehow different spelling, and should therefore be placed in the Self- plagiarism category",
          "14 correctly quote the source paper, but with variants in the spelling of the authors names, of the papers title or of the conference or journal source, or correctly citing the source paper but forgetting to place it among the references, and should therefore be placed in the Reuse category.",
          "After manual corrections: 224 cases (0.33% of papers)",
          "In 52% of the cases, authors do not quote the source paper",
          "This results in 117 possible cases of plagiarism (0.17%):",
          "The copying paper cites another reference from the same authors of the source paper",
          "(typically a previous reference, or a paper published in a Journal) (46 cases)",
          "Both papers use extracts of a third paper that they both cite (31 cases)",
          "Authors of the two papers are different, but from same laboratory (typical in industrial laboratories or funding agencies) (11 cases)",
          "Authors of the two papers previously co-authored papers (typically as supervisor and PhD student or postdoc) but are now in different laboratories (11 cases)",
          "Authors of the papers are different, but collaborated in the same project which is presented in the two papers (2 cases) The two papers present the same short example, result or definition coming from another source (13 cases) Only 3 remaining cases of possible plagiarism: same paper as a patchwork of 3 other papers, while sharing several references with them.",
          "Used Using acl acmtslp alta anlp cath cl coling conll csal eacl emnlp hlt icassps ijcnlp inlg isca jep lre lrec ltc modulad mts muc naacl paclic ranlp sem speechc tacl tal taln taslp tipster trec",
          "Total used Total using Difference",
          "anlp anlp cath cath cl cl coling coling conll conll csal csal eacl eacl emnlp emnlp hlt hlt icassps icassps ijcnlp ijcnlp inlg inlg isca isca jep jep lre lre lrec lrec ltc ltc modulad modulad mts mts muc muc naacl naacl paclic paclic ranlp ranlp sem sem speechc speechc tacl tacl tal tal taln taln taslp taslp tipster tipster trec trec Total using"
        ],
        "page_nums": [
          17,
          20,
          22
        ],
        "images": []
      },
      "13": {
        "title": "Variants in Spelling Authors Name",
        "text": [
          "Non-Linear Probability Estimation Method",
          "Used in HMM for Modeling Frame Correlation",
          "Qing Guo, Fang Zheng, Jian Wu, and Wenhu Wu",
          "An New Method Used in HMM for Modeling",
          "Guo Qing, Zheng Fang, Wu Jian and Wu Wenhu"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Variants in Spelling References",
        "text": [
          "Quoted Reference: Graham W. (2007) an OWL",
          "Ontology for HPSG proceeding of the ACL 2007",
          "Correct Reference: Graham Wilcock (2007), An",
          "OWL Ontology for HPSG",
          "Quoted Reference: Li Liu, Jianglong He, On the use of orthogonal GMM in speaker verification",
          "Correct Reference: Li Liu and Jialong He, On the use of orthogonal GMM in speaker recognition"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "15": {
        "title": "Similarity Scores Reuse Plagiarism",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "16": {
        "title": "Time Delay Publication Reuse 122 years on average",
        "text": [],
        "page_nums": [
          23
        ],
        "images": []
      },
      "17": {
        "title": "Time Delay Publication in Conferences Reuse in Journals 207 years on average",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "18": {
        "title": "Self Plagiarism or Fair Use",
        "text": [
          "(Pamela Samuelson, Comm. of ACM 1994)",
          "The previous work must be restated to lay the groundwork for a new contribution in the second work,",
          "Portions of the previous work must be repeated to deal with new evidence or arguments,",
          "The audience for each work is so different that publishing the same work in different places is necessary to get the message out,",
          "The authors think they said it so well the first time that it makes no sense to say it differently a second time.",
          "30% as an upper limit in the reuse of parts of a previously published paper.",
          "Only 1.3% of NLP4NLP papers go beyond this limit"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "19": {
        "title": "Plagiarism Right to Quote",
        "text": [
          "National legislations usually embody the Berne convention limits in one or more of the following requirements:",
          "the cited paragraphs are within a reasonable limit,",
          "<= 10% of the copied / copying papers in France / Canada",
          "Only 0.05% of NLP4NLP papers go beyond this limit",
          "the cited paragraphs are clearly marked as quotations and fully referenced, the resulting new work is not just a collection of quotations, but constitutes a fully original work in itself.",
          "the copied paragraphs must have a function in the goal of the copying paper."
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [
          "Produce results on the study of copy & paste operations on corpora of NLP archives of very large size, using NLP methods",
          "still represents a practical computing limitation.",
          "Self-reuse and self-plagiarism are common practices (18%)",
          "40% happen on same year (no way to detect beforehand)",
          "No quote of source paper in 60% of the cases (75% if same year)",
          "Natural flow from conferences to journals",
          "Current tendency for salami-slicing publications caused by the publish-and-perish demand",
          "Plagiarism very uncommon in the NLP community (<0.05%)",
          "Ethically acceptable if principles are respected"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "21": {
        "title": "Further developments",
        "text": [
          "Process rogeting: replacing words with synonymous alternatives",
          "Study the position and rhetorical structure of the copy & paste in order to identify and justify their function.",
          "Explore whether copy & paste is more common for non native-English speakers",
          "publish first in their native language, then in English in an international conference or an international journal, in order to broaden their audience"
        ],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "A Study of Reuse and Plagiarism in Speech and Natural Language Processing papers"
  },
  "1248": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Processing long, complex sentences is hard!",
          "Children, people with reading disabilities, L2 learners",
          "Sentence level NLP systems:",
          "Koehn & Knowles, 2017 Can we automatically break a complex sentence into several simple ones while preserving its meaning?"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "The Split and Rephrase Task",
        "text": [
          "Narayan, Gardent, Cohen & Shimorina, EMNLP 2017",
          "Dataset, evaluation method, baseline models",
          "Task definition: complex sentence -> several simple sentences with the same meaning",
          "Alan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as back up pilot and David Scott as commander .",
          "Alan Bean served as a crew member of Apollo 12 . Alfred Worden was the backup pilot of Apollo 12 . Apollo 12 was commanded by David Scott . Alan Bean was selected by Nasa in 1963",
          "Requires (a) identifying independent semantic units (b) rephrasing those units to single sentences"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "2": {
        "title": "This Work",
        "text": [
          "We show that simple neural models seem to perform very on the original benchmark due to memorization of the training set",
          "We propose a more challenging data split for the task to discourage memorization",
          "We perform automatic evaluation and error analysis on the new benchmark, showing that the task is still far from being solved"
        ],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "3": {
        "title": "WebSplit Dataset Construction",
        "text": [
          "<Alan_Bean | nationality | United_States, Alan_Bean | mission | Apollo_12, Alan_Bean | NASA selection | 1963> A lan Bean, born in the United St tes, was selected Alan Bean, born in the United States, was selected Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of by NASA in 1963 and served as a crew member o f by NASA in 1963 and served Apollo as 12. a crew member of Apollo 12. Apollo 12.",
          "(facts from DBpedia) Simple Sentences",
          "A lan Bean is a US national. A lan Bean is a US national. Alan Bean is a US national.",
          "<Alan_Bean | mission | Apollo_12> Alan Bean was on the crew of Apollo 12. A lan Bean was on the crew of Apollo 12. Alan Bean was on the crew of Apollo 12.",
          "<Alan_Bean | NASA selection | 1963> A lan Bean was hired by NASA in 1963. Alan Bean was hired by NASA in 1963. Alan Bean was hired by NASA in 1963.",
          "Sets of RDF triples Complex Sentences",
          "Matching via RDFs ~1M examples"
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "4": {
        "title": "Preliminary Experiments",
        "text": [
          "Vanilla LSTM seq2seq with attention",
          "sim ple sim ple simple",
          "comp lex sen ten ce",
          "Shared vocabulary between the encoder and the decoder",
          "Simple sentences predicted as a single sequence",
          "Evaluated using single-sentence, multi-reference BLEU as in Narayan et al. 2017"
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "5": {
        "title": "Preliminary Results",
        "text": [
          "Our simple seq2seq baseline outperform all but one of the baselines from",
          "seq2seq (ours) seq2seq split-multi hybrid multi-seq2seq split-seq2seq",
          "Text Only Text + RDFs",
          "Their best baselines were using the RDF structures as additional information",
          "Do the simple seq2seq model really performs so well? seq2seq (ours) seq2seq split-multi"
        ],
        "page_nums": [
          33,
          34,
          35,
          36
        ],
        "images": []
      },
      "6": {
        "title": "BLEU can be Misleading",
        "text": [
          "In spite of the high BLEU scores, our neural models suffer from:",
          "Missing facts - appeared in the input but not in the output",
          "Unsupported facts - appeared in the output but not in the input",
          "Repeated facts - appeared several times in the output"
        ],
        "page_nums": [
          37,
          38,
          39,
          40,
          41
        ],
        "images": [
          "figure/image/1248-Table3-1.png"
        ]
      },
      "7": {
        "title": "A Closer Look",
        "text": [
          "Visualizing the attention weights we find an unexpected pattern",
          "The network mainly attends to a single token instead of spreading the attention",
          "This token was usually a part of the first mentioned entity",
          "Consistent among different input examples"
        ],
        "page_nums": [
          42,
          43,
          44,
          45,
          46,
          47,
          48
        ],
        "images": [
          "figure/image/1248-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Testing for Over Memorization",
        "text": [
          "In this stage we suspect that the network heavily memorizes entity-fact pairs",
          "We test this by introducing it with inputs consisting of repeated entities alone",
          "The network indeed generates facts it memorized about those specific entities"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "9": {
        "title": "Searching for the Cause Dataset Artifacts",
        "text": [
          "The original dataset included overlap between the training/development/test sets",
          "When looking at the complex sentences side, there is no overlap",
          "On the other hand, most of the simple sentences did overlap (~90%)",
          "Dev Dev Complex Simple",
          "Complex Train Simple target",
          "Test Test Complex Simple",
          "Makes memorization very effective leakage from train on the target side"
        ],
        "page_nums": [
          54,
          55,
          56,
          57,
          58
        ],
        "images": []
      },
      "10": {
        "title": "New Data Split",
        "text": [
          "To remedy this, we construct a new data split by using the RDF information:",
          "Ensuring that all RDF relation types appear in the training set (enable generalization)",
          "Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)",
          "The resulting dataset has no overlapping simple sentences",
          "Original Split New Split unique dev simple sentences in train unique test simple sentences in train",
          "% dev vocabulary in train",
          "% test vocabulary in train",
          "Has more unknown symbols in dev/test need better models!"
        ],
        "page_nums": [
          59,
          60,
          61,
          62,
          63,
          64
        ],
        "images": []
      },
      "11": {
        "title": "Copy Mechanism",
        "text": [
          "To help with the increase in unknown words in the harder split, we incorporate a copy mechanism",
          "Uses a copy switch - feed-forward NN component with a sigmoid-activated scalar output",
          "Controls the interpolation of the softmax probabilities and the copy probabilities over the input tokens in each decoder step",
          "copy switch attention weights (copy) 1 - copy switch softmax output"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69
        ],
        "images": []
      },
      "12": {
        "title": "Results New Split",
        "text": [
          "Baseline seq2seq models completely break (BLEU < on the new split",
          "original split new split",
          "Copy mechanism helps to generalize",
          "Much lower than the original benchmark - memorization was crucial for the high BLEU"
        ],
        "page_nums": [
          70,
          71,
          72,
          73
        ],
        "images": []
      },
      "13": {
        "title": "Copying and Attention",
        "text": [],
        "page_nums": [
          74,
          75
        ],
        "images": []
      },
      "14": {
        "title": "Error Analysis",
        "text": [
          "On the original split the models did very well (due to memorization) with up to 91% correct simple sentences correct missing repeated unsupported",
          "original split new split",
          "On the new benchmark the best model got only up to",
          "The task is much more challenging then previously demonstrated"
        ],
        "page_nums": [
          76,
          77,
          78,
          79
        ],
        "images": []
      },
      "15": {
        "title": "Conclusions",
        "text": [
          "Simple neural models seem to perform well due to memorization",
          "We propose a more challenging data split for the task to discourage this",
          "A similar update was proposed by Narayan et al. in parallel to our work",
          "We perform automatic evaluation and error analysis on the new benchmarks, showing that the task is still far from being solved"
        ],
        "page_nums": [
          80,
          81,
          82,
          83,
          84
        ],
        "images": []
      },
      "16": {
        "title": "More Broadly",
        "text": [
          "Creating datasets is hard!",
          "Think how models can cheat\"",
          "Create a challenging evaluation environment to capture generalization",
          "Look for leakage of train to dev/test",
          "Numbers can be misleading!",
          "Look at the data",
          "Look at the model"
        ],
        "page_nums": [
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93
        ],
        "images": []
      }
    },
    "paper_title": "Split and Rephrase: Better Evaluation and a Stronger Baseline"
  },
  "1249": {
    "slides": {
      "0": {
        "title": "Writing Systems Hierarchy",
        "text": [
          "phonogram segmental alphabet can"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Writing Systems Population",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Writing Systems How to Input",
        "text": [
          "Logogram > Syllabic Abugida Alphabet & Abjad"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Motivation of This Study",
        "text": [
          "Can abugidas be inputted more efficiently?",
          "To insert a light layer of input method",
          "To type less and to recover automatically",
          "Various approaches for Chinese and Japanese",
          "To take advantage of redundancy in a writing system"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Abugida Simplification",
        "text": [
          "Thai, Burmese (Myanmar), Khmer (Cambodian), and Lao",
          "Based on phonetics / conventional usages reduced to 21 symbols",
          "GUTTURAL PALATE DENTAL LABIAL",
          "I I I I II NAS. APP. R-LIKE S-LIKE H-LIKE ZERO-C. LONG-A",
          "TH MY KM LO",
          "Khmer script as an example",
          "J T N N",
          "Thai Burmese Khmer Lao",
          "Around one quarter characters ( ) saved"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": [
          "figure/image/1249-Figure3-1.png"
        ]
      },
      "5": {
        "title": "Recovery Methods",
        "text": [
          "To formulate as a sequential labeling task",
          "However, list-wise search as in conditional random fields is costing",
          "To solve by point-wise classification",
          "Support vector machine (SVM) as a baseline",
          "Recurrent neural network (RNN) as a state-of-the-art method",
          "Setting for the SVM baseline",
          "Linear kernel with N-gram features",
          "Wrapped by the KyTea toolkit"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "RNN Structure and Settings",
        "text": [
          "Bi-gram of graphemes as input",
          "Embedding Bi-directional LSTM Linear transform Softmax",
          "Original writing units as output",
          "softmax Implemented by DyNet",
          "Trained by Adam 512-dim.",
          "Initial learning rate 0.001",
          "Controlled by a validation set",
          "Multi-model ensemble input J T N N"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1249-Figure4-1.png"
        ]
      },
      "7": {
        "title": "Experimental Results",
        "text": [
          "Asian Lang. Treebank data",
          "Up to 5-gram for TH, KM, LO",
          "Top-4 is satisfactory Embedding + bi-LSTM > N-gram features"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1249-Table2-1.png"
        ]
      },
      "8": {
        "title": "Experimental Results Training Data Size",
        "text": [
          "Number of graphemes after simplification",
          "RNN outperforms SVM, regardless of the training data size"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Manual Evaluation",
        "text": [
          "On Burmese and Khmer best results by RNN",
          "To classify errors into four-level",
          "0. acceptable, i.e., alternative spelling",
          "1. clear and easy to identify the correct result",
          "2. confusing but possible to identify the correct result"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1249-Table3-1.png"
        ]
      },
      "10": {
        "title": "Conclusion and Future Work",
        "text": [
          "Abugidas can be simplified largely and recovered with high accuracy",
          "Four Brahmic abugidas are investigated",
          "Simplified into a compact symbol set (around 20 graphemes)",
          "Recovered satisfactorily by standard machine learning method",
          "Experimentally show the feasibility to encode abugidas in a lossy manner",
          "To develop practical input method for abugidas"
        ],
        "page_nums": [
          14
        ],
        "images": []
      }
    },
    "paper_title": "Simplified Abugidas"
  },
  "1250": {
    "slides": {
      "0": {
        "title": "Overview Research question",
        "text": [
          "Can orthographic (spelling) information enable better word translations in low-resource contexts?",
          "Languages with common ancestors and/or borrowing exhibit increased lexical similarity",
          "Spelling of words can carry signal for translation",
          "Low-resource pairs are most in need of additional signal"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Overview Task and general approach",
        "text": [
          "Bilingual lexicon induction: single-word translations",
          "Operate on word embeddings",
          "Haghigi et al. (2008): orthographic features",
          "Mikolov et al. (2013): word2vec, linear mapping"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Baseline Artetxe et al 2017",
        "text": [
          "Start with dictionary D (inferred from numerals)",
          "Learn matrix W minimizing Euclidean distance between target (Z) and mapped source (XW) embeddings of pairs in D",
          "Use nearest neighbors as entries in new dictionary"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Baseline Artetxe et al 2017 Problems",
        "text": [
          "Language English Word Baselines Prediction Reference",
          "German unevenly gleichmaig (evenly) ungleichmaig",
          "German Ethiopians Afrikaner (Africans) Athiopier",
          "Italian autumn primavera (spring) autunno",
          "Finnish Latvians ukrainalaiset (Ukrainians) latvialaiset",
          "Suffers from clustering problems present in word2vec",
          "Similar distributions similar embeddings",
          "Hints of correct translation present in spelling"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Proposed modifications",
        "text": [
          "Use normalized edit distance in nearest-neighbor calculation",
          "During dictionary induction, distances between similarly-spelled words are reduced",
          "Extend embedding vectors with character counts",
          "Extend vectors with scaled counts of letters in both languages alphabets (scale constant k",
          "Word d1 d2 aba"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Quantitative results",
        "text": [
          "English Word Translation Accuracy",
          "German Italian Target Language Finnish",
          "Best when combined; largest contribution from embedding extension",
          "Improvement less pronounced for English-Finnish (linguistic dissimilarity)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Qualitative results",
        "text": [
          "Language English Word Baselines Prediction Our Prediction",
          "German unevenly gleichmaig (evenly) ungleichmaig",
          "German Ethiopians Afrikaner (Africans) Athiopier",
          "Italian autumn primavera (spring) autunno",
          "Finnish Latvians ukrainalaiset (Ukrainians) latvialaiset",
          "Use orthographic information to disambiguate semantic clusters",
          "Significant gains in adequacy"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Conclusion",
        "text": [
          "Orthographic information can improve unsupervised bilingual lexicon induction, especially for language pairs with high lexical similarity.",
          "These techniques can be incorporated into other embedding-based frameworks."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Results with Identity",
        "text": [
          "English Word Translation Accuracy w/ Identity",
          "German Italian Target Language Finnish"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Proof of optimal W",
        "text": [
          "W = arg min DijXiW Zj2",
          "= arg min XiW (DZ )i2",
          "= arg max Tr(XWZD) W"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Proof of optimal W continued",
        "text": [
          "W = arg max Tr(XWZD)",
          "= arg max Tr(ZDXW",
          "= arg max Tr(UV W [UV SVD(ZDX",
          "= arg max Tr(V WU)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      }
    },
    "paper_title": "Orthographic Features for Bilingual Lexicon Induction"
  },
  "1251": {
    "slides": {
      "0": {
        "title": "Reading Comprehension",
        "text": [
          "The task: to answer questions given a passage of text",
          "Childrens Book Test [Hill et al. 2016]",
          "NarrativeQA [Kocisky et al."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Race",
        "text": [
          "Passage: My father wasnt a king, he was a taxi driver, but",
          "I met Blandy at a party and he asked if Id like to buy the island. Of course I said yes but I had no money-I was just an art teacher. I tried to find some business partners, who all thought I was crazy. So I sold some of my possessions, put my savings together and bought it ...",
          "Question: How did the author get the island?",
          "a. It was a present from Blandy. b. The king sold it to him. c. He bought it from Blandy. d. He inherited from his father.",
          "Challenge: to jointly model passage, question and candidate answers"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Related Work",
        "text": [
          "Converted to sequence pair matching [Yin et al., 2016]",
          "Each candidate answer is concatenated with the question",
          "The concatenated sequences are matched against the passage",
          "b. ranking scores give meaningful representations for questions like Which statement of the following",
          "Question and answers are not clearly separated. Interaction information between a question and an answer d. is lost.",
          "Matching sequences pair by pair [Lai et al., 2017]",
          "Match passage and question first",
          "Then this representation is used to match candidate answers",
          "Q-specific passage representation matching Limitation: a. Matching P & Q may not"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "Our Solution",
        "text": [
          "Co-match each sentence in the passage with the question and the candidates answers separately.",
          "Make use of the alignments between sequences as follows:",
          "Question: How did the author get the island?",
          "Candidate Answer: He bought it from Blandy",
          "Hierarchically aggregate the co-matching representations of",
          "(sentence, question, answer) triplets for final scoring."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Co Matching",
        "text": [
          "For every word in sentence, we match it with the attention-weighted vectors computed based on the question and the candidate answer, respectively.",
          "Question: How did the author get the island?",
          "Candidate Answer: He bought it from Blandy"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Framework",
        "text": [
          "Question 1st Sentence Candidate of Passage answer ACL 2018",
          "Representation for ranking candidates",
          "2nd Sentence ACL 2018 Nth Sentence of Passage of Passage"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "6": {
        "title": "Experiments",
        "text": [
          "Our Hier-Co-Matching achieved the best performance compared with previous work.",
          "We studied two key factors:",
          "(1) the co-matching module",
          "(2) the hierarchical aggregation approach"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1251-Table2-1.png"
        ]
      },
      "7": {
        "title": "Conclusions",
        "text": [
          "We proposed a hierarchical co-matching model for answering multi-choice reading comprehension questions.",
          "We showed that our model could achieve state-of-the-art performance on the RACE dataset.",
          "There is still much room for improvement on RACE given the low absolute performance.",
          "Latest results by OpenAI: 59%"
        ],
        "page_nums": [
          10
        ],
        "images": []
      }
    },
    "paper_title": "A Co-Matching Model for Multi-choice Reading Comprehension"
  },
  "1252": {
    "slides": {
      "0": {
        "title": "Lexical Relations",
        "text": [
          "Task: Graded lexical entailment",
          "To what degree is X a type of Y?",
          "girl person guest person person guest",
          "Useful for query expansion, natural language inference, paraphrasing, machine translation, etc.",
          "Distributional vectors are not great for directional lexical relations",
          "carrot vegetable new old",
          "BUT these mostly affect words that are in the training data"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Main Idea",
        "text": [
          "Specialized network for directional lexical relations",
          "Train the network to discover task-specific regularities in the embeddings"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Supervised Directional Similarity Network",
        "text": [
          "Fixed pre-trained word embeddings as input",
          "Predict a score indicating the strength of a specific lexical relation"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1252-Figure1-1.png"
        ]
      },
      "3": {
        "title": "SDSN Gating",
        "text": [],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1252-Figure1-1.png"
        ]
      },
      "4": {
        "title": "SDSN Mapping",
        "text": [],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1252-Figure1-1.png"
        ]
      },
      "5": {
        "title": "SDSN Sparse Features",
        "text": [
          "Features based on sparse distributional representations",
          "ratio of shared contexts"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1252-Figure1-1.png"
        ]
      },
      "6": {
        "title": "SDSN Scoring",
        "text": [
          "Mapping the representations to a score"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1252-Figure1-1.png"
        ]
      },
      "7": {
        "title": "HyperLex Graded Lexical Entailment",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "HyperNet Hyponym Detection",
        "text": [
          "eo x se @ RS"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "Can train a neural network to find specific regularities in off-the-shelf word embeddings",
          "Traditional sparse embeddings still provide complementary information",
          "Achieves state-of-the-art on graded lexical entailment"
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "Scoring Lexical Entailment with a Supervised Directional Similarity Network"
  },
  "1253": {
    "slides": {
      "0": {
        "title": "Gender bias in NLP systems",
        "text": [
          "Coreference resolution systems are biased:",
          "Even though the doctor reassured the nurse, she was worried.",
          "Word embeddings carry biases:"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "This shouldnt come as a surprise our data is biased",
        "text": [
          "Google n-grams frequency counts",
          "she is a doctor"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "2": {
        "title": "Our focus stereotypes in language modeling Lu et al 2018",
        "text": [
          "Training data counts are visible as likelihoods under a language model: stereotype m f",
          "m He is a good doctor. He is a good nurse. pronoun f She is a good doctor. She is a good nurse.",
          "For every sentence with she/he: e.g., She is a nurse. add that sentence with he/she for training: e.g., He is a nurse.",
          "Now they should yield a balanced model!"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "3": {
        "title": "Agreement or what if German",
        "text": [
          "m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger. pronoun f Sie ist eine gute Arztin. Sie ist eine gute Krankenpflegerin.",
          "So, uh, can we just... change all words grammatical gender?",
          "Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)",
          "Swap all: Die Arztin sitzt auf einer Stuhl (The female doctor sits on a... what?)",
          "No, what we need is..."
        ],
        "page_nums": [
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "4": {
        "title": "Syntax to the rescue use dependency parses",
        "text": [
          "Der gute Arzt sitzt auf einem Stuhl",
          "Only words connected in the dependency parse should change!",
          "Build a MRF over morphological tags along the dependency parse!",
          "M ; SG;NOM M ;SG; NOM M ;SG; NOM",
          "learned from data, neural factors",
          "manual dampening staywhat not learned, they were boosts before tags intervention that",
          "F SG;NOM F ;SG; NOM F ;SG; NOM"
        ],
        "page_nums": [
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          34,
          35,
          36,
          37,
          38
        ],
        "images": [
          "figure/image/1253-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Recap what is a Markov Random Field Koller and Friedman 2009",
        "text": [
          "Model p(x y, z) by decomposing into factors",
          "Every factor gives a score to certain assignments:",
          "Add up all factors to obtain global score: score(x y z",
          "Get p by global normalization (easy in trees): p(x y z exp score(x y z"
        ],
        "page_nums": [
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "6": {
        "title": "Reinflect tokens to obtain the CDA sentence",
        "text": [
          "Get the new sentence by performing morphological reinflection where tags changes:",
          "(this is a reasonably well-working procedure, established in three shared tasks at SIGMORPHON and CoNLL)",
          "Die gute Arztin sitzt auf einem Stuhl",
          "F SG;NOM F ;SG; NOM F ;SG; NOM"
        ],
        "page_nums": [
          39,
          40,
          41,
          42
        ],
        "images": []
      },
      "7": {
        "title": "Intrinsic evaluation how good are we at gender swapping Hebrew Spanish",
        "text": [
          "We manually annotated over 100 sentences for each language and checked performance:",
          "P R F1 Acc Acc"
        ],
        "page_nums": [
          43,
          44,
          45,
          46,
          47
        ],
        "images": [
          "figure/image/1253-Table4-1.png"
        ]
      },
      "8": {
        "title": "Extrinsic evaluation train language models on C balanced data then evaluate",
        "text": [
          "p(Der gute Arzt x) m log log",
          "p(Die gute Arztin x) ok",
          "Gender Bias 4 2",
          "Esp Fra Heb Ita Esp Fra Heb Ita",
          "p(Der gute Arztin x) bad"
        ],
        "page_nums": [
          48,
          49,
          50,
          51,
          52
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "1. As so often, things that are easy in English...",
          "...become surprisingly hard in other languages.",
          "2. Old-school probabilistic models often work well enoughTM",
          "3. And, always, careful with your training data, Eugene!"
        ],
        "page_nums": [
          53,
          54,
          55,
          56
        ],
        "images": []
      }
    },
    "paper_title": "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology"
  },
  "1261": {
    "slides": {
      "0": {
        "title": "Semantic Graphs",
        "text": [
          "WordNet-like resources are curated to describe relations between word senses",
          "The graph is directed",
          "Edges have form <S, r, T>: <zebra, is-a, equine>",
          "Still, some relations are symmetric"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Semantic Graphs Relation Prediction",
        "text": [
          "The task of predicting relations (zebra is a <BLANK>)",
          "Local models use embeddings-based composition for scoring edges",
          "Translational Embeddings (transE) [Bordes et al. 2013]",
          "Problem: task-driven method can learn unreasonable graphs"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Incorporating a Global View",
        "text": [
          "We want to avoid unreasonable graphs",
          "Imposing hard constraints isnt flexible enough",
          "Only takes care of impossible graphs",
          "We still want the local signal to matter - its very strong.",
          "Our solution: an additive, learnable global graph score",
          "Score(<zebra, hypernym, equine>| WordNet) =",
          "slocal(edge) + (sglobal(WN edge), sglobal(WN))"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Global Graph Score",
        "text": [
          "Based on a framework called Exponential Random Graph Model (ERGM)",
          "The score sglobal(WN) is derived from a log-linear distribution across possible graphs that have a fixed number n of nodes",
          "OK. What are the features?"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Graph Features Motifs",
        "text": [],
        "page_nums": [
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "5": {
        "title": "Graph Motifs multiple relations",
        "text": [
          "(some) joint blue/orange motifs:"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "6": {
        "title": "ERGM Training",
        "text": [
          "Estimating the scores for all possible graphs to obtain a probability distribution is implausible",
          "Number of possible directed graphs with n nodes: O(exp(n2))",
          "Estimation begins to be hard at ~n=100 for R=1. In WordNet: n = 40K, R",
          "Unlike other structured problems, theres no known dynamic programming algorithm either",
          "What can we do?",
          "Decompose score over dyads (node pairs) in graph",
          "Draw and score negative sample graphs"
        ],
        "page_nums": [
          19,
          20,
          21
        ],
        "images": []
      },
      "7": {
        "title": "Max Margin Markov Graph Model M3GM",
        "text": [
          "Sample negative graphs from the local neighborhood of the true WN",
          "Loss = Max {0, 1 + score(negative sample)",
          "Its important to choose an appropriate proposal distribution (source of the negative samples)",
          "We want to make things hard for the scorer"
        ],
        "page_nums": [
          22,
          23,
          24,
          25,
          26,
          27,
          28
        ],
        "images": [
          "figure/image/1261-Table4-1.png"
        ]
      },
      "8": {
        "title": "Evaluation",
        "text": [
          "No reciprocal relations (hypernym hyponym)",
          "Still includes symmetric relations",
          "Rule baseline - take symmetric if exists in train",
          "Used in all models as default for symmetric relations DistMult",
          "Synset embeddings - averaged from FastText",
          "M3GM (re-rank top 100 from local)",
          "Metrics - MRR, H@10 transE"
        ],
        "page_nums": [
          29,
          30,
          31
        ],
        "images": []
      },
      "9": {
        "title": "Relation Prediction WN18RR",
        "text": [
          "Rule-based ComplEx Conv* transE | w/ M3GM"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "10": {
        "title": "Feature Analysis",
        "text": [
          "Motifs with heavy positive weights:",
          "Motifs with heavy negative weights:",
          "Target of both has_part and verb_group",
          "Seen in training data",
          "Derivations occur in the abstract parts of the graph",
          "(bodega canteen vs. shop)"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37,
          38
        ],
        "images": []
      },
      "11": {
        "title": "Future Work",
        "text": [
          "Multilingual transfers of semantic graphs align embeddings / translate concepts",
          "Can we introduce global features to help?"
        ],
        "page_nums": [
          39,
          40,
          41
        ],
        "images": []
      },
      "12": {
        "title": "Conclusion",
        "text": [
          "Global reasoning of graph features is beneficial for relation prediction",
          "Works well on top of strong local models",
          "Applicable to large graphs with dozens of relation types M3GM",
          "Orthogonal of word / synset embedding techniques",
          "Finds a wide variety of linguistic patterns in semantic graphs"
        ],
        "page_nums": [
          42
        ],
        "images": []
      }
    },
    "paper_title": "Predicting Semantic Relations using Global Graph Properties"
  },
  "1262": {
    "slides": {
      "0": {
        "title": "Time Expression Analysis",
        "text": [
          "the third quarter of 1984"
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/1262-Table3-1.png"
        ]
      },
      "1": {
        "title": "Time Expression Analysis Datasets",
        "text": [
          "TimeBank: a benchmark dataset used in TempEval series",
          "Gigaword: a large dataset with generated labels and used in TempEval-3",
          "WikiWars: a specific domain dataset collected from Wikipedia about war",
          "Tweets: a manually labeled dataset with informal text collected from Twitter",
          "Statistics of the datasets",
          "Dataset #Docs #Words #TIMEX",
          "The four datasets vary in source, size, domain,",
          "and text type, but we will see that their time",
          "expressions demonstrate similar characteristics."
        ],
        "page_nums": [
          3
        ],
        "images": [
          "figure/image/1262-Table3-1.png",
          "figure/image/1262-Table1-1.png",
          "figure/image/1262-Table2-1.png"
        ]
      },
      "2": {
        "title": "Time Expression Analysis Finding 1",
        "text": [
          "Short time expressions: time expressions are very short.",
          "80% of time expressions contain 3 words",
          "Average length of time expressions",
          "Time expressions follow a similar length distribution Average length: about 2 words"
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1262-Figure1-1.png",
          "figure/image/1262-Table2-1.png"
        ]
      },
      "3": {
        "title": "Time Expression Analysis Finding 2",
        "text": [
          "Occurrence: most of time expressions contain time token(s).",
          "Example time tokens (red):",
          "Percentage of time expressions that",
          "the third quarter of"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1262-Table3-1.png"
        ]
      },
      "4": {
        "title": "Time Expression Analysis Finding 3",
        "text": [
          "Small vocabulary: only a small group of time words are used to",
          "Number of distinct words and time tokens in time expressions",
          "Dataset #Words #Time tokens",
          "Number of distinct words and time tokens across four datasets next year #Words #Time tokens years year yrs ago 45 distinct time tokens appear in all the four datasets. That means, time expressions highly overlap at their time tokens. Overlap at year"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1262-Table3-1.png",
          "figure/image/1262-Table1-1.png"
        ]
      },
      "5": {
        "title": "Time Expression Analysis Finding 4",
        "text": [
          "Similar syntactic behaviour: (1) POS information cannot",
          "distinguish time expressions from common text, but (2) within time expressions, POS tags can help distinguish their constituents.",
          "(1) For the top 40 POS tags (10 4 datasets), 37 have percentage lower than",
          "(2) Time tokens mainly have NN* and RB, modifiers have JJ and RB, and numerals have CD."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Time Expression Analysis Eureka",
        "text": [
          "Similar syntactic behaviour: (1) POS information cannot",
          "distinguish time expressions from common text, but (2) within time expressions, POS tags can help distinguish their constituents.",
          "(1) For the top 40 POS tags (10 4 datasets), 37 have percentage lower than",
          "(2) Time tokens mainly have NN* and RB, modifiers have JJ and RB, and numerals have CD.",
          "When seeing (2), we realize that this is exactly how linguists define part-of-speech for",
          "language; similar words have similar syntactic behaviour. The definition of part-of-speech",
          "for language inspires us to define a type system for the time expression, part of language."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Time Expression Analysis Summary",
        "text": [
          "On average, a time expression contains two tokens; one is time token and the other is modifier/numeral. And the time tokens are in small size.",
          "To recognize a time expression, we first recognize the time token, then recognize the modifier/numeral."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Time Expression Analysis Idea",
        "text": [
          "On average, a time expression contains two tokens; one is time token and the other is modifier/numeral. And the time tokens are in small size.",
          "To recognize a time expression, we first recognize the time token, then recognize the modifier/numeral.",
          "20 days; this week; next year; July 29;"
        ],
        "page_nums": [
          10,
          11,
          12
        ],
        "images": []
      },
      "9": {
        "title": "Time Expression Recognition",
        "text": [],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1262-Table5-1.png"
        ]
      },
      "10": {
        "title": "Time Expression Recognition SynTime",
        "text": [
          "Syntactic token types A type system",
          "Time token: explicitly express time information, e.g., year",
          "15 token types: DECADE, YEAR, SEASON, MONTH, WEEK, DATE, TIME, DAY_TIME, TIMELINE,",
          "HOLIDAY, PERIOD, DURATION, TIME_UNIT, TIME_ZONE, ERA",
          "Modifier: modify time tokens, e.g., next modifies year in next year",
          "5 token types: PREFIX, SUFFIX, LINKAGE, COMMA, IN_ARTICLE",
          "Numeral: ordinals and numbers, e.g., 10 in next 10 years",
          "1 token type: NUMERAL",
          "Token types to tokens is like POS tags to words",
          "POS tags: next/JJ 10/CD years/NNS",
          "Token types: next/PREFIX 10/NUMERAL years/TIME_UNIT",
          "Only relevant to token types",
          "Independent of specific tokens"
        ],
        "page_nums": [
          14,
          15,
          16
        ],
        "images": []
      },
      "11": {
        "title": "SynTime Layout",
        "text": [
          "Type level Time Token, Modifier, Numeral",
          "Token level: time-related tokens and token regular expressions",
          "Type level: token types group the tokens and token regular expressions",
          "Rule level: heuristic rules work on token types and are independent of specific tokens"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "SynTime Overview in practice",
        "text": [
          "defined token types and",
          "do not change any rules Identify time tokens",
          "Import token regex to time",
          "numerals by expanding the"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1262-Figure3-1.png"
        ]
      },
      "13": {
        "title": "An example the third quarter of 1984",
        "text": [
          "A sequence of tokens: the third quarter of",
          "Assign tokens with token types PREFIX NUMERAL TIME_UNIT PREFIX YEAR",
          "Identify modifiers and numerals by",
          "searching time tokens surroundings",
          "A sequence of token types PREFIX NUMERAL TIME_UNIT PREFIX YEAR",
          "Export a sequence of tokens",
          "as time expression the third quarter of"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "14": {
        "title": "Time Expression Recognition Experiments",
        "text": [
          "SynTime-E: Expanded version, adding keywords to SynTime-I",
          "(Add keywords under the defined token types and do not change any rules.)",
          "TimeBank: comprehensive data in formal text",
          "WikiWars: specific domain data in formal text",
          "Tweets: comprehensive data in informal text"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "15": {
        "title": "Overall performance",
        "text": [
          "borrowed from their original papers and the papers indicated by the references.",
          "SUTime(Chang and Manning, 2013)"
        ],
        "page_nums": [
          31
        ],
        "images": [
          "figure/image/1262-Table4-1.png"
        ]
      },
      "16": {
        "title": "Difference from other Rule based Methods",
        "text": [
          "Method SynTime Other rule-based methods",
          "Rule level Deterministic Rules Rule level",
          "Layout Type level Time Token, Modifier, Numeral",
          "Property Heuristic rules work on token types and are independent",
          "of specific tokens, thus they are independent of specific",
          "domains and specific text types and specific languages.",
          "Deterministic rules directly work on tokens and phrases",
          "in a fixed manner, thus the taggers lack flexibility",
          "the third quarter of"
        ],
        "page_nums": [
          32
        ],
        "images": []
      }
    },
    "paper_title": "Time Expression Analysis and Recognition Using Syntactic Token Types and General Heuristic Rules"
  },
  "1263": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "End-to-end dialog models based on encoder-decoder models have shown great promises for",
          "modeling open-domain conversations, due to its flexibility and scalability.",
          "Dialog History/Context System Response",
          "However, dull response problem! [Li et al 2015, Serban et al. 2016]. Current solutions include:",
          "Add more info to the dialog context [Xing et al 2016, Li et al 2016]",
          "Improve decoding algorithm, e.g. beam search [Wiseman and Rush 2016]",
          "User: I am feeling quite happy today. (previous utterances) sure I dont know Yes"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Our Key Insights",
        "text": [
          "Response generation in conversation is a ONE-TO-MANY mapping problem at the discourse",
          "A similar dialog context can have many different yet valid responses.",
          "Learn a probabilistic distribution over the valid responses instead of only keep the most likely"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Our Contributions",
        "text": [
          "Present an E2E dialog model adapted from Conditional Variational Autoencoder",
          "Enable integration of expert knowledge via knowledge-guided CVAE.",
          "Improve the training method of optimizing CVAE/VAE for text generation."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Conditional Variational Auto Encoder CVAE",
        "text": [
          "C is dialog context",
          "B: Do you like cats? A: Yes I do",
          "Z is the latent variable (gaussian)",
          "X is the next response",
          "B: So do I.",
          "Trained by Stochastic Gradient Variational",
          "Bayes (SGVB) [Kingma and Welling 2013]"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": [
          "figure/image/1263-Figure2-1.png"
        ]
      },
      "4": {
        "title": "Knowledge Guided CVAE kgCVAE",
        "text": [],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1263-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Training of kgCVAE",
        "text": [
          "I like cats </s>",
          "like cats pe eee",
          "dialog act 1 * ' | Utterance Encoder",
          "eeeeee {__} Context Encoder",
          "al (__) Response Decoder |",
          "<> like Xbow ! Conversation Floor"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1263-Figure3-1.png"
        ]
      },
      "6": {
        "title": "Testing of kgCVAE",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Optimization Challenge",
        "text": [
          "Training CVAE with RNN decoder is hard due to the vanishing latent variable problem",
          "RNN decoder can cheat by using LM information and ignore Z!",
          "Bowman et al. [2015] described two methods to alleviate the problem :",
          "KL annealing (KLA): gradually increase the weight of KL term from 0 to 1 (need early stop).",
          "Word drop decoding: setting a proportion of target words to 0 (need careful parameter"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "BOW Loss",
        "text": [
          "Predict the bag-of-words in the responses X at once (word counts in the response)",
          "Break the dependency between words and eliminate the chance of cheating based on LM.",
          "z x RNN Loss",
          "c xwo FF Bag-of-word Loss"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "9": {
        "title": "Dataset",
        "text": [
          "Data Name Switchboard Release 2",
          "Number of context-response pairs",
          "Vocabulary Size Top 10K",
          "Dialog Act Labels 42 types, tagged by SVM and human",
          "Number of Topics 70 tagged by humans"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Quantitative Metrics",
        "text": [
          "Ref resp1 Hyp resp 1",
          "Ref resp Mc Hyp resp N",
          "d(r, h) is a distance function [0, 1] to measure the similarity between a reference and a hypothesis."
        ],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "11": {
        "title": "Distance Functions used for Evaluation",
        "text": [
          "Smoothed Sentence-level BLEU (1/2/3/4): lexical similarity",
          "Cosine distance of Bag-of-word Embeddings: distributed semantic similarity.",
          "(pre-trained Glove embedding on twitter)",
          "a. Average of embeddings (A-bow)",
          "b. Extrema of embeddings (E-bow)",
          "Dialog Act Match: illocutionary force-level similarity",
          "a. (Use pre-trained dialog act tagger for tagging)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Models trained with BOW loss",
        "text": [
          "Encoder Sampling Decoder Baseline",
          "Encoder z Greedy Decoder kgCVAE"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Quantitative Analysis Results",
        "text": [
          "Note: BLEU are normalized into [0, 1] to be valid precision and recall distance function"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "14": {
        "title": "Qualitative Analysis",
        "text": [
          "Topic: Recycling Context: A: are they doing a lot of recycling out in Georgia?",
          "Target (statement): well at my workplace we have places for aluminium cans",
          "Baseline + Sampling kgCVAE + Greedy",
          "1. well Im a graduate student and have two kids.",
          "2. well I was in last year and so weve had lots of recycling.",
          "2. (statement) oh youre not going to have a curbside pick up here.",
          "3. Im not sure. 3. (statement) okay I am sure about a recycling center.",
          "4. well I dont know I just moved here in new york. 4. (yes-answer) yeah so."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "15": {
        "title": "Latent Space Visualization",
        "text": [
          "Visualization of the posterior Z on the test",
          "dataset in 2D space using t-SNE.",
          "Assign different colors to the top 8 frequent",
          "The size of circle represents the response",
          "Exhibit clear clusterings of responses w.r.t the"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1263-Figure5-1.png"
        ]
      },
      "16": {
        "title": "The Effect of BOW Loss",
        "text": [
          "Same setup on PennTree Bank for LM",
          "Model Perplexity KL Cost",
          "Goal: low reconstruction loss + small but non-trivial KL cost BOW+KLA"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "KL Cost during Training",
        "text": [
          "Standard model suffers from vanishing",
          "KLA requires early stopping.",
          "BOW leads to stable convergence",
          "The same trend is observed on CVAE."
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1263-Figure6-1.png"
        ]
      },
      "18": {
        "title": "Conclusion and Future Work",
        "text": [
          "Identify the ONE-TO-MANY nature of open-domain dialog modeling",
          "Propose two novel models based on latent variables models for generating diverse yet",
          "Explore further in the direction of leveraging both past linguistic findings and deep models",
          "for controllability and explainability.",
          "Utilize crowdsourcing to yield more robust evaluation.",
          "Code available here! https://github.com/snakeztc/NeuralDialog-CVAE"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "19": {
        "title": "Training Details",
        "text": [
          "Word Embedding 200 Glove pre-trained on Twitter",
          "Utterance Encoder Hidden Size",
          "Context Encoder Hidden Size",
          "Response Decoder Hidden Size",
          "Context Window Size 10 utterances",
          "Optimizer Adam learning rate=0.001"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "20": {
        "title": "Testset Creation",
        "text": [
          "Use 10-nearest neighbour to collect similar context in the training data",
          "Label a subset of the appropriateness of the 10 responses by 2 human",
          "bootstrap via SVM on the whole test set (5481 context/response)",
          "Resulting 6.79 Avg references responses/context",
          "Distinct reference dialog acts 4.2"
        ],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders"
  },
  "1264": {
    "slides": {
      "0": {
        "title": "Geolocation Prediction",
        "text": [
          "Predict a loca8on of a person",
          "My house is at",
          "Vancouver. Vancouver geoloca8on predic8on city name an SNS message"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Our Approach",
        "text": [
          "Geoloca8on predic8on with neural networks",
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Embedding\u0001",
          "City User W ord Em bedding\u0001 Embedding\u0001 Embedding\u0001",
          "Inpu ts m essages, metadata, and u ser network",
          "Atte ntionM\u0001 Text processes with AttentionL\u0001 AttentionD\u0001 AttentionN\u0001",
          "R NN+APen8on Timezone Embedding\u0001",
          "AttentionU\u0001 with APen 8on",
          "TEXT\u0001 Quite a comp lex"
        ],
        "page_nums": [
          2,
          3,
          4,
          5,
          6
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Geolocation Prediction Target",
        "text": [
          "A popular target in previous works (Cheng et al.,",
          "Ground-truth loca8ons with geotags"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "3": {
        "title": "Metadata",
        "text": [
          "Descrip8on, loca8on, 8mezone, etc.",
          "State-of-the-art performances combined with texts",
          "Descrip0on I work as a researcher at XXX",
          "Loca0on I live in Canada.",
          "TwiPer user Timezone America/Vancouver"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "User Network",
        "text": [
          "Men8on network, friend network, etc.",
          "Predic8on with label propaga8on",
          "State-of-the-art performances combined with texts",
          "Men8on user 1 Men8on user 2"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "5": {
        "title": "Model",
        "text": [
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Embedding\u0001",
          "City User Word Em bedding\u0001 Embedding\u0001 Embedding\u0001",
          "M essages Metadata User network"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "6": {
        "title": "TEXT Component 1",
        "text": [
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Embedding\u0001",
          "City User Word Em bedding\u0001 Embedding\u0001 Embedding\u0001"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "7": {
        "title": "TEXT Component 2",
        "text": [
          "features\u0001 user network representation\u0001",
          "Figure 2: Overview of the text component with",
          "representation\u0001 nent with a detail",
          "Layers wise addition and",
          "and h are concatenated to form g where gt",
          "ht ht and are passed to the first attention layer",
          "AttentionM. Recurrent Neural Network similarly to messa",
          "AttentionM computes a message representa- Specifically, GRU (Cho et al., 2014) AttentionM\u0001 attention layer. B",
          "(Self) APen8on tion m as a weighted sum of gt with weight t: tion and one descr",
          "tion laye r is not re RNNM\u0001",
          "APen8onM m tgt RNNM output pon ent. We also c",
          "exp vTut Mul8-layer Word Em bedding\u0001 amo ng the m essag",
          "Sofmax t Perceptron tion processes bec",
          "t exp (vT ut) information. For",
          "ut = tanh (W gt b) assigned f or each",
          "where v is a weight vector, W is a weight ma- and a description"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "TEXT and META Component",
        "text": [
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Text processes Embedding\u0001",
          "(singl e te xt) Embedding RNNM\u0001 RNNL\u0001 RNND\u0001",
          "City User Word Em bedding\u0001 Embedding\u0001 Embedding\u0001",
          "M essages Metadata (loca8on, d escrip8on mezone)"
        ],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "9": {
        "title": "USERNET Component 1",
        "text": [
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Embedding\u0001",
          "City User Word Em bedding\u0001 Embedding\u0001 Embedding\u0001"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "10": {
        "title": "USERNET Component 2",
        "text": [
          "Embedding for each user",
          "Embedding for each ground-truth city of a user City User",
          "unknown for unavailable cases",
          "APen8on over N users",
          "linked user 1\u0001 User current Network\u0001 linked user\u0001 user N\u0001"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Unified Processes",
        "text": [
          "AttentionTL\u0001 USERNET\u0001 User network",
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 Timezone Embedding\u0001",
          "City User Word Em bedding\u0001 Embedding\u0001 Embedding\u0001"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1264-Figure1-1.png"
        ]
      },
      "12": {
        "title": "Data 1",
        "text": [
          "Uni-direc8onal men8on network (Rahimi et al.,",
          "Dataset users + one-hop users",
          "Set undirected edges for men8ons",
          "Bob set edge Bob"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Data 2",
        "text": [
          "* Restricted edges to sa8sfy one of the following condi8ons:",
          "Both users have ground truth loca8ons.",
          "One user has a ground truth loca8on and another user is men8oned 5 8mes or more."
        ],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/1264-Table1-1.png"
        ]
      },
      "14": {
        "title": "Baselines and Sub models",
        "text": [
          "LR X logistic (Rahimi regression, et al. 2015a) k-d tree",
          "MADCEL-B-LR X X logistic regression, k-d tree,",
          "LR-STACK X X X logistic regression, k-d tree, stacking, Modified Adsorption",
          "SUB-NN-UNET X X TEXT, USERNET",
          "SUB-NN-META X X TEXT&META",
          "Proposed Model X X X Full model"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "15": {
        "title": "Metrics",
        "text": [
          "Accuracy The percentage of correctly predicted cities.",
          "A within relaxed 161 accuracy km as correct that takes predictions. prediction errors",
          "Median Error Distance* Median value of error distances in predictions.",
          "Error Distance = 94km",
          "* Error distance evalua8ons are excluded from this presenta8on for simplifica8on."
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Results TwiPerUS",
        "text": [
          "accuracy@161 * significant improvement with 5% significance level"
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1264-Table2-1.png"
        ]
      },
      "17": {
        "title": "Results W NUT",
        "text": [
          "Baselines (reported)\u0001 Jayasinghe et al. (2016)",
          "accuracy@161 ** significant improvement with 1% significance level"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1264-Table4-1.png"
        ]
      },
      "18": {
        "title": "Analysis of Attention layers 1",
        "text": [
          "Analysis of APen8on layers (1)",
          "TwiPerUS pro bability FCUN\u0001 densit y func8ons AttentionUN\u0001 FCU\u0001",
          "AttentionTL\u0001 Timeline & USERNET\u0001",
          "Atte ntionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezo ne description\u0001 timezone\u0001 Metadata Embedd ing\u0001 RNNM\u0001 RNNL\u0001 RNND\u0001 City User W ord Em bedding\u0001 Embedding\u0001 Embedding\u0001"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": [
          "figure/image/1264-Figure1-1.png",
          "figure/image/1264-Figure5-1.png",
          "figure/image/1264-Figure4-1.png"
        ]
      },
      "19": {
        "title": "Analysis of Attention layers 2",
        "text": [
          "Analysis of APen8on layers (2)",
          "probability FCUN\u0001 density func8on",
          "Attention TL\u0001 User&UserNetw oUSrEkRNET\u0001",
          "AttentionM\u0001 AttentionL\u0001 AttentionD\u0001 AttentionN\u0001 Timezone Embedding\u0001 RNNM\u0001 RNNL\u0001 RNND\u0001",
          "City User W ord Em bedding\u0001 Embedding\u0001 Embedding\u0001"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": [
          "figure/image/1264-Figure1-1.png",
          "figure/image/1264-Figure5-1.png",
          "figure/image/1264-Table7-1.png"
        ]
      },
      "20": {
        "title": "Conclusion",
        "text": [
          "Proposed a neural network model for geoloca8on predic8on",
          "text metadata user network",
          "Improvement over previous state-of-the art models",
          "Analysis of aPen8on probabili8es:",
          "Capturing sta8s8cal characteris8cs of the datasets"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "21": {
        "title": "Future Works",
        "text": [
          "An extension of the proposed model",
          "Introduc8on of temporal state",
          "Capture loca8on changes like travel",
          "Applica8on to different tasks",
          "For example, gender analysis or age analysis",
          "Some metadata may not be effec8ve"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "22": {
        "title": "Attention Patterns",
        "text": [
          "Clustering of APen8onU and APen8onUN",
          "k-means with 9 clusters",
          "Cluster 2 and Cluster 3 balancing Timeline and Loca8on",
          "TwitterUS\u0001 TwitterUS\u0001 W-NUT\u0001 W-NUT\u0001",
          "TwitterUS\u0001 TwitterUS\u0001 W-NUT\u0001 TwitterUS\u0001 W-NUT\u0001"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "23": {
        "title": "Errors with High Confidences",
        "text": [
          "Loca8on Field: Hong Kong",
          "Perhaps, a house move",
          "Twee8ng about San Francisco"
        ],
        "page_nums": [
          46
        ],
        "images": []
      },
      "24": {
        "title": "Model Configuration 1",
        "text": [
          "Attention context vector size\u0001",
          "Max tweet number per user\u0001"
        ],
        "page_nums": [
          47
        ],
        "images": [
          "figure/image/1264-Table5-1.png"
        ]
      },
      "25": {
        "title": "Model Configuration 2",
        "text": [],
        "page_nums": [
          48
        ],
        "images": []
      },
      "26": {
        "title": "Training Time",
        "text": [
          "GeForce GTX Titan X"
        ],
        "page_nums": [
          49
        ],
        "images": []
      }
    },
    "paper_title": "Unifying Text, Metadata, and User Network Representations with a Neural Network for Geolocation Prediction"
  },
  "1265": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "A story or statement whose truth value is unverified or deliberately false",
          "The fake news went viral",
          "indicates the level of influence.",
          "Start from a grass-roots users, promoted by some influential accounts, widely spread"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": [
          "figure/image/1265-Figure1-1.png"
        ]
      },
      "1": {
        "title": "Motivation",
        "text": [
          "We generally are not good at distinguishing rumors",
          "It is crucial to track and debunk rumors early to minimize their harmful effects.",
          "Online fact-checking services have limited topical",
          "coverage and long delay.",
          "Existing models use feature engineering over simplistic;",
          "or recently deep neural networks ignore propagation structures."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Contributions",
        "text": [
          "Represent information spread on Twitter with propagation",
          "tree, formed by harvesting users interactions, to capture high-order propagation patterns of rumors.",
          "Propose a kernel-based data-driven method to generate",
          "relevant features automatically for estimating the similarity between two propagation tees.",
          "Enhance the proposed model by considering propagation",
          "paths from source tweet to subtrees to capture the context of transmission.",
          "Release two real-world twitter datasets with finer-grained"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Related Work",
        "text": [
          "Systems based on common sense and investigative",
          "Learning-based models for rumor detection",
          "Using handcrafted and temporal features: Liu et al. (2015), Ma",
          "Using recurrent neural networks: Ma et al. (2016)",
          "Tree kernel: syntactic parsing (Collins and Duffy, 2001)",
          "Semantic analysis (Moschitti, 2004)",
          "Relation extraction (Zhang et al., 2008)",
          "Machine translation (Sun et al., 2010)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Problem Statement",
        "text": [
          "Given a set of microblog posts R = {}, model each source",
          "tweet as a tree structure T = < , >, where each node provide the creator of the post, the text content and post time. And is directed edges corresponding to response relation.",
          "Task 1 finer-grained classification for each source post",
          "false rumor, true rumor, non-rumor, unverified rumor",
          "Task 2 detect rumor as early as possible"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1265-Figure3-1.png"
        ]
      },
      "5": {
        "title": "Propagation Structure",
        "text": [
          "O: Walmart donates $10,000 to support Darren Wilson and the on going racist police murders Propagatio",
          "n tree U6: Need proof of U1: You don't honestly this-can't find any... believe that, do you?",
          "U7: not sure....sorry I U2: i honestly do see a meme trending but no proof...perhaps U3: Sam Walton gave 300k to Obama's campaign? THINK.",
          "if we had real journalists? U5: where is the credible link? U8: I'm pretty good at research-I think this is not U4: Sam Walton was dead before #Obama was born. He have wired campaign",
          "true-plenty of other reasons to boycott WalMart. :)",
          "donation from heavens. Jing Ma (CUHK)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Observation and Hypothesis",
        "text": [
          "(a) In rumors Influence/Popularity (b) In non-rumors",
          "Network-based signals (e.g., relative influence) and",
          "Our hypothesis: high-order patterns needs to/could be",
          "captured using kernel method"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1265-Figure2-1.png"
        ]
      },
      "7": {
        "title": "Traditional Tree Kernel TK",
        "text": [
          "TK compute the syntactic similarity between two sentences",
          "by counting the common subtrees",
          "common subtrees rooted at and"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1265-Figure3-1.png"
        ]
      },
      "8": {
        "title": "Propagation Tree Kernel PTK",
        "text": [
          "Existing tree kernel cannot apply here, since in our case (1) node is a vector of continuous numerical values; (2) similarity needs to be softly defined between two trees instead of hardly counting on identical nodes"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Propagation Tree Kernel",
        "text": [
          "Given two trees and >PTK compute similarity between them by enumerating all similar subtrees.",
          "and are similar node pairs from and respectively",
          "similarity of two subtrees rooted at and",
          "Sub-tree 1) if or are leaf nodes, then"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "10": {
        "title": "Context Sensitive Extension of PTK",
        "text": [
          "Consider propagation paths from root node to the subtree",
          "PTK ignores the clues outside the subtrees and the route embed how the",
          "Similar intuition to context-sensitive tree kernel (Zhou et al., 2007)",
          ": the length of propagation path from root to Context path",
          "1) if and are the x-th ancestor nodes of and ,then",
          "): similarity of subtrees rooted at and",
          "Kernel Algorithm Subtree root"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "11": {
        "title": "Rumor Detection via Kernel Learning",
        "text": [
          "Incorporate the proposed tree kernel functions (i.e., PTK or",
          "cPTK) into a supervised learning framework, for which we",
          "utilize a kernel-based SVM classifier.",
          "Avoid feature engineering the kernel function can explore",
          "an implicit feature space when calculating the similarity",
          "For multi-class task, perform One vs. all, i.e., building K (#",
          "of classes) basic binary classifiers so as to separate one class",
          "from all the others."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "12": {
        "title": "Data Collection",
        "text": [
          "Construct our propagation tree datasets based on two",
          "Convert event label: Extract popular",
          "source tweets revised labels binary -> quarternary",
          "(Source tweet: highly retweeted or replied) ( retweets: Twrench.com )",
          "( replies: Web crawler )"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Statistics of Data Collection",
        "text": [
          "URL of the datasets: https://www.dropbox.com/s/0jhsfwep3ywvpca/rumdetect2017.zip?dl=0"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Approaches to compare with",
        "text": [
          "DTR: Decision tree-based ranking model using enquiry phrases to identify trending rumors (Zhao et al., 2015)",
          "DTC and SVM-RBF: Twitter information credibility model using Decision Tree Classifier (Castillo et al., 2011); SVM-based model with RBF kernel (Yang et al., 2012)",
          "RFC: Random Forest Classifier using three parameters to fit the temporal tweets volume curve (Kwon et al., 2013)",
          "SVM-TS: Linear SVM classifier using time-series structures to model the variation of social context features. (Ma et al., 2015)",
          "GRU: The RNN-based rumor detection model. (Ma et al., 2016)",
          "BOW: linear SVM classifier using bag-of-words.",
          "Ours (PTK and cPTK): Our kernel based model",
          "PTK- and cPTK-: Our kernel based model with subset node features."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "15": {
        "title": "Results on Twitter15",
        "text": [
          "NR: Non-Rumor; FR: False Rumor;",
          "TR: True Rumor; UR: Unverified Rumor;",
          "NR FR TR UR"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Results on Twitter16",
        "text": [
          "NR: Non-Rumor; FR: False Rumor;",
          "TR: True Rumor; UR: Unverified Rumor;",
          "NR FR TR UR"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "17": {
        "title": "Results on Early Detection",
        "text": [
          "(a) Twitter15 DATASET (b) Twitter16 DATASET",
          "In the first few hours, the accuracy of the kernel-based methods climbs more rapidly and stabilize more quickly",
          "cPTK can detect rumors with 72% accuracy for Twitter15 and 69.0% for Twitter16 within 12 hours, which is much earlier than the baselines and the mean official report times"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1265-Figure4-1.png"
        ]
      },
      "18": {
        "title": "Early Detection Example",
        "text": [
          "Example subtree of a rumor captured by the algorithm at early stage of propagation",
          "Influential users boost its propagation, unpopular-to-popular information flow, Textual signals (underlined)"
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/1265-Figure5-1.png"
        ]
      },
      "19": {
        "title": "Conclusion and future work",
        "text": [
          "Apply kernel learning method for rumor debunking by utilizing the propagation tree structures.",
          "Propagation tree encodes the spread of a source tweet with complex structured patterns and flat information regarding content, user and time associated with the tree nodes.",
          "Our kernel are combined under supervised framework for identifying rumors of finer-grained levels by directly measuring the similarity among propagation trees.",
          "Explore network representation method to improve the rumor detection task.",
          "Develop unsupervised models due to massive unlabeled data from social media."
        ],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1265-Figure3-1.png"
        ]
      }
    },
    "paper_title": "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning"
  },
  "1266": {
    "slides": {
      "0": {
        "title": "Who cares",
        "text": [
          "word embeddings are useful!",
          "- inherently crosslingual tasks",
          "- crosslingual transfer learning",
          "bilingual signal for training",
          "- parallel corpora bilingual signal",
          "for training - comparable corpora - numerals (1, 2, 3)",
          "Previous work This talk",
          "- parallel corpora - 25 word dictionary bilingual signal"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "1": {
        "title": "Bilingual embedding mappings",
        "text": [
          "Basque English Seed dictionary",
          "Basque arg min English",
          "formalization and implementation details in the paper based on the mapping method of Artetxe et al. (2016)",
          "Too good to be true?"
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52
        ],
        "images": []
      },
      "2": {
        "title": "Experiments",
        "text": [
          "Dataset by Dinu et al. (2015) extended to German and Finnish",
          "Monolingual embeddings (CBOW + negative sampling)",
          "Seed dictionary: 5,000 word pairs / 25 word pairs / numerals",
          "Test dictionary: 1,500 word pairs",
          "Bi. data WS RG WS"
        ],
        "page_nums": [
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81
        ],
        "images": [
          "figure/image/1266-Figure2-1.png"
        ]
      },
      "3": {
        "title": "Why does it work",
        "text": [
          "Implicit objective: = arg max max s.t.",
          "Independent from seed dictionary!",
          "So why do we need a seed dictionary?",
          "Avoid poor local optima!"
        ],
        "page_nums": [
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117
        ],
        "images": [
          "figure/image/1266-Figure3-1.png"
        ]
      },
      "4": {
        "title": "Conclusions",
        "text": [
          "Simple self-learning method to train bilingual embedding mappings",
          "High quality results with almost no supervision (25 words, numerals)",
          "Implicit optimization objective independent from seed dictionary",
          "Seed dictionary necessary to avoid poor local optima",
          "Future work: fully unsupervised training"
        ],
        "page_nums": [
          118,
          119,
          120,
          121,
          122,
          123
        ],
        "images": []
      }
    },
    "paper_title": "Learning bilingual word embeddings with (almost) no bilingual data"
  },
  "1267": {
    "slides": {
      "0": {
        "title": "Semantic Parsing with Execution",
        "text": [
          "What nation scored the most points?",
          "Where Points is Max",
          "Christelle Le Duff France",
          "Charlotte Barras England England"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Indirect Supervision",
        "text": [
          "No gold programs during training",
          "What nation scored the most points?",
          "Where Points is Max",
          "Christelle Le Duff France",
          "Charlotte Barras England England"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Learning",
        "text": [
          "x: What nation scored the most points? y: Select Nation Where Index is Minimum neural models score(x, y): encode x, encode y, and produce scores",
          "Beamseach: argmax score(x, y)",
          "Find approximated gold meaning representations"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Semantic Parsing with Indirect Supervision",
        "text": [
          "Question: What nation scored the most points?",
          "Christelle Le Duff France"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Search for Training",
        "text": [
          "In general, there are several spurious programs that execute to the gold answer but are semantically incorrect."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Search for Training Spurious Programs",
        "text": [
          "Search for training. Goal: find semantically correct parse!",
          "Question: What nation scored the most points?",
          "Select Nation Where Points = 44 England",
          "Select Nation Where Index is Minimum England",
          "Select Nation Where Pts/game is Maximum England",
          "Select Nation Where Point is Maximum England",
          "All programs above generate right answers but only one is correct."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Update Step",
        "text": [
          "Generally there are several methods to update the model.",
          "Examples: maximum marginal likelihood, reinforcement learning, margin methods."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Contributions",
        "text": [
          "Policy Shaping for handling spurious programs",
          "Generalized Update Equation for generalizing common update strategies and allowing novel updates.",
          "(1) and (2) seem independent, but they interact with each other!!",
          "5% absolute improvement over SOTA on SQA dataset"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Learning from Indirect Supervision",
        "text": [
          "Question x, Table t, Answer z, Parameters",
          "[Search for Training] With x, t, z, beam search suitable ={y}",
          "[Update] Update , according K = {y}",
          "Search in training. Goal: finding semantically correct y",
          "[Update] Update , according {y}",
          "Many different ways of update"
        ],
        "page_nums": [
          10,
          26
        ],
        "images": []
      },
      "9": {
        "title": "Spurious Programs",
        "text": [
          "Question x, Table t, Answer z, Parameters",
          "[Search for Training] With x, t, z, beam search suitable {y}",
          "If the model selects a spurious program for update then it increases the chance of selecting spurious programs in future."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Policy Shaping",
        "text": [],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Search with Shaped Policy",
        "text": [
          "Question x, Table t, Answer z, Parameters",
          "[Search for Training] With x, t, z, beam search suitable {y}"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Critique Policy",
        "text": [
          "1. Surface-form Match: Features triggered for constants in the program that match a token in the question.",
          ". Lexical Pair Score: Features triggered between keywords and tokens (e.g., Maximum and most)."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Critique Policy Features",
        "text": [
          "Question: What nation scored the most points?",
          "Select Nation Where Points is M aximum",
          "Select Nation Where Index is Mi nimum",
          "Select Nation Where Pts/game i s Maximum",
          "Select Nation Where Name = Ka ren Andrew"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Learning Pipeline Revisited",
        "text": [
          "[Search for Training] With x, t, z, beam search suitable ={y}",
          "Using policy shaping to find better K Shaping affects here",
          "[Update] Update , according K = {y}",
          "What is the better objective function J?"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Objective Functions Look Different",
        "text": [
          "Maximum Marginal Likelihood (MML)",
          "Maximum Margin Reward (MMR) Maximum Reward Program",
          "Most violated program generated according to reward augment inference"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "16": {
        "title": "Update Rules are Similar",
        "text": [
          "Maximum Marginal Likelihood (MML)"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "17": {
        "title": "Generalized Update Equation",
        "text": [
          "[Update] Update , according K = {y}"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "18": {
        "title": "Improvement over Margin Approaches",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "19": {
        "title": "Results on SQA Answer Accuracy",
        "text": [
          "Policy shaping helps improve performance.",
          "With policy shaping, different updates matters even more",
          "Achieves new state-of-the-art (previously 44.7%) on SQA"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "20": {
        "title": "Comparing Updates",
        "text": [
          "MMR and MAVER are more aggressive than MML",
          "MMR and MAVER update towards to one program",
          "MML updates toward to all programs that can generate the correct answer"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "21": {
        "title": "Conclusion",
        "text": [
          "Discussed problem with search and update steps in semantic parsing from denotation.",
          "Introduced policy shaping for biasing the search away from spurious programs.",
          "Introduced generalized update equation that generalizes common update strategies and allows novel updates.",
          "Policy shaping allows more aggressive update!"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "22": {
        "title": "Generalized Update as an Analysis Tool",
        "text": [
          "MMR and MAVER are more aggressive than MML",
          "MMR and MAVER only pick one",
          "MML gives credits to all {y} that satisfies {z}",
          "MMR and MAVER benefit more from shaping"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "23": {
        "title": "Shaping and update",
        "text": [
          "Better search more aggressive update",
          "[Search for Training] With x, t, z, beam search suitable ={y}",
          "Using policy shaping to find better K Shaping affects here directly",
          "[Update] Update , according K = {y}",
          "What is the better objective function J? Shaping affects here indirectly"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "24": {
        "title": "Novel Learning Algorithm",
        "text": [
          "Intensity Competing Distribution Dev Performance",
          "Maximum Margin Reward (MMR) Maximum Margin Reward (MMR)",
          "Maximum Margin Reward (MMR) Maximum Marginal (MML) Likelihood",
          "Mixing the MMRs intensity and MMLs competing distribution gives an update that outperforms MMR."
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "25": {
        "title": "Novel Learning Algorithms",
        "text": [],
        "page_nums": [
          29
        ],
        "images": []
      },
      "26": {
        "title": "Maximum Marginal Likelihood MML",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "27": {
        "title": "Reinforcement Learning RL",
        "text": [],
        "page_nums": [
          31
        ],
        "images": []
      },
      "28": {
        "title": "Maximum Margin Reward MMR",
        "text": [],
        "page_nums": [
          32
        ],
        "images": []
      },
      "29": {
        "title": "Maximum Margin Average Violation Reward MAVER",
        "text": [],
        "page_nums": [
          33
        ],
        "images": []
      }
    },
    "paper_title": "Policy Shaping and Generalized Update Equations for Semantic Parsing from Denotations"
  },
  "1274": {
    "slides": {
      "0": {
        "title": "Commonsense Property Comparison Task",
        "text": [
          "Is an elephant bigger or smaller than a mouse?",
          "Is Ferrari more expensive or cheaper than beer?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Problem Definition",
        "text": [],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Learning Commonsense Knowledge from Text",
        "text": [
          "Reporting bias [Gordon and Van Durme 2013]: Commonsense knowledge is rarely explicitly stated.",
          "Large knowledge dimensions: Property specified by adjectives: large, heavy, fast, rigid, etc. Creating training examples and building separate models on each type of property requires expensive labeling efforts. Handling unseen properties during the test phase (zero-shot prediction)?",
          "Language variation: An ideal model should be able to take f lexible natural language inputs.",
          "Can we build an efficient commonsense comparison model with word embedding inputs only ?"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "Categorical Linear Regressions",
        "text": [
          "Figure 1: Creating a softmax regression model for each property."
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Our PCE model",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Data",
        "text": [
          "VERB PHYSICS ( 5 physical properties) [Forbes and Choi 2017]",
          "PROPERTY COMMON SENSE ( 32 commonsense properties)"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Results Supervised Performance",
        "text": [
          "Testsize weight stren rigid speed overall",
          "Table 1: Supervised accuracy on the VERB PHYSICS data set. PCE outperforms the F&C model from previous work."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Results Zero shot Predictio",
        "text": [
          "Testsize weight stren rigid speed",
          "Table 2: Accuracy of zero-shot learning on the VERB PHYSICS data set(using"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [
          "Table 3: Accuracy on the four-way task on the PROPERTY COMMON SENSE data."
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "9": {
        "title": "Synthesis Active Learning",
        "text": [],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1274-Figure1-1.png"
        ]
      },
      "10": {
        "title": "Active Learning",
        "text": [
          ". a Lc Synthesis",
          "So o b uN n 1"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1274-Figure2-1.png"
        ]
      }
    },
    "paper_title": "Extracting Commonsense Properties from Embeddings with Limited Human Guidance"
  },
  "1275": {
    "slides": {
      "0": {
        "title": "Story Understanding and Story Generation",
        "text": [
          "An extremely challenging and long-running goal in AI (Charniak",
          "The biggest challenge: having commonsense knowledge for the interpretation of narrative events.",
          "Requires commonsense reasoning, going beyond pattern recognition and explicit information extraction.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "ROC Stories Mostafazadeh et al 2016",
        "text": [
          "A collection of high quality short five sentence stories. Each story:",
          "Has a specific beginning and ending, where something happens in between",
          "Has nothing irrelevant or redundant to the core story",
          "The Test Jennifer has a big exam tomorrow. She got so stressed, she pulled an all-nighter. She went into class the next day, weary as can be. Her teacher stated that the test is postponed for next week. Jennifer felt bittersweet about it",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Story Cloze Test Mostafazadeh et al 2016",
        "text": [
          "The current benchmark for evaluating story understanding and narrative structure learning.",
          "Story Cloze Task: Given a context of four sentences, predict the ending of the story, i.e. Select from the right and wrong ending choices.",
          "Context Right Ending Wrong Ending",
          "Jim got his first credit card in college.",
          "He didnt have a job so he bought everything on his card. After he graduated he amounted a $10,000 debt. Jim realized that he was foolish to spend so much money.",
          "Jim decided to devised a plan for repayment.",
          "Jim decided to open another credit card.",
          "From now on we will refer to SCT as SCT-v1.0",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Results On SCT 10",
        "text": [
          "Baseline Results LSDSem17 and Other Models",
          "Constant Choose First cogcomp Logistic",
          "Narrative-Chains-AP mflor Rule Based",
          "Narrative-Chains-Stories Pranav Goel Logistic",
          "cogcomp(UIUC) - Linear classiftcation system that measures a storys coherence based on the sequence of events, emotional trajectory, and plot consistency (includes endings).",
          "msap(UW) - Linear classifier based on language modeling probabilities of the entire story, and linguistic features of only the ending sentences.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Story Ending Biases",
        "text": [
          "Mostafazadeh et al. (2016) were very careful with the task design, the data collection process, and establishing various baselines sampled from ROC Stories created Wrong Ending stories through Amazon MTurk had an AMT to verify quality",
          "Despite that, Schwartz et al. found stylistic differences between right and wrong endings: number of words n-gram distribution character n-gram distribution",
          "Their classifier without feeding context achieves 72.4% accuracy on SCT-v1.0!",
          "**similar results confirmed by other models, (Cai et al., 2017)",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Biases in Various Al Datasets",
        "text": [
          "From NLI, to VQA, and now Story Cloze Test, our narrow benchmarks inevitably have data creation artifacts and hence yield biased models.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Our Main Contributions",
        "text": [
          "The summary of this talk",
          "1. Analyzed SCT-v1.0 ending features",
          "2. Developed a strong classifier on SCT-v1.0 using only ending features",
          "3. Developed a new crowd-sourcing scheme to tackle the ending biases",
          "4. Collected a new dataset, SCT-v1.5",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Statistical Analysis of Endings",
        "text": [
          "We did an extensive analysis comparing the Right Endings and Wrong",
          "Part of Speech n-grams",
          "Combined Token + POS n-grams",
          "Analysis was done by performing",
          "A two sample t-test between token count, sentiment, an complexity",
          "Count measurements for the n-grams between Right and Wrong Endings",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Analysis Token Count",
        "text": [
          "right endings wrong endings",
          "Conclusion: Right Endings tend to be longer than Wrong Endings.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Analysis Sentiment Analysis",
        "text": [
          "Used the Stanford Sentiment Analyzer [0-4] and Vader Sentiment Tagger [-1,1].",
          "right endings wrong endings p-value",
          "VADER Sentiment score is significant, right endings tend to be more positive than wrong endings.",
          "The of most stories would probably yield neutral to positive higher and more concentrated peak around Right Endings wider distribution of Right Endings",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Analysis Syntactic Complexity Measurement",
        "text": [
          "right endings wrong endings p-value",
          "Conclusion: Yngve score was generally more stable and Wrong Endings are more complex than Right Endings.",
          "Image from Roark et al. 2014",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "Analysis N gram Counts",
        "text": [
          "1-5 length stemmed token n-grams, with START token",
          "4 character size n-grams",
          "Part of Speech n-grams",
          "POS tag and bucketed",
          "Combined Token + POS n-grams",
          "Analysis: got or learn often in Right decid often in Wrong",
          "Wrong frequently have tokens like nt or snt",
          "Right Endings are more likely to feature pronouns (PRP) whereas Wrong Endings are likely to use the proper noun (NNP).",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "EndingReg Model",
        "text": [
          "A Logistic Regression Model to perform the Story Cloze Test using only the following features extracted from the endings:",
          "*also added an L2 regularization penalty and used a grid search was conducted for parameter tuning",
          "tokencount, VADER, yngve ngram pos chargrams All accuracy",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "The Criteria of the New Dataset",
        "text": [
          "The Right and Wrong Endings should:",
          "Contain a similar number of tokens",
          "Have similar distributions of token n-grams and char-grams",
          "Occur as standalone events with the same likelihood to occur, with topical, sentimental, or emotional consistencies when applicable.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "14": {
        "title": "Collecting The New Dataset",
        "text": [
          "After various rounds of pilot studies, we found the following paradigm to work the best:",
          "New Data Collection Steps:",
          "collected 5,000 new five sentence stories with MTurk second AMT round to modify the last sentence to make non-sensible story. Here, th prompt instructs the workers to make sure:",
          "a. Wrong Ending makes sense standalone b. the Right and Wrong ending do not differ in # of words by >3 c. changes cannot be as simple as negating the verb",
          "third AMT to verify quality",
          "This entire process resulted in creating the Story Cloze",
          "stories for each validation and test sets.",
          "token + POS n-gram char-gram POS n-gram",
          "Standard deviation of the word and character n-gram counts, as well as the part of speech (POS) counts, between the right and wrong endings.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "15": {
        "title": "EndingReg Results",
        "text": [
          "Classification accuracy for various models on the SCT-v1.0 and SCT-v1.5 datasets.",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "16": {
        "title": "The SOTA Models",
        "text": [
          "In Improving Language Understanding by Generative Pre-Training model achieves accuracy of 86.5 on SCT-v1.0!",
          "Pretrained language model made with Transformer network",
          "Task specific supervised learning approach to classify",
          "Initial results on SCT-1.5 show an accuracy of 81.06% for this model, which suggests a deeper story understanding model that goes beyond leveraging the intricacies of the particular test sets.",
          "in Radford, Alec, et al. \"Improving Language Understanding by Generative Pre-Training.\" Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "We presented a comprehensive analysis of the stylistic features isolated in the endings of the original Story Cloze Test (SCT-v1.0).",
          "Developed a strong classifier using only the story endings",
          "Developed a new data collection schemes for tackling the stylistic ending features",
          "Created a new SCT dataset, SCT-v1.5, which overcomes some of the biases.",
          "The success of our modified data collection method shows how extreme care must be given for sourcing new datasets.",
          "However, as shown in multiple AI tasks, no collected dataset is entirely without its inherent biases and often the biases in datasets go undiscovered.",
          "Remember: There is still a wide gap between system and human performance, on either SCT 1.0 or SCT 1.5 ;)",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "18": {
        "title": "Next Steps",
        "text": [
          "We believe that evaluation benchmarks should evolve and improve over time and we are planning to incrementally update the Story Cloze Test benchmark.",
          "Stay tuned for updates on the dataset and SOTA models via http:// cs.rochester.edu/nlp/rocstories/",
          "We expect to release the final dataset, along with reporting the performance of the most recent SCT 1.0 SOTA models on the new dataset, shortly after",
          "Allen, Omid B Tackling the Biasesakhshandeh,"
        ],
        "page_nums": [
          19
        ],
        "images": []
      }
    },
    "paper_title": "Tackling the Story Ending Biases in The Story Cloze Test"
  },
  "1276": {
    "slides": {
      "0": {
        "title": "Co Authors",
        "text": [
          "John Hewitt Dan Roth"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Derivational Morphology",
        "text": [],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Motivation",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Challenges",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Suffix Ambiguity",
        "text": [
          "I have an observament!"
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Orthographic Irregularity",
        "text": [],
        "page_nums": [
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "Model Overview",
        "text": [],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23,
          47,
          48,
          55,
          56
        ],
        "images": []
      },
      "7": {
        "title": "Orthographic Model",
        "text": [
          "Reranking with frequency information"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "8": {
        "title": "Seq2Seq Baseline",
        "text": [
          "c o m p o s i"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "9": {
        "title": "Dictionary Constrained Decoding",
        "text": [
          "Seq2Seq models generate many unattested words, but are reasonable guesses",
          "Intuition: constrain model to only generate known words"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "10": {
        "title": "Reranking with Frequency Information",
        "text": [
          "Model Output Model Score"
        ],
        "page_nums": [
          42,
          43,
          44,
          45,
          46
        ],
        "images": []
      },
      "11": {
        "title": "Distributional Model",
        "text": [
          "Orthographic information can be unreliable",
          "Semantic transformation remains the same"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53,
          54
        ],
        "images": []
      },
      "12": {
        "title": "Aggregation Model",
        "text": [
          "Ortho Score Distributional Score Aggregation Selection"
        ],
        "page_nums": [
          57,
          58,
          59,
          60
        ],
        "images": []
      },
      "13": {
        "title": "Dataset",
        "text": [],
        "page_nums": [
          62
        ],
        "images": []
      },
      "14": {
        "title": "Experiment Details",
        "text": [
          "Token information: Google Book NGrams",
          "Google News pre-trained word embeddings",
          "Evaluation: full-token match accuracy"
        ],
        "page_nums": [
          63
        ],
        "images": []
      },
      "15": {
        "title": "Results Legend",
        "text": [],
        "page_nums": [
          64
        ],
        "images": []
      },
      "16": {
        "title": "Results",
        "text": [
          "Dist Seq Aggr Seq+Freq Aggr+Freq",
          "Significant improvement when combining Dist and Seq",
          "Frequency statistics are a valuable signal",
          "Combined model still outperforms separate models",
          "22% and 37% relative error reductions over Seq"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72
        ],
        "images": []
      },
      "17": {
        "title": "Results by Transformation",
        "text": [
          "Nominal Result Agent Adverb"
        ],
        "page_nums": [
          73,
          74,
          75,
          76,
          77,
          78,
          79
        ],
        "images": []
      },
      "18": {
        "title": "What does each model do well",
        "text": [],
        "page_nums": [
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87
        ],
        "images": [
          "figure/image/1276-Figure2-1.png"
        ]
      },
      "19": {
        "title": "Conclusion",
        "text": [
          "Aggregation model for English derivational morphology",
          "Best open- and closed-vocabulary models demonstrate 22% and 37% reduction in error"
        ],
        "page_nums": [
          88
        ],
        "images": []
      },
      "20": {
        "title": "Code and Data",
        "text": [],
        "page_nums": [
          89
        ],
        "images": []
      }
    },
    "paper_title": "A Distributional and Orthographic Aggregation Model for English Derivational Morphology"
  },
  "1278": {
    "slides": {
      "0": {
        "title": "Structured Prediction Reviewed",
        "text": [
          "z Shareholders took their money",
          "s s their money took their took money their took s , s s",
          "s.t. z forms a tree"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "1": {
        "title": "Linear Programming Formulation",
        "text": [
          "z Shareholders took their money",
          "s.t. z forms a tree",
          "s s took took money their"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": []
      },
      "2": {
        "title": "Backprop",
        "text": [
          "s s took took money their",
          "s.t. z forms a tree",
          "z Shareholders took theirmoney rzL",
          "s their took rsL",
          "We have: rzL We need: rsL",
          "z = argmax z>s"
        ],
        "page_nums": [
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22
        ],
        "images": []
      },
      "3": {
        "title": "Some Geometry",
        "text": [
          "Straight-through Estimator (STE): rsL rzL",
          "q Shareholders took theirmoney"
        ],
        "page_nums": [
          23,
          24,
          25,
          26,
          27,
          28
        ],
        "images": []
      },
      "4": {
        "title": "Algorithm",
        "text": [
          "z Shareholders took their money rzL",
          "Parser z argmax z> s",
          "s s took took money their s.t. z forms a tree rsL",
          "s their took rsL z\u0000 q"
        ],
        "page_nums": [
          29,
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "5": {
        "title": "Connections to Related Work",
        "text": [
          "z \u0000rzL \u0000rzL z",
          "Pipeline STE Structured Att. SPIGOT",
          "Hard decision on z",
          "Structured Attention: Kim et al., 2017"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "6": {
        "title": "Applications",
        "text": [
          "Shareholders took theirmoney L1 Shareholders took theirmoney",
          "Joint learning Induce latent structures",
          "Training data Training data",
          "argmax Parser rL1 argmax Parser",
          "Downstream task r\u0000L2 Downstream task r\u0000L",
          "Loss L2 Loss L"
        ],
        "page_nums": [
          36,
          37,
          38
        ],
        "images": []
      },
      "7": {
        "title": "Experiments Syntactic then semantic Parsing",
        "text": [
          "arg2 Semantic graph arg1 poss",
          "Kiperwasser and Goldberg, 2016",
          "Shareholders took theirmoney NeurboParser",
          "Eisner, 1996 argmax Syntactic Parser",
          "took root money took Peng et al., 2017",
          "Concat head token embedding Semantic Parser"
        ],
        "page_nums": [
          40,
          41,
          42
        ],
        "images": []
      },
      "8": {
        "title": "SemEval 15 Micro averaged labeled F1",
        "text": [
          "Neurbo Pipeline STE Structured Att. SPIGOT",
          "Hard decision z N/A"
        ],
        "page_nums": [
          43,
          44,
          45,
          46
        ],
        "images": []
      },
      "9": {
        "title": "Semantic Parsing for Sentiment Classification",
        "text": [
          "Semantic graph arg1 poss",
          "Martins et al., arg max Semantic Parser",
          "Shareholders took theirmoney BiLSTM+MLP",
          "took: arg1 took:arg2; their:poss",
          "Concat head token and role Classifier"
        ],
        "page_nums": [
          47,
          48
        ],
        "images": []
      },
      "10": {
        "title": "Stanford Sentiment Treebank accuracy",
        "text": [
          "BiLSTM Pipeline STE SPIGOT"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [],
        "page_nums": [
          50,
          51,
          52
        ],
        "images": []
      }
    },
    "paper_title": "Backpropagating through Structured Argmax using a SPIGOT"
  },
  "1279": {
    "slides": {
      "0": {
        "title": "Inferring Character State",
        "text": [
          "The band instructor told the band to Players",
          "He often stopped the music when players were off-tone. frustrated",
          "annoyed They grew tired and started playing",
          "worse after a while.",
          "The instructor was furious and threw",
          "angry his chair. afraid",
          "He cancelled practice and expected us to perform tomorrow. stressed"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Reasoning about Naieve Psychology",
        "text": [
          "New Story Commonsense Dataset:",
          "Open text + psychology theory",
          "Complete chains of mental states of characters",
          "Implied changes to characters"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "How do we represent naive psychology",
        "text": [
          "The band instructor told the band to start playing.",
          "He often stopped the music when players were off-tone.",
          "To create a good harmony",
          "Anger feels feels frustrated"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Naieve Psychology Annotations",
        "text": [
          "Causal source to actions"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Motivation Maslow Hierarchy of Needs 1943",
        "text": [
          "She sat down on the couch and instantly fell asleep.",
          "She sat down to eat lunch."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Motivation Reiss Categories 2004",
        "text": [
          "Esteem She sat down on the couch",
          "and instantly fell asleep.",
          "Food She sat down to eat lunch."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Emotional Reaction Plutchik 1980",
        "text": [
          "Their favorite uncle died.",
          "Suddenly, they heard a loud noise."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Implicit Mental State Changes",
        "text": [
          "The band instructor told the band to start playing.",
          "He often stopped the music when players were off-tone.",
          "They grew tired and started playing worse after a while.",
          "The instructor was furious and threw his chair.",
          "How are players affected? implicitly involved inference in these cases"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Tracking Mental States",
        "text": [
          "The band instructor told the band to start playing.",
          "He often stopped the music when players were off-tone.",
          "They grew tired and started playing worse after a while.",
          "The instructor was furious and threw his chair.",
          "He cancelled practice and expected us to perform tomorrow.",
          "Why does the instructor cancel practice? based on previous info need to incorporate context"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Related Work",
        "text": [
          "Reasoning about narratives (Mostafazadeh et al 2016)",
          "Detecting emotional content (Mohammad et al 2013) or stimuli (Gui et al 2017) of a statement",
          "Both motivation and emotion for a characters outlook",
          "Leverage psychology theories and natural language explanations"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Full Annotation Chain",
        "text": [
          "Sarah gets attacked by a shark.",
          "Sarah fights off the shark.",
          "Sarah escapes the attack.",
          "Is Sarah taking action: Yes",
          "Stability to escape to safety",
          "Does the Shark have a reaction?"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "11": {
        "title": "Data Collection Summary",
        "text": [
          "Over 300k low-level annotations for 15k stories from ROC training set",
          "Open-text Open-text + categories"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Annotated Data Distributions Motivation",
        "text": [
          "Fair amount of diversity in the open-text",
          "~1/3 have positive motivation change:",
          "Sampled Explanations Open-text % Annotations where selected",
          "meet goal; to look nice",
          "to support his friends",
          "be employed; stay dry"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Annotated Data Distributions Emotion",
        "text": [
          "Lots of happy stories",
          "~2/3 have positive emotion change:",
          "Explanations % Annotations where selected"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "14": {
        "title": "New Tasks",
        "text": [
          "Given a story excerpt and a character can we explain the mental state:",
          "Explanation Generation: Generate open-text explanation of motivation/emotional reaction",
          "State Classification: Predict Maslow/Reiss/Plutchik category"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "15": {
        "title": "Task 1 Explanation Generation",
        "text": [
          "Explain mental state of character using natural language",
          "The band instructor told the band to start playing.",
          "Story Text Excerpt + Character"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "16": {
        "title": "Modeling",
        "text": [
          "Story Text + Character",
          "Encoders - LSTM, CNN, REN, NPN",
          "Decoder for generation: single layer",
          "Decoder for categorization: logistic regression cat = !$`abb()"
        ],
        "page_nums": [
          20,
          26
        ],
        "images": []
      },
      "17": {
        "title": "Encoding Modules",
        "text": [
          "Given entity and line (and entity-specific context sentences",
          "CNN, LSTM: encode last line and context -- concatenate"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "18": {
        "title": "Entity Modeling",
        "text": [
          "Recurrent Entity Networks (Henaff et al 2017)",
          "Store separate memory cells for each story character",
          "Update after each sentence with sentence-based hidden states",
          "Neural Process Networks (Bosselut et al 2018)",
          "Also has separate representations for each character",
          "Updates after each sentence using learned action embeddings"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "19": {
        "title": "Explanation Generation Set up",
        "text": [
          "Evaluation: Cosine similarity of generated response to reference",
          "Random baseline: Select random answer from dev set",
          "Words for describing intent/emotion are close in embedding space"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "20": {
        "title": "Explanation Generation Results",
        "text": [
          "Cos. Similarity to Reference",
          "Motivation (VE) Emotion (VE)",
          "Random LSTM CNN REN NPN"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "21": {
        "title": "Predicting psychological categories for mental state",
        "text": [
          "Task 2 Mental State Classification",
          "The band instructor told the band to start playing. anticipation",
          "Story Text Excerpt + Character Theory categories"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "22": {
        "title": "State Classification Results",
        "text": [
          "LSTM perform best on motivation categories",
          "Entity modeling has slight improvement in Plutchik Maslow Reiss Plutchik",
          "Random LSTM CNN REN NPN"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "23": {
        "title": "Further Improvement",
        "text": [
          "Random LSTM CNN REN NPN"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "24": {
        "title": "Effect of Entity Specific Context",
        "text": [
          "Including previous lines from context that include entity",
          "F1 w/ and w/o context",
          "Entity specific context: improves all models F1",
          "CNN CNN w/ context"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "25": {
        "title": "Pre training Encoders",
        "text": [
          "We have more open-text explanations than category annotations:",
          "1. Pre-train encoders on open- text explanations",
          "2. Fine-tune with the categorical labels",
          "Story Text + Character"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "26": {
        "title": "Effect of Pretrained Encoders",
        "text": [
          "F1 w/ and w/o Pretrained Encoders"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "27": {
        "title": "Performance Per Category",
        "text": [
          "Very concrete sets of actions (physiological F1: 40% )"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "28": {
        "title": "Future Work",
        "text": [
          "Outside Knowledge: Help with infrequent classes and subtle implied changes",
          "Social Commonsense: Help with inferring mental state especially in more contextual cases",
          "Potential Applications: Improving language models, chat systems, natural language understanding"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "29": {
        "title": "Conclusions",
        "text": [
          "15k roc stories annotated per character"
        ],
        "page_nums": [
          34
        ],
        "images": []
      }
    },
    "paper_title": "Modeling Naive Psychology of Characters in Simple Commonsense Stories"
  },
  "1281": {
    "slides": {
      "0": {
        "title": "Language Change",
        "text": [
          "Languages change over time",
          "Both an internal and external process",
          "Individuals acquire language and transmit it to future generations",
          "New variants propagate through populations",
          "Must model how the individual reacts to linguistic input and to the community"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Example The Cot Caught Merger",
        "text": [
          "// cot is pronounced the same as // caught",
          "Minimal pairs distinguished by",
          "Don collar knotty odd caught",
          "Dawn caller naughty awed",
          "Present in many dialects of North",
          "Spreading into Rhode Island",
          "Rapid! Families with Non-merged",
          "parents and older siblings but merged younger siblings"
        ],
        "page_nums": [
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Existing Frameworks",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "3": {
        "title": "Three Classes of Framework",
        "text": [
          "Individual agents on a grid moving randomly and interacting (ABM)",
          "Bloomfield (1933)s Principle of Density for free",
          "Not a lot of control over the network",
          "Thousands of degrees of freedom",
          "-> should run many many times",
          "Speakers are nodes in a graph, edges are possibility of interaction",
          "Much more control over network structure",
          "Easy to model concepts from the sociolinguistic lit. (e.g., Milroy & Milroy)",
          "Nodes only interact with immediate neighbours -> slow and less realistic?",
          "Practically implemented as random interactions between neighbours -> same problem as #1",
          "Expected outcome of interactions is calculated analytically",
          "+ Closed-form solution rather than simulation -> faster and more direct",
          "- No network structure! Always implemented over perfectly mixed populations",
          "This proliferation of boutique frameworks is a problem",
          "An ad hoc framework risks overfitting the pattern",
          "Comparison between frameworks is challenging"
        ],
        "page_nums": [
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "4": {
        "title": "Our Framework",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "5": {
        "title": "Best of All Worlds",
        "text": [
          "Impose density effects on a network structure and calculate the outcome of each iteration analytically",
          "+ Captures the Principle of Density",
          "+ Models key facts about social networks",
          "+ No random process in the core algorithm"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "The Model",
        "text": [
          "Language change as a two-step loop",
          "Propagation: Variants distribute through the network",
          "Acquisition: Individuals internalize them",
          "Propagation: L distributes through the network",
          "Acquisition: Individuals react to L to create G",
          "If this were a linear chain,"
        ],
        "page_nums": [
          18,
          21,
          22
        ],
        "images": []
      },
      "7": {
        "title": "Vocabulary",
        "text": [
          "L: That which is transmitted",
          "G: That which generates/describes/distinguishes L",
          "That which is learned/influenced by L",
          "Grammar Variety Latent Variable"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "8": {
        "title": "Binary G Examples",
        "text": [
          "G: {Merged grammar, Non-merged grammar}",
          "L: Merged or non-merged instances of cot and caught words",
          "{Dived-generating grammar, Dove-generating grammar}",
          "Instances of the past tense of dive as dived or dove",
          "{have+NEG = havent got grammar, have+NEG = dont have grammar}",
          "Instances of havent got and instances of dont have"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "9": {
        "title": "Intuition behind Propagation Algorithm",
        "text": [
          "For the individual at each node",
          "Randomly select outgoing edge by weight and follow it OR stop;",
          "Increase chance of stopping next tim e;",
          "Interact with the individual at the curren t node;",
          "Nodes are not individuals.",
          "Individuals stand on nodes",
          "Individuals travel along edges and find someone to interact with by weight and follow it OR stop;",
          "Individuals connected by shorter or higher weighted paths are more likely to interact.",
          "Rather than simulating interactions in a loop, calculate a closed-form solution"
        ],
        "page_nums": [
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "10": {
        "title": "The Propagation Function",
        "text": [
          "E is a g x n matrix: n individuals, g possible grammars",
          "For each individual, the proportion of input drawn from each grammar",
          "Of the previous generation",
          "G is an n x g matrix",
          "Proportions by which each individual produces L",
          "A is an n x n adjacency matrix",
          "The probabilities that nodes i, j interact given that the number of steps travelled declines by a geometric distribution parameter from that distribution [0,1]"
        ],
        "page_nums": [
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "11": {
        "title": "The Acquisition Function",
        "text": [
          "Should take Et as input and produce Gt+1 as output",
          "In the simplest case (neutral change), Gt+1 Et T",
          "The following case study uses a variational learner"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "12": {
        "title": "Case Study",
        "text": [
          "Spread of the Cot-Caught Merger"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "13": {
        "title": "Model for Merger Acquisition Yang 2009",
        "text": [
          "Learners will acquire the merged grammar iff more than ~17% of their environment is merged",
          "+ Accounts for mergers tendency to spread (Labov 1994)",
          "+ 17% is close to the merged rate estimated in Johnson 2007",
          "In a perfectly-mixed model, population will immediately fix at 100% g+ or g-",
          "Claim: The merged grammar has a processing advantage",
          "Claim: Merged listeners have a lower rate of initial misinterpretation",
          "Claim: Only minimal pairs are relevant",
          "If speaker A- and listener B- are both non-merged, B- misunderstands A- at the rate of mishearing one vowel for the other (A- said // but B- heard //)",
          "If A+ speaks to B-, B- initially misunderstands whenever A+ says // when B- expects // and visa-versa",
          "If A- or A+ speaks to B+, B+ cannot hear A-s distinctions. Initial misunderstandings come down to lexical access - if the intended meaning is not the most frequent meaning (Carmazza et al 2001)"
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42
        ],
        "images": []
      },
      "14": {
        "title": "Variational Model for Merger Acquisition",
        "text": [
          "Probability of initial misunderstanding depends on",
          "minimal pair frequencies mix merged (+) and non-merged (-) speakers in the environment",
          "Using minimal pair frequencies estimated from SUBTLEXus and a variational learner, learners will acquire the merged grammar iff more than ~17% of their environment is merged (Yang 2009)",
          "Penalty probabilities depend on",
          "mi, ni = frequencies of each member of a minimal pair",
          "H = i mi ni",
          "= probability of mishearing one vowel for the other",
          "C+ = (1/H) i min(mi, ni) hearing the less freq word",
          "p-(mmi nni)] misinterpreting input"
        ],
        "page_nums": [
          43,
          44,
          57,
          58
        ],
        "images": []
      },
      "15": {
        "title": "Acquisition Function",
        "text": [
          "An individual acquires 100% g+ if >17% environment is generated by"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "16": {
        "title": "Network Model",
        "text": [
          "100 clusters of 75 individuals each",
          "Each cluster is centralised randomly such that some community members are better connected than others",
          "One cluster begins 100% merged",
          "The rest start 100% non-merged (Rhode",
          "Half the RI clusters are connected to the MA cluster (the Frontier)",
          "Two members of each RI cluster are randomly connected to other clusters"
        ],
        "page_nums": [
          46,
          47,
          48,
          49
        ],
        "images": []
      },
      "17": {
        "title": "Merger Rate in Rhode Island over Time",
        "text": [
          "The average merger rate across all",
          "Rhode Island clusters follows an",
          "The 99 RI community cluster curves are also S-shaped",
          "Steep slopes = rapid change",
          "Cluster Merger Rates Rhode Island Avg"
        ],
        "page_nums": [
          50
        ],
        "images": [
          "figure/image/1281-Figure6-1.png",
          "figure/image/1281-Figure5-1.png",
          "figure/image/1281-Figure4-1.png"
        ]
      },
      "18": {
        "title": "Conclusions",
        "text": [
          "Removes the need to simulate interactions",
          "Is widely applicable rather than made-to-order",
          "Predicts behaviour consistent with the empirical data",
          "And with principles of language change"
        ],
        "page_nums": [
          51
        ],
        "images": []
      },
      "19": {
        "title": "End",
        "text": [
          "NDSEG Fellowship (US ARO)"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "20": {
        "title": "Variational Learner Yang 2000",
        "text": [
          "Learners consider multiple grammars g1, g2 simultaneously",
          "Each g is penalised when it cannot parse an input p if g1 fails",
          "The g with lower penalty probability has the advantage p if g1 parses input if g1 fails",
          "If mature speakers adopt one grammar categorically, the one with smaller C wins limt pt if C1 C2"
        ],
        "page_nums": [
          53,
          54,
          55,
          56
        ],
        "images": []
      },
      "21": {
        "title": "Results Updating Connections",
        "text": [
          "Social connections change constantly",
          "Rewire the edges (recalculate A) at every iteration",
          "The outcome is similar, but clusters tipping points are temporally closer",
          "No cluster remains particularly well or poorly connected for long",
          "Cluster Merger Rates Rhode Island Avg"
        ],
        "page_nums": [
          59,
          60
        ],
        "images": [
          "figure/image/1281-Figure6-1.png",
          "figure/image/1281-Figure5-1.png",
          "figure/image/1281-Figure4-1.png"
        ]
      },
      "22": {
        "title": "Fractional Updating",
        "text": [
          "The merger spreads rapidly enough to distinguish older and younger siblings",
          "Only a fraction of the population is of the correct age at any moment",
          "Update only 10% of random nodes at every iteration",
          "Cluster Merger Rates Rhode Island Avg",
          "Similar outcome with wider spread between cluster tipping points",
          "Simulation took about 5x as long because"
        ],
        "page_nums": [
          61,
          62
        ],
        "images": [
          "figure/image/1281-Figure6-1.png",
          "figure/image/1281-Figure5-1.png",
          "figure/image/1281-Figure4-1.png"
        ]
      },
      "23": {
        "title": "Results Network Size",
        "text": [
          "Tested our network size assumptions",
          "Repeat the experiment with 40 clusters of 18 individuals each",
          "The S-shape is less S-shaped",
          "Individual clusters shows step pattern",
          "Cluster Merger Rates Rhode Island Avg"
        ],
        "page_nums": [
          63,
          64
        ],
        "images": [
          "figure/image/1281-Figure6-1.png",
          "figure/image/1281-Figure5-1.png",
          "figure/image/1281-Figure4-1.png",
          "figure/image/1281-Figure7-1.png"
        ]
      },
      "24": {
        "title": "Results Community Averages",
        "text": [
          "At small network sizes, the community average is more sensitive to random connections",
          "Repeat the small-scale experiment 10 times",
          "The slope is ~consistent in most simulations",
          "A few simulations show aberrant behaviour"
        ],
        "page_nums": [
          65,
          66
        ],
        "images": [
          "figure/image/1281-Figure6-1.png",
          "figure/image/1281-Figure5-1.png",
          "figure/image/1281-Figure4-1.png",
          "figure/image/1281-Figure7-1.png"
        ]
      }
    },
    "paper_title": "A Framework for Representing Language Acquisition in a Population Setting"
  },
  "1282": {
    "slides": {
      "0": {
        "title": "Motivation 1 Satire or not",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "After years of ghting there",
          "nally is a settlement",
          "between the Gema and",
          "Youtube . It became known today , that in future every music video is allowed to be played back in Germany again, as long as the audio is removed",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation 2 Satire or not",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "Erfurt ( dpo ) It is an organization which operates outside of law and order, funds numerous NPD operatives and is to a not inconsiderable extent involved in the series of murders of the so-called",
          "DPA is a German news agency",
          "DPO does not exist (in this context). University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Satire",
        "text": [
          "Form of art to critize in an entertaining manner",
          "Stylistic devices include humor, irony, sarcasm",
          "Goal: Mimic regular news in diction",
          "Its not misinformation or desinformation (fake news):",
          "Articles typically contain satire markers",
          "(similar to irony or sarcasm)",
          "Automatically distinguish satirical news from regular news",
          "Challenging task (even for humans)",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Previous Work",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "Created data sets which are automatically labeled from publication source",
          "Potential limitation: Models might learn characteristics of publication sources instead of actual characteristics of satire",
          "(evaluation is not faulty, they use dierent publication sources for validation than for training)",
          "Bad generalization to unseen publication sources?",
          "Interpretation of models (regarding concepts of satire) misleading?",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Our Contributions",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "We propose adversarial training: Improve robustness of model against confounding variable of publication sources",
          "We show that adversarial training is crucial for the model to pay attention to satire instead of publication characteristics",
          "We publish a large German data set for satire detection.",
          "First dataset in German",
          "First dataset including publication sources",
          "Largest resource for satire detection so far",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Model",
        "text": [
          "satire detector publication identifier",
          "J s J p",
          "s p satire? (yes/no) publication name",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1282-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Data Collection and Selection",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "Der Spiegel, Der Standard, Die Zeit, Suddeutsche Zeitung",
          "Der Enthuller, Eulenspiegel, Nordd. Nach., Der Postillon,",
          "Satirepatzer, Die Tagespresse, Titanic, Welt (Satire), Der",
          "Zeitspiegel, Eine Zeitung, Zynismus24",
          "Publication #Articles Article Sent. Title",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Research Question 1 Performance",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "How does a decrease in publication classication performance through adversarial training aect the satire classication performance?",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Research Question 2 Attention Weights",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "Is adversarial training eective for avoiding that the model pays most attention to the characteristics of publication source rather than actual satire?",
          "Erfurt ( dpo ) - It is an organization which operates outside of law and order , funds numerous NPD operatives and is to a not inconsiderable extent involved in the series of murders of the so called Zwickauer Zelle .",
          "numerous NPD operatives and is to a not inconsiderable extent involved in the series of murders of the so called Zwickauer Zelle .",
          "After discussed all , , the whereof proposal the to Union allow hopes family for reunion an off-putting only inclusive effect mothers-in-law . is being",
          "advAfter all , the proposal to allow family reunion only inclusive mothers-in-law is being discussed , whereof the Union hopes for an off-putting effect .",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion and Availability",
        "text": [
          "Satire & Research Goals Model/Data Experiments & Results Conclusion",
          "Observation: Satire detection models learn characteristics of publication sources",
          "Adversarial training to control for this confounding variable",
          "Considerable reduction of publication identication performance while satire detection remains on comparable levels",
          "Attention weights show eectiveness of our approach",
          "First German dataset for satire detection",
          "Dataset and code available at: http://www.ims.uni-stuttgart.de/data/germansatire",
          "University of Stuttgart McHardy/Adel/Klinger June 3rd, 2019"
        ],
        "page_nums": [
          12
        ],
        "images": []
      }
    },
    "paper_title": "Adversarial Training for Satire Detection: Controlling for Confounding Variables"
  },
  "1283": {
    "slides": {
      "0": {
        "title": "Meta view",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "the task",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "e Input: a text which is perhaps ungramatical e Output: a grammatical text saying the same",
          "Example: However , there are both sides of stories"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "The task",
        "text": [
          "e Input: a text which is perhaps ungramatieal ungrammatical e Output: a grammatical text saying conveying the same",
          "Example: However , there are beth sides-of stories >",
          "However , there are two sides to the story."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Test Set",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluati",
          "ion - Level 3 Peers - Level 4",
          "e Learner sentences (perhaps ungrammatical)",
          "e References - word edits and the error type corrected by them",
          "Since ancient times , human interact with others face by face . +",
          "Since ancient times , human humans (Noun number) interact with others face by to (Wrong Preposition) face ."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Metrics",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3",
          "There are many suggestions for evaluation metrics:",
          "More on that in the paper.",
          "Peers - Level 4"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Human Rankings",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "You have become powerful, | sense the dark side in you.",
          "Powerful you have become, | sense the dark side in you.",
          "You have become powerful, the dark side I sense in you.",
          "Powerful you have become, the dark side | sense in you.",
          "Since ancient times , Auman humans (Noun number) interact with others face by to (Wrong Preposition) face .",
          "2 Since ancient times , humans interact with others face to face ."
        ],
        "page_nums": [
          8,
          13
        ],
        "images": []
      },
      "6": {
        "title": "Existing Metric Validation",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "e Annotation Humans rank system corrections e Two benchmarks GJG15 (Grundkiewicz et al. 2015), and",
          "e Score correlation between metric and human rankings",
          "e Rank each system by the metric scores of its outputs e Rank each system by the human ranks of its outputs",
          "e Correlate the two"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Human Rankings not a perfect solution",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers",
          "What Machine Translation has already found :",
          "e Costly e Low agreement e Ranking is hard (correcting is easy)",
          "e Some sentences are uncomparable",
          "p P-val p Rank p Rank"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Human Rankings CHR inherent biases",
        "text": [
          "uation - Level 2 Evaluation of evaluation - Level 3",
          ". Metrics are favored if they discern high-performing and low-performing existing systems",
          ". Systems are fitted against metrics",
          "e Systems have similar biases under-correct & favor correcting",
          "specific error types (Choshen & Abend 2018)",
          "e Metrics are evaluated based on distribution of errors in",
          "outputs, rather than true distribution"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "MAEGE Methodology for Automatic Evaluation of GEC Evaluation",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "e Annotation Humans correct errors in sentences",
          "e Widely available regular GEC corpora e Lattice graded quality e Original sentences O; e Partial corrections, apply some edits",
          "e Reference sentences RY"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1283-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Corpus Level",
        "text": [
          "The task - Lev",
          "el 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "Models Set of randomly chosen corrections",
          "MAEGE score the expected number of applied edits e We sample models from the lattices with different distributions",
          "Score correlation between the two rankings",
          "e Positive low correlation with CHR",
          "e The best metric is LT (number of detected errors)",
          "e With precision-oriented models MAEGE is similar to CHR",
          "e Indication that CHR is biased due to precision-oriented models"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Types",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4",
          "1. Pick sentence pairs with one correction difference",
          "2. Find A: the change in metric score",
          "3. Compute average A per type"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Types sensitivity analysis",
        "text": [
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3",
          "Peers - Level 4",
          "1. All metrics penalize for validly correcting certain error types",
          "2. Some error types (close class) are more commonly penalized than others (open class)"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Take home message",
        "text": [
          "The task - Evaluation - Level 2 Evaluation of evaluation - Peers - Level 4",
          "e Metrics emphasize some aspects of the task over others.",
          "e Metric validation should tell you which e If validation is opaque, metrics and systems may tune towards",
          "one another (vicious loop) e MAEGE breaks the loop by not relying on system outputs e Instead compile naturally ranked corpus",
          "The task - Level 1 Evaluation - Level 2 Evaluation of evaluation - Level 3 Peers - Level 4"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      }
    },
    "paper_title": "Automatic Metric Validation for Grammatical Error Correction"
  },
  "1284": {
    "slides": {
      "0": {
        "title": "Recursive vs recurrent NNs",
        "text": [
          "The largest city in Minnesota",
          "Miryam de Lhoneux, Miguel Ballesteros and Joakim Nivre Petite kent te aman nl",
          "English PTB Chinese CTB",
          "Examine composition in simple architecture"
        ],
        "page_nums": [
          3,
          4,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "1": {
        "title": "Recursive NN for Transition Based Parsing",
        "text": [
          "the largest city left-arc",
          "the left-arc largest city",
          "Recursive composition function in the stack-LSTM parser (Dyer et al., 2015):",
          "city1 c(city0, largest, left nmod) city2 c(city1, the, left det)"
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "2": {
        "title": "Transition Based Parsing using BiLSTM",
        "text": [
          "the brown fox jumped root",
          "Vthe Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "LSTM f LSTM f LSTM f LSTM f LSTM f",
          "X the X brown X fox X jumped X root",
          "t h e b r o w n f o x j u m p e d e(the) e(brown) e(fox) e(jumped) pe(the) pe(brown) pe(fox) pe(jumped)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "3": {
        "title": "Transition Based Parsing using BiLSTMs",
        "text": [
          "X the X brown X fox X jumped X root",
          "Vthe Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "LSTM f LSTM f LSTM f LSTM f LSTM f"
        ],
        "page_nums": [
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "4": {
        "title": "Recursive Composition in the BiLSTM parser",
        "text": [
          "V the Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "LSTM f LSTM f LSTM f LSTM f LSTM f",
          "X the X brown X fox X jumped X root",
          "V the Cthe Vbrown Cbrown Vfox Cfox Vjumped Cjumped Vroot Croot",
          "nmod Cfox = tanh(W[Cfox,Cbrown,leftnmod]+b)",
          "chead tanh(W [h; d r b) rc chead Lstm([h; d r lc"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43
        ],
        "images": []
      },
      "5": {
        "title": "Results BiLSTM composition",
        "text": [
          "cs en eu fi a gre he ja zh av.",
          "NTE eee ee oc ements",
          "[mmm bi mmm bitrc mm bitc| bit+re bi+Ic",
          "NTE eee ee oc oR Ce etd 14/22"
        ],
        "page_nums": [
          45,
          46,
          47
        ],
        "images": []
      },
      "6": {
        "title": "LSTM Feature Extractors",
        "text": [
          "V the Vbrown Vfox Vjumped Vroot",
          "concat concat concat concat concat",
          "LSTM b LSTM b LSTM b LSTM b LSTM b",
          "L STM f LSTM f LSTM f LSTM f LSTM f",
          "X the X brown X fox X jumped X root"
        ],
        "page_nums": [
          48,
          49,
          50,
          51
        ],
        "images": []
      },
      "7": {
        "title": "Results BiLSTM ablations",
        "text": [
          "a a o y",
          "Miryam de Lhoneux, Miguel Ballesteros and Joakim Nivre e Subtree Compo:",
          "BE oR oP G 8 ob",
          "cs en eu fi a gre he ja zh av.",
          "NTE eee ee oc oR Ce etd 16/22"
        ],
        "page_nums": [
          52,
          53,
          54
        ],
        "images": []
      },
      "8": {
        "title": "Results BiLSTM ablations composition",
        "text": [
          "Vienna NTE eee ee oc",
          "Reeteneact ee mest teria ens",
          "Nien enn Pe ee me eC Petite kent te aman nl paps)",
          "NN eee cg Petite kent te aman nl"
        ],
        "page_nums": [
          55,
          56,
          57
        ],
        "images": []
      },
      "9": {
        "title": "Word representation",
        "text": [
          "+pos Cf Cf Cf"
        ],
        "page_nums": [
          58,
          59,
          60
        ],
        "images": []
      },
      "10": {
        "title": "Composition gap recovery",
        "text": [
          "pos+char+ pos+char- pos-char+ pos-char-"
        ],
        "page_nums": [
          61,
          62
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Subtree composition does not reliably help a BiLSTM transition-based parser",
          "The backward part of the BiLSTM is crucial, especially for right-headed languages",
          "The forward part of the BiLSTM is less crucial",
          "A backward LSTM + subtree composition performs close to a",
          "POS information and subtree composition are two partially redundant ways of constructing contextual information"
        ],
        "page_nums": [
          64,
          65,
          66,
          67,
          68
        ],
        "images": []
      }
    },
    "paper_title": "Recursive Subtree Composition in LSTM-Based Dependency Parsing"
  },
  "1285": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "Assumption: different languages can be mapped into one shared-latent space"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Techniques based on",
        "text": [
          "Initialize the model with inferred bilingual dictionary",
          "Unsupervised word embedding mapping",
          "Learn strong language model",
          "Convert Unsupervised setting into a supervised one",
          "Constrain the latent representation produced by encoders to a shared space",
          "fully-shared encoder fixed mapped embedding GAN"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "We find",
        "text": [
          "The shared encoder is a bottleneck for unsupervised NMT",
          "The shared encoder is weak in keeping the unique and internal characteristics of each language,",
          "such as the style, terminology and sentence structure. Since each language has its own",
          "characteristics, the source and target language should be encoded and learned independently.",
          "Fixed word embedding also weakens the performance (not included in the paper)",
          "If you are interested about this part, you can find some discussions in our github code:"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "The proposed model",
        "text": [
          "The local GAN is utilized to constrain the source and target latent representations to have the same distribution (embedding-reinforced encoder is also designed for this purpose, see our paper for detail).",
          "The global GAN is utilized to fine tune the whole model."
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1285-Table1-1.png",
          "figure/image/1285-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Experiment setup",
        "text": [
          "Note: The monolingual data is built by selecting the front half of the source",
          "language and the back half of the target language.",
          "4 self-attention layers for encoder and decoder",
          "applying the Word2vec to pre-train the word embedding",
          "utilizing Vecmap to map these embedding to a shared-latent space"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Experimental results",
        "text": [
          "The effects of the weight-sharing layer number",
          "Sharing one layer achieves the best translation performance.",
          "The BLEU results of the proposed model:",
          "Baseline 1: the word-by-word translation according to the similarity of the word embedding",
          "Baseline 2: unsupervised NMT with monolingual corpora only proposed by Facebook.",
          "Upper Bound: the supervised translation on the same model.",
          "We perform an ablation study by training multiple versions of our model with some missing components: the local GAN, global GAN, the directional self-attention, the weight-sharing and the embedding-reinforced encoder.",
          "We do not test the importance of the auto-encoding, back-translation and the pre-trained embeddings since they have been widely tested in previous works."
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": [
          "figure/image/1285-Table3-1.png",
          "figure/image/1285-Figure2-1.png",
          "figure/image/1285-Table2-1.png"
        ]
      },
      "6": {
        "title": "Semi supervised NMT with 02M parallel data",
        "text": [
          "Continue training the model after unsupervised training on the",
          "From scratch, training the model on monolingual data for one",
          "epoch, and then on parallel data for one epoch, and another one on",
          "monolingual data, on and on.",
          "Only with parallel data",
          "Continuing Training on supervised data",
          "Jointly training on monolingual and parallel data"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Related works",
        "text": [
          "Unsupervised machine translation using monolingual corpora only.",
          "In International Conference on Learning Representations (ICLR).",
          "Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018.",
          "Unsupervised neural machine translation.",
          "Phrase-Based & Neural Unsupervised Machine Translation (arxiv)",
          "* The newest paper (third one) proposes the shared BPE method for unsupervised",
          "NMT, its effectiveness is to be verified (around +10 BLEU points improvement is presented)."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Future work",
        "text": [
          "Continuing testing the unsupervised NMT and seeking to",
          "find its optimal configurations.",
          "Testing the performance of semi-supervised NMT with a",
          "little amount of bilingual data.",
          "Investigating more effective approach for utilizing the",
          "monolingual data in the framework of unsupervised NMT."
        ],
        "page_nums": [
          12
        ],
        "images": []
      }
    },
    "paper_title": "Unsupervised Neural Machine Translation with Weight Sharing"
  },
  "1286": {
    "slides": {
      "0": {
        "title": "Task Semantic Parsing",
        "text": [
          "Translate natural language sentences to meaning representations, e.g., logical forms.",
          "SentenceWhich city was Barack Obama born in",
          "Logical form. () (Barack_Obama)"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Two Lines of Work in Semantic Parsing",
        "text": [
          "use semantic graphs to represent sentence meanings, no need for lexicons and grammars",
          "Two Two Lines Lines of of Work Work in in Semantic Semantic Parsing Parsing",
          "Semantic parsing as semantic graph matching or staged semantic query graph generation",
          "Semantic Graph Based Sequence-to-Sequence Based",
          "Semantic parsing as a sequence-to-sequence problem",
          "[Bast and Haussmann, [Rabinovich et al., 2017]",
          "Hard to model semantic graph construction process",
          "Hard to capture structure information",
          "Ignore the relatedness to KB"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "2": {
        "title": "Seq2Act synthesizes their advantages",
        "text": [
          "Use semantic graphs to represent sentence meanings",
          "tight-coupling with knowledge bases",
          "Leverage the powerful prediction ability of RNN models",
          "Seq2Act: Seq2Act: end-to-end end-to-end semantic semantic graph graph generation generation",
          "Which states border Texas?"
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "3": {
        "title": "Seq2Act end to end semantic graph generation",
        "text": [
          "type return A state next_to semantic graph",
          "Action 3: add node texas:st Which states border Texas? Sequence-to-Action",
          "Action 1: add node A",
          "translate Action 2: add type state",
          "Action 4: add edge next_to"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
        ],
        "images": []
      },
      "4": {
        "title": "Overview of Our Method",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "type return A state next_to KB Semantic"
        ],
        "page_nums": [
          37,
          38,
          39,
          40,
          41
        ],
        "images": [
          "figure/image/1286-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Major components of Our Model",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "type return A state next_to KB Semantic"
        ],
        "page_nums": [
          42
        ],
        "images": [
          "figure/image/1286-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Major components of Our Model 1",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state next_to KB Semantic"
        ],
        "page_nums": [
          43
        ],
        "images": [
          "figure/image/1286-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Major components of Our Model 2",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state next_to KB Semantic"
        ],
        "page_nums": [
          44
        ],
        "images": [
          "figure/image/1286-Figure1-1.png"
        ]
      },
      "8": {
        "title": "Major components of Our Model 3",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state next_to KB Semantic"
        ],
        "page_nums": [
          45
        ],
        "images": [
          "figure/image/1286-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Action Set",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state next_to",
          "Define atom actions involved in semantic graph construction",
          "Node: A (variable), texas:st (entity), state (type)",
          "Sentence: Which river runs through the most states?",
          "Add entity node traverse most",
          "E.g., texas:st type type",
          "Add type node river state",
          "E.g., state Action Sequence:",
          "Add edge add_operation most",
          "E.g., next_to add_variable A",
          "Operation action add_variable B",
          "E.g., argmax, argmin, count add_type state B add_edge traverse A, B",
          "Argument action end_operation most A, B return A For type node, edge and operation"
        ],
        "page_nums": [
          46,
          47,
          48,
          49
        ],
        "images": [
          "figure/image/1286-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Encoder Decoder Model",
        "text": [
          "Sentence Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state",
          "Typical encoder-decoder model (bi-LSTM with attention)"
        ],
        "page_nums": [
          50,
          51,
          52,
          53
        ],
        "images": [
          "figure/image/1286-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Action Embedding",
        "text": [
          "Action Action Embedding Embedding",
          "Structure part Semantic part"
        ],
        "page_nums": [
          54,
          55,
          56,
          57,
          58
        ],
        "images": []
      },
      "12": {
        "title": "Structure and Semantic Constraints",
        "text": [
          "Sentence: Which states border Texas?",
          "RNN Model arg_node: A",
          "Constraints Generate add_entity: texas:st",
          "add_edge: next_to Action set",
          "type return A state",
          "Ensure action sequence will form a connected acyclic graph",
          "Ensure the constructed graph must follow the schema of knowledge bases",
          "Partial Semantic Graph: type",
          "Structure Semantic Arg Validity",
          "add_variable A Generated add_type state A Actions add_entity texas:st",
          "add_type city texas:st Action 1: violate type conflict",
          "Candidate add_edge loc A, texas:st Action 2: violate selectional preference constraint",
          "Next add_edge next_to A, A",
          "Action add_edge next_to A, texas:st",
          "Action 3: structure constraint"
        ],
        "page_nums": [
          59,
          60,
          61
        ],
        "images": []
      },
      "13": {
        "title": "Experiments",
        "text": [
          "We generate the action sequences from logical forms automatically.",
          "what is the population of illinois ?"
        ],
        "page_nums": [
          63
        ],
        "images": [
          "figure/image/1286-Figure4-1.png"
        ]
      },
      "14": {
        "title": "Baselines",
        "text": [
          "Zettlemoyer and Collins, 2005"
        ],
        "page_nums": [
          64
        ],
        "images": []
      },
      "15": {
        "title": "Competitive performance on three datasets",
        "text": [
          "ATIS [Rabinovich et al., [Rabinovich et al.,",
          "Need to design SO TA without extra",
          "SOTA Our full model resources",
          "GEO [Liang et al., [zhao et al.,"
        ],
        "page_nums": [
          65,
          66,
          67,
          68,
          69
        ],
        "images": []
      },
      "16": {
        "title": "Seq2Act outperforms Seq2Seq",
        "text": [
          "Seq2 Seq SOTA without",
          "Se q2Act e xtra resources"
        ],
        "page_nums": [
          70,
          71,
          72,
          73,
          74
        ],
        "images": []
      },
      "17": {
        "title": "Seq2ActC1 outperforms Seq2Act",
        "text": [],
        "page_nums": [
          75
        ],
        "images": []
      },
      "18": {
        "title": "Seq2ActC1C2 outperforms Seq2ActC1",
        "text": [],
        "page_nums": [
          76
        ],
        "images": []
      },
      "19": {
        "title": "Average Length of Logical Forms and Action Sequences",
        "text": [
          "Average len of logical forms Average len of action sequences"
        ],
        "page_nums": [
          77
        ],
        "images": []
      },
      "20": {
        "title": "Error Analysis",
        "text": [
          "Iowa borders how many states? (Formal Form: How many states",
          "Please show me first class flights from indianapolis to memphis",
          "one way leaving before 10am"
        ],
        "page_nums": [
          78
        ],
        "images": []
      },
      "21": {
        "title": "Conclusion",
        "text": [
          "Sequence-to-Action: End-to-End Semantic Graph Generation",
          "Representation ability of semantic graphs",
          "Sequence prediction ability of RNN models",
          "Achieve competitive results on GEO, ATIS and OVERNIGHT"
        ],
        "page_nums": [
          79
        ],
        "images": []
      },
      "22": {
        "title": "Future work",
        "text": [
          "Weak supervised learning algorithm for Seq2Act",
          "So our method can be applied to (q, a) pair datasets such as",
          "Apply Seq2Act model to other parsing tasks (e.g., AMR parsing)"
        ],
        "page_nums": [
          80
        ],
        "images": []
      }
    },
    "paper_title": "Sequence-to-Action: End-to-End Semantic Graph Generation for Semantic Parsing"
  },
  "1289": {
    "slides": {
      "0": {
        "title": "Background Unsupervised MT",
        "text": [
          "Recently: Unsupervised neural machine translation",
          "Initialization via unsupervised cross-lingual alignment of word embedding spaces"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Background Cross lingual word embeddings",
        "text": [
          "Cross-lingual word embeddings enable cross-lingual transfer",
          "Most common approach: Project one word embedding space into another by learning a transformation matrix W between n source embeddings xi and their translations yi",
          "i=1 More recently: Use an adversarial setup to learn an",
          "Assumption: Word embedding spaces are approximately isomorphic, i.e. same number of vertices, connected the same way."
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "How similar are embeddings across languages",
        "text": [
          "Nearest neighbour (NN) graphs of top 10 most frequent words in English and German are not isomorphic.",
          "NN graphs of top 10 most frequent English words and their translations into German",
          "Word embeddings are not approximately isomorphic across languages."
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "3": {
        "title": "How do we quantify similarity",
        "text": [
          "Need a metric to measure how similar two NN graphs G1 and G2 of different languages are",
          "A1, A2 : adjacency matrices of G1, G2",
          ": eigenvalues (spectra) of L1, L2",
          "Quantifies how much two NN graphs are isospectral, i.e. they have the same spectrum (same sets of eigenvalues).",
          "Isomorphic isospectral, but isospectral isomorphic",
          "G1, G2 are isospectral (very similar)",
          "G1, G2 become less similar"
        ],
        "page_nums": [
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "4": {
        "title": "Unsupervised cross lingual learning assumptions",
        "text": [
          "Besides isomorphism, several other implicit assumptions",
          "May or may not scale to low-resource languages",
          "Dependent-marking, Languages Agglutinative, many cases fusional and isolating",
          "Languages Dependent-marking, fusional and isolating Agglutinative, many cases",
          "Corpora Comparable (Wikipedia) Different domains",
          "Algorithms/ hyperparameters Same Different"
        ],
        "page_nums": [
          33,
          34,
          35,
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "5": {
        "title": "Conneau et al 2018",
        "text": [
          "Learn monolingual vector spaces X and Y",
          "Learn a translation matrix W . Train discriminator to discriminate samples from WX and Y",
          "Build bilingual dictionary of frequent words using W . Learn a new W based on frequent word pairs.",
          "Cross-domain similarity local scaling (CSLS):",
          "Use similarity measure that increases similarity of isolated word vectors, decreases similarity of vectors in dense areas."
        ],
        "page_nums": [
          40,
          41,
          42,
          43,
          44
        ],
        "images": []
      },
      "6": {
        "title": "A simple weakly supervised method",
        "text": [
          "Extract identically spelled words in both languages",
          "Use these as bilingual seed words",
          "Run refinement step of Conneau et al. (2018)"
        ],
        "page_nums": [
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "7": {
        "title": "Experiments Bilingual dictionary induction",
        "text": [
          "Given a list of source language words, find the closest target language word in the cross-lingual embedding space",
          "Compare against a gold standard dictionary",
          "Metric: Precision at 1 (P@1)",
          "Use fastText monolingual embeddings",
          "French, German, Chinese, Russian, Spanish",
          "Estonian (ET), Finnish (FI), Greek (EL), Hungarian (HU), Polish (PL), Turkish"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53,
          54
        ],
        "images": []
      },
      "8": {
        "title": "Impact of language similarity",
        "text": [
          "EN-ES EN-ET EN-FI EN-EL EN-HU EN-PL EN-TR ET-FI",
          "Unsupervised (Adversarial) Weakly supervised (Identical strings)",
          "Unsupervised approaches are challenged by languages that are not isolating and not dependent marking",
          "Naive supervision leads to competitive performance on similar language pairs and better results for dissimilar pairs",
          "Eigenvector similarity 6 4 2",
          "Eigenvector similarity strongly correlates with BDI performance"
        ],
        "page_nums": [
          55,
          56,
          57,
          58,
          59,
          60,
          61
        ],
        "images": []
      },
      "9": {
        "title": "Impact of domain differences",
        "text": [
          "Source and target embeddings induced on 3 corpora:",
          "EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)",
          "EP-EP EP-Wiki EP-EMEA Wiki-EP Wiki-Wiki Wiki-EMEA EMEA-EP EMEA-Wiki EMEA-EMEA",
          "Domain similarity Unsupervised Weakly supervised",
          "Unsupervised approaches break down when domains are dissimilar",
          "Domain differences may exacerbate difficulties of generalising across dissimilar languages",
          "Weak supervision helps to bridge domain differences, but performance still deteriorates"
        ],
        "page_nums": [
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74
        ],
        "images": []
      },
      "10": {
        "title": "Impact of hyper parameters",
        "text": [
          "Settings: English with skipgram, win=2, ngrams=3-6",
          "Vary hyper-parameters of Spanish embeddings",
          "with skipgram, of Spanish win=2, embeddings ngrams=3-6",
          "English-Spanish (skipgram) English-Spanish (cbow)",
          "introduce embedding spaces with"
        ],
        "page_nums": [
          75,
          76,
          77,
          78,
          79,
          80,
          81
        ],
        "images": []
      },
      "11": {
        "title": "Impact of dimensionality",
        "text": [
          "EN-ES EN-ET EN-FI EN-EL EN-HU EN-PL EN-TR",
          "300-dimensional embeddings 40-dimensional embeddings",
          "Worse performance overall, but better performance for dissimilar language pairs (Estonian, Finnish, Greek).",
          "Monolingual word embeddings may overfit to rare peculiarities of languages."
        ],
        "page_nums": [
          82,
          83,
          84,
          85
        ],
        "images": []
      },
      "12": {
        "title": "Impact of evaluation procedure",
        "text": [
          "Performance on verbs is lowest across the board.",
          "Sensitivity to frequency for Hungarian, but less so for",
          "Lower precision due to loan words/proper names. High precision for free with weak supervision."
        ],
        "page_nums": [
          86,
          87,
          88,
          89
        ],
        "images": []
      },
      "13": {
        "title": "Takeaways",
        "text": [
          "Word embedding spaces are not approximately isomorphic across languages.",
          "We can use eigenvector similarity to characterise the relatedness of two monolingual vector spaces.",
          "Eigenvector similarity strongly correlates with unsupervised bilingual dictionary induction performance.",
          "Limitations of unsupervised bilingual dictionary induction:",
          "Corpora from different domains.",
          "Different word embedding algorithms."
        ],
        "page_nums": [
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97
        ],
        "images": []
      }
    },
    "paper_title": "On the Limitations of Unsupervised Bilingual Dictionary Induction"
  },
  "1290": {
    "slides": {
      "0": {
        "title": "This is NOT an architecture search paper",
        "text": [
          "The Best of Both Worlds P 2"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "A Brief History of NMT Models",
        "text": [
          "Bahdanau et al. Gehring et al.",
          "The Best of Both Worlds P 3"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "The Best of Both Worlds I",
        "text": [
          "Each new approach is: accompanied by a set of modeling and training techniques.",
          "Tease apart architectures and their accompanying techniques.",
          "Identify key modeling and training techniques.",
          "Apply them on RNN based Seq2Seq RNMT+",
          "RNMT+ outperforms all previous three approaches."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "The Best of Both Worlds II",
        "text": [
          "Also, each new approach has: a fundamental architecture (signature wiring of neural network).",
          "Analyse properties of each architecture.",
          "Devise new hybrid architectures Hybrids",
          "Hybrids obtain further improvements over all the others.",
          "The Best of Both W orlds P 5"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Building Blocks",
        "text": [
          "RNN Based NMT - RNMT",
          "Convolutional NMT - ConvS2S",
          "Conditional Transformation Based NMT -",
          "Project name P 6"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "GNMT Wu et al",
        "text": [
          "The Best of Both Worlds P 7 *Figure from Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation Wu et al. 2016"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "ConvS2S Gehring et al",
        "text": [
          "More interpretable than RNN",
          "Parallel decoder outputs during training",
          "Need to stack more to increase the receptive field",
          "P 8 *Figure from Convolutional Sequence to Sequence Learning Gehring et al. 2017"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Transformer Vaswani et al",
        "text": [
          "Gradients everywhere - faster optimization",
          "Parallel encoding both training/inference",
          "Cons: Combines many advances at once Fragile",
          "P 9 *Figure from Attention is All You Need Vaswani et al. 2017"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "The Best of Both Worlds I RNMT",
        "text": [
          "Bi-directional encoder 6 x LSTM",
          "Uni-directional decoder 8 x LSTM",
          "Layer normalized LSTM cell",
          "The Best of Both Worlds P 10"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1290-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Model Comparison I BLEU Scores",
        "text": [
          "The Best of Both Worlds P 11"
        ],
        "page_nums": [
          10
        ],
        "images": [
          "figure/image/1290-Table2-1.png",
          "figure/image/1290-Table1-1.png"
        ]
      },
      "10": {
        "title": "Model Comparison II Speed and Size",
        "text": [
          "The Best of Both Worlds P 12"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1290-Table2-1.png",
          "figure/image/1290-Table1-1.png",
          "figure/image/1290-Table3-1.png"
        ]
      },
      "11": {
        "title": "Stability Ablations",
        "text": [
          "Evaluate importance of four key techniques:",
          "Critical to stabilize training",
          "(especially with multi-head attention)",
          "* Indicates an unstable training run Synchronous training",
          "Significant quality drop for RNMT+ Successful only with a tailored learning-rate schedule",
          "The Best of Both Worlds P 13"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1290-Table4-1.png"
        ]
      },
      "12": {
        "title": "The Best of Both Worlds II Hybrids",
        "text": [
          "Strengths of each architecture:",
          "Highly expressive - continuous state space representation.",
          "Full receptive field - powerful feature extractor.",
          "Combining individual architecture strengths:",
          "Capture complementary information - Best of Both Worlds.",
          "Trainability - important concern with hybrids",
          "Connections between different types of layers need to be carefully designed.",
          "The Best of Both Worlds P 14"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Encoder Decoder Hybrids",
        "text": [
          "Decoder - conditional LM",
          "Encoder - build feature representations",
          "Designed to contrast the roles.",
          "The Best of Both Worlds P 15"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1290-Table5-1.png",
          "figure/image/1290-Table6-1.png"
        ]
      },
      "14": {
        "title": "Encoder Layer Hybrids",
        "text": [
          "Enrich stateful representations with global self-attention",
          "Pre-trained components to improve trainability",
          "Layer normalization at layer boundaries",
          "Cascaded Hybrid - vertical combination",
          "Multi-Column Hybrid - horizontal combination",
          "The Best of Both Worlds P 16"
        ],
        "page_nums": [
          15,
          16
        ],
        "images": [
          "figure/image/1290-Figure2-1.png",
          "figure/image/1290-Table5-1.png",
          "figure/image/1290-Table6-1.png"
        ]
      },
      "15": {
        "title": "Lessons Learnt",
        "text": [
          "Need to separate other improvements from the architecture itself:",
          "Your good ol architecture may shine with new modelling and training techniques",
          "Stronger baselines (Denkowski and Neubig, 2017)",
          "Dull Teachers - Smart Students",
          "A model with a sufficiently advanced lr-schedule is indistinguishable from magic.",
          "Hybrids have the potential, more than duct taping.",
          "Game is on for the next generation of NMT architectures",
          "The Best of Both Worlds P 18"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"
  },
  "1292": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Good translation preserves the meaning of the sentence.",
          "Neural MT learns to represent the sentence.",
          "Is the representation meaningful in some sense?"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Gist of our idea",
        "text": [
          "1. Train variants of NMT to obtain sentence representations.",
          "2. Evaluate all such representations semantically.",
          "3. Relate performance in MT and in semantics."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Evaluating sentence representations",
        "text": [
          "prediction tasks for evaluating sentence embeddings",
          "focus on semantics (recently, linguistics task added, too).",
          "HyTER paraphrases (Dreyer and Marcu, 2014)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Evaluation through classification",
        "text": [
          "SentEval Classification Tasks an ambitious and moving but bleak film . | and that makes all the difference . | rarely , a movie is more than a movie . +> H | the movie is well done , but slow . | | | the pianist is polanski 's best film . i ||",
          "and that makes all the difference .",
          "rarely , a movie is more than a movie . +> H | > 1*x C4)",
          "the movie is well done , but slow .",
          "the pianist is polanski 's best film .",
          "e Solo: movies sentiment, product review polarity, question type...",
          "A square full of people and life . is . =>. E v",
          "The square is busy . Hifi",
          "The couple is at a restaurant . > LM ~. N Xx",
          "A cute couple at a club Hl |",
          "A white dog bounding through snow Ew > F Cv",
          "e Paired: natural language inference, semantic equivalence e 10 classification tasks in total, we report them as AvgAcc",
          "A cute couple at a club || 7",
          "oO 4k-55k training examples, with testset or 10-fold crosseval."
        ],
        "page_nums": [
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "4": {
        "title": "Evaluation through similarity",
        "text": [
          "7 similarity tasks: pairs of sentences + human judgement",
          "I think it probably depends on your money. It depends on your country.",
          "Yes, you should mention your experience. Yes, you should make a resume",
          "Hope this is what you are looking for. Is this the kind of thing you're looking for?",
          "with training set, sent. similarity predicted by regression, without training set, cosine similarity used as sent. sim., ultimately, the predicted sent. similarity is correlated with the golden truth.",
          "In sum, we report them as AvgSim."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation using paraphrases the data",
        "text": [
          "500 translations each captions each",
          "Khe NaS AKSR AAR, BN-TAAM. the deep cut and halter golden swimwear weighs half kilogram selling at ten million JPY.",
          "10,000,000 is the retail value for the low-cut gold bathing suit with a low back, and the weight is 5 hundred g. at the weight of five hundred grams, the low cut, halter swimsuit made up of gold will sell at ten million Japanese Yen (JPY).",
          "a person is feeding a donut to the cat. a cat being fed a donut by someone in a grey shirt. a cat nibbles on a sprinkled donut that is being fed by the owner. a grey cat biting into a frosted donuts a cat is eating a donut from a"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Evaluation using paraphrases the metrics",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Cluster separation Davies Bouldin index",
        "text": [
          "find the least well-"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "8": {
        "title": "Paraphrase retrieval task NN",
        "text": [
          "ee ----@ nearest neighbor a KON and check",
          "e oe the same cluster"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Classification task",
        "text": [
          "Remove some points from the clusters.",
          "Train an LDA classifier with the remaining points.",
          "Classify the removed points back."
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Sequence to sequence with attention",
        "text": [
          "ij: weight of the jth encoder state for the ith decoder state"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1292-Figure1-1.png"
        ]
      },
      "11": {
        "title": "Ways of getting sentence embeddings",
        "text": [],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": [
          "figure/image/1292-Figure1-1.png"
        ]
      },
      "12": {
        "title": "Multi head inner attention",
        "text": [
          "ij: weight of the jth encoder state for the ith column of MT",
          "concatenate columns of MT",
          "linear projection of columns to control embedding size"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1292-Figure1-1.png"
        ]
      },
      "13": {
        "title": "Proposed NMT architectures",
        "text": [
          "ATTN-CTX ATTN-ATTN (compound att.)",
          "decoder operates on entire embedding decoder selects components of embedding"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": [
          "figure/image/1292-Figure1-1.png"
        ]
      },
      "14": {
        "title": "Evaluated NMT models",
        "text": [
          "FINAL, FINAL-CTX: no attention",
          "AVGPOOL, MAXPOOL: pooling instead of attention",
          "ATTN-CTX: inner attention, constant context vector",
          "ATTN-ATTN: inner attention, decoder attention",
          "TRF-ATTN-ATTN: Transformer with inner attention",
          "translation from English (to Czech or German), evaluating embeddings of English (source) sentences"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "15": {
        "title": "Sample Results translation quality encs",
        "text": [
          "Selected models trained for translation from English to Czech. The embedding size is 1000 (except ATTN).",
          "BLEU is consistent with human evaluation.",
          "Attention in the encoder helps translation quality."
        ],
        "page_nums": [
          25,
          26,
          27,
          28
        ],
        "images": []
      },
      "16": {
        "title": "Sample Results representation eval encs",
        "text": [
          "Selected models trained for translation from English to Czech. InferSent and GloVe- BOW are trained on monolingual (English) data.",
          "Baselines are hard to beat.",
          "Attention harms the performance."
        ],
        "page_nums": [
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "17": {
        "title": "Full Results correlations excluding Transformer",
        "text": [
          "BLEU vs. other metrics:"
        ],
        "page_nums": [
          33,
          34
        ],
        "images": [
          "figure/image/1292-Figure2-1.png"
        ]
      },
      "18": {
        "title": "Compound attention interpretation",
        "text": [
          "ATTN-ATTN en-cs model with 8 heads"
        ],
        "page_nums": [
          35,
          36
        ],
        "images": [
          "figure/image/1292-Figure4-1.png"
        ]
      },
      "19": {
        "title": "Summary",
        "text": [
          "Proposed NMT architecture combining the benefit of attention and one $&!#* vector representing the whole sentence.",
          "Evaluated the obtained sentence embeddings using a wide range of semantic tasks.",
          "The better the translation, the worse performance in meaning representation.",
          "Heads divide sentence equidistantly, not logically.",
          "Heads divide sentence eJoqiuni doisutr antly, not logically.",
          "JNLE Special Issue on Sentence Representations:"
        ],
        "page_nums": [
          41,
          42,
          43,
          44,
          45
        ],
        "images": []
      },
      "20": {
        "title": "InferSent multi task training in OCs thesis only",
        "text": [
          "e |dea: produce better representations by jointly training",
          "NMT with other tasks",
          "e Proxy: predict InferSent embeddings as the auxiliary task",
          "L= Ly + alomse",
          "L tar mT, target"
        ],
        "page_nums": [
          46
        ],
        "images": []
      },
      "21": {
        "title": "Multi task training results encs",
        "text": [
          "<I Multitask Inactive, a",
          "Small loss in BLEU xc. maxeooy, Sometimes gain iN AVGACC cexe. 4000, 4h)",
          "<4 Multitask Active, a"
        ],
        "page_nums": [
          47,
          48,
          49
        ],
        "images": []
      },
      "22": {
        "title": "Multi task training results ende",
        "text": [
          "SEE Ne Een Sennen aoe",
          "en-de results less stable (much smaller vocabulary).",
          "<1 Multitask Inactive, a <4 Multitask Active, a=",
          "e Generally promising. L",
          "e Further exploration of a values |...",
          "and datasets needed. L"
        ],
        "page_nums": [
          50,
          51,
          52,
          53
        ],
        "images": []
      }
    },
    "paper_title": "Are BLEU and Meaning Representation in Opposition?"
  },
  "1293": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Machine Translation Dialogue Text to Code",
          "the big black cat A: What do you want to do tonight? sort a list of numbers",
          "B: Lets go for a movie!",
          "for i in range(len(A)): min_idx = i",
          "Input Sentence Compression Reconstruction"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Unsupervised Models for Language",
        "text": [
          "Discrete Latent Variable Autoencoders",
          "Model the discreteness of language",
          "Sampling is not differentiable",
          "REINFORCE: sample inefficient and unstable"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Contributions",
        "text": [
          "Model Supervision Abstractive Differentiable Latent",
          "Fully unsupervised and abstractive",
          "Fully differentiable (continuous approximations)",
          "Human-readable compressions via LM prior",
          "User-defined flexible compression ratio",
          "SOTA in unsupervised sentence compression"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "SEQ3 Overview",
        "text": [
          "Reconstruction loss: distill input into the latent sequence",
          "LM Prior loss: human-readable compressions",
          "Compressor Minimize DKL between Compressor and LM:",
          "Topic loss: similar topic as input",
          "vx: IDF-weighted average of esi",
          "Reconstructor vy: average of eci",
          "Length constraints: user-defined shorter length",
          "Length-aware decoder initializat ion",
          "Countdown Encoder inputs Decoder",
          "3. Explicit length penalty"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "4": {
        "title": "Differentiable Sampling",
        "text": [
          "Forward-pass: Discrete embedding (Gumbel-max trick)",
          "Backward-pass: Mixture of embeddings (Gumbel-softmax approx.)"
        ],
        "page_nums": [
          26,
          27,
          28
        ],
        "images": []
      },
      "5": {
        "title": "Experimental Setup",
        "text": [
          "Train LM (LM prior) Train seq3",
          "Never exposed to target sentences (compressions)",
          "Vocabulary: 15K most frequent words in source sentences",
          "Average F1 of ROUGE-1, ROUGE-2, ROUGE-L"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "6": {
        "title": "Results on Gigaword",
        "text": [
          "Supervision Model R-1 R-2 R-L",
          "Unsupervised Pretrained Generator (Wang & Lee,2018)",
          "Table: Results on (English) Gigaword for sentence compression."
        ],
        "page_nums": [
          30,
          31
        ],
        "images": []
      },
      "7": {
        "title": "Ablation",
        "text": [
          "Both topic and LM losses work in synergy",
          "LM prior loss: how words should be included",
          "Topic loss: what words to include"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "8": {
        "title": "Model Outputs",
        "text": [
          "the central election commission ( cec ) on monday decided that taiwan will hold another election of national assembly members",
          "national <unk> election scheduled for may",
          "the central election commission ( cec ) announced elections",
          "INPUT dave bassett resigned as manager of struggling english pre-",
          "mier league side nottingham forest on saturday after they were",
          "knocked out of the f.a. cup in the third round according to local reports on saturday",
          "forest manager bassett quits",
          "dave bassett resigned as manager of struggling english premier league side UNK forest on knocked round press"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "9": {
        "title": "Conclusions and Future Work",
        "text": [
          "Fully differentiable seq2seq2seq (seq3) autoencoder",
          "SOTA in unsupervised abstractive sentence compression",
          "Topic loss is essential for convergence",
          "LM prior improves readability",
          "Next Step: unsupervised machine translation",
          "Machine Translation Dialogue Text to Code",
          "the big black cat A: What do you want to do tonight? sort a list of numbers",
          "B: Lets go for a movie!"
        ],
        "page_nums": [
          34,
          35
        ],
        "images": []
      },
      "10": {
        "title": "Differentiable Sampling Extended",
        "text": [
          "Soft-argmax: Weighted sum of embeddings from peaked softmax",
          "= argmax(ai i), i Gumbel",
          "y = softmax(ai i), i Gumbel",
          "Gumbel-softmax: Differentiable approximation to sampling",
          "Straight-Through: forward-pass: one-hot, backward-pass: soft"
        ],
        "page_nums": [
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "11": {
        "title": "Out of Vocabulary OOV Words",
        "text": [
          "We copy OOV words using the approach of Fevry and Phang (2018).",
          "Simpler alternative to pointer networks (See et al., 2017).",
          "We use a set of special OOV tokens: oov1, oov2, . . . , oovN",
          "We replace the ith unknown word in the input with the oovi token.",
          "If all the OOV tokens are used, we use the generic UNK token.",
          "In inference, we replace the special tokens with the original words.",
          "RAW John arrived in Rome yesterday. While in Rome, John had fun.",
          "INPUT oov1 arrived in oov2 yesterday. While in oov2, oov1 had fun."
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "12": {
        "title": "Temperature for Gumbel Softmax",
        "text": [
          "Temperature does not affect the forward pass, but it affects gradients.",
          "Havrylov & Titov (2017) tune bound",
          "In our experiments the learned temperature lead to instability."
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "13": {
        "title": "Implementation Details",
        "text": [
          "Decoders: 2-layer unidirectional LSTM with size",
          "Embedding: initialize with 100d GloVe (Pennington et al., 2014)",
          "Tied encoders of the compressor and reconstructor.",
          "Shared embedding layer for all encoders and decoders.",
          "Tied embedding-output layers of both decoders."
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "14": {
        "title": "Length Control",
        "text": [
          "Sample target length M.",
          "Decoders state length-aware initialization."
        ],
        "page_nums": [
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "15": {
        "title": "Results on DUC Shared Tasks",
        "text": [
          "Table: Results on the DUC-2004"
        ],
        "page_nums": [
          49
        ],
        "images": [
          "figure/image/1293-Table2-1.png"
        ]
      },
      "16": {
        "title": "Model Output Extra",
        "text": [
          "INPUT the american sailors who thwarted somali pirates flew home",
          "to the u.s. on wednesday but without their captain , who was still aboard a navy destroyer after being rescued from the hijackers",
          "GOLD us sailors who thwarted pirate hijackers fly home",
          "SEQ3 the american sailors who foiled somali pirates flew home"
        ],
        "page_nums": [
          50
        ],
        "images": []
      }
    },
    "paper_title": "SEQ 3 : Differentiable Sequence-to-Sequence-to-Sequence Autoencoder for Unsupervised Abstractive Sentence Compression"
  },
  "1294": {
    "slides": {
      "0": {
        "title": "Power laws of natural language",
        "text": [
          "2. Burstiness About how the words are aligned",
          "Words occur in clusters These can be analyzed through power laws",
          "Occurrences of words fluctuate",
          "Todays talk is about quantifying the degree of fluctuation.",
          "How these could be useful will be presented at the end."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Fluctuation underlying text Look at variance in t",
        "text": [
          "Any words (any word, any set of words) occur in clusters",
          "Occurrences of rare words in Moby Dick (below 3162th)",
          "Two ways of analysis",
          "Long range correlation weaknesses"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Any words any word any set of words occur in clusters",
        "text": [
          "Fluctuation underlying text Look at variance in",
          "Occurrences of rare words in Moby Dick (below 3162th)",
          "Variance is larger when events are clustered vs. random",
          "Two ways of analysis",
          "Fluctuation Analysis (Ebeling 1994) variance w.r.t.",
          "Taylors analysis Our achievements Long range correlation variance w.r.t. mean"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Taylors law Smith 1938 Taylor 1961",
        "text": [
          "Power law between standard deviation and mean of event occurrences within (space or) time",
          "Empirically (but is of course possible, too)",
          "Empirically known to hold in vast fields (Eisler, 2007) ecology, life science, physics, finance, human dynamics",
          "The only application to language is",
          "Gerlach & Altmann (2014) not really Taylor analysis",
          "We devised a new method based on the original concept of Taylors law"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Our method",
        "text": [
          "1 For every word kind C count its number of occurrence within given length",
          "Estimate using the least squares method in log scale",
          "2 Obtain mean C and standard deviation C of C.",
          "@ log C log C'",
          "3 Plot C and C for all words. CF0"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Taylors law of natural language",
        "text": [
          "- - Moby Taylors Here, Every English, vocabulary Dick point law 250k in",
          "5000. is size log a words, word 20k scale words kind",
          "Taylor exponent corresponds to gradient of log -log plot.",
          "Taylors law in log scale"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "6": {
        "title": "Theoretical analysis of the exponent",
        "text": [
          "if all words are independent and identically distributed (i.i.d.).",
          "Taylor Exponent because shuffled text is equivalent to i.i.d. process.",
          "if words always co-occur with the same proportion. ex) Suppose that = {0,1}, and occurs always twice as"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "7": {
        "title": "Taylors law for other data",
        "text": [
          "Lisp, crawled and parsed",
          "dear this platform truck insert up xload things and hand unless let"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Datasets",
        "text": [
          "Newspapers 3 (En,Zh,Ja) WSJ",
          "Tagged Wiki 1 (En+tag) enwiki8",
          "CHILDES 10(En, Fr, Thomas (English)",
          "Program Codes C++, Lisp, Haskell,"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Taylor exponents of various data kind",
        "text": [
          "None of the real texts showed the exponent 0.5"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Summary thus far",
        "text": [
          "Taylors law holds in vast fields including natural/social science",
          "Taylors law also holds in languages and other linguistic related sequential data",
          "Taylor exponent shows the degree of co-occurrence among words",
          "Taylor exponent differs among text categories",
          "(No such quality for Zipfs law, Heaps law)",
          "How can our results be useful?",
          "Do machine generated texts produce"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Machine generated text by n grams",
        "text": [
          "bigrams of Moby Dick"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1294-Figure4-1.png"
        ]
      },
      "12": {
        "title": "Machine generated texts by character based LSTM language model",
        "text": [
          "Stacked LSTM (3 LSTM layers)",
          "Distribution of following character",
          "Learning: Shakespeare by naive setting",
          "Generation: Probabilistic generation of succeeding characters",
          "128 preceding characters State-of the art models present different results"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Texts generated by machine translation",
        "text": [
          "Les Miserables translated by",
          "Google translator (in English)",
          "Fluctuation that derives from the context is provided by the source text"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Conclusion",
        "text": [
          "Taylors law holds in vast fields including natural/social science",
          "Taylors law also holds in languages and other linguistic related sequential data",
          "Taylor exponent shows the degree of co-occurrence among words",
          "Taylor exponent differs among text categories",
          "(No such quality for Zipfs law, Heaps law)",
          "How can our results be useful?",
          "Do machine generated texts produce",
          "The nature of : context and long memory one limitation of CL",
          "Taylor analysis would possibly evaluate machine outputs",
          "Knowing mathematical characteristic of texts serve for language engineering"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Taylor's Law for Human Linguistic Sequences"
  },
  "1296": {
    "slides": {
      "0": {
        "title": "Natural Language Understanding",
        "text": [
          "How long does it take to get a PhD?"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "Human Interactions",
        "text": [],
        "page_nums": [
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "2": {
        "title": "Teach Machines to Ask Clarification Questions",
        "text": [
          "How long does it take to get a PhD ? Give me a recipe for lasagna",
          "In which field? Any dietary",
          "Please bring me my coffee mug from the kitchen What color is your coffee mug?",
          "Context-aware questions about missing information"
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "3": {
        "title": "Reading Comprehension Question Generation",
        "text": [
          "My class is going to the movies on a field trip next week.",
          "We have to get permission slips signed before we go.",
          "We are going to see a movie that tells the story from a",
          "Goal: Assess someones understanding of the text",
          "Q: What do the students need to do before going to the movies?",
          "o Heilman. Automatic factual question generation from text Ph.D. thesis 2011",
          "o Vasile, et al. \"The first question generation shared task evaluation challenge. NLG 2010",
          "o Olney, Graesser, and Person. \"Question generation from concept maps.\" Dialogue & Discourse 2012",
          "o Chali and Hasan. \"Towards Topic-to-Question Generation.\" ACL 2015",
          "Serban, et al. \"Generating Factoid Questions With Recurrent Neural Networks ACL 2016",
          "Du, Shao & Cardie \"Learning to ask: Neural question generation for reading comprehension\" ACL 2017",
          "Tang et al. \"Learning to Collaborate for Question Answering and Asking.\" NAACL 2018",
          "Mrinmaya and Xing. \"Self-Training for Jointly Learning to Ask and Answer Questions.\" NAACL 2018"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "4": {
        "title": "Question Generation for Slot Filling",
        "text": [
          "I want to go to Melbourne on July 14",
          "What time do you want to leave?",
          "I must be in Melbourne by 11 am",
          "Would you like a Delta flight that arrives at 10.15 am?",
          "In what name should I make the reservation?",
          "o Goddeau, et al. \"A form-based dialogue manager for spoken language applications. 1996",
          "o Bobrow., et al. \"GUS, a frame-driven dialog system.\" Artificial intelligence 1977",
          "o Lemon, et al. \"An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic",
          "slot-filling in the TALK in-car system. EACL 2006",
          "Williams, et al. The Dialog State Tracking Challenge SIGDIAL 2013",
          "Young, et al. Pomdp-based statistical spoken dialog systems: A review. IEEE 2013",
          "o Dhingra, et al. \"Towards End-to-End Reinforcement Learning of Dialogue Agents for Information",
          "o Bordes, et al. \"Learning end-to-end goal-oriented dialog. ICLR 2017"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "5": {
        "title": "Other types of Question Generation",
        "text": [
          "o Liu, et al. Automatic question generation for literature review writing support.\"",
          "International Conference on Intelligent Tutoring Systems. 2010",
          "o Penas and Hovy, Filling knowledge gaps in text for machine reading International",
          "Conference on Computational Linguistics: Posters ACL 2010",
          "o Artzi & Zettlemoyer, Bootstrapping semantic parsers from conversations EMNLP 2011",
          "o Labutov, et al.Deep questions without deep understanding ACL 2015",
          "o Mostafazadeh et al. \"Generating natural questions about an image.\" ACL 2016",
          "o Mostafazadeh et al. \"Multimodal Context for Natural Question and Response",
          "o Rothe, Lake and Gureckis. Question asking as program generation NIPS 2017."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "6": {
        "title": "Clarification Questions Dataset",
        "text": [
          "How to configure path or set environment variables for installation?",
          "I'm aiming to install ape, a simple code for pseudopotential generation.",
          "I'm having this error message while running ./configure",
          "So I have the library but the program installation isn't finding it.",
          "Any help? Thanks in advance!",
          "Finding: Questions go unanswered for a long time if they are not clear enough",
          "Asaduzzaman, Muhammad, et al. \"Answering questions about unanswered questions of stack overflow. Working Conference on Mining Software Repositories. IEEE Press, 2013.",
          "What version of ubuntu do you have?",
          "I'm aiming to install ape in Ubuntu 14.04 LTS, a simple code for pseudopotential generation.",
          "Edit as an answer to the question",
          "post question answer triples",
          "question Clarification question posted in comments",
          "answer Edit made to the post in response to the question",
          "OR authors reply to the question comment",
          "Dataset Size: ~77 K triples",
          "Domains: Askubuntu, Unix, Superuser",
          "Note: We identify a question using the question mark (?) token. We match the edit to the answer using timestamp & word embedding similarity based heuristics."
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27
        ],
        "images": []
      },
      "7": {
        "title": "Problem Formulation Question Ranking",
        "text": [
          "What is the make of your wifi card?",
          "How to configure path or set environment variables for installation?",
          "What is the make What version of of your wifi card? Ubuntu do you have?",
          "What OS are you using?",
          "Rank the question candidates",
          "I'm aiming to install ape, a simple code for pseudopotential generation.",
          "I'm having this error message while running ./configure",
          "So I have the library but the program installation isn't finding it.",
          "Any help? Thanks in advance!",
          "What version of Ubuntu do you have?",
          "How are you installing ape? Shortlist of useful questions",
          "Do you have GSL installed?"
        ],
        "page_nums": [
          29,
          30,
          31,
          32
        ],
        "images": []
      },
      "8": {
        "title": "Expected Value of Perfect Information EVPI inspired model",
        "text": [
          "How to configure path or set environment variables for installation?",
          "I'm aiming to install ape, a simple code for pseudopotential generation.",
          "I'm having this error message while running ./configure",
          "So I have the library but the program installation isn't finding it.",
          "Any help? Thanks in advance!",
          "(a) What version of Ubuntu do you have? Just right",
          "(b) What is the make of your wifi card? Not useful",
          "(c) Are you running Ubuntu 14.10 kernel 4.4.0-59- generic on an x86 64 architecture? Unlikely to add value",
          "o Use EVPI to identify questions that add the most value to the given post",
          "Avriel, Mordecai, and A. C. Williams. \"The value of information and stochastic programming.\" Operations Research 18.5 (1970)",
          "o Definition: Value of Perfect Information VPI (x)",
          "How much value does x add to a given information content c?",
          "o Since we have not acquired x, we define its value in expectation",
          "Likelihood of x given c",
          "Value of updating c with x",
          "EVPI formulation for our problem",
          "p : given post",
          "qi : question from set of question candidates Q",
          "Likelihood of aj being the answer to qi on post p",
          "EVPI qi p P aj p qi U( p aj",
          "Utility of updating the post p with answer aj",
          "aj : answer from set of answer candidates A",
          "We rank questions based on their EVPI value",
          "Question & Answer Candidate Generator",
          "Post p as query",
          "Ten posts similar to given post p",
          "Lucene Search Engine pj qj aj",
          "Questions paired with those posts",
          "Answers paired with those posts",
          "Documents p2 q2 a2",
          "P qi aj p qi Embans( p",
          "P aj p qi cosine_sim(Embans( p qi aj",
          "Embans( p Average Feedforward",
          "Close to true ai paired with p p Close to ak qi paired with qk ai : Ubuntu 14.04 LTS similar to true qi",
          "qi Which version of",
          "Embans( qi p Average Feedforward",
          "Word embedding module ak : Ubuntu 11.10",
          "qK What OS are you using? p qi aj",
          "Value between 0 and 1",
          "qj : What OS are you using? y = 0 aj : Ubuntu 11.10 Post LSTM Question LSTM Answer LSTM",
          "qi : Which version of Ubuntu do you have? y = 1",
          "qk : What is the make of your wifi card? y = 0 Word embedding module ak : TP-Link TL-WDN4800",
          "Training (Minimize binary cross-entropy)",
          "Train time behavior: For each (p, q, a) in our train set",
          "Generate question candidates (Q) and answer candidates (A)",
          "Train Answer Model and Utility Calculator",
          "using joint loss function : lossans (p, q, a, Q) + lossutil (y, p, q, a)",
          "Test time behavior: Given a post from our test set",
          "Calculate P(aj |p, qi) for each q Q using Answer Model",
          "Calculate U(p + aj) for each a A using Utility Calculator",
          "Rank questions by EVPI (qi | p) = P(aj | p, qi) U(p + aj) aj A",
          "LONG SHORT TERM MEMORY (LSTM)",
          "Sepp Hochreiter and Jurgen Schmidhuber. 1997. Long short-term memory. Neural computation , 9(8):17351780.",
          "Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation In Empirical Methods on Natural Language Processing."
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          110
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation",
        "text": [
          "Too much disk read/write when launching an application",
          "I have Xubuntu 13.04 on an old Dell Inspiron.",
          "When I launch an application it takes a pretty long time to be launched and I see a lot of",
          "If the system was short on memory, this would be understandable as the system would",
          "use swap. But that's not the case in my situation (i.e. I have this problem even when the",
          "RAM is almost empty).",
          "How much ram do you have installed ? and what size it the swap disk partition ?",
          "If you do not have any problem with getting a little techy then may i suggest a method ?",
          "How is it slow exactly ? boot time ? hdd read/write ? cpu time ? graphics rendering ?",
          "What is the longest time you have let it run ?",
          "This may be a silly question but ... did you make your usb stick bootable ?",
          "Do your system were recently updated ?",
          "Why not have two ssds in raid 1 for redundancy ?",
          "Is that a `parted -- list` on the synology device ? Can you tell us a little about your configuration ? Did you turn hardware virtualization on in bios/efi ?",
          "Question Candidates Contains more than one good question!",
          "o We recruit 10 Unix admin experts using UpWork",
          "o Given a post and the set of ten question candidates",
          "Mark the one best question",
          "Mark any other valid questions",
          "o We annotate a total of 500 posts from our test set",
          "o Each post is annotated by two experts",
          "Union of Bests: Questions marked as best by either of the annotators",
          "Intersection of Valids: Questions marked as valid by both annotators",
          "Intersection of Valids: Q1, Q3, Q5",
          "Random: Randomly permute the 10 candidate questions",
          "Bag-of-ngrams: Train linear classifier using bag-of-ngrams of p, q and a",
          "o SemEval Task: Rank comments by relevance to post on Qatar Living",
          "o Winning model: Logistic regression trained with string similarity & word embedding based features (Nandi et al., 2017)",
          "o Our baseline: We retrain this model on our dataset",
          "have similar no. of parameters Post LSTM Ques LSTM Ans LSTM",
          "Feedforward Neural (p, q, a)",
          "pi qi ai Both Neural (p, q, a) and EVPI (q | p, a)",
          "Explicitly modeling answer is useful",
          "Both use only (p, q)",
          "Note: Difference between EVPI and all baselines is statistically significant with p < 0.05",
          "Mainly differ in their",
          "Intersection of Valids Union of Best",
          "Neural (p, q) significant",
          "Union of Best (with true removed)"
        ],
        "page_nums": [
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          103,
          104,
          105,
          106,
          107
        ],
        "images": []
      },
      "10": {
        "title": "Conclusion",
        "text": [
          "Create a dataset of ~77K clarification questions (and answers) with context",
          "Introduce novel model that integrates deep learning with classic notion of",
          "expected value of perfect information",
          "Create an evaluation set of size 500 with expert human annotations",
          "A context can have multiple good clarification question",
          "Explicitly modeling the answer helps in identifying good questions",
          "EVPI formalism provides leverage over similarly expressive feedforward network",
          "Sequence-to-sequence based question generation model",
          "How to automatically evaluate performance?",
          "CODE + DATA: https://github.com/raosudha89/ranking_clarification_questions"
        ],
        "page_nums": [
          98,
          99,
          100,
          101
        ],
        "images": []
      },
      "11": {
        "title": "Backup Slides",
        "text": [],
        "page_nums": [
          102
        ],
        "images": []
      },
      "12": {
        "title": "Sample output",
        "text": [
          "Too much disk read/write when launching an application",
          "I have Xubuntu 13.04 on an old Dell Inspiron.",
          "When I launch an application it takes a pretty long time to be launched and I see a lot of",
          "If the system was short on memory, this would be understandable as the system would",
          "use swap. But that's not the case in my situation (i.e. I have this problem even when the",
          "RAM is almost empty).",
          "Ranking of Question Candidates EVPI value Best Valid",
          "How much ram do you have installed? and what size is the swap disk partition",
          "Can you tell us a little about your configuration ?",
          "What is the longest time you have let it run ?",
          "How is it slow exactly ? boot time ? hdd read/write ? cpu time ?",
          "If you do not have any problem with getting a little techy may i suggest a method ?",
          "This may be a silly question but ... did you make your usb stick bootable ?",
          "Do your system were recently updated ?",
          "Why not have two ssds in raid 1 for redundancy ? Is that a `parted -- list` on the synology device ? Did you turn hardware virtualization on in bios/efi ?",
          "No wifi after restart in Ubuntu 16.04",
          "After upgrading to 16.04, there is no wifi whenever I restart the system. My wireless",
          "On iwconfig I got the following eth0 no wireless extensions.",
          "Currently to start wifi again I have to shutdown, then boot the system again. How to fix the problem?",
          "EVPI value Best Valid Ranking of Question Candidates",
          "I doubt it, shutdown and reboot are exactly identical! are you really rebooting?",
          "Be clear about the problem. Is Ubuntu not showing them even though they are present?",
          "What is 4g wifi connection?",
          "Can you type `iwconfig` in terminal and paste what it returns here?",
          "What does this tell us?",
          "If I post it as an answer, would you kindle mark as such?",
          "What exactly do you mean by make fails? Welcome to ask Ubuntu! ; - ) Is the wireless lan disabled in the bios? Is Ubuntu detecting your wireless card ? **iwconfig** does list your card?"
        ],
        "page_nums": [
          108,
          109
        ],
        "images": []
      }
    },
    "paper_title": "Learning to Ask Good Questions: Ranking Clarification Questions using Neural Expected Value of Perfect Information"
  },
  "1297": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "Raw unlabeled data points x1, x2,",
          "Classifier Oracle/Expert: Provides labels for queries",
          "At any time during the AL process, we have a current guess for the classifier",
          "AL Strategy: Query the point closest to the decision boundary",
          "Not clear whether heuristics lead to optimal querying behavior",
          "Not clear which hard coded heuristic is good for a task at hand",
          "Can we learn the best active learning strategy ?"
        ],
        "page_nums": [
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "Agent based Active Learning",
        "text": [
          "Need to train an AL agent to tell what data to select next, given the previously selected data the pool of unlabeled data available the underlying classifier, Raw unlabeled learned data so points far x1, x2,",
          "Classifier Oracle/Expert: Provides labels for queries"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "2": {
        "title": "AL Query Strategy by an Agent",
        "text": [
          "Raw unlabeled data points x1, x2,",
          "The Tutoring AL Agent & Learning Student (Classifier)",
          "Oracle/Expert: Provides labels for queries"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "3": {
        "title": "Agent Operates in Markov Decision Process",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Training Agents Policy",
        "text": [
          "IDEA: Lets train the agent based on AL simulation for a rich-data task and then transfer it to AL problem of interest",
          "This is Meta-Learning: Learning to Actively Learn",
          "Synthesize many AL problems",
          "Use Imitation/Reinforcement Learning algorithms"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "5": {
        "title": "Synthesizing AL Problems",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "6": {
        "title": "Imitation Learning",
        "text": [
          "The algorithmic oracle gives the correct action in each world state",
          "Train the agent (policy network) to prefer the correct action compared to incorrect ones (i.e. classification)",
          "The collected state-action pairs are not i.i.d. hence problematic for classifier learning",
          "Data Aggregation (DAGGER): Once in a while, use the predicted action by the policy network during training",
          "This is to make sure the policy sees bad states and the correct action to recover from them in the training time"
        ],
        "page_nums": [
          14,
          16
        ],
        "images": [
          "figure/image/1297-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Algorithmic Oracle",
        "text": [
          "It computes the correct action in each world state",
          "Re-train the underlying model using all possible queries/actions",
          "Mark the one leading to the most accurate prediction on the evaluation set",
          "argmax(xi,yi) in Pool Accuracy ( Retrain( , xi,yi)",
          "Too slow for typical large pools of data",
          "IDEA: Randomly sample a subset and maximize over it",
          "Leads to efficient training and effective learned policies"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "8": {
        "title": "Experiments Task 1 text classification",
        "text": [
          "Sentiment Classification: Positive/Negative sentiment of a review",
          "Train the AL policy on one product, and apply to the reviews of another",
          "Authorship Profiling: Gender of the author of a tweet",
          "Train the AL policy on one language, and apply to another",
          "Direct transfer: Initialize the classifier on the source data, without",
          "Cold-start: Start training the classifier from random initialization, continue training with AL agent",
          "Warm-start: Start training the classifier from the pre-trained model on the source data, continue training with AL agent"
        ],
        "page_nums": [
          18,
          20,
          21
        ],
        "images": [
          "figure/image/1297-Figure2-1.png",
          "figure/image/1297-Table1-1.png"
        ]
      },
      "9": {
        "title": "Experiments Baseline methods",
        "text": [
          "PAL (Fang et al., 2017) : A deep reinforcement learning based approach, they designed a Q-network for stream-based AL"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "10": {
        "title": "Experiments Task 2 Named Entity Recognition",
        "text": [],
        "page_nums": [
          22,
          23
        ],
        "images": [
          "figure/image/1297-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Analysis Insight on the selected data",
        "text": [
          "We use MRR(Mean reciprocal rank) and acc to show the agreement of queried data points returned by our AL agent and other strategies."
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1297-Table3-1.png"
        ]
      },
      "12": {
        "title": "Analysis Sensitivity to K size of unlabeled subset",
        "text": [
          "K: size of subset from the original unlabelled set"
        ],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/1297-Figure4-1.png",
          "figure/image/1297-Figure5-1.png"
        ]
      },
      "13": {
        "title": "Analysis schedule parameter for the policy",
        "text": [],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1297-Figure5-1.png"
        ]
      },
      "14": {
        "title": "Related work",
        "text": [
          "Meta learning eg learning to learn without gradient descent by gradient descent (Chen et al 2016)",
          "Stream-based AL as MDP; learning the policy with reinforcement learning (Fang et al, 2017) suffers from the credit assignment problem (Bechman et al 2017)",
          "Imitation Learning: Lerning from expert demonstrations eg (Schaal"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "Use heuristics or learn an agent for the AL query strategy.",
          "Agent-based AL as a Markov Decision Process.",
          "Formulate learning AL strategies/policies as an imitation learning problem.",
          "Our imitation learning approach performs better than previous heuristic-based and RL-based methods."
        ],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "Learning How to Actively Learn: A Deep Imitation Learning Approach"
  },
  "1298": {
    "slides": {
      "0": {
        "title": "Creativity",
        "text": [
          "I Can machine learning models be creative?",
          "I Can these models compose novel and interesting narrative?",
          "I We focus on sonnet generation in this work."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Sonnets",
        "text": [
          "Shall I compare thee to a summers day?",
          "Thou art more lovely and more temperate:",
          "Rough winds do shake the darling buds of May,",
          "And summers lease hath all too short a date:",
          "I A distinguishing feature of poetry is its aesthetic forms, e.g. rhyme and",
          "I Rhyme: {day May}; {temperate, date}."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Modelling Approach",
        "text": [
          "I We treat the task of poem generation as a constrained language modelling task.",
          "I Given a rhyming scheme, each line follows a canonical meter and has a fixed",
          "I We focus specifically on sonnets as it is a popular type of poetry (sufficient data)",
          "and has regular rhyming (ABAB, AABB or ABBA) and stress pattern (iambic pentameter).",
          "I We train an unsupervised model of language, rhyme and meter on a corpus of"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Sonnet Corpus",
        "text": [
          "I We first create a generic poetry document collection using GutenTag tool, based",
          "on its inbuilt poetry classifier.",
          "I We then extract word and character statistics from Shakespeares 154 sonnets.",
          "I We use the statistics to filter out all non-sonnet poems, yielding our sonnet corpus."
        ],
        "page_nums": [
          4
        ],
        "images": [
          "figure/image/1298-Table1-1.png"
        ]
      },
      "4": {
        "title": "Model Architecture",
        "text": [
          "(a) Language model (b) Pentameter model (c) Rhyme model"
        ],
        "page_nums": [
          5,
          13
        ],
        "images": [
          "figure/image/1298-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Language Model LM",
        "text": [
          "I LM is a variant of an LSTM encoderdecoder model with attention.",
          "I Encoder encodes preceding contexts, i.e. all sonnet lines before the current line.",
          "I Decoder decodes one word at a time for the current line, while attending to the",
          "I Preceding context is filtered by a selective mechanism.",
          "I Character encodings are incorporated for decoder input words.",
          "I Input and output word embeddings are tied."
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Pentameter Model PM",
        "text": [
          "I PM is designed to capture the alternating stress pattern.",
          "I Given a sonnet line, PM learns to attend to the appropriate characters to predict",
          "the 10 binary stress symbols sequentially.",
          "Shall I compare thee to a summers day?",
          "I PM fashioned as an encoderdecoder model.",
          "I Encoder encodes the characters of a sonnet line.",
          "I Decoder attends to the character encodings to predict the stresses.",
          "I Decoder states are not used in prediction.",
          "I Attention networks focus on characters whose position is monotonically increasing.",
          "I In addition to cross-entropy loss, PM is regularised further with two auxilliary",
          "objectives that penalise repetition and low coverage."
        ],
        "page_nums": [
          7,
          8,
          9
        ],
        "images": []
      },
      "7": {
        "title": "Rhyme Model",
        "text": [
          "I We learn rhyme in an unsupervised fashion for 2 reasons:",
          "I Extendable to other languages that dont have pronunciation dictionaries;",
          "I The language of our sonnets is not Modern English, so contemporary pronunciation",
          "dictionaries may not be accurate.",
          "I Assumption: rhyme exists in a quatrain.",
          "I Feed sentence-ending word pairs as input to the rhyme model and train it to",
          "separate rhyming word pairs from non-rhyming ones.",
          "Shall I compare thee to a summers day?",
          "Thou art more lovely and more temperate:",
          "Rough winds do shake the darling buds of May,",
          "And summers lease hath all too short a date: ut ur",
          "I top(Q, k) returns the k-th largest element in Q.",
          "I Intuitively the model is trained to learn a sufficient margin that separates the best",
          "pair from all others, with the second-best being used to quantify all others."
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "8": {
        "title": "Joint Training",
        "text": [
          "I All components trained together by treating each component as a sub-task in a",
          "I Although the components (LM, PM and RM) appear to be disjointed, shared",
          "parameters allow the components to mutually influence each other during training.",
          "I If each component is trained separately, PM performs poorly."
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation Crowdworkers",
        "text": [
          "I Crowdworkers are presented with a pair of poems (one machine-generated and",
          "one human-written), and asked to guess which is the human-written one.",
          "I LM: vanilla LSTM language model;",
          "I LM: LSTM language model that incorporates both character encodings and",
          "I LM+PM+RM: the full model, with joint training of the language, pentameter and"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Evaluation Crowdworkers 2",
        "text": [
          "I Accuracy improves LM LM LM+PM+RM, indicating generated quatrains are",
          "I Are workers judging poems using just rhyme?",
          "I Test with LM+RM reveals thats the case.",
          "I Meter/stress is largely ignored by laypersons in poetry evaluation."
        ],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1298-Table4-1.png"
        ]
      },
      "11": {
        "title": "Evaluation Expert",
        "text": [
          "Model Meter Rhyme Read. Emotion",
          "I A literature expert is asked to judge poems on the quality of meter, rhyme,",
          "I Full model has the highest meter and rhyme ratings, even higher than human,",
          "reflecting that poets regularly break rules.",
          "I Despite excellent form, machine-generated poems are easily distinguished due to",
          "lower emotional impact and readability.",
          "I Vanilla language model (LM) captures meter surprisingly well."
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1298-Table4-1.png"
        ]
      },
      "12": {
        "title": "Summary",
        "text": [
          "I We introduce a joint neural model that learns language, rhyme and stress in an",
          "I We encode assumptions we have about the rhyme and stress in the architecture of",
          "I Model can be adapted to poetry in other languages.",
          "I We assess the quality of generated poems using judgements from crowdworkers",
          "and a literature expert.",
          "I Our results suggest future research should look beyond forms, towards the",
          "substance of good poetry.",
          "I Code and data: https://github.com/jhlau/deepspeare"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Untitled",
        "text": [
          "in darkness to behold him, with a light and him was filled with terror on my breast and saw its brazen ruler of the night but, lo! it was a monarch of the rest"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Deep-speare: A joint neural model of poetic language, meter and rhyme"
  },
  "1299": {
    "slides": {
      "0": {
        "title": "Read the question carefully",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Tabular QA Visual QA Reading Comprehension",
        "text": [
          "Peyton Manning became the first quarterback ever to lead two different teams to multiple Super Bowls. He is also the oldest quarterback ever to play in a",
          "Super Bowl at age 39. The past record was held by John Elway, who led the Broncos to victory in Super Bowl XXXIII at age 38 and is currently Denvers Executive Vice",
          "President of Football Operations and",
          "Q: How many medals did India win? Q: How symmetrical are the white Q: What is the name of the",
          "A: bricks on either side of the building?",
          "A: very quarterback who was 38 in Super Bowl",
          "Neural Programmer (2016) Kazemi and Elqursh (2017) model. Yu et al (2018) model. accuracy on WikiTableQuestions (state of the art) on VQA 1.0 dataset (state of the art = 66.7%) F-1 score on SQuAD (state of the art)",
          "Have the models read the question carefully?"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "2": {
        "title": "Visual QA",
        "text": [
          "Kazemi and Elqursh (2017) model.",
          "Q: How asymmetrical are the white bricks on either side of the building?",
          "Q: How big are the white bricks on either side of the building?",
          "Q: How fast are the bricks speaking on either side of the building? A: very"
        ],
        "page_nums": [
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "3": {
        "title": "QA over tables",
        "text": [
          "33.5% validation accuracy on WikiTableQuestions dataset (state of the art)",
          "Q: Which country won the most medals?",
          "Neural Programmer: max(total), print(nation)",
          "Q: Which country won the most number of medals?",
          "Neural Programmer: max(bronze), print(nation)"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "4": {
        "title": "Jia and Liang 2017 Adversarial Attacks on Reading Comprehension Models",
        "text": [
          "EMNLP 2017 Outstanding Paper Award",
          "Add an adversarial sentence to the paragraph to fool the model",
          "Highly successful attacks: over 16 models, F1 score drops from 75% to 36%",
          "Their takeaway: reading comprehension models are overly stable; unable to distinguish a sentence that answers the question from one that merely has words common with the question",
          "Question for us: How does overstability manifest? Why do their attacks work?"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "5": {
        "title": "Our contributions",
        "text": [
          "A workflow based on attributions (word-importances) to understand",
          "input-output behavior of networks",
          "Identify weaknesses in the networks as suggested by attributions",
          "Craft adversarial examples by exploiting the weaknesses",
          "Explain and improve Jia and Liang (2017)s attacks"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "6": {
        "title": "Attributions",
        "text": [
          "Problem statement: Attribute a complex deep networks prediction to input",
          "features, relative to a certain baseline (informationless) input",
          "E.g. : attribute an object recognition networks prediction to its pixels,",
          "a text sentiment networks prediction to individual words",
          "Explain F(input) - F(baseline) in terms of input features"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "7": {
        "title": "Integrated Gradients",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "8": {
        "title": "Visual QA attributions",
        "text": [
          "Q: How symmetrical are the white bricks on either side of the building?",
          "red: high attribution blue: negative attribution gray: near-zero attribution"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "9": {
        "title": "Overstability",
        "text": [
          "Drop all words from the dataset except ones which are frequently top attributions",
          "E.g. How many players scored more than 10 goals? How many",
          "Visual QA Neural Programmer",
          "color, many, what, how, doing, or, where, there, many, tm_token, how, number, total, after,"
        ],
        "page_nums": [
          22,
          23
        ],
        "images": [
          "figure/image/1299-Figure4-1.png"
        ]
      },
      "10": {
        "title": "Adversarial Examples",
        "text": [],
        "page_nums": [
          24
        ],
        "images": []
      },
      "11": {
        "title": "Stopword deletion attack",
        "text": [
          "Delete contentless words from the question",
          "show, tell, did, me, my, our, are, is, were, this, on, would, and, for, should, be,",
          "by, based, in, of, bring, with, to, from, whole, being, been, want, wanted, as, can, see, doing, got, sorted, draw, listed, chart, only",
          "Neural Programmers accuracy falls from 33.5% to 28.5%"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "12": {
        "title": "Subject ablation attack",
        "text": [
          "Replace the subject of a question with a low-attribution noun from the vocabulary",
          "What is the man doing? What is the tweet doing?",
          "How many children are there? How many tweet are there?",
          "VQ A models response remains same 75.6% of the time on questions that it originally answered correctly"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "13": {
        "title": "Question concatenation attacks",
        "text": [
          "Prefix a content-free phrase to the question",
          "Neural Programmer Visual QA",
          "Original accuracy: Original accuracy:"
        ],
        "page_nums": [
          27,
          29
        ],
        "images": [
          "figure/image/1299-Table3-1.png",
          "figure/image/1299-Table1-1.png"
        ]
      },
      "14": {
        "title": "Operator triggers in Neural Programmer",
        "text": [],
        "page_nums": [
          28
        ],
        "images": []
      },
      "15": {
        "title": "Predicting the effectiveness of Jia and Liang 2017s adversarial attacks",
        "text": [
          "Attacks are more likely to be effective when",
          "High-attribution words are present in the adversarial sentence",
          "Only low-attribution words are mutated",
          "red: high attribution, blue: negative attribution, gray: near-zero attribution"
        ],
        "page_nums": [
          30
        ],
        "images": [
          "figure/image/1299-Table4-1.png"
        ]
      },
      "16": {
        "title": "Summary",
        "text": [
          "An attribution-based workflow to look inside and understand weaknesses of a model",
          "Explained how overstability manifests - QA networks do not focus on the right words!",
          "Crafted adversarial examples and improved Jia and Liang (2017)s attacks",
          "Deep learning practitioners can easily use attributions to look inside models",
          "Adding soft network constraints",
          "E.g. add bias to attention vector so as to limit the influence of how, what, etc.",
          "Informed enrichment of datasets",
          "E.g. add more questions with word symmetrical such that answer is not very"
        ],
        "page_nums": [
          31
        ],
        "images": []
      }
    },
    "paper_title": "Did the Model Understand the Question?"
  },
  "1300": {
    "slides": {
      "0": {
        "title": "Who cares about stock movements",
        "text": [
          "ft q he road",
          "bono ay hat\" lt Ye wie ome",
          "Feb Mr -M Mey in",
          "No one would be unhappy if they could predict stock movements"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Background",
        "text": [
          "I Two mainstreams in finance: technical and fundamental analysis",
          "I Two main content resources in NLP: public news and social media",
          "I History of NLP models",
          "Feature engineering (before 2010)",
          "Hierarchical attention nets (2018)"
        ],
        "page_nums": [
          4,
          5,
          6,
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "However it has never been easy",
        "text": [
          "The market is highly stochastic, and we make temporally-dependent predictions from chaotic data."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "3": {
        "title": "Divide and Treat",
        "text": [
          "When a company suffers from a major scandal on a trading day, its stock price will have a downtrend in the coming trading days",
          "Public information needs time to be absorbed into movements over time (Luss and dAspremont, 2015), and thus is largely shared across temporally-close predictions"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Divide and treat",
        "text": [
          "Chaotic market information Market Information Encoder",
          "High market stochasticity Variational Movement Decoder",
          "Random walk theory (Malkiel, 1999)",
          "Temporally-dependent prediction Attentive Temporal Auxiliary",
          "When a company suffers from a major scandal on a trading day, its stock price will have a downtrend in the coming trading days",
          "Public information needs time to be absorbed into movements over time (Luss and dAspremont, 2015), and thus is largely shared across temporally-close predictions"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Problem Formulation",
        "text": [
          "I We estimate the binary movement where 1 denotes rise and 0 denotes fall",
          "I Target trading day: d",
          "I We use the market information comprising relevant tweets, and historical prices, in",
          "the lag [d d d where d is a fixed lag size"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "6": {
        "title": "Generative Process",
        "text": [
          "I T eligible trading days in the d lag",
          "I Encode observed market information as a",
          "random variable X = [x1; xT",
          "I Generate the latent driven factor",
          "I Generate stock movements"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": [
          "figure/image/1300-Figure1-1.png"
        ]
      },
      "7": {
        "title": "Factorization",
        "text": [
          "I For multi-task learning, we model p (y |X",
          "p (y ,Z |X instead of p(yT |X",
          "p (yt |xt zt p (zt |z<t xt yt"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "8": {
        "title": "Primary components",
        "text": [
          "Market Information Encoder (MIE)",
          "Variational Movement Decoder (VMD)",
          "Infers Z with X y and decodes stock movements y from X ,Z",
          "Z Attentive Temporal Auxiliary (ATA)",
          "|D| Integrates temporal loss for training"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1300-Figure1-1.png"
        ]
      },
      "9": {
        "title": "StockNet architecture",
        "text": [
          "Temporal Attention hdec Variational decoder",
          "N (0, I) henc Variational encoder",
          "(b) Market Information Encoder (MIE)",
          "Historical Prices Input Attention Attention Attention (d) VAEs Bi-GRUs Message Embedding Layer"
        ],
        "page_nums": [
          18,
          21
        ],
        "images": [
          "figure/image/1300-Figure2-1.png"
        ]
      },
      "10": {
        "title": "Variational Movement Decoder",
        "text": [
          "I Goal: recurrently infer Z from X y and decode y from X ,Z",
          "I Challenge: posterior inference is intractable in our factorized model",
          "I Neural approximation and reparameterization",
          "I Adopt a posterior approximator"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "11": {
        "title": "Interface between VMD and ATA",
        "text": [
          "I Integrate the deterministic feature ht",
          "and the latent variable zt",
          "gt tanh(Wg[xt ,hst zt bg)",
          "I Decode movement hypothesis: first",
          "auxiliary targets, then main target",
          "I Temporal attention: v"
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1300-Figure3-1.png"
        ]
      },
      "12": {
        "title": "Attentive Temporal Auxiliary",
        "text": [
          "I Break down the approximated L to temporal objectives f RT1",
          "ft log p (yt |xt zt",
          "I Reuse v to build the final temporal weight vector v R1T",
          "where controls the overall auxiliary effects"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "13": {
        "title": "Experimental setup",
        "text": [
          "Two-year daily price movements of 88 stocks",
          "Two components: a Twitter dataset and a historical price dataset",
          "Development: 2 months, 2,555 movements",
          "I Lag window: 5",
          "I Metrics: accuracy and Matthews Correlation Coefficient (MCC)",
          "I Comparative study: five baselines from different genres and five StockNet variations"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "14": {
        "title": "Baselines and variants",
        "text": [
          "I RAND: a naive predictor making",
          "I ARIMA: Autoregressive Integrated",
          "I TSLDA (Nguyen and Shirai, 2015)",
          "I TECHNICALANALYST: from only prices",
          "I FUNDAMENTALANALYST: from only tweets",
          "I INDEPENDENTANALYST: optimizing only",
          "I DISCRIMINATIVEANALYST: a discriminative"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "15": {
        "title": "Results",
        "text": [
          "Baseline models Acc. MCC",
          "StockNet variations Acc. MCC",
          "I The accuracy of is generally",
          "reported as a satisfying result",
          "I ARIMA: does not yield satisfying",
          "I Two best baselines: TSLDA and HAN",
          "I Two information sources are",
          "I Generative framework incorporates"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "16": {
        "title": "Effects of temporal auxiliary",
        "text": [
          "I The auxiliary weight",
          "controls overall auxiliary effects",
          "I Our models do not linearly benefit",
          "I Tweaking acts as a trade-off",
          "between focusing on the main target and generalizing by denoising"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "17": {
        "title": "Summary",
        "text": [
          "I We demonstrated the effectiveness of deep generative approaches for stock",
          "movement prediction from social media",
          "Better way to integrate fundamental information and technical indicators",
          "Other market signals, e.g. financial disclosures, periodic analyst reports and company profiles",
          "Investment simulation with modern portfolio theory",
          "I Dataset is available at https://github.com/yumoxu/stocknet-dataset"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "18": {
        "title": "Appendix Market Information Encoder",
        "text": [
          "Temporal input: xt = [ct ,pt",
          "I Multiple tweets with varied quality",
          "I Message embedding: Bi-GRU",
          "I Corpus embedding: messages",
          "I Price signals: the adjusted closing,",
          "pt pct p t h pl t",
          "ut softmax(wu tanh(Wm,uMt I Normalization ct Mtu t pt pt/pct1"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "19": {
        "title": "Appendix Variational Inference",
        "text": [
          "log p (yt |xt zt",
          "log p (y |X log p (y |X where the likelihood term",
          "p (yt |xt zt p (yt |xt zt if t T if t T"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "20": {
        "title": "Appendix Attentive Temporal Auxiliary",
        "text": [
          "Temporal Attention v i w i",
          "gT v d g T tanh(Wg,dG"
        ],
        "page_nums": [
          32
        ],
        "images": [
          "figure/image/1300-Figure3-1.png"
        ]
      },
      "21": {
        "title": "Appendix Trading day Alignment",
        "text": [
          "I We reorganize our inputs, including the tweet corpora and historical prices, by",
          "aligning them to the T trading days in a lag",
          "I Specifically, on the t th trading day, we recognize market signals from the corpusMt",
          "in [dt1,dt and the historical prices pt on dt1, for predicting the movement yt on dt"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "22": {
        "title": "Appendix Denoising Regularizer",
        "text": [
          "I Objective-level auxiliary can be regarded as a denoising regularizer: for a sample",
          "with a specific movement as the main target, the market source in the lag can be heterogeneous",
          "Affected by bad news, tweets on earlier days are negative but turn to positive due to timely crises management",
          "Without temporal auxiliary tasks, the model tries to identify positive signals on earlier days only for the main target of rise movement, which is likely to result in pure noise",
          "I Temporal auxiliary tasks help to",
          "Filter market sources in the lag as per their respective aligned auxiliary movements",
          "Encode more useful information into the latent driven factor Z"
        ],
        "page_nums": [
          34
        ],
        "images": []
      }
    },
    "paper_title": "Stock Movement Prediction from Tweets and Historical Prices"
  },
  "1305": {
    "slides": {
      "0": {
        "title": "ICLR 2018 Neural Language Modeling by Jointly Learning Syntax and Lexicon",
        "text": [
          "Supervised Constituency Parsing with Syntactic Distance?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Chart Neural Parsers Transition based Neural Parsers",
        "text": [
          "Complexity of CYK is O(n^3).",
          "Incompleted tree (the shift and reduce steps may not match).",
          "The model is never exposed to its own mistakes during training"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Intuitions",
        "text": [
          "Only the order of split (or combination) matters for reconstructing the tree.",
          "Can we model the order directly?"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "3": {
        "title": "Syntactic distance",
        "text": [],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1305-Figure1-1.png"
        ]
      },
      "4": {
        "title": "Convert to binary tree",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Tree to Distance",
        "text": [
          "The height for each non-terminal node is the maximum height of its children plus 1"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "6": {
        "title": "Distance to Tree",
        "text": [
          "Split point for each bracket is the one with maximum distance."
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "Framework for inferring the distances and labels",
        "text": [
          "Labels for non-leaf nodes",
          "Labels for leaf nodes"
        ],
        "page_nums": [
          14,
          19,
          20
        ],
        "images": []
      },
      "8": {
        "title": "Inferring the distances",
        "text": [
          "<s> She enjoys| | playing tennis a </s>"
        ],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "9": {
        "title": "Pairwise learning to rank loss for distances",
        "text": [
          "a variant of hinge loss",
          "While di > dj While di < dj"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "10": {
        "title": "Inferring the Labels",
        "text": [
          "on to fu fu te"
        ],
        "page_nums": [
          21,
          22,
          23
        ],
        "images": [
          "figure/image/1305-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Putting it together",
        "text": [],
        "page_nums": [
          24,
          25
        ],
        "images": [
          "figure/image/1305-Figure3-1.png"
        ]
      },
      "12": {
        "title": "Experiments Penn Treebank",
        "text": [],
        "page_nums": [
          27
        ],
        "images": []
      },
      "13": {
        "title": "Experiments Chinese Treebank",
        "text": [
          "Model LP LR Fil Semi-supervised"
        ],
        "page_nums": [
          28
        ],
        "images": [
          "figure/image/1305-Table2-1.png"
        ]
      },
      "14": {
        "title": "Experiments Detailed statistics in PTB and CTB",
        "text": [],
        "page_nums": [
          29
        ],
        "images": [
          "figure/image/1305-Table3-1.png"
        ]
      },
      "15": {
        "title": "Experiments Ablation Test",
        "text": [],
        "page_nums": [
          30
        ],
        "images": [
          "figure/image/1305-Table4-1.png"
        ]
      },
      "16": {
        "title": "Experiments Parsing Speed",
        "text": [],
        "page_nums": [
          31
        ],
        "images": [
          "figure/image/1305-Table5-1.png"
        ]
      },
      "17": {
        "title": "Conclusions and Highlights",
        "text": [
          "A novel constituency parsing scheme: predicting tree structure from a set of real-valued scalars (syntactic distances).",
          "Completely free from compounding errors.",
          "Strong performance compare to previous models, and",
          "Significantly more efficient than previous models",
          "Easy deployment: The architecture of model is no more than a stack of standard recurrent and convolutional layers."
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "18": {
        "title": "One more thing",
        "text": [
          "The research in rank loss is well-studied in the topic of",
          "Models that are good at learning these syntactic distances are not widely known until the rediscovery of LSTM in 2013 (Graves 2013).",
          "Efficient regularization methods for LSTM didnt become mature until"
        ],
        "page_nums": [
          33
        ],
        "images": []
      }
    },
    "paper_title": "Straight to the Tree: Constituency Parsing with Neural Syntactic Distance"
  },
  "1307": {
    "slides": {
      "0": {
        "title": "Neural Semantic Parsing NSP",
        "text": [
          "Model used in this work",
          "Android_phone_call, Any_phone_call_missed Archive your missed LSTM LSTM <then> Google_drive, Add_row_to_spreadsheet, calls from Android to ((Spreadsheet_name",
          "Google Drive missed) (Formatted_row )) (Drivefolder_path IFTTT/Android))",
          "Input Sequence Sequence Logical",
          "Utterance Encoder Decoder Form"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Confidence Modeling is Important",
        "text": [
          "Most models always tend to guess some outputs",
          "We also want to know how confident they are",
          "Alexa, buy me something from"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Motivation",
        "text": [
          "From the perspective of applications",
          "Generate clarification questions to verify the results",
          "Nonlinearity of neural networks",
          "Unclear for neural models (Johansen and Socher,",
          "Lack of explicit lexicons or templates",
          "Difficult to trace errors and inconsistencies"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Research Goal",
        "text": [
          "Estimate confidence scores for NSP",
          "Higher score -> the prediction is more likely correct",
          "Which parts of input contribute to uncertain predictions"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Confidence Estimation Overview",
        "text": [
          "Indicate whether the prediction is likely to be correct",
          "Confidence Metrics Characterize causes of uncertainty",
          "Archive your missed calls from Android to Google Drive",
          "LSTM LSTM Android_phone_call, Any_phone_call_missed <then> Google_drive, Add_row_to_spreadsheet, ((Spreadsheet_name missed) (Formatted_row )) (Drivefolder_path IFTTT/Android)) Input Sequence Sequence Logical Utterance Encoder Deco der Form"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Confidence Metrics",
        "text": [
          "Model is unconfident about",
          "Unsure about model parameters or structure",
          "Estimate reliably, but the entropy is large",
          "Input itself is unspecific/ambiguous, which would lead to several different correct outputs"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Model Uncertainty",
        "text": [
          "Token-level: avg log min{",
          "Dropout as a Bayesian approximation (Yarin Gal, Zoubin",
          "1. Inject noise to the model multiple times",
          "LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Data Uncertainty",
        "text": [
          "(|): probability of input",
          "KenLM (Heafield et al., 2013) estimated on the training set",
          "Number of unknown words of input"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Input Uncertainty",
        "text": [
          "Variance of top candidates var",
          "Entropy of decoding log",
          "Approximated by Monte Carlo sampling"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Confidence Scoring",
        "text": [
          "Use logistic regression to fit F1 scores of outputs",
          "Model Uncertainty Data Uncertainty Input Uncertainty",
          "Dropout perturbation Gaussian noise Posterior probability",
          "Probability of input Number of unknown tokens",
          "Variance of top candidates Entropy of decoding"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Uncertainty Interpretation",
        "text": [
          "Trace prediction uncertainty back to input words",
          "Users can verify or refine the input quickly",
          "Benefit the development cycle IF",
          "text me when its freezing",
          "Agreement of top-4 uncertain input words",
          "Between model prediction and gold standard"
        ],
        "page_nums": [
          11,
          21
        ],
        "images": []
      },
      "11": {
        "title": "Uncertainty Backpropagation",
        "text": [
          "Initialize decoder's output neuron with uncertainty scores",
          "Obtain scores for input words",
          "LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM LSTM",
          "from child neurons Child()",
          "Contribution ratios from to its",
          "parent neurons are normalized to 1 Parent()"
        ],
        "page_nums": [
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "12": {
        "title": "Backpropagation Rules",
        "text": [
          "If contributes more to s value, ratio should",
          "be larger (i.e., backprop more from to"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Experiments",
        "text": [
          "IFTTT-style semantic parsing (Quirk et al., 2015)",
          "Archive your missed calls from Android to Google Drive",
          "Python code generation (Yin et al., 2017)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "14": {
        "title": "Confidence Estimation",
        "text": [
          "Spearman correlation ( ) between confidence score and F1 score",
          "Spearman correlation Posterior Conf Spearman correlation Posterior Conf",
          "Confidence scores are used as threshold to filter out uncertain examples"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      },
      "15": {
        "title": "Importance of Confidence Metrics",
        "text": [
          "Model Uncertainty Data Uncertainty Input Uncertainty"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Examples IFTTT",
        "text": [
          "ATT: attention; BP: uncertainty backpropagation"
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "Confidence Modeling for Neural Semantic Parsing"
  },
  "1308": {
    "slides": {
      "0": {
        "title": "Distributional hypothesis",
        "text": [
          "You shall know the meaning of the word",
          "by the company it keeps",
          "Words that occur in similar contexts tend to have similar meanings"
        ],
        "page_nums": [
          1
        ],
        "images": [
          "figure/image/1308-Table2-1.png"
        ]
      },
      "1": {
        "title": "Cars Drivers Vehicles and Wheels",
        "text": [
          "Words co-occur in text due to",
          "Paradigmatic relations (e.g., synonymy, hypernymy), but also due to",
          "Syntagmatic relations (e.g., selectional preferences)",
          "Distributional vectors conflate all types of association",
          "driver and car are not paradigmatically related",
          "Not synonyms, not antonyms, not hypernyms, not co-hyponyms, etc.",
          "But both words will co-occur frequently with",
          "driving, accident, wheel, vehicle, road, trip, race, etc."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Vector specialization using external resources",
        "text": [
          "Key idea: refine vectors using external resources",
          "Specializing vectors for semantic similarity",
          "Integrate external constraints into the learning objective",
          "Modify the pre-trained word embeddings using lexical constraints",
          "(+) Specialize the entire vocabulary (of the corpus)",
          "() Tailored for a specific embedding model",
          "() Specialize only the vectors of words found in external constraints",
          "(+) Applicable to any pre-trained embedding space",
          "(+) Much better performance than joint models (Mrksic et al., 2016)"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "3": {
        "title": "This work",
        "text": [
          "Best of both worlds",
          "Performance and flexibility of retrofitting models, while",
          "Specializing entire embedding spaces (vectors of all words)",
          "Learn an explicit retrofitting/specialization function",
          "Using external lexical constraints as training examples"
        ],
        "page_nums": [
          5
        ],
        "images": [
          "figure/image/1308-Table2-1.png"
        ]
      },
      "4": {
        "title": "Explicit Retrofitting Model",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Explicit retrofitting",
        "text": [
          "Constraints (synonyms and antonyms) used as training examples",
          "for learning the explicit specialization function",
          "Non-linear: Deep Feed-Forward Network (DFFN)"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1308-Figure1-1.png"
        ]
      },
      "6": {
        "title": "Constraints to training instances",
        "text": [
          "Specialization function: x f(x)",
          "Distance function: g(x1, x2)",
          "(wi, wj, syn) embeddings as close as possible after specialization",
          "(wi, wj, ant) embeddings as far as possible after specialization",
          "(wi, wj) the non-costraint words stay at the same distance",
          "Micro-batches each constraint (wi, wj, r) paired with",
          "K pairs {(wi, wm k)}k wm k most similar to wi in distributional space",
          "Total: 2K+1 word pairs"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": []
      },
      "7": {
        "title": "Loss function",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Evaluation",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Model Configuration",
        "text": [
          "Distance function g: cosine distance",
          "DFFN activation function: hyperbolic tangent",
          "Constraints from previous work (Zhang et al, 14; Ono et al., 15)",
          "But only 57K unique words in these constraints!",
          "of micro-batches used for model validation",
          "K = 4 (micro-batch size = 9), batches of 100 micro-batches",
          "ADAM optimization (Kingma & Ba, 2015)"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Intrinsic Evaluation",
        "text": [
          "Important aspect: percentage of test words covered by constraints",
          "Comparison with Attract-Repel (Mrksic et al., 2017)",
          "SimLex, lexically disjoint SimLex, lexical overlap (99%)",
          "GloVe-CC fastText SGNS-W2 GloVe-CC fastText SGNS-W2",
          "Distributional Attract-Repel Explicit retrofitting Distributional Attract-Repel Explicit retrofitting",
          "Synonymy and antonymy constraints contain of SL and SV words",
          "Performance is an optimistic estimate or true performance",
          "Realistic setting: downstream tasks",
          "Coverage of test set words by constraints between and"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "11": {
        "title": "Donwstream tasks DST and LS",
        "text": [
          "Dialog state tracking (DST) first component of a dialog system",
          "Neural Belief Tracker (NBT) (Mrksic et al., 17)",
          "Makes inferences purely based on an embedding space",
          "of words in NBT test set (Wen et al., 17) covered by specialization constraints",
          "Lexical simplification (LS) complex words to simpler synonyms",
          "Light-LS (Glavas & Stajner, 15) decisions purely based on an embedding space",
          "of LS dataset words (Horn et al., 14) found in specialization constraints",
          "Crucial to distinguish similarity from relatedness",
          "DST: cheap pub in the east vs. expensive restaurant in the west",
          "LS: Ferraris pilot Sebastian Vettel won the race., driver vs. airplane"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Downstream tasks Evaluation",
        "text": [
          "Lexical simplification (LS) and Dialog state tracking (DST)",
          "GloVe-CC fastText SGNS-W2 GloVe-CC",
          "Distributional Attract-Repel Explirefit Distributional Attract-Repel Explirefit"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Cross lingual specialization",
        "text": [],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1308-Figure2-1.png"
        ]
      },
      "14": {
        "title": "Language transfer",
        "text": [
          "Lexico-semantic resources such as WordNet needed to collect",
          "synonymy and antonymy constraints",
          "Idea: use shared bilingual embedding spaces to transfer the",
          "specialization to another language",
          "*Image taken from Lample et al., ICLR 2018",
          "Most models learn a (simple) linear mapping"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "15": {
        "title": "Cross lingual transfer resuits",
        "text": [
          "Transfer to three languages: DE, IT, and HR",
          "Different levels of proximity to English",
          "Variants of SimLex-999 exist for each of these three languages",
          "German (DE) Italian (IT) Croatian (HR)",
          "Distributional ExpliRefit (language transfer)"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "Retrofitting models specialize (i.e., fine-tune) distributional",
          "vectors for semantic similarity",
          "Shortcoming: specialize only vectors of words seen in external constraints",
          "Learning the specialization function using constrains as training examples",
          "Able to specialize distributional vectors of all words",
          "Good intrinsic (SL, SV) and downstream (DST, LS) performance",
          "Cross-lingual specialization transfer possible for languages"
        ],
        "page_nums": [
          20
        ],
        "images": []
      }
    },
    "paper_title": "Explicit Retrofitting of Distributional Word Vectors"
  },
  "1309": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Sentiment to Sentiment Translation",
        "text": [
          "The movie is amazing! - The movie is boring!",
          "2) I went to this restaurant last weak, the staff was friendly, and I were so happy to have a great meal! - I went to this restaurant last weak, the staff was rude, and I were so angry to have a terrible meal!"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Applications Dialogue Systems",
        "text": [
          "I am sad about the failure of the badminton player A.",
          "The badminton player B defeats A. Congratulations!",
          "Refined Answer: Im sorry to see that the badminton player B defeats A.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 5 of 34"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Applications Personalized News Writing",
        "text": [
          "Sentiment-to-sentiment translation can save a lot of human labor!",
          "The visiting team defeated the home team",
          "News for fans of the visiting team: The players of the home team performed badly, and lost this game.",
          "News for fans of the home team: Although the players of the home team have tried their best, they lost this game regretfully.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 6 of 34"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Challenge Can a sentiment dictionary handle this task",
        "text": [
          "The simple replacement of emotional words causes low-quality sentences.",
          "The food is terrible like rock The food is delicious like rock",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 7 of 34",
          "For some emotional words, word sense disambiguation is necessary.",
          "For example, good has three antonyms: evil, bad, and ill in WordNet. Choosing which word needs to be decided by the semantic meaning of good based on the given content.",
          "Some common emotional words do not have antonyms.",
          "For example, we find that WordNet does not annotate the antonym of delicious."
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "Background",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "Background State of the Art Methods",
        "text": [
          "They first separate the non-emotional information from the emotional information in a hidden vector.",
          "They combine the non-emotional context and the inverse sentiment to generate a sentence.",
          "Advantage: The models can automatically generate appropriate emotional antonyms based on the non- emotional context.",
          "Drawback: Due to the lack of supervised data, most existing models only change the underlying sentiment and fail in keeping the semantic content.",
          "The food is delicious What a bad movie",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 11 of 34"
        ],
        "page_nums": [
          10,
          11
        ],
        "images": []
      },
      "7": {
        "title": "Approach",
        "text": [],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Approach Overview",
        "text": [
          "Extract non-emotional semantic information",
          "Add sentiment to the neutralized semantic content",
          "Combine and train two modules.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 14 of 34"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1309-Figure1-1.png"
        ]
      },
      "9": {
        "title": "Neutralization Module",
        "text": [
          "Long-Short Term Memory Network",
          "Generate the probability of being neutral or being polar",
          "The learned attention are the supervisory signal.",
          "The cross entropy loss is computed as",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 15 of 34"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "Emotionalization Module",
        "text": [
          "Bi-decoder based encoder-decoder network",
          "The encoder compresses the context",
          "The decoder generates sentences",
          "The input is the neutralized input sequence",
          "The supervisory signal is the original sentence",
          "The cross entropy loss is computed as",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 16 of 34"
        ],
        "page_nums": [
          15
        ],
        "images": [
          "figure/image/1309-Figure1-1.png"
        ]
      },
      "11": {
        "title": "Cycled Reinforcement Learning",
        "text": [
          "1) Neutralize an emotional sentence to non-emotional",
          "2) Reconstruct the original sentence by adding the source",
          "3) Train the emotionalization module using the",
          "4) Train the neutralization module using reinforcement",
          "2) Force the emotionalization module to reconstruct the",
          "original sentence by adding the source sentiment.",
          "3) The reconstruct loss is used to train the"
        ],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": [
          "figure/image/1309-Figure1-1.png"
        ]
      },
      "12": {
        "title": "Reward",
        "text": [
          "Add different sentiment to the semantic content",
          "Use the quality of the generated text as reward",
          "The confidence score of a sentiment classifier",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 21 of 34"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Experiment",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Dataset",
        "text": [
          "Provided by McAuley and Leskovec (2013). It consists of amounts of food",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 23 of 34"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Baselines",
        "text": [
          "Refined alignment of latent.",
          "Multi-Decoder with Adversarial Learning (MDAL)",
          "A multi-decoder model with adversarial.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 24 of 34"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "16": {
        "title": "Evaluation Metrics",
        "text": [
          "The annotators are asked to score the transformed text in terms of sentiment and semantic",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 25 of 34",
          "sentiment and semantic similarity."
        ],
        "page_nums": [
          24,
          25
        ],
        "images": []
      },
      "17": {
        "title": "Results",
        "text": [
          "Yelp ACC BLEU G-score",
          "Amazon ACC BLEU G-score",
          "Automatic evaluations of the proposed method and baselines.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 27 of 34",
          "Yelp Sentiment Semantic G-score"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": []
      },
      "18": {
        "title": "Generated Examples",
        "text": [
          "Input: I would strongly advise against",
          "CAAE: I love this place for a great",
          "MDAL: I have been a great place was",
          "Proposed Method: I would love using",
          "Input: Worst cleaning job ever!",
          "CAAE: Great food and great service!",
          "MDAL: Great food, food!",
          "Proposed Method: Excellent outstanding job ever!",
          "Input: Most boring show Ive ever been.",
          "CAAE: Great place is the best place in town.",
          "MDAL: Great place Ive ever ever had.",
          "Proposed Method: Most amazing show Ive ever been.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 29 of 34"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "19": {
        "title": "Analysis",
        "text": [],
        "page_nums": [
          29
        ],
        "images": []
      },
      "20": {
        "title": "Analysis of the neutralization module",
        "text": [
          "Michael is absolutely wonderful.",
          "I would strongly advise against using this company.",
          "Worst cleaning job ever!",
          "Most boring show i ve ever been.",
          "Hainan chicken was really good.",
          "I really dont understand all the negative reviews for this dentist.",
          "Smells so weird in there.",
          "The service was nearly non-existent and extremely rude.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 31 of 34"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "21": {
        "title": "Error Analysis",
        "text": [
          "The service here is very good Outstanding and bad service",
          "Its our first time to the bar and it is totally amazing Its our first time to the bar",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 32 of 34"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "22": {
        "title": "Conclusion",
        "text": [
          "A. Enable training with unpaired data.",
          "B. Tackle the bottleneck of keeping semantic.",
          "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 33 of 34"
        ],
        "page_nums": [
          32
        ],
        "images": []
      }
    },
    "paper_title": "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach"
  },
  "1310": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "- Getting manually labeled data in each domain for sentiment analysis is always an expensive and a time consuming task, cross-domain sentiment analysis provides a solution.",
          "- However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another.",
          "Changing Significance: Entertaining, boring, one-note, etc. are classification in the movie domain. significant for",
          "Changing Polarity: Unpredictable plot of a movie //Positive sentiment",
          "Unpredictable behaviour of a machine //Negative sentiment"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Problem Definition",
        "text": [
          "Significant Consistent Polarity (SCP) words represent the transferable (usable) information across domains.",
          "We present an approach based on test and cosine-similarity between context vector of words to identify polarity preserving significant words across domains.",
          "Furthermore, we show that a weighted ensemble of the classifiers enhances the cross-domain classification performance."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Technique Find SCP",
        "text": [
          "Significant Consistent Polarity (SCP): S T",
          "//Transferable information from the source (S) to the target (T) for cross-domain SA.",
          "S: Significant words with their polarity orientation in the labeled source domain: 2 test",
          "H0 : unpredictable has equal distribution in the positive and negative corpora",
          "Ha : unpredictable has significantly different count in either positive or negative corpus",
          "If X2 score is greater than",
          "Probability of the observed value given null hypothesis is true is less than",
          "=> Reject the Null hypothesis",
          "=> unpredictable has occurred significantly more often in one of the class with a 2 score of",
          "CwP > CwN , hence unpredictable is po sitiveraksha.sharma1@tcs.com"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Technique Find SCP 2",
        "text": [
          "T: Significant words with their polarity orientation in the unlabeled target domain:",
          "Significance: NormalizedCountt(Significants(w)) > Significantt(w)",
          "Note: We construct a 100 dimensional vector for each candidate word from the unlabeled target domain data.",
          "Significant Consistent Polarity (SCP): S T",
          "//Transferable information from the source to the target for cross-domain SA."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Example Inferred polarity orientation in the Target Domain",
        "text": [
          "Cosine-similarity score with the Pos-pivot (great) and Neg-pivot (bad), and inferred polarity orientation of words in the movie domain."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "F score for SCP words identification task",
        "text": [
          "Available at: http://www.cs.jhu.edu/~mdredze/datasets/sentiment/ind ex2.html",
          "Gold standard SCP words: Application of test in both the domains considering target domain is also labeled gives us gold standard SCP words from the corpus. No manual annotation.",
          "SCL: Structured Correspondence Learning (Bhatt et al., 2015)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Domain Adaptation Algorithm",
        "text": [
          "Cs(exampleDoc) = -0.07 (wrong prediction, negative)",
          "Ct(exampleDoc) = 0.33 (correct prediction, positive)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Cross domain Results",
        "text": [
          "Sys1 Sys2 Sys3 Sys4 Sys5 Sys6",
          "System Name: Transferred Info",
          "System-4: System-1 + iterations",
          "We obtained a strong positive",
          "cross-domain between and accuracy"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "- Significant Consistent Polarity (SCP) words shows a strong positive correlation of 0.78 with the sentiment classification accuracy achieved in the unlabeled target domain.",
          "- Essentially, a set of less erroneous transferable features lead to a more accurate classification system in the unlabeled target domain."
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1310-Table8-1.png"
        ]
      }
    },
    "paper_title": "Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification"
  },
  "1311": {
    "slides": {
      "0": {
        "title": "Motivations",
        "text": [
          "Distributed representations for words / text have had lots of successes in NLP",
          "(language models, machine translation, text classification)",
          "Can we induce embeddings for all kinds of features, especially those wi th very few occ urrences (e.g. ngrams, rare words) - Simple text embeddings using ngram embeddings which perform well on classification tasks",
          "Can we develop simple methods for unsupervised text embedding that compete well with state-of-the-art LSTM methods",
          "We make progress on both problems",
          "(ngrams, rare words, synsets)"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Word embeddings",
        "text": [
          "Core idea: Cooccurring words are trained to have high inner product",
          "E.g. LSA, word2vec, GloVe and variants",
          "Require few passes over a very large text corpus and do non-convex optimization",
          "Used for solving analogies, language models, machine translation, text classification"
        ],
        "page_nums": [
          5,
          6,
          7
        ],
        "images": []
      },
      "2": {
        "title": "Feature embeddings",
        "text": [
          "Capturing meaning of other natural language features",
          "E.g. ngrams, phrases, sentences, annotated words, synsets",
          "Interesting setting: features with zero or few occurrences",
          "One approach (extension of word embeddings): Learn embeddings for all features in a text corpus",
          "Usually need to learn embeddings for all features together",
          "Need to learn many parameters",
          "Computation cost paid is prix fixe rather than a la carte",
          "Bad quality for rare features",
          "Firth revisited: Feature derives meaning from words around it",
          "Given a feature and one (few) context(s) of words around it, can we find a reliable embedding for efficiently?",
          "Scientists attending ACL work on cutting edge research in NLP",
          "Petrichor: the earthy scent produce when rain falls on dry soil",
          "Roger Federer won the first setNN of the match"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "3": {
        "title": "Problem setup",
        "text": [
          "Given: Text corpus and high quality word embeddings trained on it",
          "Input: A feature in context(s) Output: Good quality embedding for the feature"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "4": {
        "title": "Linear approach",
        "text": [
          "Given a feature f and words in a context c around it",
          "stop words (is, the) are frequent but are less informative",
          "Word vectors tend to share common components which will be amplified"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "5": {
        "title": "Potential fixes",
        "text": [
          "SIF weights1: Down-weight frequent words (similar to tf-idf)",
          "is frequency of w in corpus",
          "All-but-the-top2: Remove the component of top direction from word vectors"
        ],
        "page_nums": [
          18,
          19,
          20
        ],
        "images": []
      },
      "6": {
        "title": "Our more general approach",
        "text": [
          "Down-weighting and removing directions can be achieved by matrix multiplication",
          "Learn by using words as features",
          "Learn by linear regression and is unsupervised"
        ],
        "page_nums": [
          21,
          22
        ],
        "images": []
      },
      "7": {
        "title": "Theoretical justification",
        "text": [
          "[Arora et al. TACL 18] prove that under a generative model for text, there exists a matrix which satisfies",
          "Empirically we find that the best recovers the original word vectors"
        ],
        "page_nums": [
          23,
          24
        ],
        "images": []
      },
      "8": {
        "title": "A la carte embeddings",
        "text": [
          "1. Learn induction matrix"
        ],
        "page_nums": [
          25,
          26,
          27
        ],
        "images": []
      },
      "9": {
        "title": "Advantages",
        "text": [
          "a la carte: Compute embedding only for given feature",
          "Simple optimization: Linear regression",
          "Computational efficiency: One pass over corpus and contexts",
          "Sample efficiency: Learn only !\"parameters for (rather than",
          "Versatility: Works for any feature which has at least 1 context"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "10": {
        "title": "Effect of induction matrix",
        "text": [
          "We plot the extent to which down-weights words against frequency of words compared to all-but-the-top",
          "Change in Embedding Norm under Transform",
          "mainly down-weights words with very high and very low frequency",
          "All-but-the-top mainly down-weights frequent words"
        ],
        "page_nums": [
          29,
          30
        ],
        "images": [
          "figure/image/1311-Figure1-1.png"
        ]
      },
      "11": {
        "title": "Effect of number of contexts",
        "text": [
          "Contextual Rare Words (CRW) dataset1 providing contexts for rare words",
          "Task: Predict human-rated similarity scores for pairs of words",
          "Evaluation: Spearmans rank coefficient between inner product and score",
          "1: Subset of RW dataset [Luong et al. 13]",
          "Compare to the following methods:",
          "Average of words in context",
          "Average of non stop words",
          "SIF weighted average all-but-the-top",
          "Average Average, all-but-the-top Average, no stop words SIF SIF + all-but-the-top a la carte"
        ],
        "page_nums": [
          31,
          32
        ],
        "images": [
          "figure/image/1311-Figure2-1.png"
        ]
      },
      "12": {
        "title": "Nonce definitional task",
        "text": [
          "Task: Find embedding for unseen word/concept given its definition",
          "Evaluation: Rank of word/concept based on cosine similarity with true embedding",
          "iodine: is a chemical element with symbol I and atomic number 53",
          "1: Herbelot and Baroni 17",
          "Method Mean Reciprocal Rank Median Rank",
          "of word2vec average, no stop words"
        ],
        "page_nums": [
          33,
          34
        ],
        "images": []
      },
      "13": {
        "title": "Ngram embeddings",
        "text": [
          "Induce embeddings for ngrams using contexts from a text corpus",
          "We evaluate the quality of embedding for a bigram by looking at closest words to this embedding by cosine similarity.",
          "Method beef up cutting edge harry potter tight lipped meat, out cut, edges deathly, azkaban loose, fitting",
          "but, however which, both which, but but, however",
          "add, reallocate weft, edges",
          "science, multidisciplinary robards, keach naruto, pokemon scaly, bristly wintel, codebase",
          "a la carte need, improve innovative, technology deathly, hallows worried, very"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "14": {
        "title": "Unsupervised text embeddings",
        "text": [
          "This movie is great!",
          "Predict surrounding words / sentences",
          "SOTA on some tasks",
          "Sum of word/ngram embeddings",
          "Compete with Bag-of-ngrams and LSTMs on some tasks"
        ],
        "page_nums": [
          36,
          37
        ],
        "images": []
      },
      "15": {
        "title": "A la carte text embeddings",
        "text": [
          "Linear schemes are typically weighted sums of ngram embeddings",
          "Types of ngrams embeddings",
          "Method n dimension MR CR SUBJ MPQA TREC SST (1) SST IMDB"
        ],
        "page_nums": [
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "16": {
        "title": "Conclusions",
        "text": [
          "Simple and efficient method for inducing embeddings for many kinds of features, given at least one context of usage",
          "Embeddings produced are in same semantic space as word embeddings",
          "Good empirical performance for rare words, ngrams and synsets",
          "Text embeddings that compete with unsupervised LSTMs",
          "Code is on github: https://github.com/NLPrinceton/ALaCarte",
          "CRW dataset available: http://nlp.cs.princeton.edu/CRW/"
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "17": {
        "title": "Future work",
        "text": [
          "Zero shot learning of feature embeddings",
          "Harder to annotate features (synsets)",
          "Contexts based on other syntactic structures"
        ],
        "page_nums": [
          43
        ],
        "images": []
      }
    },
    "paper_title": "A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors"
  },
  "1312": {
    "slides": {
      "0": {
        "title": "Semantic Parsing",
        "text": [
          "Mapping natural language to structured representations",
          "all flights from dallas before 10am",
          "Example from ATIS (Kwiatkowski et al., 2011)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Neural Semantic Parsing",
        "text": [
          "Sequence decoder (Jia and Liang, 2016; Dong and Lapata, 2016; Ling",
          "Syntactically-constrained decoder (Dong and Lapata, 2016;",
          "do not require a",
          "Input Structured Encoder Decoder Utterance Representation"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "This Work",
        "text": [
          "all flights from dallas before 10am",
          "(e.g., arguments and variable names)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Meaning Sketch",
        "text": [
          "if length of bits is lesser than integer 3 or second",
          "element of bits is not equal to string as ,",
          "if len ( NAME ) < NUMBER or NAME [ NUMBER ] != STRING :",
          "What record company did conductor Mikhail Snitko",
          "WHERE > AND =",
          "SELECT Record Company WHERE (Year of Recording",
          "AND (Conductor Mikhail Snitko)",
          "Disentangle high-level from low-level semantics",
          "Model meaning at different levels of granularity",
          "More compact meaning representation",
          "Explicit sharing coarse structure",
          "For examples that have the same basic meaning",
          "Provide global context to fine meaning decoder",
          "Know what the basic meaning of input looks like"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "Method",
        "text": [
          "tT t T tT tT <s> \\lambdat2 land fight@t departure 2 ) ) )",
          "<s> (lambda#2 (and flight@1 (< departure ? _time@1 Input Encoding all flights before tiO",
          "Sketch-Guided t t t t t t f",
          "T tT T <s> (lambda#2 ( land fight (< departure ?",
          "_time@1 Input extinn O-O-O-O",
          "Sketch constrains the decoding output",
          "Example 1: one augment is missing",
          "Example 2: type information"
        ],
        "page_nums": [
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "5": {
        "title": "Training and Inference",
        "text": [
          ": input, : sketch, : meaning representation",
          "Training: maximize the log likelihood"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Neural Semantic Parsing Tasks",
        "text": [
          "Natural language to logical form (Geo/ATIS)",
          "what is the population of the state with the largest area?",
          "Natural language to source code (Django)",
          "if length of bits is lesser than integer 3 or second element of bits is not equal to string as ,",
          "Natural language to SQL (WikiSQL)",
          "Pianist Conductor Record Company Year of Recording Format",
          "What record company did conductor Mikhail Snitko record for after 1996?",
          "SELECT Record Company WHERE (Year of Recording AND"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Natural Language to Logical Form",
        "text": [
          "Arguments of predicate or operator"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Natural Language to Source Code",
        "text": [
          "Substitute tokens with their token types",
          "Built-in keywords (e.g., True, and while)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Natural Language to SQL",
        "text": [
          "WHERE (cond_column cond_operator cond_value)",
          "WHERE (Year of Recording AND (Conductor Mikhail Snitko)",
          "WHERE > AND =",
          "How many presidents are graduated from A?",
          "SELECT COUNT(President) WHERE (College A)",
          "College Number of Presidents",
          "SELECT Number of Presidents WHERE (College A)",
          "Q uestion- to-Table Attentio n",
          "college number of presidents ||",
          "Input Question Column 1 Column 2",
          "MIN, MAX, SUM, AVG}",
          "What record company did conductor",
          "Mikhail Snitko record for after 1996 ?",
          "Sketch Classification WHERE AND",
          "Point to a table column",
          "Point to a text span"
        ],
        "page_nums": [
          14,
          15,
          16,
          17,
          18,
          19,
          20
        ],
        "images": [
          "figure/image/1312-Table5-1.png",
          "figure/image/1312-Figure2-1.png",
          "figure/image/1312-Figure3-1.png"
        ]
      },
      "10": {
        "title": "Experimental Results",
        "text": [
          "Seq2Seq Seq2Tree ASN OneStage Coarse2Fine",
          "Aug Pointer Network (Zhong et al., 2017)"
        ],
        "page_nums": [
          21,
          22,
          23
        ],
        "images": []
      },
      "11": {
        "title": "Sketch Accuracy",
        "text": [
          "Geo ATIS Django WikiSQL"
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1312-Table5-1.png"
        ]
      },
      "12": {
        "title": "Oracle Meaning Sketch",
        "text": [
          "Geo ATIS Django WikiSQL",
          "Coarse2Fine + Oracle Sketch"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "13": {
        "title": "Future Work",
        "text": [
          "Alternative ways of defining meaning sketches",
          "Different levels of granularity",
          "Meaning sketch reduces search space",
          "Only annotate meaning sketches for some examples"
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Coarse-to-Fine Decoding for Neural Semantic Parsing"
  },
  "1313": {
    "slides": {
      "0": {
        "title": "Constituency Parsing is Useful",
        "text": [
          "Textual Entailment (Bowman et al., 2016)",
          "Semantic Parsing (Hopkins et al., 2017)",
          "Sentiment Analysis (Socher et al., 2013)",
          "Language Modeling (Dyer et al., 2016)"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Penn Tree Bank PTB marcus et al 1993",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "But Target Domains Are Diverse",
        "text": [
          "What's the second-most-used vowel in English?",
          "Ethoxycoumarin was metabolized by isolated epidermal cells via dealkylation to",
          "7-hydroxycoumarin ( 7-OHC ) and subsequent conjugation."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Performance Outside Source Domain",
        "text": [
          "Parse geometry sentence with PTB trained parser",
          "aperimeter of 16 one side of"
        ],
        "page_nums": [
          4,
          5,
          6
        ],
        "images": []
      },
      "4": {
        "title": "How can we cheaply create high",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Relevant Recent Developments in NLP",
        "text": [
          "Contextualized word representations improve sample",
          "Span-focused models achieve state-of-the-art constituency"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Contributions",
        "text": [
          "Show contextual word embeddings help domain adaptation.",
          "Adapt a parser using partial annotations.",
          "E.g., Increase correct geometry-domain parses by 23%."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Review Contextual Word Representations",
        "text": [
          "Parsing as Span Classification",
          "The Span Classification Model",
          "Performance on PTB and new Domains",
          "Adapting Using Partial Annotations"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Contextualized Word Representations",
        "text": [
          "ELMo trained on Billion Word Corpus"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "9": {
        "title": "Partial Annotations",
        "text": [
          "Parsing as Span Classification",
          "The Span Classification Model"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Selectively Annotate Important Phenomena",
        "text": [
          "A triangle has [a perimeter {of 16] and one side of length 4}."
        ],
        "page_nums": [
          14,
          15,
          16,
          17
        ],
        "images": []
      },
      "11": {
        "title": "Full Versus Partial Annotation",
        "text": [
          "(S (NP A triangle) (VP has (NP (NP (NP a perimeter) (PP of",
          "A triangle has [a perimeter {of 16] and one side of length 4}."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Partial Annotation Definition",
        "text": [
          "Partial annotation is a labeled span.",
          "A triangle has [NP a perimeter of 16] and one side of length 4 ."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Why Partial Annotations",
        "text": [
          "Allowing annotators to selectively annotate important phenomena, makes the process faster and simpler."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "14": {
        "title": "Objective for Full Annotation",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Objective for Partial Annotation",
        "text": [
          "Since we do not have a full parse,",
          "marginalize out components for which no supervision exists."
        ],
        "page_nums": [
          23,
          24
        ],
        "images": []
      },
      "16": {
        "title": "One Solution Approximation",
        "text": [
          "top k parses consistent with annotations"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "17": {
        "title": "Our Solution Parsing as Span Classification",
        "text": [
          "Assume probability of a parse factors into a product of probabilities.",
          "Objective now simplifies to:",
          "Easy if model classifies spans!"
        ],
        "page_nums": [
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "18": {
        "title": "Parse Tree Labels All Spans",
        "text": [
          "4) PRP VBZ S",
          ". . . . tennis input { She enjoys playing tennis",
          "*(Cross and Huang, 2016; Stern et al., 2017) Pd sen unswret eevee 32 for ARTIFICIAL INTELLIGENCE ALLENALORG:",
          "*(Cross and Huang, 2016; Stern et al., 2017) {2 Aue institute for ARTIFICIAL INTELLIGENCE ALLENALORG.",
          "*(Cross and Huang, 2016; Stern et al., 2017) ALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE ALLENALORG.",
          "*(Cross and Huang, 2016; Stern et al., 2017) Ag. tsninsture, 41 for ARTIFICIAL INTELLIGENCE ALLENALORG.",
          "(NP) 1 S PRP VBZ S",
          "| (vp) g She enjoys |"
        ],
        "page_nums": [
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "19": {
        "title": "Training on Full and Partial Annotations",
        "text": [
          "A partial annotation is a labeled span.",
          "A full parse labels every span in the sentence.",
          "Therefore, training on both is identical under our derived objective."
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "20": {
        "title": "Parsing Using Span Classification Model",
        "text": [
          "Find maximum using dynamic programming:"
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "21": {
        "title": "Summary",
        "text": [
          "Partial annotations are labeled spans.",
          "Use a span classification model to parse.",
          "Training on partial and full annotations becomes identical."
        ],
        "page_nums": [
          44,
          45,
          46
        ],
        "images": []
      },
      "22": {
        "title": "Model Architecture stern et al 2017",
        "text": [
          "She enjoys playing tennis . :"
        ],
        "page_nums": [
          48,
          49,
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "23": {
        "title": "Differences",
        "text": [
          "Objective Maximum likelihood on labels",
          "Maximum margin on trees",
          "POS Tags as Input No Yes"
        ],
        "page_nums": [
          54,
          55,
          56,
          57
        ],
        "images": []
      },
      "24": {
        "title": "Experiments and Results",
        "text": [
          "Learning Curve on New Domains",
          "Adapting Using Partial Annotations"
        ],
        "page_nums": [
          58
        ],
        "images": []
      },
      "25": {
        "title": "Performance on PTB",
        "text": [
          "+Maximum Likelihood on Labels Ours"
        ],
        "page_nums": [
          59,
          60
        ],
        "images": []
      },
      "26": {
        "title": "Question Bank Judge et al 2006",
        "text": [
          "In contrast, PTB has few questions.",
          "Who is the author of the book, ``The Iron Lady: A Biography of Margaret Thatcher''?"
        ],
        "page_nums": [
          62
        ],
        "images": []
      },
      "27": {
        "title": "Do We Need Domain Adaptation",
        "text": [],
        "page_nums": [
          63
        ],
        "images": []
      },
      "28": {
        "title": "How Much Data Do We Need",
        "text": [
          "From 0 to 100 parses"
        ],
        "page_nums": [
          64,
          65
        ],
        "images": []
      },
      "29": {
        "title": "Geometry Problems seo et al 2015",
        "text": [
          "In the diagram at the right, circle O has a radius of 5, and CE = 2. Diameter AC is perpendicular to chord BD at E. What is the length of BD?",
          "Ethoxycoumarin was metabolized by isolated epidermal cells via dealkylation to",
          "7-hydroxycoumarin ( 7-OHC ) and subsequent conjugation ."
        ],
        "page_nums": [
          67
        ],
        "images": []
      },
      "30": {
        "title": "Setup",
        "text": [
          "Annotator is a parsing expert.",
          "Annotated sentences randomly split into train and dev."
        ],
        "page_nums": [
          68
        ],
        "images": []
      },
      "31": {
        "title": "Biochemistry Annotations",
        "text": [
          "610 partial annotations (Avg. 4.6 per sentence)",
          "In situ hybridization has revealed a striking subnuclear distribution of c-myc RNA transcripts",
          "Cell growth of neuroblastoma cells in serum containing medium was clearly diminished by inhibition of FPTase"
        ],
        "page_nums": [
          69
        ],
        "images": []
      },
      "32": {
        "title": "What do partial annotations buy us",
        "text": [
          "Correct Constituent % Error-Free Sentences %",
          "= PTB + Geo"
        ],
        "page_nums": [
          70,
          72
        ],
        "images": []
      },
      "33": {
        "title": "Geometry Annotations",
        "text": [
          "379 partial annotations (Avg. 3 per sentence)",
          "What is the value of y + z",
          "Diameter AC is perpendicular to chord BD at E",
          "Find the measure of the angle designated by x"
        ],
        "page_nums": [
          71
        ],
        "images": []
      },
      "34": {
        "title": "Iterative Annotation",
        "text": [],
        "page_nums": [
          73
        ],
        "images": []
      },
      "35": {
        "title": "Error Analysis on Geometry Training Set",
        "text": [
          "19% right-attaching participial adjectives",
          "Eg: segment labeled x, the center indicated"
        ],
        "page_nums": [
          74
        ],
        "images": []
      },
      "36": {
        "title": "Right Attaching Participial Adjective Error",
        "text": [
          "Find the hypotenuse of the triangle labeled t."
        ],
        "page_nums": [
          75
        ],
        "images": []
      },
      "37": {
        "title": "Iterative Annotation Proof of Concept",
        "text": [
          "Invent 3 sentences similar to the incorrect one:",
          "Find the hypotenuse of the triangle labeled t",
          "Given a circle with the tangent shown",
          "Examine the following diagram with the square"
        ],
        "page_nums": [
          76,
          77,
          78
        ],
        "images": []
      },
      "38": {
        "title": "Performance after Iterative Annotation",
        "text": [],
        "page_nums": [
          79
        ],
        "images": []
      },
      "39": {
        "title": "Conclusion",
        "text": [
          "Recent developments make it much easier to train on",
          "partial annotations and build custom parsers.",
          "Making a few partial annotations can lead to significant"
        ],
        "page_nums": [
          80
        ],
        "images": []
      }
    },
    "paper_title": "Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples"
  },
  "1314": {
    "slides": {
      "0": {
        "title": "Recursive neural network",
        "text": [],
        "page_nums": [
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "images": []
      },
      "1": {
        "title": "Latent tree learning",
        "text": [
          "Recent work has shown that:",
          "Trees do not resemble any semantic or syntactic formalisms",
          "Parsing strategies are not consistent across random restarts",
          "These models fail to learn the simple context-free grammar"
        ],
        "page_nums": [
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "2": {
        "title": "ListOps Nangia and Bowman 2018",
        "text": [],
        "page_nums": [
          19,
          20,
          21
        ],
        "images": []
      },
      "3": {
        "title": "Tree LSTM parser Choi et al 2018",
        "text": [],
        "page_nums": [
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "4": {
        "title": "Separation of syntax and semantics",
        "text": [],
        "page_nums": [
          35
        ],
        "images": []
      },
      "5": {
        "title": "Parsing as a RL problem",
        "text": [],
        "page_nums": [
          36
        ],
        "images": []
      },
      "6": {
        "title": "Optimization challenges",
        "text": [
          "Size of the search space is",
          "For a sentence with 20 words, there are possible trees.",
          "Syntax and semantic has to be learnt simultaneously",
          "model has to infer from examples that [MIN 0 1] = 0",
          "nonstationary environment (i.e the same sequence of actions can receive different rewards)",
          "Typically, the compositional function is learned faster than the parser",
          "This fast coadaptation limits the exploration of the search space to parsing strategies similar to those found at the beginning of the training.",
          "High variance in the estimate of a parsers gradient has to be addressed.",
          "Learning paces of a parser and a compositional function is levelled off by controlling parsers updates using Proximal Policy",
          "High variance in the estimate of a parsers gradient is addressed by using self-critical training (SCT) baseline of Rennie et al. (2017)."
        ],
        "page_nums": [
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          56
        ],
        "images": []
      },
      "7": {
        "title": "Variance reduction",
        "text": [
          "the moving average of recent rewards",
          "self-critical training (SCT) baseline Rennie et al. (2017)"
        ],
        "page_nums": [
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51
        ],
        "images": []
      },
      "8": {
        "title": "Synchronizing syntax and semantics learning",
        "text": [
          "Proximal Policy Optimization (PPO) of Schulman et al. (2017)"
        ],
        "page_nums": [
          52,
          53,
          54,
          55
        ],
        "images": []
      },
      "9": {
        "title": "ListOps results",
        "text": [],
        "page_nums": [
          57,
          58,
          59,
          60,
          61
        ],
        "images": []
      },
      "10": {
        "title": "Extrapolation",
        "text": [],
        "page_nums": [
          62
        ],
        "images": []
      },
      "11": {
        "title": "Sentiment Analysis SST 2",
        "text": [
          "Tree-LSTM RL-SPINN ST-Gumbel Ours 65"
        ],
        "page_nums": [
          63,
          64
        ],
        "images": []
      },
      "12": {
        "title": "Natural language inference MultiNLl",
        "text": [],
        "page_nums": [
          65
        ],
        "images": []
      },
      "13": {
        "title": "Time and Space complexities",
        "text": [
          "n sentence length d tree-LSTM dimensionality",
          "K number of updates in PPO"
        ],
        "page_nums": [
          66
        ],
        "images": []
      },
      "14": {
        "title": "Conclusions",
        "text": [
          "The separation between syntax and semantics allows coordination between optimisation schemes for each module.",
          "Self-critical training mitigates credit assignment problem by distinguishing hard and easy to solve datapoints.",
          "The model can recover a simple context-free grammar of mathematical expressions.",
          "The model performs competitively on several real natural language tasks."
        ],
        "page_nums": [
          67
        ],
        "images": []
      }
    },
    "paper_title": "Cooperative Learning of Disjoint Syntax and Semantics"
  },
  "1315": {
    "slides": {
      "0": {
        "title": "Complex Model Wins",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Classification vs Structured Prediction",
        "text": [
          "I like this book Classifier",
          "Predictor I like this book"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Search based Structured Prediction",
        "text": [
          "I like this book"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "3": {
        "title": "pas that Controls Search Space",
        "text": [],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Generic pas Learning Algorithm",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "5": {
        "title": "Problems of the Generic Learning Algorithm",
        "text": [
          "Ambiguities in training data Training and test discrepancy both this and the seems reasonable What if I made wrong decision?",
          "I like this book"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "6": {
        "title": "Solutions in Previous Works",
        "text": [],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Where We Are",
        "text": [],
        "page_nums": [
          12
        ],
        "images": []
      },
      "8": {
        "title": "Knowledge Distillation",
        "text": [
          "book I like love the this book I like love the this",
          "is the output distribution of a teacher model (e.g. ensemble)",
          "On supervised data argmax0"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "9": {
        "title": "Knowledge Distillation from Where",
        "text": [
          "Learning from knowledge distillation",
          "argmax sumy q(y) p(y |I, like)",
          "book I like love the this",
          "Ambiguities in training data",
          "We use ensemble of M structure predictor as the teacher q"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "KD on Supervised reference Data",
        "text": [
          "book I like love the this book I like love the this",
          "I like this book"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "KD on Explored Data",
        "text": [
          "book I like love the this",
          "I like book this the",
          "Training and test discrepancy Search Space",
          "Explore (Ross and Bagnell, 2010)",
          "We use teacher q to explore the search space & learn from KD on the explored data"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "12": {
        "title": "Experiments",
        "text": [
          "Penn Treebank (Stanford dependencies)",
          "LAS Neural Machine Translation",
          "MIXER (Ranzato et al."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "13": {
        "title": "Analysis Why the Ensemble Works Better",
        "text": [
          "Examining the ensemble on the problematic states.",
          "Testbed: Transition-based dependency parsing.",
          "Tools: dynamic oracle, which returns a set of reference actions for one state.",
          "Evaluate the output distributions against the reference actions."
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "14": {
        "title": "Analysis Is it Feasible to Fully Learn from KD w o NLL",
        "text": [
          "Transition-based Parsing Neural Machine Translation",
          "Fully learning from KD is feasible"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "15": {
        "title": "Analysis Is Learning from KD Stable",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "We propose to distill an ensemble into a single model both from reference and exploration states.",
          "Experiments on transition-based dependency parsing and machine translation show that our distillation method significantly improves the single models performance.",
          "Analysis gives empirically guarantee for our distillation method."
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "Distilling Knowledge for Search-based Structured Prediction"
  },
  "1319": {
    "slides": {
      "0": {
        "title": "Machine learning can help you",
        "text": [
          "***If you have enough training data"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Traditional Labeling",
        "text": [
          "Tom Brady was spotted in New York City on Monday with his wife Gisele Bundchen amid rumors of",
          "Bradys alleged role in Deflategate.",
          "Is person 1 married to person 2?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Higher Bandwidth Supervision",
        "text": [
          "Tom Brady was spotted in New York City on Monday with his wife Gisele Bundchen amid rumors of",
          "Bradys alleged role in Deflategate.",
          "Is person 1 married to person 2?",
          "Why do you think so?",
          "Because the words his wife are right before person 2."
        ],
        "page_nums": [
          3
        ],
        "images": [
          "figure/image/1319-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Explanations Encode Labeling Heuristics",
        "text": [
          "Why did you label True?",
          "Because the words his wife are right before person 2.",
          "Barack batted back tears as he thanked his wife, Michelle, for all her help.",
          "Both Bill and his wife Hillary smiled and waved at reporters as they rode by.",
          "George attended the event with his wife, Laura, and their two daughters.",
          "Big Idea: Instead of collecting labels, collect labeling heuristics (in the form of explanations) that can be used to label more examples for free."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Babble Labble Framework",
        "text": [
          "INPUT SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR DISC. MODEL",
          "y x y e1",
          "Unlabeled Examples + Explanations Labeling Functions Filters Label Matrix",
          "Label whether person 1 is married to person 2",
          "x1 Tom Brady and his wife Gisele Bundchen were",
          "spotted in New York City on Monday amid rumors",
          "of Bradys alleged role in Deflategate.",
          "return if his wife in left(x.person2, dist==1) else Correct x1 x2 x3 x4",
          "def LF_1b(x): return if his wife in right(x.person2) else",
          "(inconsistent) True, because the words his wife are right before person 2. def LF_2a(x): return if x.person1 in x.sentence and x.person2 in x.sentence else x2 None of us knows what happened at Kanes home Aug. 2, but it is telling that the NHL has not suspended Kane.",
          "Pragmatic Filter LF4c (always true)",
          "def LF_2b(x): return if x.person1 x.person2) else Correct False, because person 1 and person in the sentence are identical. y",
          "Noisy Labels Classifier x3 Dr. Michael Richards and real estate and insurance businessman Gary Kirke did not attend the event. Correct",
          "False, because the last word of person 1 is different than the last word of person 2.",
          "Pragmatic Filter (duplicate of LF_3a)",
          "y x y PRAGMATIC",
          "True, because LF1A x1 x2 x3",
          "x1 x2 x3 y False, because",
          "EXPLANATIONS LABELING FUNCTIONS LABEL MATRIX PROBABILISTIC LABELS TRAINED MODEL",
          "IMPORTANT: No Babble Labble components require no labeled training data!"
        ],
        "page_nums": [
          6,
          11,
          15,
          18,
          33,
          34
        ],
        "images": [
          "figure/image/1319-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Explanations Encode Heuristics",
        "text": [
          "Why did you label True?",
          "Because the words his wife are right before person 2.",
          "def f(x): return if (his wife in left(x.person2, dist==1)) else 0 #abstain"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Semantic Parser",
        "text": [
          "START LABEL FALSE BECAUSE ARG AND ARG IS EQUAL STOP",
          "<START> label false because X and Y are the same person <STOP>",
          "Lexical Rules Unary Rules Compositional Rules Ignored token",
          "<START> START FALSE BOOL TRUE BOOL START LABEL BOOL BECAUSE CONDITION STOP LF label false LABEL FALSE INT NUM ARGLIST ISEQUAL ARG AND ARG CONDITION ARGLIST",
          "def LF(x): return [label] if [condition] else [abstain]"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1319-Figure3-1.png"
        ]
      },
      "7": {
        "title": "Predicates",
        "text": [],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1319-Table1-1.png"
        ]
      },
      "8": {
        "title": "Semantic Parser I O",
        "text": [
          "1 Explanation 1 Parse",
          "True, because def f(x): return 1 if",
          "Goal: produce the correct parse",
          "1 Explanation Many Parses",
          "Goal: produce useful parses (whether theyre correct or not)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Filter Bank",
        "text": [
          "True, because def f(x): return 1 if def f(x): return 1 if",
          "def f(x): return 1 if False, because"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Semantic Filter",
        "text": [
          "Example x1: Tom Brady was spotted in New York City on",
          "Monday with his wife Gisele Bundchen amid rumors of Bradys alleged role in Deflategate.",
          "Explanation True, because the words his wife",
          "are right before person 2.",
          "right before = to the right of right before = immediately before",
          "def LF_1b(x): return if his wife in right(x.person2) else def LF_1a(x): return if his wife in left(x.person2, dist==1) else",
          "(his wife is not to the right of person 2) (his wife is, in fact, 1 word to the left of person 2)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Pragmatic Filters",
        "text": [
          "How does the LF label our unlabeled data?",
          "Uniform labeling signature xN x1"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Label Aggregator",
        "text": [
          "High correlation; not independent?",
          "High conflict; low accuracy?",
          "Low coverage, high accuracy?",
          "How should I break this tie?",
          "Data Programming: (Ratner, et al. NIPS 2016)",
          "As implemented in: snorkel.stanford.edu"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "13": {
        "title": "Discriminative Classifier",
        "text": [
          "Labeling functions generate noisy, conflicting votes",
          "Resolve conflicts, re-weight & combine",
          "Generalize beyond the labeling functions"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "14": {
        "title": "Generalization",
        "text": [
          "Task: identify disease-causing chemicals",
          "Keywords mentioned in LFs:",
          "treats, causes, induces, prevents,",
          "Highly relevant features learned by discriminative model:",
          "could produce a, support diagnosis of,",
          "Training a discriminative model that can take advantage of additional useful features not specified in labeling functions boosted performance by 4.3 F1 points on average (10%)."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "15": {
        "title": "Datasets",
        "text": [
          "Name Unlabeled Sample Explanations",
          "Spouse 22k Label true because \"and\" occurs between X",
          "and Y and \"marriage\" occurs one word after person1.",
          "Disease 6.7k Label true because the disease is immediately",
          "after the chemical and \"induc\" or \"assoc\" is in the chemical name.",
          "Protein 5.5k Label true because \"Ser\" or \"Tyr\" are within",
          "10 characters of the protein."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "16": {
        "title": "Results",
        "text": [
          "Classifiers trained with Babble Labble and explanations achieved the same F1 score as ones trained with traditional labels while requiring 5100x fewer user inputs"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "Utilizing Unlabeled Data",
        "text": [
          "With labeling functions, training set size (and often performance) scales with the amount of unlabeled data we have."
        ],
        "page_nums": [
          23
        ],
        "images": [
          "figure/image/1319-Figure6-1.png"
        ]
      },
      "18": {
        "title": "Filter Bank Effectiveness",
        "text": [
          "Babble Labble % Incorrected",
          "The filters removed almost of incorrect parses. Without the filters removing bad parses, F1 drops by 15 F1 points on average."
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "19": {
        "title": "Perfect Parsers Need Not Apply",
        "text": [
          "Task Babble Labble Babble Labble",
          "Using perfect parses yielded negligible improvements. In this framework, for this task, a naive semantic parser is good enough!"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "20": {
        "title": "Limitations",
        "text": [
          "Alice beat Bob in the annual office pool tournament.",
          "No, because it sounds like theyre just co-workers. Prefers",
          "(e.g., it says so) (e.g., keywords, word distance, capitalization, etc.)",
          "Users reasons for labeling are sometimes high-level concepts that are hard to parse."
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "21": {
        "title": "Related Work Data Programming",
        "text": [
          "Use weak supervision (e.g., labeling functions) to generate training sets",
          "Flagship platform for dataset creation from weak supervision",
          "Structure Learning (Bach et al., ICML 2017)",
          "Learning dependencies between correlated labeling functions",
          "Reef (Varma and Re, In Submission)",
          "Auto-generating labeling functions from a small labeled set"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "22": {
        "title": "Related Work Explanations as Features",
        "text": [
          "What if we use our explanations to make features instead of training labels?",
          "Use as features for classifier",
          "LABEL AGGREGATOR DISC. MODEL Exp 4:",
          "Exp 5: y x y Use as labels for training set",
          "Using the parses to label training data instead of as features boosts 4.5 F1 points."
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "23": {
        "title": "Related Work Highlighting",
        "text": [
          "Highlight key phrases in text:",
          "Mark key regions in images:",
          "Label key features directly:",
          "Tom Brady was spotted in New York City on Monday with his wife Gisele Bundchen amid rumors of Bradys alleged role in Deflategate.",
          "Benefits of natural language approach: more options: e.g., X is not in the sentence, X or Y is in the sentence more direct credit assignment (compared to highlighting) no feature set required a priori"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "24": {
        "title": "Summary",
        "text": [
          "We need more efficient ways to collect supervision",
          "We can collect labeling heuristics instead of labels",
          "Using this approach, training set size grows with the amount of unlabeled data we have"
        ],
        "page_nums": [
          30
        ],
        "images": [
          "figure/image/1319-Figure6-1.png"
        ]
      },
      "25": {
        "title": "Extra slides",
        "text": [],
        "page_nums": [
          31
        ],
        "images": []
      },
      "26": {
        "title": "Dataset Statistics",
        "text": [],
        "page_nums": [
          32
        ],
        "images": [
          "figure/image/1319-Table2-1.png"
        ]
      },
      "27": {
        "title": "Babble Labble",
        "text": [
          "Tom Brady was spotted in New York City on Monday with his wife Gisele Bundchen amid rumors of",
          "Bradys alleged role in Deflategate.",
          "LF3 Is person 1 married to person 2?",
          "Why do you think so? Aggregated Labels",
          "Because the words his wife are right before person 2. y",
          "x y def LF1(x): return if his wife in left(x.person2, dist==1) else"
        ],
        "page_nums": [
          35
        ],
        "images": [
          "figure/image/1319-Figure1-1.png"
        ]
      }
    },
    "paper_title": "Training Classifiers with Natural Language Explanations"
  },
  "1321": {
    "slides": {
      "0": {
        "title": "Location Lost in Translation",
        "text": [
          "S ocial Media Society"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Applications Public Health Monitoring",
        "text": [
          "Allergy Rates (Paul and Dredze, 2011)"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Applications Emergency Situation Awareness Bushfires Floods and Earthquakes",
        "text": [
          "Fight bushfire with #fire: Alert hospital before anybody calls"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Location Location Location",
        "text": [
          "Profile field is noisy (Hecht et. al, 2011), GPS data is scarce",
          "(Hecht and Stephens, 2014), and biased toward younger urban users (Pavalanathan and Eisenstein, 2015)"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Geolocation The three Ls",
        "text": [
          "Aint this place a geographical oddity; two weeks away from everywhere!",
          "User geolocation is the task of identifying the home location of a social media user using contextual information such as geographical variation in language use and in social interactions."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Previous Work not exhaustive",
        "text": [
          "Text-based Supervised Classification Network-based Semi-supervised Regression",
          "No Text Joint/Hybrid Text+Network No Network",
          "Do et al. (2017) Dont utilise unlabelled text data Miura et al. (2017)",
          "Our work: Text+Network Semi-supervised Geolocation"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Twitter Geolocation Datasets",
        "text": [],
        "page_nums": [
          8
        ],
        "images": []
      },
      "7": {
        "title": "Discretisation of Labels",
        "text": [
          "Cluster continuous lat/lon: cluster ids are labels.",
          "Use the median training point of the predicted region as the inal f continuous prediction.",
          "Evaluate using Mean and Median errors between the known and the predicted coordinates."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "8": {
        "title": "Text and Network Views of Data",
        "text": [
          "Karin Mark Steven Trevor",
          "Normalised Adj. Matrix: A Text BoW: X",
          "Two users are connected if they have a common @-mention."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Baseline 1 FeatConcat",
        "text": [
          "Concatenate A and X , and feed them to a DNN:",
          "The dimensions of A, and consequently the number of parameters grow with the number of samples."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Baseline 2 DCCA",
        "text": [
          "FC linear FC softmax",
          "FC sigmoid FC ReLU",
          "X : text BoW A: Neighbours",
          "Unsupervised DCCA Supervised Geolocation",
          "Learn a shared representation using Deep Canonical Correlation"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1321-Figure2-1.png"
        ]
      },
      "11": {
        "title": "Proposed Model GCN",
        "text": [
          "H l1 Highway GCN: ,",
          "Adding more layers results in expanded neighbourhood smoothing: control with highway gates W lh, bl h"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "12": {
        "title": "Highway GCN Control Neighbourhood Smoothing",
        "text": [
          "layer gates: T (~hl) = W lh ~hl blh",
          "weighted sum of layer input and output"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "13": {
        "title": "Neighbourhood Smoothing",
        "text": [
          "Karin Mark Steven Tim Trevor",
          "Normalised Adj. Matrix: A Text BoW: X",
          "Smoothing immediate neighbourhood: A X smoothing expanded neighbourhood: A A X"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "14": {
        "title": "Sample Representation using t SNE",
        "text": [
          "FeatConcat [X, A] DCCA",
          "GCN A X GCN A A X"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "15": {
        "title": "Test Results Median Error",
        "text": [
          "Median Error in km"
        ],
        "page_nums": [
          17,
          18,
          19
        ],
        "images": []
      },
      "16": {
        "title": "Top Features Learnt from Unlabelled Data 1 Supervision",
        "text": [
          "Seattle, WA Austin, TX Jacksonville, FL Columbus, OH",
          "#goseahawks smock traffuck ferran promissory chowdown ckrib",
          "#meatsweats lanterna pupper effaced",
          "#austin lmfbo unf ribault wahoowa wjct fscj floridian",
          "Top terms for a few regions detected by GCN using only 1% of",
          "Twitter-US for supervision. The terms that existed in labelled data are removed."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "17": {
        "title": "Dev Results How much labelled data do we really have",
        "text": [
          "labelled data (%samples) labelled data (%samples)",
          "median error (km) Median Error in km",
          "Joint DCCA 1% Joint FeatConcat 1% Joint GCN 1%",
          "labelled data (%samples) GeoText TwitterUS TwitterWorld",
          "Twitter-World Test results with 1% labelled data"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "18": {
        "title": "Confusion Matrix Between True Location and Predicted Location",
        "text": [
          "NC SC WV OH FL GA MI Users from smaller states are misclassified in nearby larger",
          "KY IN AL states such as TX, NY, CA, and OH.",
          "MS LA MO AR Users from FL are misclassified in several other states possibly MN IA KS because they are not born in FL, and are well connected to NE OK TX their hometowns in other states. SD ND WY CO NM UT MT AZ ID NV CA WA OR ME MA RI NH VT CT NY NJ DE MD PA VA NC SC WV OH FL GA MI KY IN AL TN WI IL MS LA MO AR MN IA KS NE OK TX SD ND WY CO NM UT MT AZ ID NV CA WA OR Predicted"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "19": {
        "title": "Conclusion",
        "text": [
          "Simple concatenation in FeatConcat is a strong baseline with large amounts of labelled data.",
          "GCN performs well with both large and small amounts of",
          "labelled data by effectively using unlabelled data.",
          "Gating mechanisms (e.g. highway gates) are essential for controlling neighbourhood smoothing in GCN with multiple layers.",
          "The models proposed here are applicable to other demographic inference tasks."
        ],
        "page_nums": [
          23
        ],
        "images": []
      }
    },
    "paper_title": "Semi-supervised User Geolocation via Graph Convolutional Networks"
  },
  "1323": {
    "slides": {
      "0": {
        "title": "Topic modeling Word clustering",
        "text": [
          "Method to extract latent topics on a corpus",
          "Each topic is a distribution on words",
          "yogurt rose LDA about",
          "milk oil Bulgaria food organic",
          "yogurt rose dance LDA about",
          "milk oil fire Bulgaria food organic sexy",
          "kazanlak walk exotic Size of each word",
          "re presents its frequency"
        ],
        "page_nums": [
          1,
          2,
          3,
          4
        ],
        "images": []
      },
      "1": {
        "title": "Existing work Andrzejewski ICML2009",
        "text": [
          "Constraints on words for topic modeling",
          "Must-Link(A,B) A and B appear in the same topic",
          "Cannot-Link(A,B) A and B dont appear in the same topic",
          "W ant to split into fire dance",
          "dance dance CL Cannot-Link(fire, sexy) fire sexy"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "2": {
        "title": "Problem of the existing work",
        "text": [
          "Constraints often dont align with users intention",
          "You might get blaze topic",
          "instead of fire dance topic",
          "W ant to split into fire dance",
          "blaze dance CL Cannot-Link(fire, sexy) fire sexy"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "This work",
        "text": [
          "Logical constraints on words for topic modeling",
          "Conjunctions (), disjunctions (), negations ()",
          "W ant to split into fire dance",
          "ML dance dance CL fire sexy",
          "ancient bikini Must-Link(dance, sexy))",
          "Algorithm to generate logically constrained distributions on LDA-DF",
          "We can not apply the existing algorithm",
          "This constraint cannot be",
          "mapped to a graph"
        ],
        "page_nums": [
          8,
          23
        ],
        "images": []
      },
      "4": {
        "title": "Latent Dirichlet Allocation LDA Blei JMLR2003",
        "text": [
          "Famous Topic modeling method",
          "(i) Assume a generative model of documents",
          "Each topic is a distribution on words",
          "Each document is a distribution on topics",
          "Taken from Dirichlet distributions to generate discrete distributions",
          "(ii) Infer parameters for the two distributions inverting the generative model"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Generative process of documents in LDA",
        "text": [
          "Each topic is a distribution on words",
          "Each document is a distribution on topics",
          "Topic 1 Document 1",
          "Topic 2 Document 2",
          "yogurt yogurt milk yogurt food",
          "milk rose oil fruit food yogurt",
          "food milk bacteria fat drink",
          "fruit cream yogurt milk rose",
          "rose rose oil yogurt rose valley",
          "oil essential milk pure",
          "organic kazanlak quality rose food",
          "essential oil organic yogurt milk"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "6": {
        "title": "Parameter inference in LDA",
        "text": [
          "Infer word and topic distributions from a corpus inverting the generative process",
          "Topic 1 Document 1",
          "yogurt milk yogurt food",
          "rose oil fruit food yogurt",
          "milk bacteria fat drink",
          "cream yogurt milk rose",
          "Topic 2 Document 2",
          "rose oil yogurt rose valley",
          "kazanlak quality rose food",
          "oil organic yogurt milk"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "7": {
        "title": "LDA DF Andrzejewski ICML2009",
        "text": [
          "Semi-supervised extension of LDA",
          "Only conjunction of Must-Links and Cannot-Links",
          "Must-Link(A,B) A and B appear in the same topic",
          "Cannot-Link(A,B) A and B dont appear in the same topic",
          "Extending the generative process",
          "Each topic is a constrained distribution on words",
          "Taken from a Dirichlet tree distribution, which is a generalization of a Dirichlet distribution",
          "Each document is a distribution on topics",
          "Taken from a Dirichlet distribution"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "8": {
        "title": "Generative process of LDA DF",
        "text": [
          "Always generates a distribution, where yogurt and rose do not appear in the same topic.",
          "Topic 1 Document 1",
          "yogurt yogurt milk yogurt food",
          "milk rose oil fruit food yogurt",
          "food milk bacteria fat drink",
          "CL fruit cream yogurt milk rose",
          "Topic 2 Document 2",
          "rose rose oil yogurt rose valley",
          "oil essential milk pure",
          "organic kazanlak quality rose food",
          "essential oil organic yogurt milk"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Algorithm to generate distributions in LDA DF",
        "text": [
          "1. Map links to a graph",
          "3. Extract the maximal independent sets (MIS)",
          "4. Generate a distribution based on each MIS",
          "Any conjunction of links can be mapped to a graph",
          "Regard two words on each Must-Link as one word",
          "MIS = Maximal set of nodes without edges",
          "Equalize the frequencies of contracted words",
          "Zero the frequencies of words not in the MIS",
          "A B C D E F G",
          "CL ML CL CD FA G"
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22
        ],
        "images": []
      },
      "10": {
        "title": "Negations",
        "text": [
          "Delete negations () in a preprocessing stage",
          "Weak negation: Must-Link(A,B) = no constraint",
          "(A and B need not appear in the same topic)",
          "Strong negation: Must-Link(A,B) Cannot-Link(A,B)",
          "Focus only on conjunctions and disjunctions"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "11": {
        "title": "Key observation for logical expressions",
        "text": [
          "Any constrained distribution is represented by a conjunctive expression by two primitives",
          "ZeroPrim(A): makes p(A)0 Same Equal frequency",
          "A B C D E F G",
          "EqualPrim(B, E) EqualPrim(C, D)"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "12": {
        "title": "Substitution of links with primitives",
        "text": [
          "A B C A B C"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "13": {
        "title": "Proposed algorithm for logical expressions",
        "text": [
          "1. Substitute links with primitives",
          "2. Calculate the minimum disjunctive normal form (DNF) of the primitives",
          "3. Generate distributions for each conjunction of the DNF",
          "A B C A B C primitives",
          "DNF = Disjunction of conjunctions of primitives",
          "Combine each conjunction of primitives",
          "A B C D E F G A B C D E F G A B C D E F G"
        ],
        "page_nums": [
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "14": {
        "title": "Correctness of our method",
        "text": [
          "[Theorem] Our method and the existing method are asymptotically equivalent w.r.t. conjunctive expressions of links",
          "A B C D A B C D istributions by primitives CL",
          "Primitives are the same as CL",
          "d is trib u tio ns by a grap h",
          "A B C D A B C D B C",
          "A B C D E F G A B C D E F G"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "15": {
        "title": "Customization of new links",
        "text": [
          "X1,,Xn do not appear (nearly)",
          "(Remove unnecessary words and stop words",
          "ISL( X Xn i1ZeroPrim(Xi)",
          "B appears if A appears in a topic (AB)",
          "(Use when B has multiple meanings)",
          "IL( A ,B) EqualPrim(A,B)ZeroPrim(A)",
          "Y appears if X1,,Xn appear in a topic (X1,,XnY)",
          "XIL( X XY n EqualPrim( XY n i i",
          "n ZeroPrim( X i i"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "16": {
        "title": "Interactive topic analysis",
        "text": [
          "Topic High frequency words",
          "have give night film turn performance year mother take out",
          "not life have own first only family tell yet moment even",
          "movie have nt get good not see know just other time make",
          "have black scene tom death die joe ryan man final private",
          "film have nt not make out well see just very watch even",
          "have film original new never more evil nt time power",
          "All topics are unclear",
          "Movie review corpus (1000 reviews)",
          "Isolate-Link(have, film, movie, not, nt)",
          "Remove specified words as well as related unnecessary words",
          "(Isolated) have film movie not good make nt character see more get",
          "star war trek planet effect special lucas jedi science",
          "Comedy comedy funny laugh school hilarious evil power bulworth",
          "Disney disney voice mulan animated song feature tarzan animation",
          "Family life love family mother woman father child relationship",
          "Thriller truman murder killer death thriller carrey final detective",
          "Star Wars and Star Trek are merged, although most topics are clear",
          "Cannot-Link(jedi, trek) Dared to select jedi since",
          "star and war are too common",
          "Star Wars star war lucas effect jedi special matrix menace computer",
          "Comedy funny comedy laugh get hilarious high joke humor bob smith",
          "Disney disney truman voice toy show animation animated tarzan",
          "Family family father mother boy child son parent wife performance",
          "Thriller killer murder case lawyer man david prison performance",
          "Star Trek disappears, altough Star Wars is obtained",
          "Star Wars star war toy jedi menace phantom lucas burton planet",
          "Star Trek alien effect star science special trek action computer",
          "Comedy comedy funny laugh hilarious joke get ben john humor fun",
          "Disney disney voice animated mulan animation family tarzan shrek",
          "Family life love family man story child woman young mother",
          "Thriller scream horror flynt murder killer lawyer death sequel case",
          "We obtained Star Wars and Star Trek appropriately"
        ],
        "page_nums": [
          33,
          34,
          35,
          36
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion",
        "text": [
          "Simple algorithm for logical constraints on words for topic modeling",
          "Must-Link(A,B) A and B appear in the same topic",
          "Cannot-Link(A,B) A and B do not appear in the same topic",
          "Theorem for the correctness of the algorithm",
          "Customization of new links",
          "Imply-Link(A, B): B appears if A appears in a topic",
          "Comparative experiments on real corpora"
        ],
        "page_nums": [
          37
        ],
        "images": []
      },
      "18": {
        "title": "Appendix Visualization of Priors",
        "text": [
          "ML = Must-Link, CL = Cannot-Link, IL = Imply-Link"
        ],
        "page_nums": [
          39,
          40,
          41
        ],
        "images": []
      }
    },
    "paper_title": "Topic Models with Logical Constraints on Words"
  },
  "1325": {
    "slides": {
      "0": {
        "title": "Generative Models for Conversations",
        "text": [
          "Context encoder: RNN hierarchical RNN",
          "Objective: log probability of GT response given context.",
          "Can generate novel responses for novel contexts!!"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Retrieval Models for Conversations",
        "text": [
          "Retrieve a response from a nearest neighbor index constructed from the training data.",
          "Can be used for closed domain problems.",
          "Answers are grounded in the domain.",
          "Easy to prune answers according to requirements.",
          "Can not generate novel responses.",
          "Can we use generative models to fix this?"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Exemplar Encoder Decoder",
        "text": [
          "Build an index from all context-response pairs offline.",
          "For each context c:",
          "Retrieve a set of exemplar contexts and corresponding responses.",
          "Input Context Index Exemplar conversations",
          "Match the exemplar contexts with c and get the similarities.",
          "Use these similarities to weigh the exemplar responses."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Matching Exemplar Contexts",
        "text": [
          "Customer: hi . today i have received the wst non- compliance.",
          "Agent: i see that you have an issue with wst non complaints.",
          "Customer: its regarding the tem",
          "Customer : i am getting wst non-complaint for tem install",
          "Agent: okay . . let me create a ticket to l2 support team Customer : ok .",
          "Customer : regarding wst non-compliant report . i am unable to install tivoli endpoint manager ( tem",
          "Agent: what is error report you get ? Customer : this one.",
          "Customer : i received an email action required : it security noncompliance reported by wst. Agent: is this showing as wst non complaint ? Customer : yes ... seems . may i show you the mail that i received ?",
          "The normalized similarities are used to weigh the exemplar responses."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Analyzing the Objective",
        "text": [
          "Think of exemplar contexts and responses as latent variables"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Evaluation",
        "text": [
          "TF-IDF for retrieving exemplar conversations",
          "IBM Tech Support Dataset",
          "Activity and Entity metrics"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Activity and Entity metrics",
        "text": [
          "These metrics compare the precision, recall and F1 score of specific nouns and ve present in the generated response as compared to the groundtruth response.",
          "For comparison, the retrieval only model has an activity F1 score of and entity F1 score of respectively."
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1325-Table4-1.png"
        ]
      },
      "7": {
        "title": "Embedding metrics",
        "text": [
          "These metrics compare the word embeddings of the generated response with the words of the groundtruth response.",
          "These metrics do not correlate with human judgements for Ubuntu",
          "1How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1325-Table5-1.png"
        ]
      },
      "8": {
        "title": "Generated and retrieved responses",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Discussion",
        "text": [
          "A generative model that utilizes similar conversations for response generation.",
          "Can generate novel responses while ensuring that the responses are grounded in the domain.",
          "Incorporating retrieved conversations during generation improves performance as evident from several metrics.",
          "The proposed idea is general and can be used for image captioning and neural machine translation."
        ],
        "page_nums": [
          11
        ],
        "images": []
      }
    },
    "paper_title": "Exemplar Encoder-Decoder for Neural Conversation Generation"
  },
  "1326": {
    "slides": {
      "0": {
        "title": "Paper Contributions",
        "text": [
          "Dataset Models Experiments Conclusion",
          "In this paper, we contributed:",
          "Noun phrase-annotated SMS corpus1",
          "1Tao Chen and Min-Yen Kan (2013). Creating a live, public short message service corpus: the NUS SMS corpus. In: Language Resources and Evaluation. Vol. 47. Springer Netherlands, pp. 299335."
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "NP annotated SMS Corpus",
        "text": [
          "Contributions Models Experiments Conclusion",
          "We used Brat Rapid Annotation Tool (BRAT)2 for annotations, recruiting undergraduate students to annotate the noun phrases."
        ],
        "page_nums": [
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "2": {
        "title": "Annotations Statistics",
        "text": [
          "Contributions Models Experiments Conclusion"
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "3": {
        "title": "Models Comparison",
        "text": [
          "Contributions Dataset Experiments Conclusion",
          "n : # words in the sentence, |Y| : # labels, L : max segment length",
          "B B B N N N",
          "N N N N N N",
          "O O O O O O"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "4": {
        "title": "Empirical Verification",
        "text": [
          "Contributions Dataset Models Conclusion"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "5": {
        "title": "F1 Score",
        "text": [
          "Contributions Dataset Models Conclusion",
          "Linear CRF Semi-CRF Weak Semi-CRF",
          "Basic features +affixes All features"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "6": {
        "title": "Training Speed",
        "text": [
          "Contributions Dataset Models Conclusion",
          "Avg. time per iteration (s)",
          "# training instances (SMS)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "7": {
        "title": "Conclusion",
        "text": [
          "Contributions Dataset Models Experiments",
          "We have created a new NP-annotated dataset on informal text",
          "We can split the decisions of selecting segment length and segment type to improve the training time, while maintaining similar accuracy"
        ],
        "page_nums": [
          24,
          25,
          26
        ],
        "images": []
      }
    },
    "paper_title": "Weak Semi-Markov CRFs for NP Chunking in Informal Text"
  },
  "1328": {
    "slides": {
      "0": {
        "title": "Background Dialog",
        "text": [
          "Personal assistant, helps people complete specific tasks",
          "Combination of rules and statistical components",
          "No specific goal, attempts to produce natural responses",
          "Using variants of seq2seq model"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Background Neural Model",
        "text": [
          "utterance-response: n-to-1 relationship e.g., the response Must support! Cheer! is used for 1216 different input utterances",
          "My friends and I are shocked! pre-defined a set of topics",
          "from an external corpus rely on external corpus",
          "treat all the utterance-response pairs uniformly employ a single model to learn the mapping between utterance and response",
          "introduce latent responding factors to model multiple responding mechanisms lack of interpretation",
          "favor such general responses with high frequency"
        ],
        "page_nums": [
          2
        ],
        "images": [
          "figure/image/1328-Figure1-1.png"
        ]
      },
      "2": {
        "title": "How to capture different utterance response relationships",
        "text": [
          "Our motivation comes from"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Human Conversation Process",
        "text": [
          "Do you know a good eating place for Australian special food?",
          "knowledge state dialogue partner",
          "Good Australian eating places include steak, seafood, cake, etc. What do you want to choose?"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Model Architecture",
        "text": [
          "introduce an explicit specificity control variable s to represent the response purpose",
          "s summarizes many latent factors into one variable s has explicit meaning on specificity actively controls the generation of the response",
          "knowledge state dialogue partner"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Model Encoder",
        "text": [
          "the specificity control variable is introduced into the Seq2Seq model single model -> multiple model",
          "different <utterance, response>, different , different models",
          "semantic representation: relates to the semantic meaning usage representation: relates to the usage preference",
          "my name is John Semantic-based & Specificity-based Generation P(John) = ()(John) + (John) Response Decoder <eos> my name is Attentive Read Gaussian Kernel Layer Specificity Control Variable Utterance Encoder U",
          "Semantic Representation Usage Representation what is your name"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1328-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Model Decoder",
        "text": [
          "Bi-RNN: modeling the utterance from both forward and backward directions",
          "predict target word based on a mixture of two probabilities: the semantic-based and specificity-based generation probability",
          "decides what to say next given the input",
          "hidden state semantic representation"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": [
          "figure/image/1328-Figure2-1.png"
        ]
      },
      "7": {
        "title": "Model Training",
        "text": [
          "decides how specific we should reply",
          "the specificity control variable interacts with the usage representation of words through the layer let the word usage representation regress to the variable through certain mapping function (sigmoid) , )U",
          "specificity control variable 2U exp(",
          "0 denotes the most general response",
          "1 denotes the most specific response variance usage representation"
        ],
        "page_nums": [
          9
        ],
        "images": [
          "figure/image/1328-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Distant Supervision",
        "text": [
          "Objective function log likelihood",
          "Training data: triples s is not directly available in the raw conversation corpus",
          "How to obtain s to learn our model?",
          "We propose to acquire distant labels for"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "9": {
        "title": "Specificity Controlled Response Generation",
        "text": [
          "Normalized Inverse Response Frequency (NIRF)",
          "a response is more general if it corresponds to more input utterances the Inverse Response Frequency (IRF) in a conversation corpus",
          "Normalized Inverse Word Frequency (NIWF)",
          "a response is more specific if it contains more specific words the maximum of the Inverse Word Frequency (IWF) of all the words in a response"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "10": {
        "title": "Experiments Dataset",
        "text": [
          "Specificity Controlled Response Generation",
          "Given a new input utterance, we can generate responses at different specificity levels by varying the control variable s",
          "Different s, different models, different responses",
          "= 1: the most informative response",
          ": more dynamic , enrich the styles in the response",
          "= 0: the most general response",
          "General response Specific response"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "11": {
        "title": "Experiments Model Analysis",
        "text": [
          "Short Text Conversation (STC) dataset",
          "released in NTCIR-13 a large repository of post-comment pairs from the Sina Weibo",
          "3.8 million post-comment pairs",
          "Jieba Chinese word segmenter"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": [
          "figure/image/1328-Table2-1.png",
          "figure/image/1328-Table1-1.png"
        ]
      },
      "12": {
        "title": "Experiments Comparisons",
        "text": [
          "PRA She SaueNSSRAS ASS",
          "Key Laboratory of Network Data Science & Technology, CAS",
          "Models distinct-1 distinct-2 BLEU-1 BLEU-2 Average Extrema",
          "Table 3: Comparisons between our SC-Seq2Seq and the baselines under the automatic evaluation.",
          "When s = 1, our SC-Seq2Seqnywr model can achieve the best specificity performance",
          "BLEU-1 BLEU-2 Average Extrema Models distinct-1 distinct-2",
          "1. our SC-Seq2Seqyywr model can best fit the ground truth data",
          "2. there are diverse responses in real data in terms of specificity"
        ],
        "page_nums": [
          15,
          16,
          17
        ],
        "images": [
          "figure/image/1328-Table2-1.png",
          "figure/image/1328-Table3-1.png"
        ]
      },
      "13": {
        "title": "Experiments Case study",
        "text": [],
        "page_nums": [
          18,
          19
        ],
        "images": [
          "figure/image/1328-Table4-1.png"
        ]
      },
      "14": {
        "title": "Experiments Analysis",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion",
        "text": [],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1328-Figure3-1.png",
          "figure/image/1328-Table6-1.png"
        ]
      }
    },
    "paper_title": "Learning to Control the Specificity in Neural Response Generation"
  },
  "1329": {
    "slides": {
      "0": {
        "title": "Core Dimensions of Meaning",
        "text": [
          "have shown that the three most important, largely independent, dimensions of word meaning: valence (V): positive/pleasure negative/displeasure arousal (A): active/stimulated sluggish/bored dominance (D): powerful/strong powerless/weak",
          "Thus, when comparing the meanings of two words, we can compare their V, A, D scores. For example: banquet indicates more positiveness than funeral nervous indicates more arousal than lazy queen indicates more dominance than delicate"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Human annotations of words for VAD",
          "For use by automatic systems: predicting VAD of words predicting sentiment and emotions of sentences, tweets, etc. detecting stance, personality traits, well-being, cyber-bullying, etc.",
          "To draw inferences about people: to understand how we (or different groups of people) use language to express meaning and emotions analyze text written/spoken by different groups of people analyze VAD judgments of different groups of people"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Related Work Existing VAD Lexicons Bids",
        "text": [
          "Affective Norms of English Words (ANEW) (Bradley and Lang, 1999)",
          "Warriner et al. Norms (Warriner et al. 2013)",
          "Small number of VAD lexicons in non-English languages as well",
          "Redondo et al. (2007) for Spanish rating scale"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "Rating scales",
        "text": [
          "e 6 = Transformative: This paper is likely to change our field. Give this score exceptionally for papers worth best paper consideration. e 5= Exciting: The work presented in this submission includes original, creative contributions, the methods are solid, and the paper is well written. e 4= Interesting: The work described in this submission is original and basically sound, but there are a few problems with the method or paper. e 3-= Uninspiring: The work in this submission lacks creativity, originality, or insights. I'm",
          "ambivalent about this one.",
          "e 2= Borderline: This submission has some merits but there are significant issues with respect to originality, soundness, replicability or substance, readability, etc. e 1= Poor: | cannot find any reason for this submission to be accepted.",
          "National Research Conseil national de A as i +i Council Canada recherches Canada y @SaifM Mohammad Canada"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "4": {
        "title": "Likert Item Likert 1932",
        "text": [
          "1. The website has a user friendly interface.",
          "strongly agree neutral disagree strongly agree disagree",
          "Note: A Likert scale is the sum of responses on several Likert items.",
          "National Research Conseil national . BHM Coinci'cancda rechorenos Canada WV @SaifMMohammad Canada"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "5": {
        "title": "Problems with rating scales",
        "text": [
          "- difficult for an annotator to be self consistent",
          "- scale region bias",
          "National Research il national d . BD cotter Cancaa fecherehes Canada WV @SaifMMohammad Canada"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Comparative Annotations",
        "text": [
          "If X is the property of interest (positive, useful, etc.), give two terms and ask which is more X less cognitive load helps with consistency issues requires a large number of annotations order N2, where N is number of terms to be annotated"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "BestWorst Scaling BWS Louviere and Woodworth 1990",
        "text": [
          "The annotator is presented with four words (say, A, B, C, and D) and asked:",
          "which word is associated with the most/highest X (property of interest, say valence) which word is associated with the least/lowest X",
          "By answering just these two questions, five out of the six inequalities are known",
          "If A: highest valence and D: lowest valence, then we know:"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Best Worst Scaling Louviere and Woodworth 1990",
        "text": [
          "Each of these BWS questions can be presented to multiple annotators.",
          "We can obtain real-valued scores for all the terms using a simple counting method",
          "the scores range from:",
          "-1 (least X) X = property of interest, say valence",
          "the scores can then be used to rank all the terms",
          "preserves the comparative nature keeps the number of annotations down to about 2N leads to more reliable, less biased, more discriminating annotations"
        ],
        "page_nums": [
          14,
          15,
          25
        ],
        "images": []
      },
      "9": {
        "title": "Creating the Valence Arousal and",
        "text": [
          "National Research Conseil national de . ne i* Council Canada recherches Canada yw @SaifMMohammad Canada"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Term Selection",
        "text": [
          "We wanted to include: commonly used English terms terms common in tweets terms that denotate or connotate emotions",
          "All terms in the NRC Emotion Lexicon (Mohammad and Turney, 2013): ~14,000 labels indicate association with eight basic emotions anger, anticipation, disgust, fear, joy, sadness, surprise, and trust (Plutchik, 1980) includes terms that occur frequently in the Google n-gram corpus",
          "All terms in the Warriner et al. lexicon",
          "Words from the Rogets Thesaurus categories corresponding to the eight basic",
          "High-frequency content terms, including emoticons, from the Hashtag Emotion Corpus (a tweets corpus) (Mohammad, 2012): ~1000"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Best Worst Questionnaires",
        "text": [
          "Q1. Which of the four words below is associated with the",
          "LEAST happiness / pleasure / positiveness / satisfaction / contentedness / hopefulness",
          "OR LEAST unhappiness / annoyance / negativeness / dissatisfaction / melancholy / despair?",
          "(Four words listed as options)",
          "Similar questions for arousal and dominance",
          "This study was approved by the NRC Research Ethics Board (NRC-REB) under protocol number 2017-98. REB review seeks to ensure that research projects involving humans as participants meet Canadian standards of ethics."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "12": {
        "title": "Crowdsourcing and Quality Control i",
        "text": [
          "About 2% of the data was annotated internally beforehand (by the author)",
          "These gold questions are interspersed with other questions",
          "If one gets a gold question wrong, they are immediately notified of it feedback to improve task understanding",
          "If ones accuracy on the gold questions falls below 80%, they are refused further annotation all of their annotations are discarded",
          "Mechanism to avoid malicious or random annotations"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "13": {
        "title": "Valence Arousal and Dominance Annotations with BWS",
        "text": [
          "Annotators worldwide worldwide worldwide",
          "il National Research Conseil national de Council Canada recherches Canada",
          "Dataset #words Annotators Item #Items #Annotators MAI #Q/Item Annotations",
          "~1000 annotators for each task",
          "minimum and median annotations per 4-tuple",
          "Location of Annotation #Best-Worst",
          "number of pairs of bestworst annotations",
          "Nati | Re he Co il national di . oI eee eer Cea ohercnos Canada W @SaifMMohammad Canadi 25"
        ],
        "page_nums": [
          20,
          21,
          22,
          23,
          24
        ],
        "images": [
          "figure/image/1329-Table1-1.png"
        ]
      },
      "14": {
        "title": "Example Entries in the VAD Lexicon",
        "text": [
          "Dimension Word Scoret Word Score|",
          "Scores are in the range 0 (lowest V/A/D) to 1 (highest V/A/D)",
          "Nati | Re he Co il national di . eee eer Cea ohercnos Canada W @SaifMMohammad Canadi_-.27"
        ],
        "page_nums": [
          26
        ],
        "images": [
          "figure/image/1329-Table2-1.png"
        ]
      },
      "15": {
        "title": "Reliability Reproducibility of Annotations",
        "text": [
          "Average split-half reliability (SHR): a commonly used approach to determine consistency (Kuder and Richardson, 1937; Cronbach, 1946)",
          "Pearson correlation: -1(most inversely correlated) to 1(most correlated)"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "16": {
        "title": "Split Half Reliability Scores for VAD Annotations",
        "text": [
          "Annotations # Terms # Annotations V A D",
          "Markedly lower SHR for A and D.",
          "The dominance ratings seem especially problematic since the Warriner",
          "Ours (Warriner terms) 6 per tuple",
          "Ours (all terms) 6 per tuple",
          "These SHR scores show for the first time that highly reliable fine-grained ratings can be obtained for valence, arousal, and dominance. Also, our V-D correlation is 0.48."
        ],
        "page_nums": [
          28,
          29,
          30
        ],
        "images": []
      },
      "17": {
        "title": "NRC VAD Lexicon and the Warriner et al Lexicon",
        "text": [
          "How Different are the Scores?",
          "Annotations V A D",
          "The especially low correlations for dominance and arousal indicate that our lexicon has substantially different scores and rankings of terms."
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "18": {
        "title": "Shared Understanding of VAD",
        "text": [
          "With in and Across Demographic Groups",
          "Human cognition and behaviour are impacted by evolutionary and socio-cultural factors",
          "These factors impact different groups of people differently",
          "Men, women, and other genders are substantially more alike than different",
          "However, they have encountered different socio-cultural influences",
          "Often these disparities have been a means to exert unequal status and asymmetric power relations",
          "Gender studies examine both the overt and subtle impacts of these socio-cultural influences ways to mitigate the inequity how different genders perceive and use language"
        ],
        "page_nums": [
          33
        ],
        "images": []
      },
      "19": {
        "title": "Demographic Survey",
        "text": [
          "Annotators could optionally respond to a separate survey asking for their demographic information: age gender country personality traits we asked how they viewed themselves across the big five personality traits",
          "991 people (55% of the VAD annotators) chose to provide their demographic information"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "20": {
        "title": "Experiment",
        "text": [
          "e For each demographic attribute, we partitioned the annotators into two groups:",
          "male (m) and female (f) those 18 to 35 (young) and those over 35 (grownups) agreeable (Ag) and Disagreeable (Di) extrovert (Ex) and introvert (In) and so on",
          "i+ gato nal Research Conseil natior nal de recherches Can W @SaifMMohammad Canadi s-.36",
          "Calculated the extent to which people within the same group agreed with each other on the",
          "VAD annotations whether the differences in average agreements in each group are significant chi-square test for independence and significance level of 0.05"
        ],
        "page_nums": [
          35,
          36
        ],
        "images": [
          "figure/image/1329-Table3-1.png"
        ]
      },
      "21": {
        "title": "Differences in Average Agreements Gender",
        "text": [
          "Sub-group with Significantly Higher Agreement",
          "SS [ Valence Arousal Dominance",
          "Nati | Re he Co il ional de } BB Sstona! Research Conseil national de W @SaifMMohammad Canada 38",
          "FF vs. MM MM FF MM",
          "Women have a higher shared understanding of the degree of arousal of words.",
          "Men have a higher shared understanding of the dominance and valence of words."
        ],
        "page_nums": [
          37,
          38
        ],
        "images": []
      },
      "22": {
        "title": "Differences in Average Agreements Age",
        "text": [
          "Sub-group with Significantly Higher Agreement",
          "[| Valence Arousal Dominance",
          "Nati | Re he Co il ional de + eee eer Cea ohercnos Canada W @SaifMMohammad Canadi 40",
          "YY vs. GG GG GG YY",
          "The young have a higher shared understanding of the dominance of words.",
          "The grownups have a higher shared understanding of valence and arousal of words."
        ],
        "page_nums": [
          39,
          40
        ],
        "images": []
      },
      "23": {
        "title": "Differences in Average Agreements Big 5 Traits",
        "text": [
          "Sub-group with Significantly Higher Agreement",
          "AgAg vs. DiDi AgAg AgAg DiDi",
          "CoCo vs. EaEa CoCo CoCo",
          "ExEx vs. InIn ExEx ExEx ExEx",
          "NeNe vs SeSe SeSe SeSe",
          "OpOp vs ClCl OpOp OpOp OpOp",
          "Ag = Agreeableness (friendly and compassionate)",
          "Di = Disagreeableness (careful in whom to trust, argumentative)",
          "Co = Conscientiousness (efficient and organized) Ea = Easygoing (easy-going and carefree)",
          "Ex = Extrovert (outgoing, energetic, seek the company of others) In = Introvert (solitary, reserved, meeting many people causes anxiety)",
          "Ne = Neurotic (often feel anger, anxiety, depression, and vulnerability) Se = Secure (rarely feel anger, anxiety, depression, and vulnerability) Op = Open to experiences (inventive and curious; seek out new experiences) Cl = Closed to experiences (consistent and cautious; anxious about new experiences)"
        ],
        "page_nums": [
          41
        ],
        "images": []
      },
      "24": {
        "title": "Selected Applications and Future Work dy",
        "text": [
          "Source of features for systems in sentiment, emotion, and other affect-related tasks",
          "useful to create emotion-aware word embeddings and emotion-aware sentence representations",
          "Source of gold (reference) scores, to evaluate automatic methods of determining V,",
          "Study the interplay between the basic emotion model and the VAD model of emotions (Mohammad, 2018: LREC paper)",
          "Companion lexicon: NRC Emotion Intensity Lexicon provides real-valued affect intensity scores for ~6000 words with four basic emotions (anger, fear, sadness, joy)",
          "Study the role of high VAD words in high emotion intensity sentences, tweets, snippets from literature"
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "25": {
        "title": "Summary",
        "text": [
          "Created the NRC Valence, Arousal, and Dominance Lexicon: has entries for about 20,000 English words has fine-grained real-valued scores for V, A, and D (core dimensions of meaning) showed that the annotations are reliable (high split-half reliability scores)",
          "Showed that certain demographic attributes impact how we view the world around",
          "The VAD lexicon is useful in a wide range of applications and research projects."
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "26": {
        "title": "The NRC Valence Arousal and Dominance Lexicon",
        "text": [
          "prov ides ratings of valence, arousal, and dominance for ~20,000 English words",
          "The NRC WordEmotion Association Lexicon aka NRC Emotion Lexicon",
          "provides associations for ~14,000 words with eight emotions (anger, fear, joy, sadness,",
          "anticipation, disgust, surprise, trust) http://saifmohammad.com/WebPages/NRC-Emotion- Lexicon.htm",
          "The NRC Emotion Intensity Lexicon aka Affect Intensity Lexicon",
          "provides intensity scores for ~6000 words with four emotions (anger, fear, joy, sadness)",
          "The NRC WordColour Association Lexicon provides associations for ~14,000 words with 11 common colours"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "27": {
        "title": "Pictures Attribution",
        "text": [
          "Family by b farias from the Noun Project",
          "Shovel and Pitchfork by Symbolon from the Noun Project",
          "Checklist by Nick Bluth from the Noun Project",
          "Generation by Creative Mahira from the Noun Project",
          "Human by Adrien Coquet from the Noun Project",
          "Search by Maxim Kulikov from the Noun Project"
        ],
        "page_nums": [
          46
        ],
        "images": []
      },
      "28": {
        "title": "Resources Available at wwwsaifmohammadcom",
        "text": [
          "NRC Valence, Arousal, and Dominance Lexicon",
          "NRC Emotion Lexicon and Emotion Intensity Lexicon",
          "Many thanks to Svetlana Kiritchenko, Michael Wojatzki, and Norm Vinson for helpful discussions."
        ],
        "page_nums": [
          47
        ],
        "images": []
      }
    },
    "paper_title": "Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words"
  },
  "1330": {
    "slides": {
      "0": {
        "title": "Entity Typing",
        "text": [
          "1. Bill robbed John, and he was arrested shortly afterwards.",
          "2. Nvidia hands out Titan V for free to AI researchers.",
          "Information extraction [Ling 12, YY17]",
          "Coreference resolution [Durrett 14]",
          "Entity linking [Durrett 14, Raiman 18]",
          "Question answering [Yavuz 16]"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Scaling Up Entity Typing Mention Coverage",
        "text": [
          "Bill robbed John, and he was arrested shortly afterwards.",
          "2. Nvidia hands out Titan V for free to AI researchers.",
          "Prior Work This Work",
          "Titan V Titan V John John He",
          "Reasoning over diverse, challenging mention strings"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "2": {
        "title": "Scaling Up Entity Typing Type Coverage",
        "text": [
          "Bill robbed John, and he was arrested shortly afterwards.",
          "2. Nvidia hands out Titan V for free to AI researchers.",
          "PER, Victim PER, Criminal PER, Criminal",
          "ORG, Company OBJ, Product, Electronics PER, Researcher, Professional",
          "Any frequent nouns from dictionary is allowed as a type"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Challenge 2 Very large label space",
        "text": [
          "PER, criminal PER, victimPER, criminal",
          "Bill robbed John. He was arrested shortly afterwards.",
          "sp ud mig ric rga dic ncti nam orma uca marke demi band ufac data ounc mina me oup ale on co blin vin ecta ive p_a ate dic ent atio nk nce de per icu f ot thi em na pla fer drug staf eke for ric orm il_lpio gre ativ ex gr er ar lua ou cul uild olit ow star mic_ alu dus ha oy ec ere cili eit al_ opic serv inne lop dm wm vilia stig ab era en xt_ ie nn an b_s rai ve_ ria f ire ag",
          "https://homes.cs.washington.edu/~eunsol/finetype_visualization/figer_index.html atis ilo pai ter nt cto ontr age pinio uipm sast policy point ball_p ministra risone ontra hoic gine ove nda po dca re ide dit ain book ateme rvicem _tra",
          "ess ne otio ud ecti risi gme elativ uratio gisla name fenda tructur aract ecord aim vern war owe eat roo twa urn ma eat tdo ap tu lid ship spo fes nom part mmo pita ula spl unt pre sta",
          "Nvidia hands out Titan V for free to AI researchers. fe al mis sum visio show ocume citizen enterprise actor meetin liat iva nc seb aso uis oxe rts an den bill maste professiona elebrit squad wspa elin erie aid ar_ https://homes.cs.washington.edu/~eunsol/finetype_visualization/onto_index.html ta _sc abit ian r_ve se ocie /country lec inist ilwa rren oble victim ecia state year licem mou ome crip mp alit roo /building ontestan performe team atherin land ist tne eac man home ave /company los up mst eig no ec mba ateri achi battle eporte musicia slat title king ndin tra /city /company uti goa politician apo em let ym umb crimina hang inessm etwo hiev um tem giti /event ea /time nec olfe onv tuatio case ou ctio adc oubl rrito business coach bstan esu tru gre cor",
          "ORG, company an nce tain OBJ, product male leader sen ual c_g two raine action nsequen wo er ctio company resenta er co nn album song rtain uni athe PER, eal ou researcher, professional s_p ace ell /location ecut wife ac es rum pro ess sh player ran stm kpl ceho ruc hurc lica music ystem tfo tin time ma astro object mmunica agu ffic ncip tertain islat soci las rde ov pokesperso stitu child utho dre bra gw har erv writer adult /person /organization wgi oar cide car aceme cientis agen prize ho urre pas ca usa titu hea toc mpaig soldie city work pta ers singe tary apit erm activity region lam olu /other urg elo men eath udg re /person win em ders party lan dar_m space og semb nes zen erta ille rga urnal era girl government law us_l m_s on ssu int ws vem cuss blicati ndin idea person organization worker play spu adiu pa et _se oss vesto artist appeni emb tor mo alk bby stom mpetit ini"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "This Talk",
        "text": [
          "Task: Ultra-Fine Covers all entity mentions",
          "Allows all concepts as types",
          "Crowdsourcing ultra fine-grained typing data",
          "New source of distant supervision",
          "Multitask loss for predicting ultra-fine types",
          "Sets state-of-the-art results on existing benchmark",
          "New Task: Ultra-Fine Entity Typing"
        ],
        "page_nums": [
          9,
          16,
          24,
          40,
          55
        ],
        "images": []
      },
      "5": {
        "title": "Fine grained NER",
        "text": [
          "He was elected over John McCain",
          "coarse f ine grained Type Ontology grained",
          "FIGER [Ling 12] OntoNotes [Gillick TypeNet [next talk] Person, Politician Ours",
          "2 hierarchy level 3 hierarchy level hierarchy level No hierarchy"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "6": {
        "title": "Label Coverage Problem",
        "text": [
          "He was elected over [ John McCain",
          "In both, top 9 types covers over 80% of the",
          "In OntoNotes, 52% of mentions was marked",
          "Named NER Fine grained NER",
          "Paris Agreement coarse Security Mortgages Oil f ine",
          "grained Type Ontology grained"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "7": {
        "title": "Label Distribution In Evaluation Data",
        "text": [
          "/organization https://homes.cs.washington.edu/~eunsol/finetype_visualization/figer_index.html /legal /country /country /building /company",
          "/time /event OntoNotes [Gillick 14]",
          "/art /location itten_wo ational_ins nment_a",
          "/city /company sp ud mig ric rga dic ncti nam orma uca marke demi band ufac data ounc mina me oup ale on co mm blin vin ecta p_a",
          "ate dic ent atio nk nce de per icu f ot thi em na pla fer drug staf eke for ric orm il_lpio gre ativ ex gr er ar lua ou cili cul eit uild al_ olit serv ow star inne mic_ alu dus dm vilia ha oy ec ab ere opic lop wm stig ive era en xt_ ie nn an b_s rai ve_ ria ire f ag",
          "ess ne otio ud ecti risi gme elativ uratio gisla name fenda tructur aract ecord aim vern war owe eat roo twa urn ma eat tdo ap tu lid ship spo fes nom part mmo pita ula spl unt pre sta"
        ],
        "page_nums": [
          14,
          15
        ],
        "images": []
      },
      "8": {
        "title": "Automatic Mention Detection",
        "text": [
          "Maximal noun phrases from the constituency parser (Manning et al 14)",
          "Mentions from the co-reference resolution system (Lee et al 17)",
          "In 1817, in collaboration with David Hare, he set up the Hindu College."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "9": {
        "title": "Crowdsourcing Type Labels",
        "text": [
          "Michael Buble putting career on hold after sons cancer diagnosis Person Parent Professional",
          "Label space: 10K most common nouns from Wiktionary",
          "Five crowd workers provide labels per each example",
          "Collected 6K examples, 5.2 labels per example.",
          "On average, 1 general type, 4 fine types"
        ],
        "page_nums": [
          18,
          19
        ],
        "images": []
      },
      "10": {
        "title": "Diverse Fine grained Types",
        "text": [
          "town, company, space, mountain, work, murderer, journalist, army, outcome, politician, duty, document, women, employment, community, ballot, stage, host, son, friend, investigator, inflation, film, injection, album, music_group, food, milestone, chancellor, village, philosopher, military, medicine, river, health, incident, male, actor, citizenship,",
          "language, prisoner, exhibition, cricketer, attack, singer, battle, religious_leader,",
          "economy, vice_president, man, benefit, agency, deity, painting, bread, effect, university, power, direction, competition, civilian, reviewer, worker, member, cinema, talk, thinker, contract, landmark, fashion_designer, citizen, investor, territory, train, moss, concert, team, troglodyte, consequence, staff, subject, professor, use, tournament, planet, city, coach, date, curator, poet, rule, goddess, symptom, senator, month, weapon, parent, crime, hiding, general, position, political, religion, cell, business, designation,",
          "computer_game, promotion, disaster, historian, poll, institution, transportation,",
          "painter, free, official, traveller, year, player, beverage, performer, biographer, priest, wind, cash, race, guest, area, agreement, prison, analyst, draw, love, police, actress",
          "economy, vice_president, man, benefit, agency, deity, painting, bread, effect, university, 2,300 unique types for 6K xamples power, direction, competition, civilian, reviewer, worker, member, cinema, talk, thinker, contract, landmark, fashion_designer, citizen, investor, territory, train, moss, concert, To cover 80% of labels, 429 types a e needed team, troglodyte, consequence, staff, subject, professor, use, tournament, planet, city, coach, date, curator, poet, rule, goddess, symptom, senator, month, weapon, parent, crime, hiding, general, position, political, religion, cell, business, designation,"
        ],
        "page_nums": [
          20,
          21,
          22
        ],
        "images": []
      },
      "11": {
        "title": "Data Validation",
        "text": [
          "town, company, space, mountain, work, murderer, journalist, army, outcome, politician, duty, document, women, employment, community, ballot, stage, host, son, friend, investigator, inflation, film, injection, album, music_group, food, milestone, chancellor, village, philosopher, military, medicine, river, health, incident, male, actor, citizenship,",
          "language, prisoner, exhibition, cricketer, attack, singer, battle, religious_leader, 86% binary agreement",
          "economy, vice_president, man, benefit, agency, deity, painting, bread, effect, university, power, direction, competition, civilian, reviewer, worker, member, cinema, talk, thinker, Only collects labels that majority of validators contract, landmark, fashion_designer, citizen, investor, territory, train, moss, concert, team, troglodyte, consequence, staff, subject, professor, use, tournament, planet, city, (3/5) agreed coach, date, curator, poet, rule, goddess, symptom, senator, month, weapon, parent, crime, hiding, general, position, political, religion, cell, business, designation,",
          "computer_game, promotion, disaster, historian, poll, institution, transportation,",
          "painter, free, official, traveller, year, player, beverage, performer, biographer, priest, wind, cash, race, guest, area, agreement, prison, analyst, draw, love, police, actress"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "12": {
        "title": "1 Knowledge Base Supervision",
        "text": [
          "[ Arnold Schwarzenegger] gives a speech at Mission",
          "Serves service project on Veterans Day 2010.",
          "Entity linking person, politician, athlete,",
          "businessman, artist, actor, author"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29
        ],
        "images": []
      },
      "13": {
        "title": "2 Wikipedia Supervision",
        "text": [
          "Arnold Alois Schwarzenegger is an Austrian-",
          "American actor, producer, businessman, investor, author, philanthropist, activist, politician and former professional body-builder.",
          "[ Arnold Schwarzenegger] gives a speech at Mission",
          "Serves service project on Veterans Day 2010.",
          "4.6K unique types on 3.1M entities",
          "Mexican National Championship competition",
          "Palestinian Interest Committee movement",
          "Giovanni Paolo Lancelotti canonist"
        ],
        "page_nums": [
          30,
          31,
          32,
          33
        ],
        "images": []
      },
      "14": {
        "title": "Supervision Summary",
        "text": [
          "Entity linking General Fine X Good base",
          "Entity linking, Wikipedia Finer X Better Parser",
          "Entity tit linking li i General Fine X Good",
          "Entity linking, Entity linking,",
          "Fine-grained Finer X Better Better",
          "Dependency Headword Finest O Best Parser"
        ],
        "page_nums": [
          34,
          38
        ],
        "images": []
      },
      "15": {
        "title": "3 Head Word Supervision",
        "text": [
          "[Controversial judge James Pickles] sentences Tracey",
          "Scott to six months in prison after she admitted helping shoplifter.",
          "Using a head word from original noun phrase as a source of supervision.",
          "[Consent forms , Institutional Review Boards,] peer review committees and data safety committees did not exist decades ago.",
          "In [addition] there's an USB 1.1 port that can be used to attach to a printer."
        ],
        "page_nums": [
          35,
          36,
          37
        ],
        "images": []
      },
      "16": {
        "title": "Supervision Summary II",
        "text": [
          "Source Cover Accuracy* Scale",
          "KB Named Entities M",
          "Wikipedia Named Entities M",
          "* Manual examination on examples"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "17": {
        "title": "Bidirectional RNN Model",
        "text": [
          "Closely follow previous model for ine-grained f NER [Shimaoka 17]",
          "Single LSTM to cover left, right context and mention"
        ],
        "page_nums": [
          41,
          42
        ],
        "images": []
      },
      "18": {
        "title": "Multitask Objective",
        "text": [
          "Binary classification log likelihood objective for each label",
          "Sum loss at different type granularities"
        ],
        "page_nums": [
          43
        ],
        "images": []
      },
      "19": {
        "title": "Experiments",
        "text": [
          "Ultra-Fine Entity Typing Dataset",
          "OntoNotes Fine-Grained Typing Dataset (Gillick et al 14)",
          "Macro-averaged Precision, Recall, F1"
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "20": {
        "title": "Data Setup",
        "text": [
          "Ultra-Fine Entity Typing Benchmark OntoNotes Dataset (Gillick et al 14)",
          "2K crowdsourced 2.69M KB supervision",
          "Train 20M Headword 2.1M Headword supervision",
          "5M Entity Linking 0.6M Wikipedia supervision",
          "Test 2K crowdsourced 8K crowdsourced"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "21": {
        "title": "Comparison Systems",
        "text": [
          "AttentiveNER Model [Shimaoka et al., 2017]",
          "Ablation on the different sets of supervision"
        ],
        "page_nums": [
          46
        ],
        "images": []
      },
      "22": {
        "title": "Ultra Fine Entity Typing",
        "text": [
          "Multitask loss encourages prediction on fine-grained labels, hurting precision but improves recall Mean Reciprocal Rank",
          "Our model architecture (character-level CNN, single LSTM) improves the performance AttentiveNER"
        ],
        "page_nums": [
          47,
          48
        ],
        "images": []
      },
      "23": {
        "title": "Ablation Study",
        "text": [
          "All -Entity Linking -Headword",
          "General F1 Fine F1 Ultra-Fine F1",
          "person, organization, event, object politician, artist, building, company friend, accident, talk, president",
          "Finer types are harder to predict",
          "Headword is more important for ultra-fine types, entity linking for f ine types."
        ],
        "page_nums": [
          49,
          50,
          51
        ],
        "images": []
      },
      "24": {
        "title": "OntoNotes Fine grained Types",
        "text": [
          "AttentiveNER AttentiveNER Our Data Ours + Our Data"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "25": {
        "title": "Example Outputs",
        "text": [
          "More Examples at: https://homes.cs.washington.edu/~eunsol/_site/acl18_sample_output.html",
          "Evaluation is still challenging : annotation coverage can be improved",
          "Model suffers from recall problem",
          "Joint modeling of type labels would be helpful"
        ],
        "page_nums": [
          53,
          54
        ],
        "images": [
          "figure/image/1330-Table5-1.png"
        ]
      }
    },
    "paper_title": "Ultra-Fine Entity Typing"
  },
  "1331": {
    "slides": {
      "0": {
        "title": "Intro Approach Experiments Summary",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "Knowledge graph",
        "text": [
          "A directed graph composed of entities (nodes) and relations (edges)",
          "(Cristiano Ronaldo, bornIn, Funchal)",
          "(Cristiano Ronaldo, playsFor, Real Madrid)",
          "(Cristiano Ronaldo, teammates, Sergio Ramos)",
          "(Sergio Ramos, bornIn, Camas)",
          "(Sergio Ramos, playsFor, Real Madrid)",
          "(Real Madrid, locatedIn, Spain)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Knowledge graph embedding",
        "text": [
          "Learn to represent entities and relations in continuous vector spaces",
          "Entities as points in vector spaces (vectors)",
          "Relations as operations between entities"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "3": {
        "title": "Knowledge graph embedding cont",
        "text": [
          "Easy computation and inference on knowledge graphs",
          "Is Spain more similar to Camas (a municipality located in Spain) or Portugal",
          "(both Portugal and Spain are European countries)?",
          "Spain Camas Spain Portugal",
          "What is the relationship between Cristiano Ronaldo and Portugal?",
          "C. Ronaldo Portugal teammates"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "Previous approaches",
        "text": [
          "Simple models developed over RDF triples, e.g., TransE, RESCAL,",
          "Designing more complicated triple scoring models",
          "Usually with higher computational complexity",
          "Incorporating extra information beyond RDF triples",
          "Not always applicable to all knowledge graphs"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "This work",
        "text": [
          "Using simple constraints to improve knowledge graph embedding",
          "Non-negativity constraints on entity representations",
          "Approximate entailment constraints on relation representations",
          "Code and data available at https://github.com/iieir-km/ComplEx-NNE_AER"
        ],
        "page_nums": [
          7,
          23
        ],
        "images": []
      },
      "6": {
        "title": "Basic embedding model ComplEx",
        "text": [
          "Entity and relation representations: complex-valued vectors",
          "Re Im Re Im",
          "Triple scoring function: multi-linear dot product",
          "Triples with higher scores are more likely to be true"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Non negativity of entity representations",
        "text": [
          "Uneconomical to store negative properties of an entity/concept",
          "Positive properties of cats",
          "Cats have four legs",
          "Negative properties of cats",
          "Cats are not vehicles",
          "Cats do not have wheels",
          "Cats are not used for communication"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Approximate entailment for relations",
        "text": [
          ": relation approximately entails relation with confidence level",
          ": a person born in a country is very likely, but not necessarily, to have a nationality of that country",
          "Can be derived automatically by modern rule mining systems"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "Approximate entailment for relations cont",
        "text": [
          "A sufficient condition for",
          "Introducing confidence and allowing slackness in",
          "A higher confidence level shows less tolerance for violating the constraints"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Overall model",
        "text": [
          "Basic embedding model of ComplEx + non-negativity constraints + approximate entailment constraints",
          "logistic loss for ComplEx",
          "approximate entailment constraints on relation representations",
          "non-negativity constraints on entity representations"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Complexity analysis",
        "text": [
          "Space complexity: the same as that of ComplEx",
          "is the number of entities",
          "is the number of relations",
          "is the dimensionality of the embedding space",
          "Time complexity per iteration:",
          "is the average number of entities in a mini-batch",
          "is the total number of approximate entailments"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Experimental setups",
        "text": [
          "WN18: subset of WordNet",
          "FB15k: subset of Freebase",
          "DB100k: subset of DBpedia",
          "AMIE+ with confidence level higher than 0.8"
        ],
        "page_nums": [
          16
        ],
        "images": [
          "figure/image/1331-Table2-1.png",
          "figure/image/1331-Table1-1.png"
        ]
      },
      "13": {
        "title": "Experimental setups cont",
        "text": [
          "To complete a triple with or missing",
          "Simple embedding models based on RDF triples",
          "Other extensions of ComplEx incorporating logic rules",
          "Recently developed neural network architectures",
          "ComplEx-NNE: only with non-negativity constraints",
          "ComplEx-NNE+AER: also with approximate entailment constraints"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "14": {
        "title": "Link prediction results",
        "text": [
          "Simple embedding models Incorporating logic rules Neural network architectures",
          "ComplEx-NNE+AER can beat very strong baselines just by introducing the simple constraints"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "15": {
        "title": "Analysis on entity representations",
        "text": [
          "Visualization of entity representations",
          "Pick 4 types reptile/wine region /species/programming language, and randomly select 30 entities from each type",
          "Visualize the representations of these entities learned by",
          "Compact and interpretable entity representations",
          "Each entity is represented by only a relatively small number of active dimensions",
          "Entities with the same type tend to activate the same set of dimensions"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1331-Figure1-1.png"
        ]
      },
      "16": {
        "title": "Analysis on entity representations cont",
        "text": [
          "Semantic purity of latent dimensions",
          "For each latent dimension, pick top K percent of entities with the highest activation values on this dimension",
          "Calculate the entropy of the type distribution of these entities",
          "Latent dimensions with higher semantic purity",
          "A lower entropy means entities along this dimension tend to have the same type"
        ],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/1331-Figure2-1.png"
        ]
      },
      "17": {
        "title": "Analysis on relation representations",
        "text": [
          "Visualization of relation representations",
          "Encode logical regularities quite well"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1331-Figure3-1.png"
        ]
      }
    },
    "paper_title": "Improving Knowledge Graph Embedding Using Simple Constraints"
  },
  "1332": {
    "slides": {
      "0": {
        "title": "Adpositions are Pervasive",
        "text": [
          "Adpositions: prepositions or postpositions",
          "Order of Adposition and Noun Phrase WALS / Dryer and Haspelmath"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Prepositions are some of the most frequent",
        "text": [
          "Based on the COCA list of 5000 most frequent words"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "We know Prepositions are challenging for Syntactic Parsing",
        "text": [
          "a talk at the conference on prepositions",
          "But what about the meaning beyond linking governor and object?"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Prepositions are highly Polysemous",
        "text": [
          "in love, in trouble",
          "in fact leave for Paris ate for hours a gift for mother raise money for the party"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Translations are Many to Many",
        "text": [
          "raise money for the church a gift for mother",
          "give the gift to mother",
          "go to Paris raise money to buy a house"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Potential Applications",
        "text": [
          "MT into English: mistranslation of prepositions among most common errors",
          "Semantic Parsing / SRL"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Goal Disambiguation",
        "text": [
          "Descriptive theory (annotation scheme)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Our Approach",
        "text": [
          "Comprehensive with respect to naturally occurring text",
          "Unified scheme for prepositions and possessives",
          "Scene role and prepositions lexical contribution are distinguished",
          "In this paper: English"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Senses vs Supersenses",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "9": {
        "title": "Challenges for Comprehensiveness",
        "text": [
          "What counts as a preposition/possessive marker?",
          "Prepositional multi-word expressions (of course)",
          "Phrasal verbs (give up)",
          "Rare senses (RateUnit, 40 miles per Gallon)",
          "Rare prepositions (in keeping with)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Supersense Inventory",
        "text": [
          "Semantic Network of Adposition and Case Supersenses (SNACS)",
          "50 supersenses, 4 levels of depth",
          "Simpler than its predecessor (Schneider et al., 2016)",
          "Fewer categories, smaller hierarchy",
          "Usually core semantic roles",
          "Usually non-core semantic roles"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "11": {
        "title": "Construal",
        "text": [
          "Challenge: the preposition itself and the verb may suggest different labels",
          "Similar meanings: the same label?",
          "1. Vernon works at Grunnings",
          "at Grunnings: Locus or OrgRole",
          "2. Vernon works for Grunnings for Grunning: Beneficiary or",
          "Approach: distinguish scene role and preposition function",
          "Scene role and preposition function may diverge:",
          "Function = Scene Role in 1/3 of instances"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": []
      },
      "12": {
        "title": "Documentation",
        "text": [
          "A web-app and repository of prepositions/supersenses",
          "Standardized format and querying tools to retrieve relevant examples/guidelines"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Re annotated Dataset",
        "text": [
          "STREUSLE is a corpus annotated with (preposition) supersenses",
          "Text: review section of the English Web Treebank",
          "Complete revision of STREUSLE: version 4.0",
          "5,455 target prepositions, including 1,104 possessives"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Preposition Distribution",
        "text": [
          "10 account for 2/3 of the mass",
          "regardless of abou in time in the process of it fot",
          "under circumstances according to a least",
          "out of date on the cheap ahead of time across",
          "over the years in time of need just about below all over between home without than our to"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "15": {
        "title": "Supersense Distribution",
        "text": [
          "Path Cost Extent Co-Agent Experiencer Stimulus",
          "Topic Time Gestalt Locus"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "16": {
        "title": "Inter Annotator Agreement",
        "text": [
          "Annotated a small sample of The Little Prince",
          "5 annotators, varied familiarity with scheme",
          "Exact agreement (pairwise avg.):"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "17": {
        "title": "Disambiguation Models",
        "text": [
          "Most Frequent (MF) baseline: most frequent label for the preposition in training",
          "Neural: BiLSTM over sentence + multilayer perceptron per preposition",
          "Feature-rich linear: SVM per preposition, with features based on previous work (Srikumar &",
          "Lexicon-based features: WordNet, Roget thesaurus"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "18": {
        "title": "Target Identification",
        "text": [
          "Multi-word prepositions, especially rare ones (e.g., after the fashion of)",
          "Idiomatic PPs (e.g., in action, by far)"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "19": {
        "title": "Disambiguation Results",
        "text": [
          "With gold standard syntax target identification:",
          "Role Acc Fxn Acc Full Acc",
          "Most Frequent Neural Feature-rich linear"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "20": {
        "title": "Results Summary",
        "text": [
          "Predicting function label is more difficult than role label",
          "~8% gap in F1 score in both settings",
          "This mirrors a similar effect in IAA, and is probably due to:",
          "Less ambiguity in function labels (given a preposition)",
          "The more literal nature of function labels",
          "Syntax plays an important role",
          "4-7% difference in performance",
          "Neural and feature-rich approach are not far off in terms of performance",
          "Feature-rich is marginally better",
          "They agree on about 2/3 of cases; agreement area is 5% more accurate"
        ],
        "page_nums": [
          23,
          24
        ],
        "images": []
      },
      "21": {
        "title": "Multi Lingual Perspective",
        "text": [
          "Work is underway in Chinese, Korean, Hebrew and German",
          "Parallel Text: The Little Prince",
          "Complex interaction with morphology (e.g., via case)",
          "How do prepositions change in translation?",
          "How do role/function labels change in translation?"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "22": {
        "title": "Conclusion",
        "text": [
          "A new approach to comprehensive analysis of the semantics of prepositions and possessives in English",
          "Simpler and more concise than previous version",
          "Encouraging initial disambiguation results"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "23": {
        "title": "Ongoing Work",
        "text": [
          "Multi-lingual extensions to four languages",
          "Streamlining the documentation and annotation processes",
          "Semi-supervised and multi-lingual disambiguation systems",
          "Integrating the scheme with a structural scheme (UCCA)"
        ],
        "page_nums": [
          27
        ],
        "images": []
      }
    },
    "paper_title": "Comprehensive Supersense Disambiguation of English Prepositions and Possessives"
  },
  "1333": {
    "slides": {
      "0": {
        "title": "Background",
        "text": [
          "Naturally and consistently converse with",
          "human-beings on open-domain topics."
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Context Response Matching",
        "text": [],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Retrieval based Chatbot",
        "text": [
          "An information retrieval approach to short text conversation. Ji et al., 2014"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Adversarial Dialogue Generation",
        "text": [
          "Adversarial Learning for Neural Dialogue Generation. Li et al., EMNLP-2017"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Challenges",
        "text": [
          "Detecting truly matched segment pairs across context and response.",
          "Segment pairs could be matched at different granularities.",
          "Segment pairs, across context and response, could be matched because of textual relevance or semantic dependency."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Conversation Context",
        "text": [
          "Speaker A: Hi I am looking to see what packages are installed on my system,",
          "I dont see a path, is the list being held somewhere else?",
          "Speaker B: Try dpkg - get-selections Matching with surface text",
          "Speaker A: What is that like? A database for packages instead of a flat file structure? Matching with dependency",
          "Speaker B: dpkg is the debian package manager - get-selections simply shows you what packages are handed by it",
          "Response of Speaker A: No clue what do you need it for, its just reassurance as I dont know the debian package manager",
          "Speaker B: T rdykp dg p+k `g`i t- ge t-selections",
          "Response of Speaker A: No clue what do you need it for, its just reassurance it + ``dpkg as I dont know the debian package manager"
        ],
        "page_nums": [
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "6": {
        "title": "Motivation",
        "text": [
          "Use GRU/LSTM to encode segments and match context with response only considering textual relevance.",
          "Self-Attention: Using intra-attention of utterance/response to gradually construct multi-grained semantic representations.",
          "Cross-Attention: Using attention across context and response to match with dependency information."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "Attentive Module",
        "text": [
          "Feed-Forward Qatt LayerNorm(Vatt +Q)",
          "Attention is All You Need. Vaswani et al., NIPS-2017",
          "Capture structures across Q and K-V",
          "Composite semantic representations of captured structures with input embedding"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1333-Figure3-1.png"
        ]
      },
      "8": {
        "title": "Experiment",
        "text": [
          "One-one multi-turn conversation Ubuntu Corpus V1 Douban Conversation",
          "Train Dev Test Train Dev Test",
          "One-one multi-turn conversation # candidates per context",
          "Open domain topics # positive candidates per context",
          "Min. # turns per context Task Max. # turns per context",
          "Given multi-turn context and serval Avg. # turns per context",
          "response candidates Avg. #words per utterance",
          "Select the best candidate based on",
          "Test stacking 3-7 self-attention layers",
          "Sequential Matching Network (SMN) (Wu et al., ACL-2017), Multi-view Matching (Zhou et",
          "LMNOP : without stacked self-attention",
          "QROP : only using the last layer of stacked self-attention",
          "OSQL : only using self-attention-match",
          "TNUOO : only using cross-attention-match"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": []
      },
      "9": {
        "title": "Evaluation Results",
        "text": [],
        "page_nums": [
          29
        ],
        "images": [
          "figure/image/1333-Table1-1.png"
        ]
      },
      "10": {
        "title": "Self Attention Match Visualization",
        "text": [
          "selfattentionmatch selfattentionmatch in in stack stack selfattentionmatch in stack 0 selfattentio selfattentionmatch selfattentionmatch match in in stack in stack stack selfattentionmatch selfattentionmatch selfattentionmatch in in stack stack in stack",
          "man manager manager ger man manager manager ger man manager manager ger package package package package package package package package package debain debain debain debain debain debain debain debain debain the the the the the the the the the know know know know know know know know know dont dont dont dont dont i i dont dont dont i i i i dont",
          "as as i as as as i as as as i reassurance reassurance reassurance",
          "as reassurance reassurance reassurance just just just just its its just for. for. response reassurance just just just its its its its its its just for. for. for. for. for. its it it it it for. it it it for. need need it need need need need need it you you you you you need do do you you you need do do do do you what what do what what do what what what do clue clue what no clue clue clue clue clue what no no no clue no no clue no",
          "somewhere somewhere else no no",
          "hi i hi hi am i i looking am am to looking looking see to to what see see packages what what are packages packages installed are are on installed installed my on on system my my i.1 system system dont i.1 i.1 see.1 dont dont a see.1 see.1 path a a is path path the is is list the the being list list held being held else else being somewhere held hi i hi am i hi looking am i to looking am see to",
          "looking what see to packages what see are packages what installed are packages on installed are my on",
          "installed system my on i.1 system my dont i.1 system see.1 dont i.1 a see.1 dont path a see.1 is path a the is path list the is list held being held else else being the list somewhere being somewhere held somewhere else hi i hi am i hi looking am to i looking see am to what looking see packages to what are packages see installed are what on installed packages my on are system my",
          "installed i.1 system on dont i.1 my see.1 dont system a see.1 i.1 path a dont is path see.1 the is a list the path being list is held being the held somewhere list else ls",
          "turn 0 turn 0 turn 0 turn 0 turn 0 turn 0",
          "selfattention selfattention Stack-0 of of response response in in stack stack turn 0 selfattention of turn 0 in stack 3 selfattention of turn 0 in stack 3 selfattention of response in stack 3 selfattention of turn 0 in stack 3 Stack-2 turn 0 attention of response over turn 0 in stack 4 attention of response over turn 0 in stack 4 Stack-4 turn 0",
          "manager manager somewhere somewhere else else else attention of response over turn 0 in stac manager manager package manager pack somewhere h held ld package pack manager ge debain package deb in being being held the list being list debain debain package debain the know know the the list the the debain the is the is know know the"
        ],
        "page_nums": [
          30
        ],
        "images": []
      },
      "11": {
        "title": "Cross Attention Match Visualization",
        "text": [
          "selfattentionmatch in stack 0 selfattentionmatch in stack 2 selfattentionmatch in stack 0 selfattentionmatch in stack 2 selfattentionmatch in stack 4 selfattentionmatch in stack 4 crossattentionmatch in stack 4 crossattentionmatch in stack 4",
          "manager manager manager manager manager manager manager manager package package package package package package package package debain debain debain debain debain the know dont i as debain debain the know dont i as debain the the the the the the know know know know know know dont dont dont dont dont dont i i i i i i",
          "reassurance just its as as as as",
          "just its as reassurance reassurance reassurance just just its its for. for. for. for. for. for. for. for. it it it it need need need need you you you you do do do do what what what what clue clue clue clue no no no no",
          "do it need you do what clue no it need you you do what what clue clue no no",
          "somewhere path else is the list being held somewhere else hi i am looking to see what hi packages i are am installed looking on to my see system what i.1 packages dont are see.1 installed a on path my is system the i.1 list dont being see.1 held a",
          "somewhere path else is the list being held else somewhere hi i am looking to see hi what i packages am are looking installed to on see my what system packages i.1 are dont installed see.1 on a my path system is i.1 the dont list see.1 being a held path is else the list being held else somewhere somewhere hi i am looking to see hi what i packages am are looking installed to on see my what system packages i.1 are dont installed see.1 on a my path system is i.1 the dont list see.1 being a held path somewhere is else the list being held somewhere else",
          "turn 0 turn 0 turn 0 turn 0 turn 0 turn 0 turn 0 turn 0",
          "selfattention selfattention of response of in response stack 3 in stack 3 selfattention selfatte of turn tion 0 in of stack turn 0 in stack 3 Self-Attention attention of att response nti of over response turn Match over in stack urn 0 in stack 4 attention of turn 0 over response in stack 4 Catrteontisons -f Aturnt 0t evner treisoponns eM in satactkc 4h",
          "manager manager else else somewhere somewhere manager manager else else"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "12": {
        "title": "Summary",
        "text": [
          "We propose a novel deep attention matching network for multi-turn",
          "response selection that entirely based on attention.",
          "We use stacked self-attention to construct multi-grained semantic",
          "We use cross-attention to match context with its candidate response",
          "considering both textual and dependency information"
        ],
        "page_nums": [
          32
        ],
        "images": []
      }
    },
    "paper_title": "Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network"
  },
  "1334": {
    "slides": {
      "0": {
        "title": "Novelty",
        "text": [
          "1. Identify and paraphrase metaphors in",
          "whole sentences from unrestricted",
          "2. Using word embedding input and output",
          "vectors to model a word and its context",
          "Translation. bi | ING",
          "3. Metaphor processing for Machine G."
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "1": {
        "title": "The definition of metaphor",
        "text": [
          "Linguistically, metaphor is defined as a language expression that uses one or several words to represent another concept, rather than taking their literal meanings of the given words in the context (Lagerwerf"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Metaphors are widespread in natural language",
        "text": [
          "One third of sentences in typical corpora contain metaphors."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Contexts help to find anomalies and identify metaphors",
        "text": [
          "She devoured his sandwiches.",
          "She devoured his novels.",
          "devoured means enjoyed avidly. Interpretation",
          "itently and enjoyed are different concepts identification"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Motivation",
        "text": [
          "Many previous metaphor processing methods are domain dependent",
          "Many works simply use input vectors",
          "Metaphor processing has rarely been applied to a real-world NLP task, instead mostly reporting accuracy on metaphor identification or interpretation."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "5": {
        "title": "Contribution",
        "text": [
          "1. Metaphor detection and interpretation in sentences from",
          "2. Investigate the effectiveness of input and output vectors of word embedding.",
          "3. Apply metaphor detection and G. Google",
          "interpretation to improve Machine Translate"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "1 Metaphor detection and interpretation in whole sentence from unrestricted domains",
        "text": [
          "She devoured his novels.",
          "Sentence level Phrase level",
          "This young man knows how",
          "to climb the social ladder. T ladder"
        ],
        "page_nums": [
          9,
          10
        ],
        "images": []
      },
      "7": {
        "title": "2 Investigate the effectiveness of input and output vectors of word embeddings",
        "text": [
          "Output vector Input vector of of enjoyed enjoyed"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "3 Apply metaphor detection and interpretation to improve Machine Translation",
        "text": [
          "Chinese English Spanish English -detected ~",
          "She devoured his novels.",
          "Sb eSMET thet) Vi.",
          "Chinese (Simplified) English Spanish - RT",
          "xoo< ile te de xidoshud.",
          "* | ennese Smpites ) English",
          "eo =n | ( ) Translator",
          "* SOEERR AT iE",
          "SRE BE She enjoyed his novels.",
          "4 o wrOoo< sin te de xi"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "One of novelties of our work is to model co occurrence between words with input and output vectors",
        "text": [
          "CBOW word2vec Input Hidden Output",
          "Context words c, O T Target words",
          "O ff Ban Output vector",
          "OB ME Abandoned ii",
          "Sona aaa (e.g., gensim word2vec",
          "Input vec Output vec"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "10": {
        "title": "The interaction between input and output vectors represents the co occurrence of words and contexts",
        "text": [
          "Input vec Output vec apple",
          "500 iterations on wevi https://ronxin.github.io/wevi/",
          "orange drink input vec"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "11": {
        "title": "Summary",
        "text": [
          "Input vectors can better model the similarity between words with similar semantics and syntax;",
          "Output vector can better model the co-occurrence between words with different Part-of-Speech"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "The co occurrence between a target word and its context is measured by",
        "text": [
          "SCOTEcooccur = cos( vp, Veontext )",
          "Veontext mL , Yen"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Hypotheses",
        "text": [
          "H11. Literal sense is more common that metaphorical.",
          "One third of sentences in typical corpora contain metaphors.",
          "H2. A metaphorical word can be identified, if the sense the Identify a word takes within its context and its literal sense come from metaphor"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Framework",
        "text": [
          "cos( w;, context) cos( s;, context) argmax COS( Sz, context)! 5 w* ew",
          "cos(h;, context) | Best fit word",
          "literal, if S > threshold 4 . S = cos(w*, w;) metaphoric, otherwise"
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1334-Figure2-1.png"
        ]
      },
      "15": {
        "title": "Step 1 training word embedding models on Wikipedia so that we can model the common expressions",
        "text": [
          "W, Ox ZO W,",
          "Train W2 O PS > LZ 0 Wa",
          "Word Embedding XK OK",
          "Wikipedias language could be more literal.",
          "We model the literal so that we can identify the anomalies in metaphor in next steps. (H1)"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "16": {
        "title": "Step 2 look up WordNet to list all possible senses of a target word",
        "text": [
          "Candidate word set W",
          "Separate context words and a target word.",
          "Acandidate word set consists of hypernyms and synonyms of the target word, which represents all possible senses of the target word."
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "17": {
        "title": "Step 3 identify the most likely sense from the candidate set",
        "text": [
          "Candidate word set W",
          "argmax cos(s,,context) | w*EWw",
          "cos( h;, context ) Best fit word",
          "* Compute the most likely word appearing in the context.",
          "The best fit word is interpreted as the sense that metaphor"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "18": {
        "title": "Step 4 identify the metaphoricity of a target word",
        "text": [
          "literal, if S > threshold metaphoric, otherwise",
          "A metaphor could be identified as the real sense and its literal sense come from different domains. (H2)"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "19": {
        "title": "An example in Step 2",
        "text": [
          "She devoured his novels.",
          "Context words: {She, his, novels}",
          "{devour, devoured, devours, devouring}"
        ],
        "page_nums": [
          27
        ],
        "images": []
      },
      "20": {
        "title": "An example in Step 3",
        "text": [
          "Veontext = m Ven 3 (Vsne + Vhis + Vnovels)",
          "cos(Vgestroyed Veontext ) = 0.04",
          "arg max O i _",
          "Best fit word = enjoyed"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "21": {
        "title": "An example in Step 4",
        "text": [
          ": literal, if S > threshold",
          "S= COS(Ven joy Vaevour) . .",
          "Best fit word Target word"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "22": {
        "title": "Different setups in Step 3",
        "text": [],
        "page_nums": [
          30
        ],
        "images": []
      },
      "23": {
        "title": "Examine on Machine Translation before paraphrasing",
        "text": [
          "Translate Tum off instant translation @",
          "Chinese English Spanish English - detected ~ 4 Chinese (Simplified) English Spanish ~ Ea",
          "She devoured his novels. * thaSIti-7-AhAO/) i. * She (physically) swallowed his novels.",
          "TA tinshile ta de xidoshud.",
          "HE Microsoft b 2",
          "She voraciously wrote novels.",
          "1 ling ton ha yan 0 8 xo stud,",
          "She devoured his novels. HORA Alte S 1) ik. : )"
        ],
        "page_nums": [
          31
        ],
        "images": []
      },
      "24": {
        "title": "Examine on Machine Translation after paraphrasing",
        "text": [
          "Translate Tum off instant translation |",
          "cm i ha - (C ae",
          "She enjoyed his novels. <p EEPR HAO) iE. ) * She enjoyed his novels.",
          "Ta thud t de aidoshus",
          "Wx hun t Ge xido shud,",
          "She enjoyed his novels. - PhS RAJ ii , )"
        ],
        "page_nums": [
          32
        ],
        "images": []
      },
      "25": {
        "title": "Experiment setup",
        "text": [
          "Metaphor identification: e Sentence level: inputs are original sentences e Phrase level: inputs are parsed phrases"
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "26": {
        "title": "Dataset and baselines",
        "text": [
          "Shutova et al. (2016) used Skip-gram input vectors to model the similarity between two component",
          "* Rei et al. (2017) used sigmoid function, projecting",
          "Skip-gram input vectors into another space, then",
          "Sentence Phrase training a deep neural network based classifier."
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "27": {
        "title": "Metaphor identification results",
        "text": [
          "Method P R Fl"
        ],
        "page_nums": [
          36
        ],
        "images": [
          "figure/image/1334-Table1-1.png"
        ]
      },
      "28": {
        "title": "Evaluation with different thresholds",
        "text": [
          "P R Fl Fl gim-csow, o Filsim-se, O",
          "Table 2: Model performance vs. different threshold (7) settings. | NB: the sentence level results are based on"
        ],
        "page_nums": [
          37
        ],
        "images": [
          "figure/image/1334-Table2-1.png"
        ]
      },
      "29": {
        "title": "Experiment design for Machine Translation evaluation",
        "text": [
          "The ex-boxer's job is to bounce people who want to enter this private club. bounce: eject from the premises Good / Bad",
          "BB ARENT EE BRA EAN HEA EL ERB APB EFAS TEE LAR BEE A EL ER BA SB AB RAST ea HEA BEA AL ER PB A AS eGR eT BI AE A ER A BPR RNS TET A fea EEA XL ERB. BB EASE eT aa BE AEE A LER A,",
          "Google translation on the original sentence.",
          "Bing Translation on the original sentence.",
          "Google translation on our model paraphrased sentence.",
          "Google translation on Context2Vec paraphrased sentence. Bing Translation on Context2Vec paraphrased sentence."
        ],
        "page_nums": [
          38
        ],
        "images": [
          "figure/image/1334-Figure6-1.png"
        ]
      },
      "30": {
        "title": "Metaphor interpretation results",
        "text": [
          "L) Paraphrased by our model",
          "A Paraphrased by the baseline (Melamud et al. 2016)",
          "Literal Metaphoric Overall Literal Metaphoric Overall"
        ],
        "page_nums": [
          39
        ],
        "images": [
          "figure/image/1334-Figure5-1.png"
        ]
      },
      "31": {
        "title": "Takeaway",
        "text": [
          "A novel model for metaphor identification and interpretation on sentence level.",
          "A metaphor could be identified by its interpretation.",
          "Input and output vectors could better model the",
          "co-occurrence between two words.",
          "Effective paraphrasing of metaphors could improve"
        ],
        "page_nums": [
          41
        ],
        "images": []
      }
    },
    "paper_title": "Word Embedding and WordNet Based Metaphor Identification and Interpretation"
  },
  "1336": {
    "slides": {
      "0": {
        "title": "Towards natural language understanding",
        "text": [
          "11. Reasoning about Time"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Time is important",
        "text": [
          "[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh. As a boy, Chris lived in",
          "Cotchfield Farm. When he was three, his father wrote a poem about him. His father later wrote Winnie the Pooh in 1925.",
          "Where did Chris Robin live?",
          "This is time sensitive.",
          "When was Chris Robin born? poem [Chris at age 3]",
          "Requires identifying relations between events, and temporal reasoning.",
          "Temporal relation extraction Time could be expressed implicitly",
          "A happens BEFORE/AFTER B;",
          "Events are associated with time intervals:",
          "12 temporal relations in every 100 tokens (in TempEval3 datasets)"
        ],
        "page_nums": [
          2,
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Temporal relations a key component",
        "text": [
          "Temporal Relation (TempRel): I turned off the lights and left.",
          "Challenges faced by existing datasets/annotation schemes:",
          "Low inter-annotator agreement (IAA)",
          "Time consuming: Typically, 2-3 hours for a single document.",
          "Our goal is to address these challenges,",
          "And, understand the task of temporal relations better."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Highlights and outline",
        "text": [
          "276 docs: Annotated the 276 documents from TempEval3",
          "1 week: Finished in about one week (using crowdsourcing)",
          "IAA improved from literatures 60% to 80%",
          "Re-thinking identifying temporal relations between events",
          "Results in re-defining the temporal relations task, and the corresponding annotation scheme, in order to make it feasible",
          "Outline of our approach (3 components)",
          "Multi-axis: types of events and their temporal structure",
          "Start & End points: end-points are a source of confusion/ambiguity",
          "Crowdsourcing: collect data more easily while maintaining a good quality"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "1 temporal structure modeling existing annotation schemes",
        "text": [
          "Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.",
          "Task: to annotate the TempRels between the bold faced events",
          "(according to their start-points).",
          "Existing Scheme 1: General graph modeling (e.g., TimeBank, ~2007)",
          "Annotators freely add TempRels between those events.",
          "Its inevitable that some TempRels will be missed,",
          "Pointed out in many works.",
          "E.g., only one relation between eliminate and restore is annotated in",
          "TimeBank, while other relations such as tried is before eliminate and",
          "tried is also before killed are missed.",
          "Existing Scheme 2: Chain modeling (e.g., TimeBank-Dense ~2014)",
          "All event pairs are presented, one-by-one, and an annotator must",
          "provide a label for each of them.",
          "No missing relations anymore.",
          "Rationale: In the physical world, time is one dimensional, so we should",
          "be able to temporally compare any two events.",
          "However, some pairs of events are very confusing, resulting in low",
          "E.g., whats the relation between restore and killed?"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "5": {
        "title": "1 temporal structure modeling difficulty",
        "text": [
          "Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.",
          "Why is restore vs killed confusing?",
          "One possible explanation: the text doesnt provide evidence that the",
          "restore event actually happened, while killed actually happened",
          "So, non-actual events dont have temporal relations?",
          "We dont think so:",
          "tried is obviously before restore: actual vs non-actual eliminate is obviously before restore: non-actual vs non-actual",
          "So relations may exist between non-actual events."
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "6": {
        "title": "1 temporal structure modeling multi axis",
        "text": [
          "Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.",
          "We suggest that while time is 1-dimensional in the physical world, multiple temporal axes may exist in natural language.",
          "police tried 51 people killed"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "7": {
        "title": "1 multi axis modeling not simply actual vs non actual",
        "text": [
          "Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.",
          "Is it a non-actual event axis?-We think no.",
          "First, tried, an actual event, is on both axes.",
          "Second, whether restore is non-actual is questionable. Its very likely that order was indeed restored in the end.",
          "Real world axis police tried 51 people killed"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "1 multi axis modeling",
        "text": [
          "Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.",
          "Instead, we argue that its an Intention Axis",
          "It contains events that are intentions: restore and eliminate",
          "and intersects with the real world axis at the event that invokes these intentions: tried",
          "Real world axis police tried 51 people killed",
          "So far, we introduced the intention axis and distinguished it from",
          "The paper extends these ideas to more axes and discusses their difference form (non-)actuality axes",
          "Event Type Time Axis",
          "intention, opinion orthogonal axis",
          "hypothesis, generic parallel axis",
          "Negation not on any axis",
          "static, recurrent not considered now",
          "all others main axis"
        ],
        "page_nums": [
          12,
          14
        ],
        "images": []
      },
      "9": {
        "title": "Intention vs actuality",
        "text": [
          "Identifying intention can be done locally, while identifying actuality often depends on other events.",
          "I called the police to report the body. Yes Yes",
          "I called the police to report the body, but the line was busy.",
          "Police came to restore order. Yes Yes",
          "Police came to restore order, but 51 people were killed."
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "1 multi axis modeling a balance between two schemes",
        "text": [
          "Our proposal: Multi-axis modeling balances the extreme schemes.",
          "Allows dense modeling, but only within an axis.",
          "Scheme 1: General graph modeling",
          "A strong restriction on modeling",
          "Relations are inevitably missed",
          "Scheme 2: Chain modeling",
          "Any pair is comparable",
          "But many are confusing"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "11": {
        "title": "Overview multi axis annotation scheme",
        "text": [
          "Step 0: Given a document in raw text",
          "Step 1: Annotate all the events",
          "Step 2: Assign axis to each event (intention, hypothesis, )",
          "Step 3: On each axis, perform a dense annotation scheme according to events start-points",
          "In this paper, we use events provided by TempEval3, so we skipped Step 1.",
          "Our second contribution is successfully using crowdsourcing for",
          "Step 2 and Step 3, while maintaining a good quality."
        ],
        "page_nums": [
          16,
          19
        ],
        "images": []
      },
      "12": {
        "title": "2 crowdsourcing",
        "text": [
          "Annotation guidelines: Find at http://cogcomp.org/page/publication_view/834",
          "Quality control: A gold set is annotated by experts beforehand.",
          "Qualification: Before working on this task, one has to pass with 70% accuracy on sample gold questions.",
          "Important: with the older task definition, annotators did not pass the qualification test.",
          "Survival: During annotation, gold questions will be given to annotators without notice, and one has to maintain 70% accuracy; otherwise, one will be kicked out and all his/her annotations will be discarded.",
          "Majority vote: At least 5 different annotators are required for every judgement and by default, the majority vote will be the final decision."
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "3 an interesting observation ambiguity in end points",
        "text": [
          "Given two time intervals:",
          "Metric Pilot Task 1 Pilot Task 2 Interpretation",
          "Comparing the end-points is",
          "significantly harder than comparing",
          "Avg. response time 33 sec 52 sec Task 2 is also significantly slower.",
          "How durative events are expressed (by authors) and perceived (by readers):",
          "Readers usually take longer to perceive durative events than punctual",
          "events, e.g., restore order vs. try to restore order.",
          "Writers usually assume that readers have a prior knowledge of durations",
          "(e.g., college takes 4 years and watching an NBA game takes a few hours)",
          "We only annotate start-points because duration annotation",
          "should be a different task and follow special guidelines."
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Quality metrics of our new dataset",
        "text": [
          "Step 2: Axis Step 3: TempRel",
          "Expert (~400 random relations)",
          "Remember: Literature expert values are around 60%",
          "For interested readers, please refer to our paper for more analysis regarding each individual label.",
          "Worker Agreement With Aggregate (WAWA): assumes that the",
          "aggregated annotations are gold and then compute the accuracy."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "15": {
        "title": "Result on our new dataset",
        "text": [
          "We implemented a baseline system, using conventional features and the sparse averaged perceptron algorithm",
          "The overall performance on the proposed dataset is much better than those in the literature for TempRel extraction, which used",
          "We do NOT mean that the proposed baseline is better than other existing algorithms",
          "Rather, the proposed annotation scheme better defines the machine learning task.",
          "Training Test Annotation Training Set Test Set P R F P R F",
          "TBDense Same-axis & Cross-axis Same-axis"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "We proposed to re-think the important tasks of identifying",
          "temporal relations, resulting in a new annotation scheme it.",
          "Multi-axis modeling: a balance between general graphs and chains",
          "Identified that end-point is a major source of confusion",
          "Showed that the new scheme is well-defined even for non-experts and crowdsourcing can be used.",
          "The proposed scheme significantly improves the inter-annotator",
          "The resulting dataset defines an easier machine learning task.",
          "We hope that this work can be a good start for further investigation in this important area."
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "A Multi-Axis Annotation Scheme for Event Temporal Relations"
  },
  "1337": {
    "slides": {
      "0": {
        "title": "Utility to site moderators and administrators",
        "text": [
          "Controversy (as we have defined it) is not necessarily a bad thing.",
          "Monitoring for bad controversy can prevent harm to the group",
          "Bringing productive controversy to the communitys attention can help the group solve problems"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Observation controversy is community specific",
        "text": [
          "break up: controversial in the Reddit group on relationships, but not in the group for posing questions to women",
          "my parents: controversial for personal-finance group",
          "(example: live with my parents) but not in the relationships group"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Observation we can also use early reactions",
        "text": [
          "Early opinions can greatly affect subsequent opinion dynamics",
          "(Salganik et al. MusicLab experiment, Science 2006, inter alia)",
          "Both the content and structure of the early discussion tree may prove helpful."
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "3": {
        "title": "Our datasets derived from Baumgartner",
        "text": [
          "6 communities on www.reddit.com: two QA subreddits: AskMen, AskWomen a special interest community: Fitness three advice communities:",
          "Posts and comments mostly web-English",
          "Up/downvote information: eventual percent-upvoted",
          "(we cant use early votes: no timestamps)"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "4": {
        "title": "Data selection",
        "text": [
          "All posts with %- upvoted Filtered Posts no edits, stable %-upvoted",
          "Label validation steps (details in paper): 1) high-precision overlap (>88 F-measure) with reddits low-recall rank-by-controversy 2) we ensure popularity prediction != controversy prediction"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "Labeled Dataset Statistics",
        "text": [
          "Balanced, binary classification with controversial/non-controversial labeling"
        ],
        "page_nums": [
          12
        ],
        "images": [
          "figure/image/1337-Table1-1.png"
        ]
      },
      "6": {
        "title": "Some posting time text only results",
        "text": [
          "(this, plus timestamp, is our baseline)",
          "o Rather than passing BERT vectors to a bi-LSTM, it",
          "works about as well and faster to mean-pool, dimension-reduce, and feed to a linear classifier",
          "o Our hand-crafted features + word2vec match BERT- based algorithms on 3 of 6 subreddits"
        ],
        "page_nums": [
          13,
          14
        ],
        "images": [
          "figure/image/1337-Table2-1.png"
        ]
      },
      "7": {
        "title": "Early comments how many",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "8": {
        "title": "Does the shape of the tree predict controversy",
        "text": [
          "Usually yes, even after controlling for the rate of incoming comments.",
          "max depth/total comment ratio proportion of comments that were top-level (i.e., made in direct reply to the original post) average node depth average branching factor proportion of top-level comments replied to Gini coefficient of replies to top-level comments (to measure how clustered the total discussion is) Wiener Index of virality (average pairwise pathlength between all pairs of nodes)",
          "total number of comments logged time between OP and the first reply average logged parent-child reply time (over all pairs of comments)",
          "[binary logistic regression, LL-Ratio test p<.05 in 5/6 communities]"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "9": {
        "title": "Prediction results incorporating comment features",
        "text": [
          "4 comments, on average"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "10": {
        "title": "Tree Rate features transfer better than content",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      },
      "11": {
        "title": "Takeaways modulo caveats see paper",
        "text": [
          "We advocate an early-detection, community-specific approach to controversial-post prediction",
          "We can use features of the content and structure of the early discussion tree",
          "Early detection outperforms posting-time-only features in 5 of 6",
          "Reddit communities tested, even for quite small early-time windows",
          "Early content is most effective, but tree-shape and rate features transfer across domains better"
        ],
        "page_nums": [
          21
        ],
        "images": []
      }
    },
    "paper_title": "Something's Brewing! Early Prediction of Controversy-causing Posts from Discussion Features"
  },
  "1342": {
    "slides": {
      "0": {
        "title": "Sentence extraction",
        "text": [
          "document modeling is essential to many NLP tasks",
          "apparent in problems where capturing long range",
          "from documents, with an end goal in mind",
          "Extractive Summarization and Question Answer Selection",
          "Seoul (CNN) -- South Korea's Prime Minister Lee Wan-koo offered to resign on Monday amid a growing political scandal.",
          "Lee will stay in his official role until South Korean President",
          "Park Geun-hye accepts his resignation.",
          "Park heard about the resignation ...",
          "Calls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging from a tree in Seoul.",
          "Woan-jong was found hanging ... both tasks require",
          "Sung, who was under investigation for fraud and bribery left a note listing names and amounts of cash given to top officials, including those who work for the President. deep understanding of",
          "the document Lee and seven other politicians ...",
          "Question: Who resigned over the scandal?",
          "Answer: South Korea's Prime",
          "Minister Lee Wan Koo",
          "local and global contextual reasoning"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
        ],
        "images": []
      },
      "1": {
        "title": "Documents are more than plain text chunks",
        "text": [
          "Seoul (CNN) South Korea's Prime Minister",
          "images Lee Wan-koo offered to resign on Monday",
          "amid a growing political scandal. image captions Lee will stay in his official role until South",
          "Lee will stay in his official role until South",
          "Korean President Park Geun-hye accepts his",
          "resignation. He has transferred his ...",
          "They can also contain over bribery scandal investigation",
          "South Korean PM Suicide note leads to",
          "offers resignation government bribery",
          "which can contain key events"
        ],
        "page_nums": [
          16,
          17,
          18,
          19,
          20
        ],
        "images": []
      },
      "2": {
        "title": "Main ideas of this work",
        "text": [
          "external information can be useful to sentence selection",
          "document modeling with richer content: read whole document before starting to extract sentences",
          "do not rely on similarity metrics to extract sentences",
          "neural architecture for sentence extraction (XNet)"
        ],
        "page_nums": [
          21,
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "3": {
        "title": "XNet Document Encoder",
        "text": [
          "Convolutional Sentence encoder Document encoder",
          "sentences are encoded by a convolutional encoder (Kim, 2014)",
          "get a document embedding before extraction begins"
        ],
        "page_nums": [
          26,
          27,
          28
        ],
        "images": []
      },
      "4": {
        "title": "XNet Sentence Extractor",
        "text": [
          "1 e2 3 External",
          "takes document embedding as input",
          "instead of attending to text, attends over external information",
          "softmax over the output produces binary labels"
        ],
        "page_nums": [
          29,
          30,
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "5": {
        "title": "XNet for Extractive Summarization",
        "text": [
          "e attention over external information",
          "e sentences encoded with the convolutional sentence encoder",
          "e sentences encoded with / \\",
          "t C1 c2 External attention",
          "= title T 7 Ti"
        ],
        "page_nums": [
          35,
          36,
          37,
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "6": {
        "title": "Extractive Summarization Experiments",
        "text": [
          "CNN part of CNN/DailyMail dataset",
          "extract titles (each article has a title) and image captions (avg 3 captions per article; 40% articles have at least one)",
          "oracle summaries: select sentences that give collectively high ROUGE score wrt the gold summary (Nallapati et al., 2017)",
          "summary: 3 top-scoring sentences according to the extractor"
        ],
        "page_nums": [
          42,
          43,
          44,
          45
        ],
        "images": []
      },
      "7": {
        "title": "External info helps extractive summarization",
        "text": [
          "Ablation results on validation set (ROUGE recall scores)",
          "PointerNet is Cheng and Lapata (2016)",
          "ROUGE 1 ROUGE 2",
          "Pointer Pointer Net Net"
        ],
        "page_nums": [
          46,
          47,
          48,
          49
        ],
        "images": []
      },
      "8": {
        "title": "Results",
        "text": [
          "model ROUGE 1 ROUGE 2 ROUGE L",
          "(XNet is XNet+title+caption, PointerNet is Cheng and Lapata (2016))",
          "consistent behavior on SQuAD, WikiQA and MSMarco",
          "consistent behavior on all metrics",
          "Wrd Cnt: word count",
          "Wgt Wrd Cnt: weighted word count",
          "PairCNN: encode (question, candidate sent) isolated"
        ],
        "page_nums": [
          50,
          51,
          52,
          53,
          70,
          71,
          72,
          73
        ],
        "images": []
      },
      "9": {
        "title": "Human evaluation confirms the quality of generated summaries",
        "text": [
          "model 1st 2nd 3rd 4th",
          "annotators ranked systems from best (1st) to worst (4th)"
        ],
        "page_nums": [
          54,
          55,
          56
        ],
        "images": []
      },
      "10": {
        "title": "XNet for QA Selection",
        "text": [
          "qa ISF IDF External attention",
          "inverse document frequency (IDF)",
          "inverse sentence frequency (ISF; Trischler",
          "local ISF (ISF with considering no of sents in article)"
        ],
        "page_nums": [
          57,
          58,
          59,
          60,
          61,
          62,
          63
        ],
        "images": []
      },
      "11": {
        "title": "QA Selection Experiments",
        "text": [
          "leave out unanswered questions",
          "report scores for accuracy, Mean Average Precision",
          "(MAP) and Mean Reciprocal Rank (MRR)"
        ],
        "page_nums": [
          64,
          65,
          66,
          67,
          68
        ],
        "images": []
      },
      "12": {
        "title": "XNet variants",
        "text": [
          "model SQuAD WikiQA NewsQA MSMarco",
          "reporting accuracy, similar patters for MRR and MAP",
          "XNet: only considering q",
          "XNet+: considers q, IDF, ISF, LocalISF",
          "XNetTopk: choose top k sentences based on ISF and then XNet",
          "LRXNet: ensemble <XNet, CompAggr (Wang et al., 2017), classifier considering word overlap scores>"
        ],
        "page_nums": [
          69
        ],
        "images": []
      },
      "13": {
        "title": "Summary",
        "text": [
          "a robust neural model for sentence extraction that",
          "reads whole document before extraction",
          "attends to external information",
          "attending to external information ( title and caption) helps creating better extractive summaries",
          "attending to question and word overlap metrics helps with question answer selection",
          "considering external information helps"
        ],
        "page_nums": [
          74,
          75,
          76,
          77,
          78
        ],
        "images": []
      }
    },
    "paper_title": "Document Modeling with External Attention for Sentence Extraction"
  },
  "1343": {
    "slides": {
      "0": {
        "title": "Amr",
        "text": [
          "After its competitor invented the",
          "front loading washing machine,",
          "capable-41 person countermeasure invent-01 the CEO of the American IM",
          "ARG2 A RG0-of p urpose mod ARG1 ARG0",
          "ARG1 innovate-01 have-org-role-91 innovate-01 strategy machine company believed that each of",
          "ARG0 ARG2 p rep-in ARG1-of ARG0-of company its employees had the ability for",
          "person CEO industry load-01 wash-01 ARG0-of",
          "ARG1-of mod A RG1 mod compete-01 innovation, and formulated",
          "employ-01 each front ARG1 ARG0 strategic countermeasures for",
          "company innovation in the industry.",
          "name mod name country op1 name IM name op1 op2 United States"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Transition based AMR parsing",
        "text": [
          "There has been previous work (Sagae and Tsujii;",
          "Damonte et al.; Zhou et al.; Ribeyre et al.; Wang et al.) on transition-based graph parsing.",
          "Our work introduces a new data structure cache for generating graphs of certain treewidth."
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "2": {
        "title": "Introduction to treewidth",
        "text": [
          "Gildea, Satta, and Peng",
          "ALB LBR BRD RDM DMF MF",
          "w I A B D F G J",
          "K L R M O E KAL DMP",
          "j s H IKA MPH",
          "Q m N HCS CSQ SQ",
          "Figure 4 Graph for the semantic representation of the sentence John wants Mary to succeed. (a) Vertex w A tree: treewidth 1 treewidth 2 Complete graph of N",
          "nodes: treewidth (b) N-1 represents word token wants, vertex j represents John, vertex s represents succeed, and vertex m represents Mary. Figure 2 (a) An optimal tree decomposition of graph G in Figure 1; this is a set of overlapping cl Gs vertices, arranged in a tree. (b) The high-level treelike structure of G becomes appa",
          "capable-41 person countermeasure invent-01",
          "ARG2 ARG0-of purpose mod ARG1 ARG0 ARG1 innovate-01 have-org-role-91 innovate-01 strategy machine",
          "ARG0 ARG2 p rep-in ARG1-of ARG0-of company",
          "person CEO industry load-01 wash-01 ARG0-of ARG1-of mod A RG1 m od compete-01 employ-01 each front ARG1 ARG0 company name mod name country op1 name IM name op1 op2 United States",
          "small tree width large tree width"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "3": {
        "title": "Tree decomposition",
        "text": [
          "Gildea, Satta, and Peng Gildea, Satta, and Peng",
          "I D J ALB LBR BRD RDM DMF MFO FOG A B F G",
          "I A B D F G J",
          "K L R M O E P KAL DMP OGE",
          "P H IKA MPH GEJ",
          "N HCS CSQ SQN (a) (b)"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "4": {
        "title": "Cache transition system",
        "text": [
          "Stack $: place for temporarily storing concepts",
          "Cache *: working zone for making edges, fixed size corresponding to the treewidth.",
          "Buffer ': unprocessed concepts",
          "E: set of already-built edges",
          "SHIFT PUSH(i): shift one concept from buffer to right- most position of cache, then select one concept (index i) from cache to stack.",
          "SHIFT PUSH(1) stack cache buffer",
          "POP: pop the top from stack and put back to cache, then drop the right-most item from cache.",
          "Arc(i, l, d): make an arc (with direction d, label l) between the right-most node to node i. Arc(i,-,-) represents no edge between them."
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "5": {
        "title": "Example of cache transition",
        "text": [
          "(2, UNIVERSITYf ROCHESTER NO",
          "Action taken: SHIFT, PUSH(1)",
          "ee Cette | Necceeeee bene e eas",
          "stack cache x ARGI>S. buffer",
          "/ ARGO a / ARG1 ~*s. ie: / a7 TT TSK sy Hypothesis: IN a RY",
          "Action taken: POP POP POP"
        ],
        "page_nums": [
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "6": {
        "title": "Sequence to sequence models for cache transition system",
        "text": [
          "Concepts are generated from input sentences by another classifier in the preprocessing step.",
          "Separate encoders are adopted for input sentences and sequences of concepts, respectively.",
          "One decoder for generating transition actions."
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "7": {
        "title": "Seq2seq soft attentionfeatures",
        "text": [
          "want-O1 go-01 Input sequence Concept sequence"
        ],
        "page_nums": [
          20
        ],
        "images": [
          "figure/image/1343-Figure3-1.png",
          "figure/image/1343-Figure4-1.png"
        ]
      },
      "8": {
        "title": "Seq2seq hard attentionfeatures",
        "text": [
          "NOARC ARC L-ARGO SHIFT Pushindex(1)",
          "Per want-0O. go-01 Input sequence Concept sequence"
        ],
        "page_nums": [
          21
        ],
        "images": [
          "figure/image/1343-Figure3-1.png",
          "figure/image/1343-Figure4-1.png"
        ]
      },
      "9": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "10": {
        "title": "AMR Coverage with different cache sizes",
        "text": [
          "An example AMR graph for the sentence: John wants Mary to like him."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "11": {
        "title": "Development results",
        "text": [
          "Model P R F cache size P R F",
          "Impact of various components Impact of cache size"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "12": {
        "title": "Main results",
        "text": [
          "Model P R F"
        ],
        "page_nums": [
          25
        ],
        "images": []
      },
      "13": {
        "title": "Accuracy on reentrancies",
        "text": [
          "Model P R F"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "14": {
        "title": "Reentrancy example",
        "text": [
          "Sentence: I have no desire to live in any city .",
          "ARG0 location polarity JAMR output: ARG1 mod",
          "i desire-01 live-01 any city",
          "location Peng et al. (2018) output: polarity ARG1 mod",
          "Our hard attention output: ARG0 location ARG0 polarity ARG1 mod"
        ],
        "page_nums": [
          27
        ],
        "images": [
          "figure/image/1343-Figure5-1.png"
        ]
      },
      "15": {
        "title": "Conclusion",
        "text": [
          "Cache transition system based on a mathematical sound formalism for parsing to graphs.",
          "The cache transition process can be well-modeled by sequence-to-sequence models.",
          "Features from transition states."
        ],
        "page_nums": [
          28
        ],
        "images": []
      }
    },
    "paper_title": "Sequence-to-sequence Models for Cache Transition Systems"
  },
  "1344": {
    "slides": {
      "0": {
        "title": "Task Knowledge Base Completion",
        "text": [
          "Knowledge Bases (KBs) store a large amount of facts in",
          "the form of <head entity, relation, tail entity> triples:",
          "The Knowledge Base Completion (KBC) task aims to",
          "predict missing parts of an incomplete triple:",
          "Help discover missing facts in a KB"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Vector Based Approach",
        "text": [
          "A common approach to KBC is to model triples with a",
          "low dimension vector space, where",
          "Entity: represented by a",
          "that similar entities are",
          "close to each other)",
          "transformation of the vector",
          "space, which can be:",
          "Up to design choice"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Popular Types of Representations for Relation",
        "text": [
          "Relation as vector translation Relation as linear",
          "Intuitively suitable for 1-to-1",
          "relation Flexibly modeling N-to-N",
          "currency AUD relation of_country Australia country_of_film USD",
          "Australia US The Matrix US Finding Nemo",
          "same number of entities",
          "same distances within We follow July 18, 2018"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Matrices are Difficult to Train",
        "text": [
          "More parameters compared to entity vector",
          "Objective is highly non-convex"
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "In this work",
        "text": [
          "Propose jointly training relation matrices with an",
          "In order to reduce the high dimensionality",
          "Modified SGD with separated learning rates:",
          "In order to handle the highly non-convex",
          "Use modified SGD to enhance joint training with",
          "Other techniques for training relation matrices",
          "Achieve SOTA on standard KBC datasets"
        ],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Training techniques",
        "text": [],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Joint Training with an Autoencoder",
        "text": [
          "Represent relations as matrices in",
          "a bilinear model, can be",
          "Train an autoencoder to",
          "reconstruct relation matrix from",
          "training [Nickel+11, Guu+15, Tian+16] original reconstructed",
          "autoencoders in which the",
          "original input is not updated",
          "Reduce the high dimensionality of relation matrices",
          "Help learn composition of relations",
          "Not easy to carry out",
          "Training objective is highly non-convex",
          "Easily fall into local minimums"
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "7": {
        "title": "Modified SGD Separated Learning Rates",
        "text": [
          "Different learning rates for different parts of our model",
          "The common practice for setting",
          "learning rates of SGD [Bottou, 2012]:",
          "Different parts in a neural network",
          "may have different learning rates",
          ": initial learning rate",
          ": coefficient of L2-regularizer",
          ": counter of trained examples",
          "KB: for KB-learning objective",
          "AE: for autoencoder objective Learning rates for frequent entities and relations can decay more quickly : counter of each entity",
          ": counter of each entity",
          ": counter of each relation July 18, 2018",
          "NN usually can be decomposed",
          "into several parts, each one is",
          "convex when other parts are fixed",
          "NN joint co-training of many",
          "Natural to assume different",
          "learning rate for each part"
        ],
        "page_nums": [
          9,
          10,
          11
        ],
        "images": []
      },
      "8": {
        "title": "Learning Rates for Joint Training Autoencoder",
        "text": [
          "objective trying to fit to",
          "AE is initialized randomly",
          "Does not make much sense",
          "to fit matrices to AE",
          "As the training proceeds",
          "KB and AE should"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Other Training Techniques",
        "text": [
          "instead of pure Gaussian"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "11": {
        "title": "Datasets for Knowledge Base Completion",
        "text": [
          "Dataset #Entity #Relation #Train #Valid #Test",
          "WN18RR: subset of WordNet [Miller 95]",
          "The previous WN18 and FB15k have an information",
          "leakage issue (refer our paper for test results)",
          "Evaluate models by how high the model ranks the gold"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Base Model vs Joint Training with Autoencoder",
        "text": [
          "MR MRR H10 MR MRR H10",
          "BASE: The bilinear model",
          "Jointly train relation matrices",
          "MRR (Mean Reciprocal Rank):",
          "Joint training with an autoencoder",
          "improves upon the base bilinear model"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "13": {
        "title": "Compared to Previous Research",
        "text": [
          "MR MRR H10 MR MRR H10",
          "Base model is competitive enough",
          "Our models achieved state-of-the-art results"
        ],
        "page_nums": [
          17,
          18
        ],
        "images": []
      },
      "14": {
        "title": "What Does the Trained Autoencoder Look Like",
        "text": [
          "Sparse coding of relation matrices",
          "Interpretable to some extent"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1344-Figure2-1.png"
        ]
      },
      "15": {
        "title": "Composition of Relations",
        "text": [
          "Composition of two relations in a KB coincide",
          "with a third relation:",
          "Extracted 154 examples of compositional"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "16": {
        "title": "Joint Training Helps Find Compositional Relations",
        "text": [
          "If there is a composition Learned relation matrices to indeed",
          "comply with the composition",
          "Joint training with an autoencoder helps"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "17": {
        "title": "Conclusion and Discussion",
        "text": [
          "Task Knowledge Base Completion",
          "Approach Entities as low dimension vectors, relations as matrices",
          "Techniques Joint training relation matrices with autoencoder to reduce",
          "Modified SGD: different learning rates for different parts",
          "Separated learning rates for updating relation matrices",
          "Normalization, Regularization, Initialization of relation matrices",
          "Analysis Autoencoder learns sparse and interpretable low dimensional coding of",
          "Dimension reduction helps find compositional relations",
          "Discussion Modern NNs have a lot of parameters",
          "Joint training with an autoencoder may reduce dimensionality while the NN is functioning"
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder"
  },
  "1345": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Trending of Social Media",
        "text": [
          "Facebook YouTube Instagram Twitter Snapchat Reddit Pinterest Tumblr Linkedin",
          "Number of active users (millions)",
          "ON a ts 200 croc"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Name Tagging",
        "text": [
          "[ORG France] defeated [ORG Croatia] in [MISC",
          "World Cup] final at [LOC Luzhniki Stadium].",
          "Provide inputs to downstream applications"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Challenges of Name Tagging in Social Media",
        "text": [
          "Real Madrid midfielder Toni Kroos has revealed why he snubbed Cristiano Ronaldo's birthday party, following their humiliating derby defeat to Atletico Madrid. W. W",
          "Read: Khedira Doesn't Regret Attending CR7's Party Ronaldo received a lot of criticism for hosting his birthday party just hours after his side lost 4-0 to Atletico, and although Kroos understands it was difficult to cancel the party, he feels the tim- ing wasn't right. was invited to Cristiano Ronaldo's party. | didn't go because I knew what could happen he told German TV station ZDF. It wasn't the moment to have a party after losing 4-0 against Atletico. It's also true that many people had been invited and cancelling it wouldn't have been easy.\" R 7 Oo r T K8",
          "The 25-year-old, who won the World Cup with Germany in Brazil, also insisted that recent media reports of a Real Madrid crisis' were thrown out of proportion. \"We should take a step back and look at the whole picture in the face of what is being said. We have only lost the one game, Kroos added. e Limited Textual Context I think that many teams would love to suffer a crisis like ours. Of course we should be criticised if we play a bad game, as we did that day, without doubt.\" e Performs much worse on Read: Barca In Trouble For Drunk Ronaldo Chants? : . social media data Kroos joined Los Blancos for 30 million last summer and started all but two games for Real, as- sisting 12 goals and scoring one. Do you think Real Madrid will return to their form from before Christmas? Have your say in the comments section below.",
          "Social Media eLanguage Variations",
          "Alison wonderlandxDiploxjuaz B2B ayee",
          "Within word white spaces"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "Utilization of Vision",
        "text": [
          "Karl-Anthony Towns named unanimous intimate surprise set at Shea 2015-2016 NBA Rookie of the Year",
          "Difficult cases based on text only"
        ],
        "page_nums": [
          6
        ],
        "images": [
          "figure/image/1345-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Task Definition",
        "text": [
          "Multimedia Input: image-sentence pair",
          "Colts Have 4th Best QB Situation in NFL with Andrew Luck #ColtStrong",
          "[ORG Colts] Have 4th Best QB Situation in [ORG",
          "NFL] with [PER Andrew Luck] #ColtStrong",
          "Output: tagging results on sentence"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "6": {
        "title": "Our work",
        "text": [
          "State-of-the-art for news articles (",
          "Visual attention model (Bahdanau et al.,",
          "Extract visual features from image regions that are most related to accompanying sentence",
          "Modulation Gate before CRFs",
          "Combine word representation with visual features based on their relatedness"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Model",
        "text": [],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Overall Framework",
        "text": [
          "Multimodal Input : B-PER |-PER I- t I-PER",
          "Florence and the Machine ~ text",
          "surprises ill teen with _ LSTM",
          "private concert Hl 4 CRE",
          "/ a dk -p/ /isual - > L od Modulation",
          "f } G j m\\ \\ Gate | Gate \\ Gate ate / Gate",
          "ceo I Forward Attention Model ! LSTM I",
          "Gee fF Aw we = = = LI 114 Ss word SQ embedding ; ie char e representations \\ Florence and the Machine",
          "_ Visual Attention Model :"
        ],
        "page_nums": [
          11
        ],
        "images": [
          "figure/image/1345-Figure2-1.png",
          "figure/image/1345-Figure3-1.png"
        ]
      },
      "9": {
        "title": "Sequence LabelingBLSTM CRE Lample et al 2016",
        "text": [
          "and a re the input, memory and hidden state at time t respectively. and are weight matrices. is the element-wise product functions and is the element-wise sigmoid function"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Attention Model for Text Related Visual Features Localization",
        "text": [
          "V= CNN(I) Outputs from convolutional layer",
          "Ss Florence and the Machine fe surprises ill teen with private concert QU",
          "e,= W pa; + by Attention",
          "I Input image C= S a,V; Context Vector"
        ],
        "page_nums": [
          13
        ],
        "images": [
          "figure/image/1345-Figure3-1.png"
        ]
      },
      "11": {
        "title": "Modulation Gate",
        "text": [
          "UV C visual context",
          "() Multiplication word _",
          "* representations ( a ) activation function",
          "f_ ; / \\ (tanh } activation function { tanh } (tanh)",
          "visual gate visual context word representations",
          "By o(Wyh; + Uyve + by) Uc Visual context",
          "Bw = o(Wwh; + UO wve + by) h; Word representation",
          "Wm bw . h; + By -M Wm, _ Visually tuned word representation"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Dataset",
        "text": [
          "Topics: Sports, concerts and other social events",
          "Named Entity Types: Person, Organization, Location and MISC",
          "Size of the dataset in numbers of sentences and tokens"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Results",
        "text": [
          "Precision Recall F1 Precision Recall F1",
          "Gate controlled visual attention"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "15": {
        "title": "Attention Visualization",
        "text": [
          "(a). [PER Kiay Thompson} [ORG (b). [PER Radiohead] offers old and (c). [MISC Cannes} just became the",
          "Warriors} overwhelm [ORG new at first concert in four years. [PER Blake Lively] show",
          "(d). #iPhoneAtt0: How [PER Steve (e). [PER Florence and the Machine] (f). [ORG Warriorette) Basketball Jobs} and [ORG Apple] changed surprises ill teen with private concert Campers ready tor Day 2 modern society",
          "(g). ts defending champ [PER Sandeul] (h). Shirts at the ready for our (i). ARMY put up a huge ad in [LOC able to win for the third time on (MISC hometown game today #[{ORG Times Square] for [PER BTS} 4th Duet Song Festival)'? Leicester] #pgautomotive 4[(ORG anniversary! premierteague]"
        ],
        "page_nums": [
          18
        ],
        "images": [
          "figure/image/1345-Figure5-1.png",
          "figure/image/1345-Figure3-1.png"
        ]
      },
      "16": {
        "title": "Error analysis",
        "text": [
          "Nice sine of [PER Kevin Love] and [PER Kyle Very drunk in a #magnum concert Looking forward to editing some SBU baseball",
          "Korver] during 1st half #NBAFinals #Cavsin9 # shots from Saturday. [LOC Cleveland]",
          "Poor Alignment between Image and Blur Images Wrong Visual Attention Sentence"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1345-Figure6-1.png"
        ]
      },
      "17": {
        "title": "Future Work",
        "text": [],
        "page_nums": [
          20
        ],
        "images": []
      }
    },
    "paper_title": "Visual Attention Model for Name Tagging in Multimodal Social Media"
  },
  "1346": {
    "slides": {
      "0": {
        "title": "Situation Overview",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "I Situation: deployed system (e.g. QA, MT ...)",
          "I Goal: improve system using human feedback",
          "I Plan: create a log Dlog of user-system interactions",
          "& improve system offline (safety)",
          "Here: Improve a Neural Semantic Parser"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Contrast to Previous Approaches",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "parses Database A nswers",
          "Parser R ewards r1, ..., rs Comparison",
          "required data question x gold answer"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Our Approach",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "parse y Database answer a",
          "train (x, y, r) Parser",
          "required data question x gold answer required data question x",
          "y1, parses ..., ys answer a Database A nswers",
          "Parser Rewards Parser log train",
          "r1, ..., rs C omparison User Feedback",
          "I No supervision: given an input, the gold output is unknown",
          "I Bandit: feedback is given for only one system output",
          "I Bias: log D is biased to the decisions of the deployed system",
          "Solution: Counterfactual / Off-policy Reinforcement Learning"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": [
          "figure/image/1346-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Task",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "4": {
        "title": "A natural language interface to OpenStreetMap",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "I OpenStreetMap (OSM): geographical database",
          "I NLmaps v2: extension of the previous corpus, now totalling",
          "I example question: How many hotels are there in Paris?",
          "I correctness of answers are difficult to judge",
          "judge parses by making them human-understandable",
          "I feedback collection setup:",
          "automatically convert a parse to a set of statements humans judge the statements"
        ],
        "page_nums": [
          6,
          7
        ],
        "images": []
      },
      "5": {
        "title": "Example Feedback Formula",
        "text": [
          "Introduction Task Objectives Experiments Conclusion"
        ],
        "page_nums": [
          8
        ],
        "images": [
          "figure/image/1346-Figure2-1.png"
        ]
      },
      "6": {
        "title": "Objectives",
        "text": [],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Counterfactual Learning",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "collected log Dlog {(xt yt , t)}nt=1 with",
          "I xt : input",
          "I yt : most likely output of deployed system",
          "I t 0]: loss (i.e. negative reward) received from user",
          "Deterministic Propensity Matching (DPM)",
          "I minimize the expected risk for a target policy w",
          "I improve w using (stochastic) gradient descent",
          "I high variance use multiplicative control variate"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "8": {
        "title": "Multiplicative Control Variate",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "I for random variables X and Y , with Y the expectation of Y",
          "RHS has lower variance if Y positively correlates with X",
          "DPM with Reweighting (DPM+R)",
          "I reduces variance but introduces a bias of order O( 1n ) that",
          "decreases as n increases n should be as large as possible",
          "I Problem: in stochastic minibatch learning, n is too small"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "9": {
        "title": "One Step Late OSL Reweighting",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "Perform gradient descent updates & reweighting asynchronously",
          "I evaluate reweight sum R on the entire log of size n using",
          "I update using minibatches of size m, m",
          "I periodically update R",
          "retains all desirable properties n"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "10": {
        "title": "Token Level Feedback",
        "text": [
          "Introduction Task Objectives Experiments Conclusion"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "11": {
        "title": "Experiments",
        "text": [],
        "page_nums": [
          14
        ],
        "images": []
      },
      "12": {
        "title": "Experimental Setup",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "I sequence-to-sequence neural network Nematus",
          "I deployed system: pre-trained on 2k question-parse pairs",
          "humans judged 1k system outputs",
          "I average time to judge a parse: 16.4s",
          "simulated feedback for 23k system outputs",
          "I token-wise comparison to gold parse",
          "I bandit-to-supervised conversion (B2S): all instances in log",
          "with reward 1 are used as supervised training"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "13": {
        "title": "Experimental Results",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "Human Feedback (1k) Large-Scale Simulated Feedback (23k)"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "14": {
        "title": "Take Away",
        "text": [
          "Introduction Task Objectives Experiments Conclusion",
          "I safely improve a system by collecting interaction logs",
          "I applicable to any task if the underlying model is differentiable",
          "I DPM+OSL: new objective for stochastic minibatch learning",
          "Improving a Semantic Parser",
          "I collect feedback by making parses human-understandable",
          "I judging a parse is often easier & faster than formulating a",
          "I large question-parse corpus for QA in the geographical domain",
          "I integrate feedback form in the online NL interface to OSM"
        ],
        "page_nums": [
          17
        ],
        "images": []
      }
    },
    "paper_title": "Improving a Neural Semantic Parser by Counterfactual Learning from Human Bandit Feedback"
  },
  "1349": {
    "slides": {
      "0": {
        "title": "Noun Compounds",
        "text": [
          "Two or more nouns function as a unit to create a new concept",
          "hot dog, hot dog bun, hot dog bun package. . .",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "We focus on two-word compounds",
          "Express implicit relationship between the constituent nouns:",
          "apple cake: cake made of apples birthday cake: cake eaten on a birthday",
          "They are like text compression devices [Nakov, 2013]",
          "Were pretty good at decompressing them!"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "images": []
      },
      "1": {
        "title": "We are good at Interpreting Noun Compounds",
        "text": [
          "We easily interpret noun-compounds",
          "Even when we see them for the first time",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "What is a parsley cake?",
          "cake eaten on a parsley?"
        ],
        "page_nums": [
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "2": {
        "title": "Generalizing Existing Knowledge",
        "text": [
          "What can cake be made of?",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Parsley (sort of) fits into this distribution",
          "Similar to selectional preferences [Pantel et al., 2007]"
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "3": {
        "title": "We need Computers to Interpret Noun Compounds",
        "text": [],
        "page_nums": [
          15
        ],
        "images": []
      },
      "4": {
        "title": "Noun Compound Interpretation Tasks",
        "text": [
          "Compositionality Prediction is spelling bee related to bee?",
          "Relation Classification apple cake ingredient birthday cake time",
          "Paraphrasing cake made of apples cake eaten on a birthday",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "5": {
        "title": "Noun Compound Paraphrasing",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "6": {
        "title": "Motivation",
        "text": [
          "Given a noun-compound w1w2, express the relation between the head w2 and the modifier w1 with multiple prepositional and verbal paraphrases [Nakov and Hearst, 2006]",
          "olive oil [w2] extracted from [w1]",
          "ground attack [w2] from [w1]",
          "boat whistle [w2] located in [w1]",
          "baby oil Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "7": {
        "title": "Evaluation Setting",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "A ranking rather than a retrieval task",
          "Systems get a list of noun compounds",
          "Extract paraphrases from free text",
          "Evaluated for correlation with human judgments",
          "Gold paraphrase score: how many annotators suggested it?"
        ],
        "page_nums": [
          22,
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "8": {
        "title": "Prior Methods 1 2",
        "text": [
          "Based on constituent co-occurrences: cake made of apple",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Many unseen compounds, no paraphrases in the corpus",
          "rare: parsley cake or highly lexicalized: ice cream",
          "Many compounds with just a few paraphrases",
          "Can we infer cake containing apple given cake made of apple?",
          "Prior work provides partial solutions to either (1) or (2)"
        ],
        "page_nums": [
          27,
          28,
          29,
          30
        ],
        "images": []
      },
      "9": {
        "title": "Prior Methods 2 2",
        "text": [
          "Represent NC by applying a function to its constituent distributional vectors: vec(apple cake) = f (vec(apple), vec(cake))",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Predict paraphrase templates given NC vector",
          "Generalizes for similar unseen NCs, e.g. pear tart",
          "Learn is-a relations between paraphrases:",
          "Our solution: multi-task learning to address both problems"
        ],
        "page_nums": [
          31,
          32,
          33,
          34,
          35
        ],
        "images": []
      },
      "10": {
        "title": "Model",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          36
        ],
        "images": []
      },
      "11": {
        "title": "Multi task Reformulation",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Predict a paraphrase p for a given NC w1w2:",
          "What is the relation between apple and cake?",
          "Predict w1 given a paraphrase p and w2:",
          "What can cake be made of?",
          "What can be made of apple?"
        ],
        "page_nums": [
          37,
          38,
          39,
          40
        ],
        "images": []
      },
      "12": {
        "title": "Main Task 1 Predicting Paraphrases",
        "text": [
          "What is the relation between apple and cake?",
          "Encode placeholder [p] in cake [p] apple using biLSTM",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Predict an index in the paraphrase vocabulary",
          "Fixed word embeddings, learned placeholder embeddings",
          "(1) Generalizes NCs: pear tart expected to yield similar results"
        ],
        "page_nums": [
          41,
          42,
          43,
          44
        ],
        "images": []
      },
      "13": {
        "title": "Helper Task 2 Predicting Missing Constituents",
        "text": [
          "What can cake be made of?",
          "Encode placeholder in cake made of [w1] using biLSTM",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Predict an index in the word vocabulary",
          "[w2] containing [w1] expected to yield similar results"
        ],
        "page_nums": [
          45,
          46,
          47
        ],
        "images": []
      },
      "14": {
        "title": "Training Data",
        "text": [
          "Collected from Google N-grams",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Templates of POS tags (e.g. [w2] verb prep [w1])",
          "Weighting by frequency and length"
        ],
        "page_nums": [
          48,
          49,
          50,
          51
        ],
        "images": []
      },
      "15": {
        "title": "Evaluation",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          52
        ],
        "images": []
      },
      "16": {
        "title": "Ranking Model",
        "text": [
          "Predict top k paraphrases for each noun compound",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Learn to re-rank the paraphrases",
          "to better correlate with human judgments",
          "SVM pair-wise ranking with the following features:",
          "POS tags in the paraphrase",
          "Prepositions in the paraphrase",
          "Similarity to predicted paraphrase"
        ],
        "page_nums": [
          53,
          54,
          55
        ],
        "images": []
      },
      "17": {
        "title": "Results",
        "text": [
          "conservative models rewards only precision rewards recall and precision",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018"
        ],
        "page_nums": [
          56,
          57,
          58,
          59
        ],
        "images": []
      },
      "18": {
        "title": "Error Analysis False Positive",
        "text": [
          "Valid, missing from gold-standard",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "(life of women in community)",
          "E.g., n-grams dont respect syntactic structure: rinse away the oil from baby s head oil from baby",
          "(force of coalition forces)"
        ],
        "page_nums": [
          60,
          61,
          62,
          63,
          64,
          65,
          66
        ],
        "images": []
      },
      "19": {
        "title": "Error Analysis False Negative",
        "text": [
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "(mutation of a gene)"
        ],
        "page_nums": [
          67,
          68,
          69,
          70
        ],
        "images": []
      },
      "20": {
        "title": "Recap",
        "text": [
          "A model for generating paraphrases for given noun-compounds",
          "Vered Shwartz and Ido Dagan Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations ACL 2018",
          "Generalize for unseen noun-compounds",
          "Embed semantically-similar paraphrases in proximity",
          "Improved performance in challenging evaluation settings"
        ],
        "page_nums": [
          71,
          72,
          73,
          74
        ],
        "images": []
      }
    },
    "paper_title": "Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations"
  },
  "1350": {
    "slides": {
      "0": {
        "title": "Motivation",
        "text": [
          "Online adaptation is a key feature of modern computer-aided translation (CAT)",
          "Source #1: Der Terrier beit die Frau",
          "Hypothesis #1: The dog bites the lady",
          "The terrier bites the woman",
          "Source #2: Der Mann beit den Terrier",
          "The dog bites the man",
          "The man bites the terrier",
          "Translators have a reasonable expectation that . . .",
          "New vocabulary (in context) gets quickly picked up by the system, ideally right away",
          "The system generally adapts to new domains",
          "With neural machine translation fine-tuning can readily be used [Turchi et al.,"
        ],
        "page_nums": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "1": {
        "title": "Approach",
        "text": [
          "f ine-tuning is evaluated in a batch setting",
          "Corpus BLEU or isolated sentence-wise metrics are often used",
          "These do not necessarily express how fast a system adapts",
          "As we will show this is not good enough",
          "We seek to measure perceived, immediate adaptation performance",
          "Calculate recall on the set of all words that are not stopwords, ignoring",
          "1In each of the data sets considered in this work, the average number of occurrences of content",
          "words ranges between 1.01 and 1.11 per sentence",
          "Since the task is online adaptation - specifically focus on few-shot learning:",
          "Consider only first and second occurrences of words!"
        ],
        "page_nums": [
          11,
          12,
          13,
          14
        ],
        "images": []
      },
      "2": {
        "title": "One Shot Recall R1",
        "text": [
          "After seeing a word exactly once before in a reference/confirmed translation, is it correctly produced the second time around?",
          "Hi Content words in the hypothesis i th example",
          "R1,i Content inthe reference words for whose",
          "i th example second occurrence is"
        ],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "3": {
        "title": "One Shot Recall R1 Example",
        "text": [
          "Source #1: Der Terrier beit die Frau",
          "Hypothesis #1: The dog bites the lady",
          "The terrier bites the woman",
          "Source #2: Der Mann beit den Terrier",
          "The man bites1 the terrier1"
        ],
        "page_nums": [
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
        ],
        "images": []
      },
      "4": {
        "title": "Zero Shot Recall R0",
        "text": [
          "Not having seen a word before, is it still correctly produced? Is the system adapting",
          "to the domain at hand?",
          "Hi Content words in the hypothesis for i th example",
          "R0,i Content thereference words for",
          "i th that example occur for the first time in"
        ],
        "page_nums": [
          26,
          27
        ],
        "images": []
      },
      "5": {
        "title": "Zero and One Shot Recall R01",
        "text": [
          "Hi Content words in the hypothesis for i th example",
          "R0,i R1,i secondtime Content in the words reference that occur for",
          "i for th the example first or"
        ],
        "page_nums": [
          28
        ],
        "images": []
      },
      "6": {
        "title": "Corpus Level Metric",
        "text": [
          "G: Corpus of |G| source, reference/confirmed seg-"
        ],
        "page_nums": [
          29
        ],
        "images": []
      },
      "7": {
        "title": "Complete Example",
        "text": [
          "Der Terrier beit die Frau",
          "The dog bites the lady",
          "The terrier0 bites0 the woman0",
          "Source #2: Der Mann beit den Terrier",
          "The terrier bites the man",
          "The man0 bites1 the terrier1"
        ],
        "page_nums": [
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
        ],
        "images": []
      },
      "8": {
        "title": "Evaluation Adaptation Methods",
        "text": [
          "The task is online adaptation to the Autodesk data set [Zhechev, 2012]. The background model is an English-to-German Transformer, trained on about 100M segments.",
          "Four methods for comparison: bias Add an additional bias to the output projection [Michel and Neubig, 2018] full Fine-tuning of all weights top Adapt top encoder/decoder layers only lasso Dynamic selection of adapted tensors with group lasso regularization [Wuebker"
        ],
        "page_nums": [
          42,
          43
        ],
        "images": []
      },
      "9": {
        "title": "Results",
        "text": [
          "Relative differences for adaptive systems, positive results highlighted with green color.",
          "System Metric BLEU TER R1 R0 R0+1",
          "bias full top lasso"
        ],
        "page_nums": [
          44
        ],
        "images": []
      },
      "10": {
        "title": "Results Novel Content Words",
        "text": [
          "Results when calculating the metrics only for truly novel content words, i.e. ones that do not occur in the training data.",
          "System Metric R1 R0 R0+1"
        ],
        "page_nums": [
          45
        ],
        "images": []
      },
      "11": {
        "title": "Conclusion",
        "text": [
          "Immediate adaptation performance is important for adaptive MT in CAT",
          "We proposed three metrics for measuring immediate and possibly perceived adaptation performance",
          "R1 for one-shot recall, quantifying pick up of new vocabulary",
          "R0 for zero-shot recall, quantifying general domain adaptation performance",
          "The combined metric R0+1",
          "These metrics give a different signal than the MT metrics that are traditionally used",
          "Zero-shot recall R0 suffers from unregularized adaptation!",
          "Careful regularization can mitigate this effect, while retaining most of the one-shot recall R1"
        ],
        "page_nums": [
          46,
          47
        ],
        "images": []
      },
      "12": {
        "title": "Bibliography I",
        "text": [
          "N. Bertoldi, P. Simianer, M. Cettolo, K. Waschle, M. Federico, and S. Riezler. Online adaptation to post-edits for phrase-based statistical machine translation. Machine",
          "S. S. R. Kothur, R. Knowles, and P. Koehn. Document-level adaptation for neural machine translation. In Proceedings of the 2nd Workshop on Neural Machine",
          "P. Michel and G. Neubig. Extreme adaptation for personalized neural machine",
          "K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311318. Association for",
          "A. Peris, L. Cebrian, and F. Casacuberta. Online learning for neural machine"
        ],
        "page_nums": [
          48
        ],
        "images": []
      },
      "13": {
        "title": "Bibliography II",
        "text": [
          "M. Turchi, M. Negri, M. A. Farajian, and M. Federico. Continuous learning from human post-edits for neural machine translation. The Prague Bulletin of",
          "J. Wuebker, P. Simianer, and J. DeNero. Compact personalized models for neural machine translation. In Proceedings of the 2018 Conference on Empirical",
          "Methods in Natural Language Processing, 2018.",
          "V. Zhechev. Machine translation infrastructure and post-editing performance at autodesk. In AMTA 2012 workshop on post-editing technology and practice"
        ],
        "page_nums": [
          49
        ],
        "images": []
      },
      "14": {
        "title": "Results Subwords",
        "text": [
          "Results when calculating the metrics with subwords.",
          "System Metric R1 R0 R0+1"
        ],
        "page_nums": [
          50
        ],
        "images": [
          "figure/image/1350-Table4-1.png"
        ]
      },
      "15": {
        "title": "Complete Results Table",
        "text": [],
        "page_nums": [
          51
        ],
        "images": []
      }
    },
    "paper_title": "Measuring Immediate Adaptation Performance for Neural Machine Translation"
  },
  "1351": {
    "slides": {
      "0": {
        "title": "Why document level machine translation",
        "text": [
          "Most MT models translate sentences independently",
          "Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency",
          "Statistical MT attempts to document MT do not yield significant empirical improvements",
          "Previous context-NMT models only use local context and report deteriorated performance when using the target-side context",
          "We incorporate global source and target document contexts"
        ],
        "page_nums": [
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "images": []
      },
      "1": {
        "title": "Document MT as Structured Prediction",
        "text": [
          "a S Beh Omi (0",
          "2 Use JL 2 grey",
          "wo Sy Ln Sy al 0",
          "Pan ne Neural N",
          "a S Sehg Oe",
          "- Use DLs 2 rgd og J (x",
          "iw Slag od (|",
          "a Us Jl 2 prgdeg ( x2",
          "cep ty ny ad",
          "a S Sah oi (",
          "eat Saag ay al (8 x3",
          "Two types of factors: f(yt xt xt), g(yt yt)",
          "PM neo CCM Le ia",
          "arg max P(yt |xt yt xt)",
          "where f and g are subsumed in the P(yt |xt yt xt)",
          "Challenge: During test time, the target document is not given",
          "Coordinate Ascent (i.e., Iterative Decoding)"
        ],
        "page_nums": [
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
        ],
        "images": [
          "figure/image/1351-Figure1-1.png"
        ]
      },
      "2": {
        "title": "Document NMT with MemNets",
        "text": [
          "P(yt |xt yt xt)",
          "Preven CC Ee Ester",
          "pectic an imum ea cs",
          "gimonda fulfils the objectives of the lisbon strategy",
          "ttt tt tot ft",
          "SF RRR OR RPP",
          "tT Ff fF FF",
          "gimonda taidab lissaboni strateegia eesmarke",
          "yt,j softmax(Wy rt,j Wym csrct Wyt ctrg t by",
          "Use only source, target, or both external memories",
          "Use Memory-to-Context/Memory-to-Output architectures for incorporating the different contexts"
        ],
        "page_nums": [
          37,
          38,
          39,
          40,
          41,
          42,
          43
        ],
        "images": []
      },
      "3": {
        "title": "Experimental Setup",
        "text": [
          "corpus #docs (H) #sents (K) avg doc len",
          "Evaluation Metrics: BLEU, METEOR",
          "Local source context baselines:"
        ],
        "page_nums": [
          45,
          46,
          47,
          48
        ],
        "images": []
      },
      "4": {
        "title": "Memory to Context Results",
        "text": [
          "PM neo CCM Le ia periments and Analysis",
          "S-NMT S-NMT+src S-NMT+trg S-NMT+both"
        ],
        "page_nums": [
          49,
          50,
          51,
          52,
          53
        ],
        "images": []
      },
      "5": {
        "title": "Memory to Output Results",
        "text": [
          "Preven CC Ee Ester",
          "S-NMT S-NMT+src S-NMT+trg S-NMT+both"
        ],
        "page_nums": [
          54,
          55,
          56,
          57,
          58
        ],
        "images": []
      },
      "6": {
        "title": "Main Results",
        "text": [],
        "page_nums": [
          59,
          60,
          61,
          62
        ],
        "images": []
      },
      "7": {
        "title": "Example translation",
        "text": [
          "Target qimonda taidab lissaboni strateegia eesmarke. qimonda meets the objectives of the lisbon strategy.",
          "<UNK> is the objectives of the lisbon strategy.",
          "the millennium development goals are fulfilling the millennium goals of the lisbon strategy. in writing. - (ro) the lisbon strategy is fulfilling the objectives of the lisbon strategy. qimonda fulfils the aims of the lisbon strategy.",
          "[Wang et al., 2017] <UNK> fulfils the objectives of the lisbon strategy."
        ],
        "page_nums": [
          63,
          64,
          65,
          66
        ],
        "images": []
      },
      "8": {
        "title": "Example translation contd",
        "text": [
          "... et riigis kehtib endiselt lukasenka diktatuur, mis rikub inim- ning etnilise vahemuse oigusi.",
          "... this country is still under the dictatorship of lukashenko, breaching human rights and the rights of ethnic minorities.",
          "... the country still remains in a position of lukashenko to violate human rights and ethnic minorities.",
          "... the country still applies to the brutal dictatorship of human and ethnic minority rights.",
          "... the country still keeps the <UNK> dictatorship that violates human rights and ethnic rights.",
          "... the country still persists in lukashenkos dictatorship that violate human rights and ethnic minority rights. [Wang et al., 2017] ... there is still a regime in the country that is violating the rights of human and ethnic minority in the country."
        ],
        "page_nums": [
          67,
          68,
          69
        ],
        "images": []
      },
      "9": {
        "title": "Conclusion",
        "text": [
          "Proposed a model which incorporates the global source and target document contexts",
          "Proposed effective training and decoding methodologies for our model",
          "Investigate document-context NMT models which incorporate specific discourse-level phenomena"
        ],
        "page_nums": [
          71,
          72,
          73,
          74,
          75
        ],
        "images": []
      }
    },
    "paper_title": "Document Context Neural Machine Translation with Memory Networks"
  },
  "1352": {
    "slides": {
      "0": {
        "title": "Textual Media",
        "text": [
          "People spend 12 hours everyday consuming media in 2018."
        ],
        "page_nums": [
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "Text Summarization",
        "text": [
          "To condense a piece of text to a shorter version while maintaining the important points"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "2": {
        "title": "Examples of Text Summarization",
        "text": [
          "Bulletins (weather forecasts/stock market reports)"
        ],
        "page_nums": [
          8,
          9,
          10,
          11,
          12
        ],
        "images": []
      },
      "3": {
        "title": "Automatic Text Summarization",
        "text": [
          "To condense a piece of text to a shorter version while maintaining the important points",
          "Extractive Summarization Abstractive Summarization",
          "select text from the article generate the summary word-by-word"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "4": {
        "title": "Extractive Summarization",
        "text": [
          "Select phrases or sentences from the source document"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "5": {
        "title": "Abstractive Summarization",
        "text": [
          "Select phrases or sentences from the source document",
          "Alexander M Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization. EMNLP 2015. Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Caglar Gulcehre, and Bing Xiang. Abstractive text summarization using sequence- tosequence rnns and beyond. CoNLL 2016. Abigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointergenerator networks. ACL 2017. Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. ICLR 2018. Fan, Angela, David Grangier, and Michael Auli. Controllable abstractive summarization. arXiv preprint arXiv:1711.05217 (2017)."
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "6": {
        "title": "Motivation",
        "text": [
          "(select sentences): Italian artist Johannes Stoetter has painted two naked women",
          "to look like a chameleon.",
          "important, correct incoherent or not concise The 37-year-old has previously transformed his models into",
          "frogs and parrots but this may be his most intricate and impressive artwork to date. Abstractive summary",
          "readable, concise may lose or mistake some facts",
          "important, correct readable, concise",
          "Johannes Stoetter has previously transformed his models into frogs and parrots but this chameleon may be his most impressive artwork to date.",
          "Justin Bieber Johannes Stoetter has previously transformed his models into",
          "Unified summary: frogs and parrots but this chameleon may be his most impressive artwork to date."
        ],
        "page_nums": [
          16,
          17,
          18,
          19
        ],
        "images": []
      },
      "7": {
        "title": "Models",
        "text": [
          "Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. AAAI 2017 Abigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointer-generator networks. ACL 2017"
        ],
        "page_nums": [
          21,
          22,
          23,
          24
        ],
        "images": []
      },
      "8": {
        "title": "Combined Attention",
        "text": [
          ": word index : sentence index : generated word index",
          "Cindy is lucky. She won $1000. She is going to",
          "Our unified model combines sentence-level and word-level attentions to take advantage of both extractive and abstractive summarization approaches.",
          "Updated word attention is used for calculating the context vector and final word distribution"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30
        ],
        "images": [
          "figure/image/1352-Figure2-1.png",
          "figure/image/1352-Figure4-1.png"
        ]
      },
      "9": {
        "title": "Encourage Consistency",
        "text": [
          "We propose a novel inconsistency loss function to ensure our unified model to be mutually beneficial to both extractive and abstractive summarization.",
          "multiplied attention of top K attended words",
          "encourage consistency of the top K attended words at each decoder time step.",
          "inconsistency loss: consistent < inconsistent",
          "Sentence 1 Sentence 2 Sentence 3"
        ],
        "page_nums": [
          31,
          32
        ],
        "images": []
      },
      "10": {
        "title": "Training Procedures",
        "text": [
          "Extractive Summarization Abstractive Summarization",
          "select sentences from the article generate the summary word-by-word",
          "3 types of loss functions:",
          "Abigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointer-generator networks. ACL 2017",
          "2. End-to-end training without inconsistency loss",
          "The extractor is used as a classifier to select sentences with high informativity and output only those sentences. = Hard attention on the original article.",
          "simply combine the extractor and abstracter by feeding the extracted sentences to the abstracter.",
          "extracted article Extractor Abstracter summary sentences",
          "the sentence-level attention is soft attention and will be combined with the word-level attention",
          "minimize extractor loss, abstracter loss and inconsistency loss:"
        ],
        "page_nums": [
          34,
          35,
          36,
          37,
          38,
          41,
          42,
          43,
          44,
          45,
          46
        ],
        "images": [
          "figure/image/1352-Figure5-1.png"
        ]
      },
      "11": {
        "title": "Training Procedures Extractor Target",
        "text": [
          "To extract sentences with high informativity:",
          "the extracted sentences should contain information that is needed to generate an abstractive summary as much as possible.",
          "1. Measure the informativity of each sentence in the article by computing the",
          "ROUGE-L recall score bet ween the sentence and the reference abstractive summary.",
          "2. Select the sentence in the order of high to low informativity and add one sentence at a time if the new sentence can increase the informativity of all the selected sentences.",
          "Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. AAAI 2017"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "12": {
        "title": "Training Procedures Combined Attention",
        "text": [
          ": word index : sentence index : generated word index"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "13": {
        "title": "Dataset CNN DailyMail Dataset",
        "text": [
          "Article Highlight 700 words 50 words"
        ],
        "page_nums": [
          48,
          49
        ],
        "images": []
      },
      "14": {
        "title": "Results Abstractive Summarization",
        "text": [],
        "page_nums": [
          50,
          51,
          52
        ],
        "images": [
          "figure/image/1352-Table2-1.png",
          "figure/image/1352-Table3-1.png"
        ]
      },
      "15": {
        "title": "Results Inconsistency Rate Rinc",
        "text": [
          "inconsistency step inconsistency rate:",
          "sentence attention and word attention in time step"
        ],
        "page_nums": [
          53,
          54,
          55,
          56
        ],
        "images": [
          "figure/image/1352-Table4-1.png"
        ]
      },
      "16": {
        "title": "Results Human Evaluation on MTurk",
        "text": [
          "how well does the summary capture the important parts of the article?",
          "is the summary clear enough to explain everything without being redundant?",
          "how well-written (fluent and grammatical) the summary is?"
        ],
        "page_nums": [
          57
        ],
        "images": []
      },
      "17": {
        "title": "Results Human Evaluation",
        "text": [
          "Informativity: how well does the summary capture the important parts of the article?",
          "Conciseness: is the summary clear enough to explain everything without being redundant?",
          "Readability: how well-written (fluent and grammatical) the summary is?"
        ],
        "page_nums": [
          58
        ],
        "images": [
          "figure/image/1352-Table3-1.png"
        ]
      },
      "18": {
        "title": "Conclusion and Future work",
        "text": [
          "We propose a unified model combining the strength of extractive and abstractive summarization.",
          "A novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions. The inconsistency loss enables extractive and abstractive summarization to be mutually beneficial.",
          "By end-to-end training of our model, we achieve the best ROUGE scores while being the most informative and readable summarization on the CNN/Daily Mail dataset in a solid human evaluation."
        ],
        "page_nums": [
          60
        ],
        "images": []
      }
    },
    "paper_title": "A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss"
  },
  "1353": {
    "slides": {
      "0": {
        "title": "What are Fake News",
        "text": [
          "Disinformation displayed as news articles",
          "Image: Claire Wardle, First Draft"
        ],
        "page_nums": [
          3,
          4,
          5
        ],
        "images": []
      },
      "1": {
        "title": "The Political Spectrum",
        "text": [
          "The left-right political spectrum is a system of classifying political positions, ideologies and parties. Left-wing politics and right-wing politics are often presented as opposed, although either may adopt stances from the other side. [Wikipedia]",
          "Alt-left Left Center Right Alt-right",
          "Hyperpartisan Partisan Partisan Hyperpartisan",
          "Partisan: someone with a psychological identification with one major party. [Wikipedia]",
          "News media reporting on politics can be aligned on this spectrum as well.",
          "We are observing an increasing number of hyperpartisan news publishers."
        ],
        "page_nums": [
          7,
          8,
          9,
          10
        ],
        "images": []
      },
      "2": {
        "title": "Fake News and Hyperpartisan News",
        "text": [
          "How can it be that the alt left and the alt right cannot be distinguished from the mainstream, when both together (hyperpartisan news) can be?",
          "Alt-left Left Center Right Alt-right",
          "Hyperpartisan Partisan Partisan Hyperpartisan",
          "The horseshoe theory asserts that the alt left and the alt right, rather than being at opposite and opposing ends of a linear political continuum, in fact closely resemble one another, much like the ends of a horseshoe. [Wikipedia] @KieselJohannes"
        ],
        "page_nums": [
          11,
          20,
          21,
          22
        ],
        "images": []
      },
      "3": {
        "title": "Why are Fake News Published by Hyperpartisan Pages",
        "text": [
          "Image: Claire Wardle, First Draft"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": [
          "figure/image/1353-Table2-1.png"
        ]
      },
      "4": {
        "title": "Fake News Detection Taxonomy of Approaches",
        "text": [
          "Requires political knowledge base",
          "q Unavailable ahead of time",
          "q We cannot trust the web",
          "Knowledge-based (also called fact checking)",
          "Semantic web / LOD",
          "q Limited to social media platforms",
          "q Part of damage already done",
          "q Allows for pre-posting check",
          "q Real-time reaction possible",
          "q Hard to mask",
          "q But are style differences sufficient?"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1353-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Fake News and Hyperpartisan News Corpus Construction",
        "text": [
          "true mix false n/a",
          "Annotations provided by journalists at BuzzFeed @KieselJohannes"
        ],
        "page_nums": [
          15,
          16
        ],
        "images": []
      },
      "6": {
        "title": "Fake News and Hyperpartisan News Selected Results",
        "text": [
          "true mix false n/a",
          "Politico Fake News Detection",
          "Annotations provided by journalists at BuzzFeed @KieselJohannes",
          "Occupy De mocrats Recall Recall"
        ],
        "page_nums": [
          17,
          18,
          19
        ],
        "images": [
          "figure/image/1353-Table2-1.png"
        ]
      },
      "7": {
        "title": "Horseshoe Validation Experiment I Leave out Classification",
        "text": [
          "q Classifier is trained to distinguish left-wing and center articles",
          "q Right-wing articles are used for testing",
          "q Majority of right-wing articles are classified as left-wing rather than center"
        ],
        "page_nums": [
          23,
          24,
          25,
          26
        ],
        "images": []
      },
      "8": {
        "title": "Horseshoe Validation Experiment II Unmasking Koppel Schler 2004",
        "text": [
          "A B a a a a a b b b b b",
          "Typical learning characteristic for . . .",
          "different authors (A B)",
          "Decision: \"same\" same author (A B)",
          "The typical learning characteristic can be learned. U Meta Learning",
          "We apply Unmasking to distinguish style genres.",
          "Nomralized accuracy 0.4 0.2 mainstream vs left mainstream vs right left vs right"
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
        ],
        "images": [
          "figure/image/1353-Figure2-1.png",
          "figure/image/1353-Figure3-1.png"
        ]
      },
      "9": {
        "title": "Summary and Outlook",
        "text": [
          "Hyperpartisan news pages produce relatively many fake news articles",
          "q Hyperpartisan news can be distinguished quiet well based on style",
          "q Style-based detection allows for real-time detection",
          "U Political extremism in news can be ousted or at least flagged",
          "q The style of alt left and alt right news is very similar",
          "q Linguistic evidence for the horseshoe theory of the political spectrum?",
          "U Large-scale analysis required"
        ],
        "page_nums": [
          39
        ],
        "images": []
      },
      "10": {
        "title": "Style Model",
        "text": [
          "n-grams with n of characters, stop words, parts-of-speech",
          "q 10 readability scores",
          "q Dictionary features based on General Inquirer",
          "q Ratios of quoted words, external links, number of paragraphs, and their",
          "q Discard word features (n-gram features) occurring in less than 2.5% (10%) of",
          "q Balancing using oversampling",
          "q Publishers are not represented in both training and test set",
          "q WEKAs random forest with default parameters @KieselJohannes"
        ],
        "page_nums": [
          42
        ],
        "images": []
      }
    },
    "paper_title": "A Stylometric Inquiry into Hyperpartisan and Fake News"
  },
  "1354": {
    "slides": {
      "0": {
        "title": "Debates and Arguments",
        "text": [],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "Argumentation is crucial in communication.",
          "We want to avoid biased perception and uninformed decisions.",
          "Being informative is already non-trivial, not to mention being persuasive."
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "2": {
        "title": "Research Question",
        "text": [
          "How can we automate human argumentation process?"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "3": {
        "title": "Our Goal",
        "text": [
          "We generate a specific type of argument: counterargument.",
          "Input: a statement of belief on some controversial topic",
          "Output: a counterargument refuting the statement",
          "Input: Humans are not designed to be vegan.",
          "Output: We are not designed to be anything, evolution is directionless.",
          "You imply unnatural is bad, that is wrong. Driving and using smartphone are also unnatural.",
          "1. Understanding the topic and stance",
          "2. Application of common sense knowledge",
          "3. Generating arguments in natural language texts"
        ],
        "page_nums": [
          9,
          10,
          11,
          12,
          13
        ],
        "images": []
      },
      "4": {
        "title": "Prior Work",
        "text": [
          "Evidence detection [Rinott et al, 2015]",
          "Classification of types of supports [Hua and Wang, 2017]",
          "Argument and Evidence Retrieval",
          "Argument search engine [Wachsmuth et al, 2017; Stab et al, 2018]",
          "Retrieval based argument generation [Sato et al, 2015]",
          "Argument strategy based generation [Zukerman et al, 2000]"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "5": {
        "title": "Data",
        "text": [
          "A subreddit for open discussion and debate",
          "I believe the government should be allowed to view my emails for national security concerns. CMV.",
          "I have nothing to hide. I dont break the law, I dont write hate e-mails",
          "[U1] Seriously, whether or not is a good thing, it runs up against the protections offered in the Fourth Amendment: [--quote--]",
          "[U2] Giving up privacy means giving up some of your right to free speech.",
          "Knowing that you might be listened in on may change what you say and how you say it",
          "I saved this answer for a Reddit Gold. It did change my opinion - I never thought that",
          "We selected the politics and policy related topics for study.",
          "We only consider high quality replies (with delta or more upvotes).",
          "Statistics as below after removing non-root and low quality replies.",
          "Input statement Human argument",
          "Avg number of sentences",
          "Avg number of tokens"
        ],
        "page_nums": [
          18,
          19,
          20,
          21,
          22,
          23
        ],
        "images": []
      },
      "6": {
        "title": "Pipeline",
        "text": [
          "<phz> right to privacy<phz>",
          "I believe the <evd> edward snowden",
          "<arg> you are ignoring the",
          "Input statement Evidence sentences",
          "I believe the government should be allowed to view my emails for national security concerns. CMV.",
          "1. Edward Snowden: Arguing that you dont care about right to privacy because.",
          "I have nothing to hide. I dont break the law",
          "2. Political corruption is the use of powers by government officials for illegitimate private gain.",
          "5. Argument Decoding (LSTM)"
        ],
        "page_nums": [
          25,
          26,
          27,
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "7": {
        "title": "Step 1 Document Retrieval",
        "text": [
          "Goal: to extract relevant evidence for counterarguments",
          "Formed from topic signatures [Lin and Hovy, 2000]",
          "Representative of the text, measured by log-likelihood ratio",
          "E.g. government, emails, national security, etc in the following post",
          "I believe the government should be allowed to view my emails for national security concerns. CMV.",
          "I have nothing to hide. I dont break the law"
        ],
        "page_nums": [
          32,
          33
        ],
        "images": []
      },
      "8": {
        "title": "Step 2 Sentence Reranking",
        "text": [
          "Returned articles are broken into paragraphs and sentences.",
          "Sentences are ranked by TF-IDF similarity against the post.",
          "1. Edward Snowden: Arguing that you dont care about right to privacy because.",
          "2. Political corruption is the use of powers by government officials for illegitimate private gain."
        ],
        "page_nums": [
          34
        ],
        "images": []
      },
      "9": {
        "title": "Step 3 Encoding",
        "text": [
          "Encode input statement and evidence sentences, separated by <evd> token",
          "I believe the <evd> edward snowden",
          "Input statement Evidence sentences"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "10": {
        "title": "Step 4 Keyphrase Decoding",
        "text": [
          "Generate keyphrase as an intermediate step",
          "Aim to inform the model of the major talking points",
          "Mimic keyphrases that are likely reused by human",
          "I believe the <evd> edward snowden <phz> right to privacy<phz>",
          "We extract noun phrases and verb phrases.",
          "The length has to be between 2 to 10 tokens.",
          "Phrase has to contain non-stop words.",
          "Numerous civil rights groups and privacy groups oppose surveillance as a violation of people's right to privacy."
        ],
        "page_nums": [
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "11": {
        "title": "Step 5 Argument Decoding",
        "text": [
          "Generate argument based on encoder or keyphrase last hidden state",
          "Attention mechanism over both input and keyphrase results",
          "<phz> right to privacy<phz>",
          "I believe the <evd> edward snowden",
          "<arg> you are ignoring the"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "12": {
        "title": "Experiments",
        "text": [
          "Initialize first layers of encoders and argument decoders",
          "Warm up the system with a good argumentation language model",
          "All training data + non-politics threads + non-root replies",
          "Sequence-to-sequence without evidence sentences or keyphrases",
          "System vs. Oracle retrieval",
          "In reality, during test time evidence can only be obtained by input statement.",
          "In Oracle setup, we retrieve evidence base on human arguments queries.",
          "System Retrieval Oracle Retrieval",
          "Input statement: I believe the government Human argument: Giving up privacy means should be allowed to view my emails giving up some of your right to free speech."
        ],
        "page_nums": [
          42,
          52,
          53
        ],
        "images": []
      },
      "13": {
        "title": "Experiments Models",
        "text": [
          "RETRIEVAL-BASED: concatenate evidence sentences",
          "SEQ2SEQ: encode the input statement only",
          "SEQ2SEQ encode evidence: encode statement and evidence sentences",
          "SEQ2SEQ encode keyphrase: encode statement and keyphrases",
          "Stronger baseline, because keyphrases are actually reused by human arguments.",
          "DEC-SHARED: Argument decoder initialized by keyphrase decoder",
          "<phz> right to privacy<phz>",
          "I believe the <evd> edward snowden",
          "<arg> you are ignoring the Attention",
          "DEC-SEPARATE attend keyphrase: with attention on keyphrase decoder",
          "Attention <arg> you are ignoring the",
          "DEC-SEPARATE: Argument decoder initialized by encoder"
        ],
        "page_nums": [
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51
        ],
        "images": []
      },
      "14": {
        "title": "Automatic Evaluation Generation Quality",
        "text": [
          "BLEU: n-gram precision based measure",
          "METEOR: unigram precision and recall based on alignment",
          "Gold-standard: user generated arguments",
          "Multi-reference setup: best aligned one -> multiple plausible arguments exist",
          "* BLEU/METEOR: The higher the better",
          "Our models have better precision.",
          "The generated content are more likely to be found in human arguments.",
          "Retrieval baseline generation has better METEOR, which considers both precision and recall.",
          "w/System Retrieval w/ Oracle Retrieval",
          "BLEU-2 METEOR Length BLEU-2 METEOR Length"
        ],
        "page_nums": [
          55,
          56,
          57,
          58,
          59,
          60
        ],
        "images": []
      },
      "15": {
        "title": "Automatic Evaluation Topic Relevance",
        "text": [
          "Motivation: Generic arguments can still have high BLEU scores.",
          "E.g. I dont agree with you., You are missing evidence., This is wrong.",
          "Semantic similarity model [Huang et al, 2013]",
          "Represents the semantic relatedness of two pieces of text",
          "Model tuned on training set",
          "Evaluated by mean reciprocal ranking (MRR) and Precision at 1 (P@1)",
          "* The higher the better"
        ],
        "page_nums": [
          61,
          62,
          63,
          64,
          65
        ],
        "images": []
      },
      "16": {
        "title": "Human Evaluation",
        "text": [
          "Motivation: Automatic evaluation cant really evaluate the overall coherence and informativeness of the generation.",
          "3 trained judges that are fluent in English",
          "3 systems: RETRIEVAL-BASED, SEQ2SEQ, OUR MODEL",
          "Aspects (each on a scale of 1 to 5, the higher the better)",
          "Grammaticality: if the output is fluent and grammatical English",
          "Informativeness: whether the output is informative or generic",
          "Relevance: it the output is on-topic and of correct stance",
          "1 (low quality) 5 (high quality)",
          "checked speed limit criminal lanes taxi to the Food security is not an issue of how much food we produce.",
          "Informativeness I dont agree with you.",
          "Israeli are under a much more persistent and realistic security threat.",
          "(Topic: racial profiling) Gun control deters crime.",
          "Minority groups who endure everyday discrimination often suffer high rates of chronic diseases.",
          "System Grammaticality Informativeness Relevance",
          "- Human judges favor RETRIEVAL-BASED model in all aspects.",
          "- RETRIEVAL-BASED is human-written and relevant.",
          "- OUR MODEL is favored over SEQ2SEQ except Grammaticality."
        ],
        "page_nums": [
          66,
          67,
          68,
          69
        ],
        "images": []
      },
      "17": {
        "title": "Sample Argument",
        "text": [
          "Original Post Generated Counterargument",
          "Putin is trying to re-form a Soviet",
          "Union with his past actions in Georgia and current actions in Ukraine.",
          "I firmly believe that Putin and the",
          "Russian Federation (RF) are trying to re-form a Soviet Union type regime",
          "The Russian Army invaded certain regions of Georgia",
          "There are two reasons you are so far beyond. There is no reason to see the military army. You can infer what they assume it, so they tend to protect up.",
          "There. If we assume it were bad, they can not be controlled. So were talking going to ignore the wars of the world.",
          "The fact of the matter is not bad. I would also assume it. However, the government can not be reminded of the world."
        ],
        "page_nums": [
          70,
          71
        ],
        "images": []
      },
      "18": {
        "title": "Future Directions",
        "text": [
          "Better evidence retrieval system",
          "Prone to incoherence, inaccurate information, generic generation etc"
        ],
        "page_nums": [
          73
        ],
        "images": []
      },
      "19": {
        "title": "Conclusion",
        "text": [
          "We study a novel neural argument generation task.",
          "We collect and release a new dataset from r/ChangeMyView and accompanying Wikipedia evidence for argument generation research.",
          "We propose an end-to-end argument generation system, enhanced with Wikipedia retrieved evidence sentences."
        ],
        "page_nums": [
          74,
          76
        ],
        "images": []
      }
    },
    "paper_title": "Neural Argument Generation Augmented with Externally Retrieved Evidence"
  },
  "1355": {
    "slides": {
      "0": {
        "title": "Knowledge Graphs KG",
        "text": [
          "Football Team Lionel Messi"
        ],
        "page_nums": [
          1,
          2,
          3,
          4,
          5,
          6
        ],
        "images": []
      },
      "1": {
        "title": "KG Embeddings",
        "text": [
          "Represents entities and relations as vectors in a vector space",
          "1. Translating Embeddings for Modeling Multi-relational Data, Bordes et al. NIPS 2013."
        ],
        "page_nums": [
          7,
          8
        ],
        "images": []
      },
      "2": {
        "title": "Geometry of Embeddings",
        "text": [
          "Arrangement of vectors in the vector space.",
          "A recent work by (Mimno and Thompson, 2017)1 presented an analysis of the geometry of word embeddings and revealed interesting results.",
          "However, geometrical understanding of KG embeddings is very limited, despite their popularity.",
          "1. The strange geometry of skip-gram with negative sampling, Mimno and Thompson, EMNLP 2017"
        ],
        "page_nums": [
          9,
          10,
          22
        ],
        "images": [
          "figure/image/1355-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Problem",
        "text": [
          "Study the geometrical behavior of KG embeddings learnt by different methods.",
          "Study the effect of various hyper-parameters used during training on the geometry of KG embeddings.",
          "Study the correlation between the geometry and performance of KG embeddings."
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "4": {
        "title": "KG Embedding Methods",
        "text": [
          "Learns d-dimensional vectors for entities and relations in a KG.",
          "A score function distinguishes correct triples from incorrect triples",
          "(Messi, plays-for-team, Barcelona) > (Messi, plays-for-team, Liverpool)",
          "A loss function is used for training the embeddings (usually logistic loss or margin-based ranking loss).",
          "Entry-wise product Circular correlation"
        ],
        "page_nums": [
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "images": [
          "figure/image/1355-Table1-1.png"
        ]
      },
      "5": {
        "title": "Geometrical Metrics",
        "text": [],
        "page_nums": [
          18,
          19,
          20,
          21
        ],
        "images": []
      },
      "6": {
        "title": "Experiments",
        "text": [
          "We study the effect of following factors on the geometry of KG",
          "Type of method (Additive or Multiplicative)",
          "Number of Negative Samples",
          "Dimension of Vector Space",
          "We also study the correlation of performance and geometry."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "7": {
        "title": "Additive vs Multiplicative Entity Vectors",
        "text": [],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1355-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Additive vs Multiplicative Relation Vectors",
        "text": [],
        "page_nums": [
          25
        ],
        "images": [
          "figure/image/1355-Figure3-1.png"
        ]
      },
      "9": {
        "title": "Additive vs Multiplicative",
        "text": [
          "Model Type Conicity Vector Spread"
        ],
        "page_nums": [
          26
        ],
        "images": []
      },
      "10": {
        "title": "Effect of Negative Samples Entity Vectors",
        "text": [
          "Model Type Vector Type Conicity AVL",
          "Entity No Change No Change",
          "Relation No Change No Change",
          "Multiplicative Relation Decreases No Change except HolE"
        ],
        "page_nums": [
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34
        ],
        "images": []
      },
      "11": {
        "title": "SGNS Word2Vec1 as Multiplicative Model",
        "text": [
          "Similar observation was made by (Mimno and Thompson, 2017)2 for",
          "SGNS based word embeddings where higher #negatives resulted in higher conicity.",
          "Word2Vec1 maximizes word and context vector dot product for positive word-context pairs.",
          "This behavior is consistent with that of multiplicative models.",
          "1. Distributed representations of words and phrases and their compositionality, Mikolov et al. NIPS 2013 2. The strange geometry of skip-gram with negative sampling, Mimno and Thompson, EMNLP 2017"
        ],
        "page_nums": [
          35
        ],
        "images": []
      },
      "12": {
        "title": "Effect of Dimensions Entity Vectors",
        "text": [],
        "page_nums": [
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "13": {
        "title": "Effect of Dimensions",
        "text": [
          "Model Type Vector Type Conicity AVL",
          "Entity No Change No Change",
          "Relation No Change No Change"
        ],
        "page_nums": [
          40
        ],
        "images": []
      },
      "14": {
        "title": "Correlation b w Geometry and Performance",
        "text": [
          "No correlation between geometry and performance.",
          "For fixed number of negative samples,",
          "Conicity has negative correlation with performance",
          "AVL has positive correlation with performance"
        ],
        "page_nums": [
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
        ],
        "images": []
      },
      "15": {
        "title": "Conclusion and Future Works",
        "text": [
          "We initiated the study of geometrical behavior of KG embeddings and presented various insights.",
          "Explore whether other entity/relation features (eg entity category) have any correlation with geometry.",
          "Explore other geometrical metrics which have better correlation with performance and use it for learning better KG embeddings."
        ],
        "page_nums": [
          51
        ],
        "images": []
      }
    },
    "paper_title": "Towards Understanding the Geometry of Knowledge Graph Embeddings"
  },
  "1356": {
    "slides": {
      "0": {
        "title": "Intuition",
        "text": [
          "When humans perform Reading Comprehension, we answer all the given questions consistently.",
          "But, when we test Machine Comprehension, most computational settings consider each question or each choice in isolation.",
          "When were the eggs added to the pan to make the omelette?",
          "When they turned on the stove",
          "When the pan was the right temperature J",
          "Why did they use stove to cook omelette?",
          "They didnt use the stove but a microwave",
          "Because they needed to heat up the pan J"
        ],
        "page_nums": [
          1,
          2
        ],
        "images": []
      },
      "1": {
        "title": "Intuition contd",
        "text": [
          "Similarly, in settings where multiple choices could be correct, we could use the relationships between choices.",
          "How can the military benefit from the existence of the CIA?",
          "They can use them as they wish",
          "The agency is keenly attentive to the militarys strategic and tactical requirements J",
          "The CIA knows what intelligence the military requires and has the resources to obtain that intelligence J",
          "c3 entails c2 flip c2 from wrong to correct.",
          "Source: MultiRC dataset ([Khashabi et al. 2018])"
        ],
        "page_nums": [
          3,
          4
        ],
        "images": []
      },
      "2": {
        "title": "Abstract",
        "text": [
          "We propose a method to leverage entailment and contradiction relations between the answer choices to improve machine comprehension.",
          "We first perform Question Answering (QA) and weakly-supervised Natural Language Inference (NLI) relation detection separately. Then, we use the NLI relations to re-evaluate the answers.",
          "We also propose a multitask learning model that learns both the tasks jointly."
        ],
        "page_nums": [
          5,
          6,
          7
        ],
        "images": []
      },
      "3": {
        "title": "Approach",
        "text": [],
        "page_nums": [
          8,
          9,
          10
        ],
        "images": []
      },
      "4": {
        "title": "Stand alone QA System",
        "text": [
          "We use the TriAN-single model proposed by",
          "Figure: TriAN model architecture (figure adopted from [Wang et al. 2018])"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "5": {
        "title": "NLI System",
        "text": [
          "Our NLI system was inspired from decomposable-attention model proposed by [Parikh et al. 2016]",
          "Issue: Choices are often short phrases. NLI relations among them exist only in the context of the given question.",
          "What do human children learn by playing games and sports?",
          "Learn about the world J",
          "Resolution: We modified the architecture proposed in",
          "[Parikh et al. 2016] to accommodate the question-choice pairs as opposed to sentence pairs in the original model."
        ],
        "page_nums": [
          12,
          13,
          14
        ],
        "images": []
      },
      "6": {
        "title": "Inference",
        "text": [
          "We enforce consistency between the QA answers and the NLI relations at inference time.",
          "The answers and the relations are scored by the confidence scores from the QA and the NLI systems.",
          "We used the following rules to enforce consistency:",
          "ci is true & ci entails cj cj is true. ci is true & ci contradicts cj cj is false.",
          "We used Deep Relational Learning (DRaiL) framework proposed by [Zhang et al. 2016] for inference"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": []
      },
      "7": {
        "title": "Self Training",
        "text": [
          "We devised a self-training protocol to adopt the NLI system to the Machine Comprehension datasets (weak-supervision)",
          "If the SNLI-trained NLI model predicted entailment with a confidence above a threshold and the gold labels of the ordered choice pair were true-true, the relation was labeled entailment, and similarly we generate data for"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "8": {
        "title": "Joint Model",
        "text": [
          "The design of our joint model is motivated by the two objec- tives:",
          "To leverage the benefit of multitask learning",
          "To obtain a better representation for the question-choice pair for"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "9": {
        "title": "MultiRC Results",
        "text": [
          "Table: Summary of results on MultiRC dataset. EM0 is the percentage of",
          "questions for which all the choices are correct. EM1 is the the percentage of questions for which at most one choice is wrong."
        ],
        "page_nums": [
          22
        ],
        "images": [
          "figure/image/1356-Table2-1.png"
        ]
      },
      "10": {
        "title": "SemEval 2018 Results",
        "text": [
          "Table: Accuracy of various models on SemEval18 task-11 dataset"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "11": {
        "title": "Error Analysis",
        "text": [
          "Identification of NLI relations is far from perfect.",
          "NLI system returns entailment when there is a high lexical overlap",
          "NLI system returns contradiction upon the presence of a strong negation word such as not."
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "12": {
        "title": "Summary",
        "text": [
          "We proposed a framework to use entailment and contradiction relations to improve Machine Comprehension",
          "Self-training results suggest the presence of other subtle relationships among choices.",
          "I went shopping this extended weekend",
          "I ate a lot of junk food recently",
          "Text: I snack when I shop"
        ],
        "page_nums": [
          25,
          26,
          27,
          28
        ],
        "images": []
      }
    },
    "paper_title": "Using Natural Language Relations between Answer Choices for Machine Comprehension"
  },
  "1358": {
    "slides": {
      "0": {
        "title": "Natural Language Generation task spectrum",
        "text": [
          "Less open-ended More open-ended",
          "Neural LMs more successful Neural LMs less successful",
          "Makes errors like repetition and generic response (under certain decoding algorithms).",
          "Neural LMs less successful",
          "Difficulty learning to make high-level decisions.",
          "Control = ability to specify desired attributes of the text at test time.",
          "Control is less important Control is more important",
          "We can use control to fix errors, and allow us to handle some high-level decisions.",
          "Mostly word-level decisions Requires high-level decisions",
          "Control is less important No automatic metric for overall quality. Control is more important",
          "Eval is difficult Eval is fiendish",
          "Dialogue is even more complex:",
          "Single-turn or multi-turn eval?",
          "Interactive or static conversation?"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Our research questions",
        "text": [
          "By controlling multiple attributes of generated text and human-evaluating multiple aspects of conversational quality, we aim to answer the following:",
          "1. How effectively can we control the different attributes?",
          "Pretty well! But some control methods only work for some attributes.",
          "2. How do the controllable attributes affect conversational quality aspects?",
          "Strongly especially controlling repetition, question-asking, and specificity vs genericness.",
          "3. Can we use control to make a better chatbot overall?",
          "Yes! But we should be careful defining \"better overall\"."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "PersonaChat task",
        "text": [
          "I love to drink fancy tea.",
          "I have a big library at home.",
          "I'm a museum tour guide.",
          "I have two dogs.",
          "I like to work on vintage cars.",
          "My favorite music is country.",
          "I own two vintage Mustangs.",
          "Hello, how are you doing?",
          "Great thanks, just listening to my favorite Johnny Cash album!",
          "Nice! I'm not much of a music fan myself, but I do love to read.",
          "Me too! I just read a book about the history of the auto industry.",
          "Most successful teams built neural sequence generation systems. (Dinan et al 2019)",
          "The winning team, Lost in Conversation, used a finetuned version of GPT.",
          "Our baseline model is a standard LSTM-based seq2seq architecture with attention.",
          "It is pretrained on 2.5 million Twitter message/response pairs, then finetuned on PersonaChat."
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "3": {
        "title": "What attributes do we control",
        "text": [
          "Goal: Reduce repetition (within and across utterances)",
          "Goal: Reduce genericness of responses (e.g. oh that's cool)",
          "Goal: Respond more on-topic; don't ignore user",
          "Goal: Find the optimal rate of question-asking"
        ],
        "page_nums": [
          7
        ],
        "images": [
          "figure/image/1358-Figure1-1.png"
        ]
      },
      "4": {
        "title": "What quality aspects do we measure",
        "text": [
          "Does the bot repeat itself?",
          "Did you find the bot interesting to talk to?",
          "Does the bot say things that don't make sense?",
          "Does the bot use English naturally?",
          "Does the bot pay attention to what you say?",
          "Does the bot ask a good amount of questions?",
          "Is it a person or a bot?",
          "Is it enjoyable to talk to?"
        ],
        "page_nums": [
          8,
          9
        ],
        "images": [
          "figure/image/1358-Figure1-1.png"
        ]
      },
      "5": {
        "title": "Control methods",
        "text": [
          "Conditional Training (CT): Train the model to generate response y, conditioned on the input x, and the desired output attribute z.",
          "Weighted Decoding (WD): During decoding, increase/decrease the probability of generating words w in proportion to features f(w)."
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Q1 How effectively can we control attributes",
        "text": [
          "Attributes: repetition, specificity, question-asking, response-relatedness",
          "Conditional Training (CT): Weighted Decoding (WD):",
          "Requires sufficient training examples for the attribute",
          "Requires attribute to be defined at the word-level",
          "Ineffective at learning complex relationships between input and output ( response-relatedness)",
          "Effective for: repetition, response-relatedness, specificity"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "7": {
        "title": "Controlling specificity WD and CT",
        "text": [
          "WD: Large range, but degenerate output at the extremes",
          "CT: Smaller range, but generally well- formed output"
        ],
        "page_nums": [
          12,
          13
        ],
        "images": [
          "figure/image/1358-Table1-1.png"
        ]
      },
      "8": {
        "title": "Controlling response relatedness WD",
        "text": [
          "Output is degenerate when weight is too high"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1358-Table2-1.png"
        ]
      },
      "9": {
        "title": "Q2 How does control affect human eval",
        "text": [
          "Reduce n-gram repetition to human level",
          "(reduce genericness) to human level",
          "Increase response- relatedness (similarity to last utterance)"
        ],
        "page_nums": [
          15,
          16,
          17,
          18
        ],
        "images": [
          "figure/image/1358-Figure1-1.png"
        ]
      },
      "10": {
        "title": "Q3 Can we make a better chatbot overall",
        "text": [
          "Yes! By controlling repetition, specificity and question-asking, we achieve near-human engagingness (i.e. enjoyability) ratings.",
          "Our raw engagingness score matches the",
          "ConvAI2 competition winner's GPT-based model, even though ours is:",
          "much smaller (2 layers vs 12) trained on 12x less data",
          "However: On the humanness (i.e. Turing test) metric, our models are nowhere near human-level!"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "11": {
        "title": "Engagingness vs Humanness",
        "text": [
          "Finding: Our bots are (almost) as engaging as humans, but they're clearly non-human.",
          "2. On this task, the human \"engagingness\" performance may be artificially low.",
          "Turkers chatting for money are less engaging than people chatting for fun.",
          "This may be why the human-level engagingness scores are easy to match."
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "12": {
        "title": "Conclusions",
        "text": [
          "Control is a good idea for your neural sequence generation dialogue system.",
          "Using simple control, we matched performance of GPT-based contest winner.",
          "Don't repeat yourself. Don't be boring. Ask more questions.",
          "Multi-turn phenomena (repetition, question-asking frequency) are important",
          "so need multi-turn eval to detect them.",
          "Engagingness = Humanness, so think carefully about which to use.",
          "Paid Turkers are not engaging conversationalists, or good judges of engaging conversation. Humans chatting for fun may be better.",
          "Problem: Manually finding the best combination of control settings is painful."
        ],
        "page_nums": [
          22
        ],
        "images": []
      }
    },
    "paper_title": "What makes a good conversation? How controllable attributes affect human judgments"
  },
  "1359": {
    "slides": {
      "0": {
        "title": "Word Embeddings",
        "text": [
          "Dense vectors of words",
          "Unsupervised training: GloVe, Word2Vec",
          "Words in similar context tend to have similar meaning",
          "Words with similar meanings tend to be close in embedding space"
        ],
        "page_nums": [
          1
        ],
        "images": []
      },
      "1": {
        "title": "Training Word Embeddings",
        "text": [
          "This camera is good for high quality"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Different Input Corpora",
        "text": [],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Wikipedia",
        "text": [
          "An article must be written from a neutral point of view, which among other things means representing fairly, proportionately, and, as far as possible, without editorial bias, all of the significant views that have been published by reliable sources on a topic."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "4": {
        "title": "Amazon",
        "text": [],
        "page_nums": [
          5
        ],
        "images": []
      },
      "5": {
        "title": "Subjectivity Scale",
        "text": [
          "More Objective More Subjective"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "6": {
        "title": "Binary Classification Tasks",
        "text": [
          "Sentiment Classification (positive vs. negative):",
          "Amazon Reviews (24 categories) + Rotten Tomatoes Reviews",
          "A very funny movie vs. One lousy movie",
          "Subjectivity Classification (subjective vs. objective)",
          "The story needs more dramatic meat vs. She's an artist",
          "Topic Classification (in-topic vs. out-of-topic)",
          "Newsgroups Dataset (6 categories)"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "7": {
        "title": "Methodology",
        "text": [
          "Cross-validation on balanced samples",
          "Binary logistic regression classifier",
          "Sentence embedding = average of word embeddings",
          "The same number of sentences and the same vocabulary when training embeddings"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "8": {
        "title": "Empirical Findings",
        "text": [
          "SE and OE are very similar on objective tasks",
          "SE understand sentiment words better than OE?",
          "Subjectivity Classification Topic Classification Amazon Sentiment Rotten Tomatoes Sentiment",
          "SentiVec does not affect objective classification tasks",
          "Amazon Sentiment (average over 24 categories) Rotten Tomatoes Sentiment"
        ],
        "page_nums": [
          9,
          16
        ],
        "images": []
      },
      "9": {
        "title": "Top Words Similar to good",
        "text": [
          "Word Similarity Word Similarity"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "10": {
        "title": "Sentiment Words Still Cause Troubles",
        "text": [
          "Word A Word B Their Similarity"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "11": {
        "title": "SentiVec Embeddings",
        "text": [
          "Similar to good Similarity Similar to good Similarity"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "12": {
        "title": "SentiVec Infusing Sentiment",
        "text": [
          "Predicts context words as in",
          "Negative: waste, junk, horrible, defective,",
          "Positive: love, great, recommend, easy,"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "13": {
        "title": "Logistic SentiVec",
        "text": [
          "This camera is good for high quality",
          "good good (good, camera)",
          "good = 1 good",
          "Random Noise (good, frog) (good, duck)"
        ],
        "page_nums": [
          14
        ],
        "images": []
      },
      "14": {
        "title": "Spherical SentiVec",
        "text": [
          "Positive Words Negative Words"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "15": {
        "title": "Changes in Similarity",
        "text": [
          "Target Word: Good Target Word: Bad"
        ],
        "page_nums": [
          17
        ],
        "images": [
          "figure/image/1359-Figure2-1.png"
        ]
      },
      "16": {
        "title": "Conclusion",
        "text": [
          "Explored effects of corpus subjectivity for word embeddings",
          "SentiVec, a method for infusing lexical information into word embeddings",
          "Sentiment-infused SentiVec embeddings space facilitate better sentiment-related similarity",
          "Pre-trained Word Embeddings & Code: https://sentivec.preferred.ai/"
        ],
        "page_nums": [
          18
        ],
        "images": []
      }
    },
    "paper_title": "Searching for the X-Factor: Exploring Corpus Subjectivity for Word Embeddings"
  },
  "1360": {
    "slides": {
      "0": {
        "title": "Current systems",
        "text": [
          "Spanish text ola mi nombre es hodor",
          "English text: hi my name is hodor Machine"
        ],
        "page_nums": [
          1,
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Unwritten languages",
        "text": [
          "Bantu language, Republic of Congo, ~160K speakers",
          "~3000 languages with no writing system",
          "Mboshi text: not available Recognition",
          "paired with French translations (Godard et al. 2018)",
          "Efforts to collect speech and translations using mobile apps"
        ],
        "page_nums": [
          5,
          6
        ],
        "images": []
      },
      "2": {
        "title": "Haiti Earthquake 2010",
        "text": [
          "Survivors sent text messages to helpline",
          "International rescue teams face language barrier",
          "No automated tools available",
          "Volunteers from global Haitian diaspora help create parallel text corpora in short time"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "3": {
        "title": "Are we better prepared in 2019",
        "text": [
          "Moun kwense nan Sakre",
          "People trapped in Sacred"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "4": {
        "title": "Can we build a speech to text translation ST system",
        "text": [
          "given as training data:",
          "Tens of hours of speech paired with text translations",
          "No source text available"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Neural models",
        "text": [
          "Sequence-to-Sequence Weiss et al. (2017)",
          "English text: hi my name is hodor"
        ],
        "page_nums": [
          10
        ],
        "images": []
      },
      "6": {
        "title": "Spanish speech to English text",
        "text": [
          "Encoder telephone speech (unscripted) realistic noise conditions multiple speakers and dialects crowdsourced English text translations",
          "Closer to real-world conditions"
        ],
        "page_nums": [
          11,
          12
        ],
        "images": []
      },
      "7": {
        "title": "But",
        "text": [
          "Poor performance in low-resource settings",
          "# hours of training data (log scale)"
        ],
        "page_nums": [
          13
        ],
        "images": []
      },
      "8": {
        "title": "Why Spanish English",
        "text": [
          "simulate low-resource settings and test our method",
          "Later: results on truly low-resource language ---"
        ],
        "page_nums": [
          20,
          21,
          22
        ],
        "images": []
      },
      "9": {
        "title": "Method",
        "text": [
          "Same model architecture for ASR and ST",
          "Attention *randomly initialized parameters"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "10": {
        "title": "Pretrain on high resource",
        "text": [
          "300 hours of English audio and text",
          "Attention *train until convergence"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "11": {
        "title": "Fine tune on low resource",
        "text": [
          "English audio Spanish audio",
          "transfer from English ASR",
          "English text English text",
          "*train until convergence Attention"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "12": {
        "title": "Will this work",
        "text": [],
        "page_nums": [
          27
        ],
        "images": []
      },
      "13": {
        "title": "Spanish English BLEU scores",
        "text": [],
        "page_nums": [
          28,
          29,
          30,
          31
        ],
        "images": []
      },
      "14": {
        "title": "Further analysis",
        "text": [],
        "page_nums": [
          32
        ],
        "images": []
      },
      "15": {
        "title": "Faster training time",
        "text": [],
        "page_nums": [
          33,
          34
        ],
        "images": []
      },
      "16": {
        "title": "Ablation model parameters",
        "text": [
          "Spanish to English, N = 20 hours",
          "+English ASR: encoder English text English text",
          "+English ASR: decoder Decoder Decoder",
          "transferring encoder only parameters works well!",
          "can pretrain on a language different from both source and target in ST pair"
        ],
        "page_nums": [
          35,
          36,
          37,
          38,
          39
        ],
        "images": []
      },
      "17": {
        "title": "Pretraining on French",
        "text": [
          "Spanish to English, N = 20 hours",
          "+English ASR: encoder Decoder Decoder",
          "+French ASR: encoder French text English text",
          "*only 20 hours of French ASR",
          "French ASR helps Spanish-English ST"
        ],
        "page_nums": [
          40,
          41
        ],
        "images": []
      },
      "18": {
        "title": "Takeaways",
        "text": [
          "Pretraining on a different language helps",
          "transfer all model parameters for best gains",
          "encoder parameters account for most of these",
          "useful when target vocabulary is different"
        ],
        "page_nums": [
          42
        ],
        "images": []
      },
      "19": {
        "title": "Mboshi French ST",
        "text": [
          "ST data by Godard et al. 2018",
          "~4 hours of speech, paired with French translations",
          "Bantu language, Republic of Congo"
        ],
        "page_nums": [
          43,
          44
        ],
        "images": []
      },
      "20": {
        "title": "Mboshi French Results",
        "text": [
          "Mboshi to French, N = 4 hours",
          "*outperformed by a naive baseline"
        ],
        "page_nums": [
          45,
          46
        ],
        "images": []
      },
      "21": {
        "title": "Pretraining on French ASR",
        "text": [
          "Mboshi to French, N = 4 hours",
          "French text French text",
          "French ASR helps Mboshi-French ST"
        ],
        "page_nums": [
          47,
          48,
          49
        ],
        "images": []
      },
      "22": {
        "title": "Pretraining on English ASR",
        "text": [
          "Mboshi to French, N = 4 hours",
          "+English ASR: encoder Decoder Decoder",
          "English text French text",
          "using encoder trained on a lot more data",
          "English ASR helps Mboshi-French ST",
          "baseline Encoder From English ASR",
          "+French ASR: all Attention",
          "+French ASR: remaining French text",
          "combining gives the best gains",
          "BLEU score is still low but above naive baseline"
        ],
        "page_nums": [
          50,
          51,
          57,
          58,
          59
        ],
        "images": []
      },
      "23": {
        "title": "Pretraining on French and English ASR",
        "text": [
          "French text French text English text"
        ],
        "page_nums": [
          54,
          55,
          56
        ],
        "images": []
      },
      "24": {
        "title": "Conclusions",
        "text": [
          "Pretraining on high-resource ASR improves low-resource ST",
          "Potentially useful for endangered and/or unwritten languages",
          "Bootstrap ST in time-critical scenarios",
          "Future work: experiments on more languages, multilingual",
          "training with joint vocabulary"
        ],
        "page_nums": [
          60
        ],
        "images": []
      },
      "25": {
        "title": "Backup",
        "text": [],
        "page_nums": [
          62
        ],
        "images": []
      },
      "26": {
        "title": "Mboshi French naive baseline",
        "text": [],
        "page_nums": [
          63
        ],
        "images": [
          "figure/image/1360-Table5-1.png"
        ]
      },
      "27": {
        "title": "Why does pretraining help",
        "text": [
          "ASR data contains audio from 100s of speakers",
          "Learning to factor out background noise (?)",
          "BLEU Baseline +English ASR"
        ],
        "page_nums": [
          64
        ],
        "images": []
      },
      "28": {
        "title": "Spanish English ST",
        "text": [
          "*results on Fisher test set ...",
          "Spanish to English, N = 20 hours",
          "+En ASR: 20h English text"
        ],
        "page_nums": [
          65,
          66,
          67
        ],
        "images": []
      },
      "29": {
        "title": "Neural model",
        "text": [
          "yo vive en bronx",
          "bi-LSTM 1 LSTM 2",
          "bi-LSTM 2 LSTM 3"
        ],
        "page_nums": [
          68,
          69
        ],
        "images": []
      }
    },
    "paper_title": "Pre-training on High-Resource Speech Recognition Improves Low-Resource Speech-to-Text Translation"
  },
  "1363": {
    "slides": {
      "0": {
        "title": "Semantic Parsing",
        "text": [
          "h h h ?",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          1,
          7,
          10
        ],
        "images": []
      },
      "1": {
        "title": "Training with Full Supervision",
        "text": [
          "y: CapitalOf.argmaEx (XT yPpe .State LocatedIn.US,Population)",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          2
        ],
        "images": []
      },
      "2": {
        "title": "Training with Weak Supervision",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "3": {
        "title": "Problems with Weak Supervision",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions",
          "Spurious programs (Pasupat and Liang, 2016; Guu et al.,"
        ],
        "page_nums": [
          4,
          5
        ],
        "images": []
      },
      "4": {
        "title": "CNLVR Cuhr et al 2017",
        "text": [
          "xz :There is a small yellow item not touching any wall",
          "Introduction Semantic parser Abstract examples > Results Conclusions"
        ],
        "page_nums": [
          6
        ],
        "images": []
      },
      "5": {
        "title": "Insight",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          8
        ],
        "images": []
      },
      "6": {
        "title": "Contributions",
        "text": [
          "Data augmentation Abstract cache",
          "helps search tackles spuriousness",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "7": {
        "title": "Logical Program",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "8": {
        "title": "Model",
        "text": [
          "There is a yellow triangle",
          "Training maximizes log-likelihood of correct programs",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "9": {
        "title": "Abstract Examples",
        "text": [],
        "page_nums": [
          13
        ],
        "images": []
      },
      "10": {
        "title": "Abstraction",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          14,
          16
        ],
        "images": [
          "figure/image/1363-Table3-1.png"
        ]
      },
      "11": {
        "title": "Analysis",
        "text": [
          "One square.. There is.. One of the. There are.. There is.... Two towers..",
          "One tower.. There are. C-Num C-Shape There is. C-Num towers.. Another last There are.. There is.. One circle. There is.. Last one..",
          "~150 abstract sentences cover of CNLVR.",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "12": {
        "title": "Data Augmentation",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "13": {
        "title": "Training Procedure",
        "text": [
          "~6000 Instantiated examples Supervised model",
          "3163 CNLVR training examples Weakly-supervised model",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          18
        ],
        "images": []
      },
      "14": {
        "title": "Abstract Cache",
        "text": [
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          19
        ],
        "images": [
          "figure/image/1363-Figure3-1.png"
        ]
      },
      "15": {
        "title": "Reward Tying",
        "text": [
          "size: 20}, . xz: There is a oi yellow item not touching any wall",
          "50% Spurious amp Y :True",
          "Introduction Semantic parser Abstract examples Results Conclusions 21",
          "a :There is a small yellow item * [Hytoe: . a Black, ty) oA"
        ],
        "page_nums": [
          20,
          21
        ],
        "images": []
      },
      "16": {
        "title": "Results",
        "text": [],
        "page_nums": [
          22
        ],
        "images": []
      },
      "17": {
        "title": "Models",
        "text": [
          "Max Entropy classifier on extracted features",
          "Weakly supervised trained model (+Re-ranker)",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "18": {
        "title": "Results Public test set",
        "text": [
          "Test-P Accuracy Test-P Consistency",
          "Majority MaxEnt Sup. Sup.+Rerank W.Sup. W.Sup.+Rerank",
          "Introduction Semantic parser Abstract examples Results Conclusions"
        ],
        "page_nums": [
          24
        ],
        "images": []
      },
      "19": {
        "title": "Ablations",
        "text": [
          "Abstract weakly supervised parser",
          "Introduction Semantic parser Abstract examples Results Conclusions",
          "Dev Accuracy Dev Consistency",
          "-Abstraction -Data augment. -Beam cache W.Sup.+Rerank"
        ],
        "page_nums": [
          25,
          26
        ],
        "images": []
      },
      "20": {
        "title": "Conclusions",
        "text": [
          "Similar ideas in: Dong and Lapata (2018) and Zhang et al.",
          "Automation would be useful"
        ],
        "page_nums": [
          27,
          28
        ],
        "images": []
      }
    },
    "paper_title": "Weakly Supervised Semantic Parsing with Abstract Examples"
  },
  "1364": {
    "slides": {
      "0": {
        "title": "Introduction",
        "text": [
          "unverified or deliberately false",
          "How the fake news propagated?",
          "people tend to stop spreading a rumor if it",
          "Previous studies focused on text mining from sequential microblog streams, we",
          "denial want to bridge the content semantics and"
        ],
        "page_nums": [
          2,
          3
        ],
        "images": []
      },
      "1": {
        "title": "Motivation",
        "text": [
          "We generally are not good at distinguishing rumors",
          "It is crucial to track and debunk rumors early to minimize their harmful effects.",
          "Online fact-checking services have limited topical coverage and long delay.",
          "Existing models use feature engineering over simplistic; or recently deep neural networks ignore propagation structures; Kernel-based method develop based on tree structure but cannot learn high-level feature representations automatically."
        ],
        "page_nums": [
          4
        ],
        "images": []
      },
      "2": {
        "title": "Observation and Hypothesis",
        "text": [
          "Existing works: Consider post representation or propagation structure",
          "(a) RNN-based model (b) Tree kernel-based model",
          "IDEA: Combining the two models, leveraging propagation structure by representation learning algorithm",
          "Why such model do better?",
          "Polarity stances (a) False rumor (b) True rumor",
          "A reply usually respond to its immediate ancestor rather than the root tweet.",
          "Repliers tend to disagree with (or question) who support a false rumor or deny a true rumor; repliers tend to agree with who deny a false rumor or support a true rumor."
        ],
        "page_nums": [
          5,
          6
        ],
        "images": [
          "figure/image/1364-Figure1-1.png"
        ]
      },
      "3": {
        "title": "Contributions",
        "text": [
          "The first study that deeply integrates both structure and content semantics based on tree-structured recursive neural networks for detecting rumors from microblog posts",
          "Propose two variants of RvNN models based on bottom-up and top-down tree structures, to generate better integrated representations for a claim by capturing both structural and textural properties signaling rumors.",
          "Our experiments based on two real-world Twitter datasets achieve superior improvements over state-of-the-art baselines on both rumor classification and early detection tasks.",
          "We make the source codes in our experiments publicly accessible at https://github.com/majingCUHK/Rumor_RvNN"
        ],
        "page_nums": [
          7
        ],
        "images": []
      },
      "4": {
        "title": "Related Work",
        "text": [
          "Systems based on common sense and investigative journalism,",
          "Learning-based models for rumor detection",
          "Using handcrafted and temporal features: Liu et al. (2015), Ma et al.",
          "Tree-kernel-based model: Without hand-",
          "images segmentation (Socher et al, 2011) phrase representation from word vectors (Socher et al, 2012)",
          "Sentiment analysis (Socher et al, 2013) etc"
        ],
        "page_nums": [
          9
        ],
        "images": []
      },
      "5": {
        "title": "Problem Statement",
        "text": [
          "Given a set of microblog posts R = {}, model each source tweet as a tree structure T = < , >, where each node provide the text content of each post. And is directed edges corresponding to response relation.",
          "Task 1 finer-grained classification for each source post",
          "false rumor, true rumor, non-rumor, unverified rumor",
          "Task 2 detect rumor as early as possible"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "6": {
        "title": "Tweet Structure",
        "text": [
          "Root tweet : #Walmart donates $10,000 to #DarrenWilson bottom-up tree fund to continue police racial profiling",
          "1:30 Idc if they killed a mf foreal. Ima always shop with @Walmart. I'm",
          ": NEED SOURCE. have a feeling this is just hearsay ... just bein honest",
          "I agree. I have been hearing this all day but no source 1:12",
          ": Exactly, i don't think Wal-Mart would let everyone know this if they did!! 2:21",
          "Wal-Mart would let everyone know this if they did!! 2:21 replies",
          "top-down tree : #Walmart donates $10,000 to #DarrenWilson fund to continue police racial profiling"
        ],
        "page_nums": [
          12
        ],
        "images": []
      },
      "7": {
        "title": "Standard Recursive Neural Networks",
        "text": [
          "RvNN (tree-structured neural networks) utilize sentence parse trees: representation associated with each node of a parse tree is computed from its direct children, computed by",
          "p: the feature vector of a parent node whose children are and computation is done recursively over all tree nodes"
        ],
        "page_nums": [
          14
        ],
        "images": [
          "figure/image/1364-Figure2-1.png"
        ]
      },
      "8": {
        "title": "Bottom up RvNN",
        "text": [
          "Input: bottom-up tree (node: a post represented as a vector of words ) GRU equation at node",
          "Structure: recursively visit every node from the leaves at the bottom to the root at the top (a natural extension to the original RvNN",
          "Intuition: local rumor indicative features are aggregated along different branches (e.g., subtrees having a denial parent and a set of supportive children) (generate a feature vector for each subtree)",
          ": #Walmart donates $10,000 to #DarrenWilson fund to continue police racial profiling",
          "1:30 Idc if they killed a mf foreal. Ima always shop with @Walmart. I'm",
          ": NEED SOURCE. have a feeling this is just hearsay ... just bein honest",
          "I agree. I have been hearing this all day but no source 1:12",
          ": Exactly, i don't think Wal-Mart would let everyone know this if they did!! 2:21"
        ],
        "page_nums": [
          15
        ],
        "images": []
      },
      "9": {
        "title": "Top down RvNN",
        "text": [
          "Input: top-down tree GRU transition equation at node",
          "Own input Parent node",
          "Structure: recursively visit from the root node to its children until reaching all leaf nodes. (reverse Bottom-up RvNN)",
          "Intuition: rumor-indicative features are aggregated along the propagation path (e.g., if a post agree with its parents stance, the parents stance should be reinforced) (models how information flows from source post to the current node)",
          ": #Walmart donates $10,000 to #DarrenWilson fund to continue police racial profiling",
          "1:30 Idc if they killed a mf foreal. Ima always shop with @Walmart. I'm",
          ": NEED SOURCE. have a feeling this is just hearsay ... just bein honest",
          "I agree. I have been hearing this all day but no source 1:12",
          ": Exactly, i don't think Wal-Mart would let everyone know this if they did!! 2:21"
        ],
        "page_nums": [
          16
        ],
        "images": []
      },
      "10": {
        "title": "Model Training",
        "text": [
          "Comparison: both of the two RvNN models aim to capture the structural properties by recursively visiting all nodes",
          "Bottom-up RvNN: the state of root node (i.e., source tweet) can be regard as the representation of the whole tree (can be used for supervised classification).",
          "Top-down RvNN: the representation of each path are eventually embedded into the hidden vector of all the leaf nodes. learned vector of root node",
          "Bottom-up RvNN: = K",
          "Top-down RvNN: = L",
          "the pooling vector over all leaf nodes",
          "Objective Function: T US; R OS; O QO =",
          "Training Procedure parameters are updated using efficient back-propagation through structure (Goller and Kuchler, 1996; Socher et al., 2013)"
        ],
        "page_nums": [
          17
        ],
        "images": []
      },
      "11": {
        "title": "Data Collection",
        "text": [
          "Use two reference Tree datasets:",
          "URL of the datasets: https://www.dropbox.com/s/0jhsfwep3ywvpca/rumdetect2017.zip?dl=0"
        ],
        "page_nums": [
          19
        ],
        "images": []
      },
      "12": {
        "title": "Approaches to compare with",
        "text": [
          "DTR: Decision tree-based ranking model using enquiry phrases to identify trending rumors (Zhao et al., 2015)",
          "DTC: Twitter information credibility model using Decision",
          "RFC: Random Forest Classifier using three parameters to fit the temporal tweets volume curve (Kwon et al., 2013)",
          "SVM-TS: Linear SVM classifier using time-series structures to model the variation of social context features. (Ma et al., 2015)",
          "SVM-BOW: linear SVM classifier using bag-of-words.",
          "SVM-TK and SVM-HK: SVM classifier uses a Tree Kernel",
          "(Ma et al., 2017) and that uses a Hybrid Kernel (Wu et al.,",
          "2015), both model propagation structures with kernels.",
          "GRU-RNN: The RNN-based rumor detection model. (Ma et",
          "Ours (BU-RvNN and TD-RvNN): Our bottom-up and top- down recursive models."
        ],
        "page_nums": [
          20
        ],
        "images": []
      },
      "13": {
        "title": "Results on Twitter15",
        "text": [
          "NR: Non-Rumor; FR: False Rumor;",
          "TR: True Rumor; UR: Unverified Rumor;",
          "user info NR vs others)"
        ],
        "page_nums": [
          21
        ],
        "images": []
      },
      "14": {
        "title": "Results on Twitter16",
        "text": [
          "NR: Non-Rumor; FR: False Rumor;",
          "TR: True Rumor; UR: Unverified Rumor;",
          "GRU-RNN models without hand-crafted features"
        ],
        "page_nums": [
          22
        ],
        "images": []
      },
      "15": {
        "title": "Results on Early Detection",
        "text": [
          "In the first few hours, the accuracy of the RvNN- based methods climbs more rapidly and stabilize more quickly",
          "RvNN only need around",
          "8 hours or about 90 tweets to achieve the comparable performance of the best baseline model."
        ],
        "page_nums": [
          23
        ],
        "images": []
      },
      "16": {
        "title": "Early Detection Example",
        "text": [
          "Example subtree of a rumor captured by the algorithm at early stage of propagation",
          "Bottom-up RvNN: a set of responses supporting the parent posts that deny or question the source post.",
          "Top-down RvNN: some patterns of propagation from the root to leaf nodes like supportdenysupport Baselines: sequential models may be confused because the supportive key terms such as be right, yeah, exactly! dominate the responses, and the SVM-TK may miss similar subtrees by just comparing the surface words."
        ],
        "page_nums": [
          24
        ],
        "images": [
          "figure/image/1364-Figure5-1.png"
        ]
      },
      "17": {
        "title": "Conclusion and future work",
        "text": [
          "Propose a bottom-up and a top-down tree-structured model based on recursive neural networks for rumor detection on Twitter.",
          "Using propagation tree to guide the learning of representations from tweets content, such as embedding various indicative signals hidden in the structure, for better identifying rumors.",
          "Results on two public Twitter datasets show that our method improves rumor detection performance in very large margins as compared to state-of-the-art baselines.",
          "Integrate other types of information such as user properties into the structured neural models to further enhance representation learning",
          "Develop unsupervised models due to massive unlabeled data from social media."
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Rumor Detection on Twitter with Tree-structured Recursive Neural Networks"
  },
  "1365": {
    "slides": {
      "0": {
        "title": "Relation Extraction",
        "text": [
          "Plain Text Corpus Entity-Relation Triple Classifier",
          "(Unstructured Info) (Structured Info)"
        ],
        "page_nums": [
          3
        ],
        "images": []
      },
      "1": {
        "title": "Distant Supervision",
        "text": [
          "If two entities participate in a relation, any sentence that contains those two entities might express that",
          "Nijlen is a municipality located in the Belgian province of Antwerp.",
          "Neural relation extraction with selective attention over instances."
        ],
        "page_nums": [
          4,
          5,
          22,
          23,
          24
        ],
        "images": []
      },
      "2": {
        "title": "Wrong Labeling",
        "text": [
          "Place_of_Death (William ODwyer, New York city)",
          "i. Some New York city mayors William ODwyer, Vincent R. Impellitteri and Abraham Beame were born abroad.",
          "Entity-Pair Level ii. Plenty of local officials have, too, including two New York city mayors,",
          "Most of entity pairs only have several sentences"
        ],
        "page_nums": [
          6,
          7,
          8
        ],
        "images": []
      },
      "3": {
        "title": "Requirements",
        "text": [
          "General Purpose and Offline Process",
          "Learn a Policy to Denoise the Training Data"
        ],
        "page_nums": [
          11
        ],
        "images": []
      },
      "4": {
        "title": "Deep Reinforcement Learning",
        "text": [
          "The average vector of previous removed sentences",
          "One relation type has an agent",
          "Positive: Distantly-supervised positive sentences",
          "Negative: Sampled from other relations",
          "Split into training set and validation set",
          "RL Agent da taset Train",
          "RL Agent C leane d Train Relation Classifier d ataset"
        ],
        "page_nums": [
          13,
          14,
          15
        ],
        "images": [
          "figure/image/1365-Figure2-1.png"
        ]
      },
      "5": {
        "title": "Reward",
        "text": [
          "Positive Set Negative Set"
        ],
        "page_nums": [
          16,
          17
        ],
        "images": []
      },
      "6": {
        "title": "Evaluation on a Synthetic Noise Dataset",
        "text": [
          "False Positive: Other relation types",
          "True Positive + False Positive: samples",
          "False Positive Removed Part Epoch"
        ],
        "page_nums": [
          19,
          20
        ],
        "images": []
      },
      "7": {
        "title": "Evaluation on Synthetic Noise Dataset",
        "text": [],
        "page_nums": [
          21
        ],
        "images": []
      },
      "8": {
        "title": "Conclusion",
        "text": [
          "We propose a deep reinforcement learning method",
          "for robust distant supervision relation extraction.",
          "Our method is model-agnostic.",
          "Our method boost the performance of recently proposed neural relation extractors."
        ],
        "page_nums": [
          26
        ],
        "images": []
      }
    },
    "paper_title": "Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning"
  }
}
